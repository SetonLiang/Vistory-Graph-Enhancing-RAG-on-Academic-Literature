[{"Name": "Collaboration with conversational AI assistants for UX evaluation: Questions and how to ask them (voice vs. text)", "Authors": ["Emily Kuang", "Ehsan Jahangirzadeh Soure", "Mingming Fan", "Jian Zhao", "Kristen Shinohara"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " AI is promising in assisting UX evaluators with analyzing usability tests, but its judgments are typically presented as non-interactive visualizations. Evaluators may have questions about test recordings, but have no way of asking them. Interactive conversational assistants provide a Q&A dynamic that may improve analysis efficiency and evaluator autonomy. To understand the full range of analysis-related questions, we conducted a Wizard-of-Oz design probe study with 20 participants who interacted with simulated AI assistants via text or voice. We found that participants asked for five categories of information: user actions, user mental model, help from the AI assistant, product and task information, and user demographics. Those who used the text assistant asked more questions, but the question lengths were similar. The text assistant was perceived as significantly more efficient, but both were rated equally in?\u2026", "IdName": "kuang2023collaboration", "Citation": "", "Keywords": ""}, {"Name": "Understanding how older adults comprehend COVID-19 interactive visualizations via think-aloud protocol", "Authors": ["Mingming Fan", "Yiwen Wang", "Yuni Xie", "Franklin Mingzhe Li", "Chunyang Chen"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Older adults have been hit disproportionally hard by the COVID-19 pandemic. One critical way for older adults to minimize the negative impact of COVID-19 and future pandemics is to stay informed about its latest information, which has been increasingly presented through online interactive visualizations (e.g., live dashboards and websites). Thus, it is imperative to understand how older adults interact with and comprehend online COVID-19 interactive visualizations and what challenges they might encounter to make such visualizations more accessible to older adults. We adopted a user-centered approach by inviting older adults to interact with COVID-19 interactive visualizations while at the same time verbalizing their thought processes using a think-aloud protocol. By analyzing their think-aloud verbalizations, we identified four types of thought processes representing how older adults comprehended the?\u2026", "IdName": "fan2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Enabling Voice-Accompanying Hand-to-Face Gesture Recognition with Cross-Device Sensing", "Authors": ["Zisu Li", "Chen Liang", "Yuntao Wang", "Yue Qin", "Chun Yu", "Yukang Yan", "Mingming Fan", "Yuanchun Shi"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Gestures performed accompanying the voice are essential for voice interaction to convey complementary semantics for interaction purposes such as wake-up state and input modality. In this paper, we investigated voice-accompanying hand-to-face (VAHF) gestures for voice interaction. We targeted on hand-to-face gestures because such gestures relate closely to speech and yield significant acoustic features (e.g., impeding voice propagation). We conducted a user study to explore the design space of VAHF gestures, where we first gathered candidate gestures and then applied a structural analysis to them in different dimensions (e.g., contact position and type), outputting a total of 8 VAHF gestures with good usability and least confusion. To facilitate VAHF gesture recognition, we proposed a novel cross-device sensing method that leverages heterogeneous channels (vocal, ultrasound, and IMU) of data from?\u2026", "IdName": "li2023enabling", "Citation": "", "Keywords": ""}, {"Name": "uxSense: Supporting user experience analysis with visualization and computer vision", "Authors": ["Andrea Batch", "Yipeng Ji", "Mingming Fan", "Jian Zhao", "Niklas Elmqvist"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Analyzing user behavior from usability evaluation can be a challenging and time-consuming task, especially as the number of participants and the scale and complexity of the evaluation grows. We propose UXSENSE, a visual analytics system using machine learning methods to extract user behavior from audio and video recordings as parallel time-stamped data streams. Our implementation draws on pattern recognition, computer vision, natural language processing, and machine learning to extract user sentiment, actions, posture, spoken words, and other features from such recordings. These streams are visualized as parallel timelines in a web-based front-end, enabling the researcher to search, filter, and annotate data across time and space. We present the results of a user study involving professional UX researchers evaluating user data using uxSense. In fact, we used uxSense itself to evaluate their sessions.", "IdName": "batch2023uxsense", "Citation": "", "Keywords": ""}, {"Name": "\"Merging Results Is No Easy Task\": An International Survey Study of Collaborative Data Analysis Practices Among UX Practitioners", "Authors": ["Emily Kuang", "Xiaofu Jin", "Mingming Fan"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Analysis is a key part of usability testing where UX practitioners seek to identify usability problems and generate redesign suggestions. Although previous research reported how analysis was conducted, the findings were typically focused on individual analysis or based on a small number of professionals in specific geographic regions. We conducted an online international survey of 279 UX practitioners on their practices and challenges while collaborating during data analysis. We found that UX practitioners were often under time pressure to conduct analysis and adopted three modes of collaboration: independently analyze different portions of the data and then collaborate, collaboratively analyze the session with little or no independent analysis, and independently analyze the same set of data and then collaborate. Moreover, most encountered challenges related to lack of resources, disagreements with?\u2026", "IdName": "kuang2022merging", "Citation": "", "Keywords": ""}, {"Name": "\"I Shake The Package To Check If It's Mine\": A Study of Package Fetching Practices and Challenges of Blind and Low Vision People in China", "Authors": ["Wentao Lei", "Mingming Fan", "Juliann Thang"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": "With about 230 million packages delivered per day in 2020, fetching packages has become a routine for many city dwellers in China. When fetching packages, people usually need to go to collection sites of their apartment complexes or a KuaiDiGui, an increasingly popular type of self-service package pickup machine. However, little is known whether such processes are accessible to blind and low vision (BLV) city dwellers. We interviewed BLV people (N=20) living in a large metropolitan area in China to understand their practices and challenges of fetching packages. Our findings show that participants encountered difficulties in finding the collection site and localizing and recognizing their packages. When fetching packages from KuaiDiGuis, they had difficulty in identifying the correct KuaiDiGui, interacting with its touch screen, navigating the complex on-screen workflow, and opening the target compartment. We?\u2026", "IdName": "lei2022shake", "Citation": "", "Keywords": ""}, {"Name": "\u201cI Used To Carry A Wallet, Now I Just Need To Carry My Phone\u201d: Understanding Current Banking Practices and Challenges Among Older Adults in China", "Authors": ["Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the 24th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Managing finances is crucial for older adults who are retired and may rely on savings to ensure their lives\u2019 quality. As digital banking platforms (e.g., mobile apps, electronic payment) gradually replace physical ones, it is critical to understand how they adapt to digital banking and the potential frictions they experience. We conducted semi-structured interviews with 16 older adults in China, where the aging population is the largest and digital banking grows fast. We also interviewed bank employees to gain complementary perspectives of these help givers. Our findings show that older adults used both physical and digital platforms as an ecosystem based on perceived pros and cons. Perceived usefulness, self-confidence, and social influence were key motivators for learning digital banking. They experienced app-related (e.g., insufficient error-recovery support) and user-related challenges (e.g., trust, security and?\u2026", "IdName": "jin2022used", "Citation": "", "Keywords": ""}, {"Name": "iWink: Exploring eyelid gestures on mobile devices", "Authors": ["Zhen Li", "Mingming Fan", "Ying Han", "Khai N Truong"], "Sources": "Proceedings of the 1st International Workshop on Human-Centric Multimedia?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Although gaze has been widely studied for mobile interactions, eyelid-based gestures are relatively understudied and limited to few basic gestures (e.g., blink). In this work, we propose a gesture grammar to construct both basic and compound eyelid gestures. We present an algorithm to detect nine eyelid gestures in real-time on mobile devices and evaluate its performance with 12 participants. Results show that our algorithm is able to recognize nine eyelid gestures with 83% and 78% average accuracy using user-dependent and user-independent models respectively. Further, we design a gesture mapping scheme to allow for navigating between and within mobile apps only using eyelid gestures. Moreover, we show how eyelid gestures can be used to enable cross-application and sensitive interactions. Finally, we highlight future research directions.", "IdName": "li2020iwink", "Citation": "", "Keywords": ""}, {"Name": "Splattingavatar: Realistic real-time human avatars with mesh-embedded gaussian splatting", "Authors": ["Zhijing Shao", "Zhaolong Wang", "Zhuang Li", "Duotun Wang", "Xiangru Lin", "Yu Zhang", "Mingming Fan", "Zeyu Wang"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "We present SplattingAvatar a hybrid 3D representation of photorealistic human avatars with Gaussian Splatting embedded on a triangle mesh which renders over 300 FPS on a modern GPU and 30 FPS on a mobile device. We disentangle the motion and appearance of a virtual human with explicit mesh geometry and implicit appearance modeling with Gaussian Splatting. The Gaussians are defined by barycentric coordinates and displacement on a triangle mesh as Phong surfaces. We extend lifted optimization to simultaneously optimize the parameters of the Gaussians while walking on the triangle mesh. SplattingAvatar is a hybrid representation of virtual humans where the mesh represents low-frequency motion and surface deformation while the Gaussians take over the high-frequency geometry and detailed appearance. Unlike existing deformation methods that rely on an MLP-based linear blend skinning (LBS) field for motion we control the rotation and translation of the Gaussians directly by mesh which empowers its compatibility with various animation techniques eg skeletal animation blend shapes and mesh editing. Trainable from monocular videos for both full-body and head avatars SplattingAvatar shows state-of-the-art rendering quality across multiple datasets.", "IdName": "shao2024splattingavatar", "Citation": "", "Keywords": ""}, {"Name": "Older Adults\u2019 Concurrent and Retrospective Think-Aloud Verbalizations for Identifying User Experience Problems of VR Games", "Authors": ["Mingming Fan", "Vinita Tibdewal", "Qiwen Zhao", "Lizhou Cao", "Chao Peng", "Runxuan Shu", "Yujia Shan"], "Sources": "Interacting with Computers", "PublishedYears": "2022", "Doi": "", "Abstracts": " While virtual reality (VR) games are beneficial for older adults to improve their physical functions and cognitive abilities, VR research often does not include older adults. Our review of the proceedings of major HCI conferences (i.e. ASSETS, CHI, CHI PLAY, CSCW and DIS) between 2016 and 2020 shows that only three out of 352 VR-related papers involved older adults. Consequently, older adults tend to encounter user experience (UX) problems with VR. One common way to identify UX problems is to conduct usability testing with think-aloud (TA) protocols. As VR games tend to be perceptually and physically demanding, older adults might need to allocate more resources to VR content and interaction and thus have fewer resources for thinking aloud. This raises the question of whether TA protocols are still a viable approach to detecting UX problems of VR games for older adult participants. To answer this?\u2026", "IdName": "fan2022older", "Citation": "", "Keywords": ""}, {"Name": "Sparkling silence: Practices and challenges of livestreaming among deaf or hard of hearing streamers", "Authors": ["Beiyan Cao", "Changyang He", "Muzhi Zhou", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Understanding livestream platforms\u2019 accessibility challenges for minority groups, such as people with disabilities, is critical to increasing the diversity and inclusion of those platforms. While prior work investigated the experiences of streamers with vision or motor loss, little is known about the experiences of deaf or hard of hearing (DHH) streamers who must work with livestreaming platforms that heavily depend on audio. We conducted semi-structured interviews with DHH streamers to learn why they livestream, how they navigate livestream platforms and related challenges. Our findings revealed their desire to break the stereotypes towards the DHH groups via livestream and the intense interplay between interaction methods, such as sign language, texts, lip language, background music, and viewer characteristics. Major accessibility challenges include the lack of real-time captioning, the small sign language?\u2026", "IdName": "cao2023sparkling", "Citation": "", "Keywords": ""}, {"Name": "CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming", "Authors": ["Felicia Li Feng", "Ryan Yen", "Yuzhe You", "Mingming Fan", "Jian Zhao", "Zhicong Lu"], "Sources": "arXiv preprint arXiv:2310.09235", "PublishedYears": "2023", "Doi": "", "Abstracts": "Natural language (NL) programming has become more approachable due to the powerful code-generation capability of large language models (LLMs). This shift to using NL to program enhances collaborative programming by reducing communication barriers and context-switching among programmers from varying backgrounds. However, programmers may face challenges during prompt engineering in a collaborative setting as they need to actively keep aware of their collaborators' progress and intents. In this paper, we aim to investigate ways to assist programmers' prompt engineering in a collaborative context. We first conducted a formative study to understand the workflows and challenges of programmers when using NL for collaborative programming. Based on our findings, we implemented a prototype, CoPrompt, to support collaborative prompt engineering by providing referring, requesting, sharing, and linking mechanisms. Our user study indicates that CoPrompt assists programmers in comprehending collaborators' prompts and building on their collaborators' work, reducing repetitive updates and communication costs.", "IdName": "feng2023coprompt", "Citation": "", "Keywords": ""}, {"Name": "Understanding Curators' Practices and Challenge of Making Exhibitions More Accessible for People with Visual Impairments", "Authors": ["Yuru Huang", "Jingling Zhang", "Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the 25th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Assistive technologies are increasingly developed and applied in exhibition environments to help blind and low vision (BLV) people deal with the challenges they face when visiting exhibitions. While studies have examined the experiences of BLV people using such technologies, little is known about the experiences and challenges of curators incorporating assistive technologies into exhibitions to make them more accessible to BLV people. This research focuses on assistive technologies for BLV people in exhibitions from a curatorial perspective. We conducted semi-structured interviews with twenty-two experienced curators to understand their practices and challenges. We also curated a list of assistive technologies from published papers and used them as probes to seek curators\u2019 attitudes and perceptions of such technologies. We uncovered four critical themes related to curators\u2019 challenges of making?\u2026", "IdName": "huang2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Understanding Strategies and Challenges of Conducting Daily Data Analysis (DDA) Among Blind and Low-vision People", "Authors": ["Chutian Jiang", "Wentao Lei", "Emily Kuang", "Teng Han", "Mingming Fan"], "Sources": "Proceedings of the 25th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Being able to analyze and derive insights from data, which we call Daily Data Analysis (DDA), is an increasingly important skill in everyday life. While the accessibility community has explored ways to make data more accessible to blind and low-vision (BLV) people, little is known about how BLV people perform DDA. Knowing BLV people\u2019s strategies and challenges in DDA would allow the community to make DDA more accessible to them. Toward this goal, we conducted a mixed-methods study of interviews and think-aloud sessions with BLV people (N=16). Our study revealed five key approaches for DDA (i.e., overview obtaining, column comparison, key statistics identification, note-taking, and data validation) and the associated challenges. We discussed the implications of our findings and highlighted potential directions to make DDA more accessible for BLV people.", "IdName": "jiang2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Opportunities of AR for Enriching Storytelling with Family Photos between Grandparents and Grandchildren", "Authors": ["Zisu Li", "Li Feng", "Chen Liang", "Yuru Huang", "Mingming Fan"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2023", "Doi": "", "Abstracts": "Storytelling with family photos, as an important mode of reminiscence-based activities, can be instrumental in promoting intergenerational communication between grandparents and grandchildren by strengthening generation bonds and shared family values. Motivated by challenges that existing technology approaches encountered for improving intergenerational storytelling (e.g., the need to hold the tablet, the potential view detachment from the physical world in Virtual Reality (VR)), we sought to find new ways of using Augmented Reality (AR) to support intergenerational storytelling, which offers new capabilities (e.g., 3D models, new interactivity) to enhance the expression for the storyteller. We conducted a two-part exploratory study, where pairs of grandparents and grandchildren 1) participated in an in-person storytelling activity with a semi-structured interview 2) and then a participatory design session with AR?\u2026", "IdName": "li2023exploring", "Citation": "", "Keywords": ""}, {"Name": "CoPracTter: Toward Integrating Personalized Practice Scenarios, Timely Feedback and Social Support into An Online Support Tool for Coping with Stuttering in China", "Authors": ["Li Feng", "Zeyu Xiong", "Xinyi Li", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Stuttering is a speech disorder influencing over 70 million people worldwide, including 13 million in China. It causes low self-esteem among other detrimental effects on people who stutter (PwS). Although prior work has explored approaches to assist PwS, they primarily focused on western contexts. In our formative study, we found unique practices and challenges among Chinese PwS. We then iteratively designed an online tool, CoPracTter, to support Chinese PwS practicing speaking fluency with 1) targeted stress-inducing practice scenarios, 2) real-time speech indicators, and 3) personalized timely feedback from the community. We further conducted a seven-day deployment study (N=11) to understand how participants utilized these key features. To our knowledge, it is the first time such a prototype was designed and tested for a long time with multiple PwS participants online simultaneously. Results indicate?\u2026", "IdName": "feng2023copractter", "Citation": "", "Keywords": ""}, {"Name": "Typist Experiment: an Investigation of Human-to-Human Dictation via Role-play to Inform Voice-based Text Authoring", "Authors": ["Can Liu", "Siying Hu", "Li Feng", "Mingming Fan"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Voice dictation is increasingly used for text entry, especially in mobile scenarios. However, the speech-based experience gets disrupted when users must go back to a screen and keyboard to review and edit the text. While existing dictation systems focus on improving transcription and error correction, little is known about how to support speech input for the entire text creation process, including composition, reviewing and editing. We conducted an experiment in which ten pairs of participants took on the roles of authors and typists to work on a text authoring task. By analysing the natural language patterns of both authors and typists, we identified new challenges and opportunities for the design of future dictation interfaces, including the ambiguity of human dictation, the differences between audio-only and with screen, and various passive and active assistance that can potentially be provided by future systems.", "IdName": "liu2022typist", "Citation": "", "Keywords": ""}, {"Name": "Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing", "Authors": ["Emily Kuang", "Minghao Li", "Mingming Fan", "Kristen Shinohara"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Usability testing is vital for enhancing the user experience (UX) of interactive systems. However, analyzing test videos is complex and resource-intensive. Recent AI advancements have spurred exploration into human-AI collaboration for UX analysis, particularly through natural language. Unlike user-initiated dialogue, our study investigated the potential of proactive conversational assistants to aid UX evaluators through automatic suggestions at three distinct times: before, in sync with, and after potential usability problems. We conducted a hybrid Wizard-of-Oz study involving 24 UX evaluators, using ChatGPT to generate automatic problem suggestions and a human actor to respond to impromptu questions. While timing did not significantly impact analytic performance, suggestions appearing after potential problems were preferred, enhancing trust and efficiency. Participants found the automatic suggestions useful?\u2026", "IdName": "kuang2024enhancing", "Citation": "", "Keywords": ""}, {"Name": "HeadEvolver: Text to Head Avatars via Locally Learnable Mesh Deformation", "Authors": ["Duotun Wang", "Hengyu Meng", "Zeyu Cai", "Zhijing Shao", "Qianxi Liu", "Lin Wang", "Mingming Fan", "Ying Shan", "Xiaohang Zhan", "Zeyu Wang"], "Sources": "arXiv preprint arXiv:2403.09326", "PublishedYears": "2024", "Doi": "", "Abstracts": "We present HeadEvolver, a novel framework to generate stylized head avatars from text guidance. HeadEvolver uses locally learnable mesh deformation from a template head mesh, producing high-quality digital assets for detail-preserving editing and animation. To tackle the challenges of lacking fine-grained and semantic-aware local shape control in global deformation through Jacobians, we introduce a trainable parameter as a weighting factor for the Jacobian at each triangle to adaptively change local shapes while maintaining global correspondences and facial features. Moreover, to ensure the coherence of the resulting shape and appearance from different viewpoints, we use pretrained image diffusion models for differentiable rendering with regularization terms to refine the deformation under text guidance. Extensive experiments demonstrate that our method can generate diverse head avatars with an articulated mesh that can be edited seamlessly in 3D graphics software, facilitating downstream applications such as more efficient animation with inherited blend shapes and semantic consistency.", "IdName": "wang2024headevolver", "Citation": "", "Keywords": ""}, {"Name": "OperARtistry: An AR-based Interactive Application to Assist the Learning of Chinese Traditional Opera (Xiqu) Makeup", "Authors": ["Zeyu Xiong", "Shihan Fu", "Mingming Fan"], "Sources": "Proceedings of the Eleventh International Symposium of Chinese CHI", "PublishedYears": "2023", "Doi": "", "Abstracts": " Chinese Traditional Opera (Xiqu) is an important type of intangible cultural heritage and one key characteristic of Xiqu is its visual effects on face achieved via makeup. However, Xiqu makeup process, especially the eye-area makeup process, is complex and time-consuming, which poses a learning challenge for potential younger inheritors. We introduce OperARtistry, an interactive application based on Augmented Reality (AR) that offers in-situ Xiqu makeup guidance for beginners. Our application provides a step-by-step guide for Xiqu eye-area makeup, incorporating AR effects at each stage. Furthermore, we conducted an initial user study (n=6) to compare our approach with existing video-based tutorials to assess the effectiveness and usefulness of our approach. Our findings show that OperARtisty helped participants achieve high-quality eye-area makeup effects with less learning time.", "IdName": "xiong2023operartistry", "Citation": "", "Keywords": ""}, {"Name": "ShadowTouch: Enabling Free-Form Touch-Based Hand-to-Surface Interaction with Wrist-Mounted Illuminant by Shadow Projection", "Authors": ["Chen Liang", "Xutong Wang", "Zisu Li", "Chi Hsia", "Mingming Fan", "Chun Yu", "Yuanchun Shi"], "Sources": "Proceedings of the 36th Annual ACM Symposium on User Interface Software and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We present ShadowTouch, a novel sensing method to recognize the subtle hand-to-surface touch state for independent fingers based on optical auxiliary. ShadowTouch mounts a forward-facing light source on the user\u2019s wrist to construct shadows on the surface in front of the fingers when the corresponding fingers are close to the surface. With such an optical design, the subtle vertical movements of near-surface fingers are magnified and turned to shadow features cast on the surface, which are recognizable for computer vision algorithms. To efficiently recognize the touch state of each finger, we devised a two-stage CNN-based algorithm that first extracted all the fingertip regions from each frame and then classified the touch state of each region from the cropped consecutive frames. Evaluations showed our touch state detection algorithm achieved a recognition accuracy of 99.1% and an F-1 score of 96.8% in the?\u2026", "IdName": "liang2023shadowtouch", "Citation": "", "Keywords": ""}, {"Name": "Enhancing Older Adults\u2019 Gesture Typing Experience Using the T9 Keyboard on Small Touchscreen Devices", "Authors": ["Emily Kuang", "Ruihuan Chen", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Older adults increasingly adopt small-screen devices, but limited motor dexterity hinders their ability to type effectively. While a 9-key (T9) keyboard allocates larger space to each key, it is shared by multiple consecutive letters. Consequently, users must interrupt their gestures when typing consecutive letters, leading to inefficiencies and poor user experience. Thus, we proposed a novel keyboard that leverages the currently unused key 1 to duplicate letters from the previous key, allowing the entry of consecutive letters without interruptions. A user study with 12 older adults showed that it significantly outperformed the T9 with wiggle gesture in typing speed, KSPC, insertion errors, and deletes per word while achieving comparable performance as the conventional T9. Repeating the typing tasks with 12 young adults found that the advantages of the novel T9 were consistent or enhanced. We also provide error analysis?\u2026", "IdName": "kuang2023enhancing", "Citation": "", "Keywords": ""}, {"Name": "SmartRecorder: An IMU-based Video Tutorial Creation by Demonstration System for Smartphone Interaction Tasks", "Authors": ["Xiaozhu Hu", "Yanwen Huang", "Bo Liu", "Ruolan Wu", "Yongquan Hu", "Aaron J Quigley", "Mingming Fan", "Chun Yu", "Yuanchun Shi"], "Sources": "Proceedings of the 28th International Conference on Intelligent User?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " This work focuses on an active topic in the HCI community, namely tutorial creation by demonstration. We present a novel tool named SmartRecorder that facilitates people, without video editing skills, creating video tutorials for smartphone interaction tasks. As automatic interaction trace extraction is a key component to tutorial generation, we seek to tackle the challenges of automatically extracting user interaction traces on smartphones from screencasts. Uniquely, with respect to prior research in this field, we combine computer vision techniques with IMU-based sensing algorithms, and the technical evaluation results show the importance of smartphone IMU data in improving system performance. With the extracted key information of each step, SmartRecorder generates instructional content initially and provides tutorial creators with a tutorial refinement editor designed based on a high recall (99.38%) of key steps?\u2026", "IdName": "hu2023smartrecorder", "Citation": "", "Keywords": ""}, {"Name": "Think-Aloud Verbalizations for Identifying User Experience Problems: Effects of Language Proficiency with Chinese Non-Native English Speakers", "Authors": ["Mingming Fan", "Lingyun Zhu"], "Sources": "Proceedings of the Ninth International Symposium of Chinese CHI", "PublishedYears": "2021", "Doi": "", "Abstracts": "Subtle patterns in users\u2019 think-aloud (TA) verbalizations (i.e., utterances) are shown to be telltale signs of user experience (UX) problems and used to build artificial intelligence (AI) models or AI-assisted tools to help UX evaluators identify UX problems automatically or semi-automatically. Despite the potential of such verbalization patterns, they were uncovered with native English speakers. As most people who speak English are non-native speakers, it is important to investigate whether similar patterns exist in non-native English speakers\u2019 TA verbalizations. As a first step to answer this question, we conducted think-aloud usability testing with Chinese non-native English speakers and native English speakers using three common TA protocols. We compared their verbalizations and UX problems that they encountered to understand the effects of language and TA protocols. Our findings show that both language?\u2026", "IdName": "fan2021think", "Citation": "", "Keywords": ""}, {"Name": "EvoK: Connecting loved ones through Heart Rate sharing", "Authors": ["Esha Shandilya", "Yiwen Wang", "Xuan Zhao", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2102.10685", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this work, we present EvoK, a new way of sharing one's heart rate with feedback from their close contacts to alleviate social isolation and loneliness. EvoK consists of a pair of wearable prototype devices (i.e., sender and receiver). The sender is designed as a headband enabling continuous sensing of heart rate with aesthetic designs to maximize social acceptance. The receiver is designed as a wristwatch enabling unobtrusive receiving of the loved one's continuous heart rate with multi-modal notification systems.", "IdName": "shandilya2021evok", "Citation": "", "Keywords": ""}, {"Name": "Neural Canvas: Supporting Scenic Design Prototyping by Integrating 3D Sketching and Generative AI", "Authors": ["Yulin Shen", "Yifei Shen", "Jiawen Cheng", "Chutian Jiang", "Mingming Fan", "Zeyu Wang"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " We propose Neural Canvas, a lightweight 3D platform that integrates sketching and a collection of generative AI models to facilitate scenic design prototyping. Compared with traditional 3D tools, sketching in a 3D environment helps designers quickly express spatial ideas, but it does not facilitate the rapid prototyping of scene appearance or atmosphere. Neural Canvas integrates generative AI models into a 3D sketching interface and incorporates four types of projection operations to facilitate 2D-to-3D content creation. Our user study shows that Neural Canvas is an effective creativity support tool, enabling users to rapidly explore visual ideas and iterate 3D scenic designs. It also expedites the creative process for both novices and artists who wish to leverage generative AI technology, resulting in attractive and detailed 3D designs created more efficiently than using traditional modeling tools or individual generative?\u2026", "IdName": "shen2024neural", "Citation": "", "Keywords": ""}, {"Name": "AromaBlendz: An Olfactory System for Crafting Personalized Scents", "Authors": ["Shihan Fu", "Jianhao Chen", "Yi Cai", "Mingming Fan"], "Sources": "Extended Abstracts of the CHI Conference on Human Factors in Computing?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": " Although the HCI community has recently begun to explore the usage of scent to enrich interactive system experiences (e.g., making VR more immersive), scent is often preset. In contrast, personalized scents might help trigger emotional responses and memory recall in many application scenarios, ranging from fostering relaxation to managing emotional states. We present AromaBlendz, a novel digital platform that enables users to create and customize their unique scent profiles. AromaBlendz comprises both hardware and software components that collectively deliver a seamless scent customization experience. The hardware includes a blending mechanism for essence oils and a user-friendly control unit, while the software component provides an intuitive interface for users to create, preview, and store their preferred scents. The platform not only allows for the generation of personalized scent profiles using a?\u2026", "IdName": "fu2024aromablendz", "Citation": "", "Keywords": ""}, {"Name": "Designing Unobtrusive Modulated Electrotactile Feedback on Fingertip Edge to Assist Blind and Low Vision (BLV) People in Comprehending Charts", "Authors": ["Chutian Jiang", "Yinan Fan", "Junan Xie", "Emily Kuang", "Kaihao Zhang", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Charts are crucial in conveying information across various fields but are inaccessible to blind and low vision (BLV) people without assistive technology. Chart comprehension tools leveraging haptic feedback have been used widely but are often bulky, expensive, and static, rendering them inefficient for conveying chart data. To increase device portability, enable multitasking, and provide efficient assistance in chart comprehension, we introduce a novel system that delivers unobtrusive modulated electrotactile feedback directly to the fingertip edge. Our three-part study with twelve participants confirmed the effectiveness of this system, demonstrating that electrotactile feedback, when applied for 0.5 seconds with a 0.12-second interval, provides the most accurate position and direction recognition. Furthermore, our electrotactile device has proven valuable in assisting BLV participants in comprehending four commonly?\u2026", "IdName": "jiang2024designing", "Citation": "", "Keywords": ""}, {"Name": "Bridging the Literacy Gap for Adults: Streaming and Engaging in Adult Literacy Education through Livestreaming", "Authors": ["Shihan Fu", "Jianhao Chen", "Emily Kuang", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Literacy\u2014the ability to read, write, and comprehend text\u2014is an important topic addressed by UNESCO. Despite global efforts to promote adult literacy education, rural areas with limited resources still lag behind. As livestreaming has gained popularity in China, many streamers leveraged its accessibility and affordability to reach low-literate adults. To gain a better understanding of the practices and challenges faced by adult literacy education through livestreaming, we conducted a mixed-methods study involving a 7-day observation of livestreaming sessions and an interview study with twelve streamers and ten viewers. We discovered streamers\u2019 altruistic motives and unique interactive approaches. Viewers perceived livestreaming as a more engaging, community-supportive method than traditional approaches. We also identified both shared and unique challenges for streamers and viewers that limit its efficacy as?\u2026", "IdName": "fu2024bridging", "Citation": "", "Keywords": ""}, {"Name": "WieldingCanvas: Interactive Sketch Canvases for Freehand Drawing in VR", "Authors": ["Xiaohui Tan", "Zhenxuan He", "Can Liu", "Mingming Fan", "Tianren Luo", "Zitao Liu", "Mi Tian", "Teng Han", "Feng Tian"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Sketching in Virtual Reality (VR) is challenging mainly due to the absence of physical surface support and virtual depth perception cues, which induce high cognitive and sensorimotor load. This paper presents WieldingCanvas, an interactive VR sketching platform that integrates canvas manipulations to draw lines and curves in 3D. Informed by real-life examples of two-handed creative activities, WieldingCanvas interprets users\u2019 spatial gestures to move, swing, rotate, transform, or fold a virtual canvas, whereby users simply draw primitive strokes on the canvas, which are turned into finer and more sophisticated shapes via the manipulation of the canvas. We evaluated the capability and user experience of WieldingCanvas with two studies where participants were asked to sketch target shapes. A set of freehand sketches of high aesthetic qualities were created, and the results demonstrated that WieldingCanvas can?\u2026", "IdName": "tan2024wieldingcanvas", "Citation": "", "Keywords": ""}, {"Name": "Designing Upper-Body Gesture Interaction with and for People with Spinal Muscular Atrophy in VR", "Authors": ["Jingze Tian", "Yingna Wang", "Keye Yu", "Liyi Xu", "Junan Xie", "Franklin Mingzhe Li", "Yafeng Niu", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent research proposed gaze-assisted gestures to enhance interaction within virtual reality (VR), providing opportunities for people with motor impairments to experience VR. Compared to people with other motor impairments, those with Spinal Muscular Atrophy (SMA) exhibit enhanced distal limb mobility, providing them with more design space. However, it remains unknown what gaze-assisted upper-body gestures people with SMA would want and be able to perform. We conducted an elicitation study in which 12 VR-experienced people with SMA designed upper-body gestures for 26 VR commands, and collected 312 user-defined gestures. Participants predominantly favored creating gestures with their hands. The type of tasks and participants\u2019 abilities influence their choice of body parts for gesture design. Participants tended to enhance their body involvement and preferred gestures that required minimal?\u2026", "IdName": "tian2024designing", "Citation": "", "Keywords": ""}, {"Name": "LightSword: A Customized Virtual Reality Exergame for Long-Term Cognitive Inhibition Training in Older Adults", "Authors": ["Qiuxin Du", "Zhen Song", "Haiyan Jiang", "Xiaoying Wei", "Dongdong Weng", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " The decline of cognitive inhibition significantly impacts older adults\u2019 quality of life and well-being, making it a vital public health problem in today\u2019s aging society. Previous research has demonstrated that Virtual reality (VR) exergames have great potential to enhance cognitive inhibition among older adults. However, existing commercial VR exergames were unsuitable for older adults\u2019 long-term cognitive training due to the inappropriate cognitive activation paradigm, unnecessary complexity, and unbefitting difficulty levels. To bridge these gaps, we developed a customized VR cognitive training exergame (LightSword) based on Dual-task and Stroop paradigms for long-term cognitive inhibition training among healthy older adults. Subsequently, we conducted an eight-month longitudinal user study with 12 older adults aged 60 years and above to demonstrate the effectiveness of LightSword in improving cognitive?\u2026", "IdName": "du2024lightsword", "Citation": "", "Keywords": ""}, {"Name": "\u201cCan It Be Customized According to My Motor Abilities?\u201d: Toward Designing User-Defined Head Gestures for People with Dystonia", "Authors": ["Qin Sun", "Yunqi Hu", "Mingming Fan", "Jingting Li", "Su-Jing Wang"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Recent studies proposed above-the-neck gestures for people with upper-body motor impairments interacting with mobile devices without finger touch, resulting in an appropriate user-defined gesture set. However, many gestures involve sustaining eyelids in closed or open states for a period. This is challenging for people with dystonia, who have difficulty sustaining and intermitting muscle contractions. Meanwhile, other facial parts, such as the tongue and nose, can also be used to alleviate the sustained use of eyes in the interaction. Consequently, we conducted a user study inviting 16 individuals with dystonia to design gestures based on facial muscle movements for 26 common smartphone commands. We collected 416 user-defined head gestures involving facial features and shoulders. Finally, we obtained the preferred gestures set for individuals with dystonia. Participants preferred to make the gestures with?\u2026", "IdName": "sun2024can", "Citation": "", "Keywords": ""}, {"Name": "To Reach the Unreachable: Exploring the Potential of VR Hand Redirection for Upper Limb Rehabilitation", "Authors": ["Peixuan Xiong", "Yukai Zhang", "Nandi Zhang", "Shihan Fu", "Xin Li", "Yadan Zheng", "Jinni Zhou", "Xiquan Hu", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Rehabilitation therapies are widely employed to assist people with motor impairments in regaining control over their affected body parts. Nevertheless, factors such as fatigue and low self-efficacy can hinder patient compliance during extensive rehabilitation processes. Utilizing hand redirection in virtual reality (VR) enables patients to accomplish seemingly more challenging tasks, thereby bolstering their motivation and confidence. While previous research has investigated user experience and hand redirection among able-bodied people, its effects on motor-impaired people remain unexplored. In this paper, we present a VR rehabilitation application that harnesses hand redirection. Through a user study and semi-structured interviews, we examine the impact of hand redirection on the rehabilitation experiences of people with motor impairments and its potential to enhance their motivation for upper limb?\u2026", "IdName": "xiong2024reach", "Citation": "", "Keywords": ""}, {"Name": "Toward Making Virtual Reality (VR) More Inclusive for Older Adults: Investigating Aging Effect on Target Selection and Manipulation Tasks in VR", "Authors": ["Zhiqing Wu", "Duotun Wang", "Shumeng Zhang", "Yuru Huang", "Zeyu Wang", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent studies show the promise of VR in improving physical, cognitive, and emotional health of older adults. However, prior work on optimizing object selection and manipulation performance in VR was mostly conducted among younger adults. It remains unclear how older adults would perform such tasks compared to younger adults and the challenges they might face. To fill in this gap, we conducted two studies with both older and younger adults to understand their performances and user experiences of object selection and manipulation in VR respectively. Based on the results, we delineated interaction difficulties that older adults exhibited in VR and identified multiple factors, such as headset-related neck fatigue, extra head movements from out-of-view interactions, and slow spatial perceptions, that significantly decreased the motor performance of older adults. We further proposed design recommendations for?\u2026", "IdName": "wu2024toward", "Citation": "", "Keywords": ""}, {"Name": "See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles", "Authors": ["Yu Zhang", "Jingwei Sun", "Li Feng", "Cen Yao", "Mingming Fan", "Liuxin Zhang", "Qianying Wang", "Xin Geng", "Yong Rui"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " The proliferation of AI-powered search and recommendation systems has accelerated the formation of \u201cfilter bubbles\u201d that reinforce people\u2019s biases and narrow their perspectives. Previous research has attempted to address this issue by increasing the diversity of information exposure, which is often hindered by a lack of user motivation to engage with. In this study, we took a human-centered approach to explore how Large Language Models (LLMs) could assist users in embracing more diverse perspectives. We developed a prototype featuring LLM-powered multi-agent characters that users could interact with while reading social media content. We conducted a participatory design study with 18 participants and found that multi-agent dialogues with gamification incentives could motivate users to engage with opposing viewpoints. Additionally, progressive interactions with assessment tasks could promote?\u2026", "IdName": "zhang2024see", "Citation": "", "Keywords": ""}, {"Name": "\" It Is Hard to Remove from My Eye\": Design Makeup Residue Visualization System for Chinese Traditional Opera (Xiqu) Performers", "Authors": ["Zeyu Xiong", "Shihan Fu", "Yanying Zhu", "Chenqing Zhu", "Xiaojuan Ma", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2402.15719", "PublishedYears": "2024", "Doi": "", "Abstracts": "Chinese traditional opera (Xiqu) performers often experience skin problems due to the long-term use of heavy-metal-laden face paints. To explore the current skincare challenges encountered by Xiqu performers, we conducted an online survey (N=136) and semi-structured interviews (N=15) as a formative study. We found that incomplete makeup removal is the leading cause of human-induced skin problems, especially the difficulty in removing eye makeup. Therefore, we proposed EyeVis, a prototype that can visualize the residual eye makeup and record the time make-up was worn by Xiqu performers. We conducted a 7-day deployment study (N=12) to evaluate EyeVis. Results indicate that EyeVis helps to increase Xiqu performers' awareness about removing makeup, as well as boosting their confidence and security in skincare. Overall, this work also provides implications for studying the work of people who wear makeup on a daily basis, and helps to promote and preserve the intangible cultural heritage of practitioners.", "IdName": "xiong2024hard", "Citation": "", "Keywords": ""}, {"Name": "FetchAid: Making Parcel Lockers More Accessible to Blind and Low Vision People With Deep-learning Enhanced Touchscreen Guidance, Error-Recovery Mechanism, and AR-based Search?\u2026", "Authors": ["Zhitong Guan", "Zeyu Xiong", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2402.15723", "PublishedYears": "2024", "Doi": "", "Abstracts": "Parcel lockers have become an increasingly prevalent last-mile delivery method. Yet, a recent study revealed its accessibility challenges to blind and low-vision people (BLV). Informed by the study, we designed FetchAid, a standalone intelligent mobile app assisting BLV in using a parcel locker in real-time by integrating computer vision and augmented reality (AR) technologies. FetchAid first uses a deep network to detect the user's fingertip and relevant buttons on the touch screen of the parcel locker to guide the user to reveal and scan the QR code to open the target compartment door and then guide the user to reach the door safely with AR-based context-aware audio feedback. Moreover, FetchAid provides an error-recovery mechanism and real-time feedback to keep the user on track. We show that FetchAid substantially improved task accomplishment and efficiency, and reduced frustration and overall effort in a study with 12 BLV participants, regardless of their vision conditions and previous experience.", "IdName": "guan2024fetchaid", "Citation": "", "Keywords": ""}, {"Name": "Toward Leveraging Augmented Reality (AR) for Enhancing Remote Intergenerational Communication in Cooking Scenarios", "Authors": ["Yuru Huang", "Liyi Xu", "You Zhou", "Qiongyan Chen", "Zhiqing Wu", "Li Feng", "Mingming Fan"], "Sources": "Proceedings of the Eleventh International Symposium of Chinese CHI", "PublishedYears": "2023", "Doi": "", "Abstracts": " The close connection between food culture and family relationship has always been regarded as an important link to maintain family harmony and intergenerational(IG) communication. Through cooking and eating together, family members inherit family customs and culture, and enhance mutual feelings and understanding. However, with the development changes in family structure, there is an urgent need to find new approaches for IG communication between the younger and older generations. In this context, this study will explore how modern technological means such as remote home intelligent control and augmented reality (AR) technology, combined with the characteristics of food culture, can be used to innovate and strengthen IG communication between family members. This study explored the challenges inherent in remote integrated circuits in the context of collaborative cooking. Building on this, we use?\u2026", "IdName": "huang2023toward", "Citation": "", "Keywords": ""}, {"Name": "A Multi-modal Toolkit to Support DIY Assistive Technology Creation for Blind and Low Vision People", "Authors": ["Liwen He", "Yifan Li", "Mingming Fan", "Liang He", "Yuhang Zhao"], "Sources": "Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We design and build A11yBits, a tangible toolkit that empowers blind and low vision (BLV) people to easily create personalized do-it-yourself assistive technologies (DIY-ATs). A11yBits includes (1) a series of Sensing modules to detect both environmental information and user commands, (2) a set of Feedback modules to send multi-modal feedback, and (3) two Base modules (Sensing Base and Feedback Base) to power and connect the sensing and feedback modules. The toolkit enables accessible and easy assembly via a \u201cplug-and-play\u201d mechanism. BLV users can select and assemble their preferred modules to create personalized DIY-ATs. ", "IdName": "he2023multi", "Citation": "", "Keywords": ""}, {"Name": "OdorV-Art: An Initial Exploration of An Olfactory Intervention for Appreciating Style Information of Artworks in Virtual Museum", "Authors": ["Shumeng Zhang", "Ziyan Wang", "You Zhou", "Hao Cui", "Shihan Fu", "Zeyu Wang", "Mingming Fan"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Style information, such as tone, mood, and genre of artworks, is important for museum visitors to appreciate them better. However, such information can be challenging for non-art specialists to comprehend in the short period that they view artworks. The sense of smell is instrumental for humans to assist their image memory, color, emotion, and shape association. However, it is rarely used in the appreciation of artworks. Taking Western landscape painting as an example, this research explores the following research questions (RQs): 1) How does the intervention of the sense of smell improve the acquisition of style information in paintings? 2) How does the intervention of the sense of smell enhance the immersion in painting appreciation? To answer RQs, we first recruited seven art specialists to participate in a co-design workshop to design a prototype of the virtual museum with olfactory intervention. We then?\u2026", "IdName": "zhang2023odorv", "Citation": "", "Keywords": ""}, {"Name": "Composition and configuration patterns in multiple-view visualizations", "Authors": ["Xi Chen", "Wei Zeng", "Yanna Lin", "Hayder Mahdi Ai-Maneea", "Jonathan Roberts", "Remco Chang"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there; and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new?\u2026", "IdName": "chen2020composition", "Citation": "", "Keywords": ""}, {"Name": "Revisiting the modifiable areal unit problem in deep traffic prediction with visual analytics", "Authors": ["Wei Zeng", "Chengqiao Lin", "Juncong Lin", "Jincheng Jiang", "Jiazhi Xia", "Cagatay Turkay", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a  Bivariate Map  equipped with an?\u2026", "IdName": "zeng2020revisiting", "Citation": "", "Keywords": ""}, {"Name": "VIStory: interactive storyboard for exploring visual information in scientific publications", "Authors": ["Wei Zeng", "Ao Dong", "Xi Chen", "Zhang-lin Cheng"], "Sources": "Journal of visualization", "PublishedYears": "2021", "Doi": "", "Abstracts": "Many visual analytics have been developed for examining scientific publications comprising wealthy data such as authors and citations. The studies provide unprecedented insights on a variety of applications, e.g., literature review and collaboration analysis. However, visual information (i.e., figures) that are widely employed for storytelling and methods description are often neglected. We present VIStory, an interactive storyboard for exploring visual information in scientific publications. We harvest the data using an automatic figure extraction method, resulting in a large corpora of figures. Each figure contains various attributes such as dominant color and width/height ratio, together with faceted metadata of the publication including venues, authors, and keywords. To depict these information, we develop an intuitive interface consisting of three components: 1) Faceted View enables efficient query by publication?\u2026", "IdName": "dong2019vistory", "Citation": "", "Keywords": ""}, {"Name": "VISAtlas: An image-based exploration and query system for large visualization collections via neural image embedding", "Authors": ["Yilin Ye", "Rong Huang", "Wei Zeng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "High-quality visualization collections are beneficial for a variety of applications including visualization reference and data-driven visualization design. The visualization community has created many visualization collections, and developed interactive exploration systems for the collections. However, the systems are mainly based on extrinsic attributes like authors and publication years, whilst neglect intrinsic property ( i.e ., visual appearance) of visualizations, hindering visual comparison and query of visualization designs. This paper presents  VISAtlas , an image-based approach empowered by neural image embedding, to facilitate exploration and query for visualization collections. To improve embedding accuracy, we create a comprehensive collection of synthetic and real-world visualizations, and use it to train a convolutional neural network (CNN) model with a triplet loss for taxonomical classification of?\u2026", "IdName": "ye2022visatlas", "Citation": "", "Keywords": ""}, {"Name": "UrbanVR: An immersive analytics system for context-aware urban design", "Authors": ["Chi Zhang", "Wei Zeng", "Ligang Liu"], "Sources": "Computers & Graphics 99", "PublishedYears": "2021", "Doi": "", "Abstracts": "Urban design is a highly visual discipline that requires visualization for informed decision making. However, traditional urban design tools are mostly limited to representations on 2D displays that lack intuitive awareness. The popularity of head-mounted displays (HMDs) promotes a promising alternative with consumer-grade 3D displays. We introduce UrbanVR, an immersive analytics system with effective visualization and interaction techniques, to enable architects to assess designs in a virtual reality (VR) environment. Specifically, UrbanVR incorporates 1) a customized parallel coordinates plot (PCP) design to facilitate quantitative assessment of high-dimensional design metrics, 2) a series of egocentric interactions, including gesture interactions and handle-bar metaphors, to facilitate user interactions, and 3) a viewpoint optimization algorithm to help users explore both the PCP for quantitative analysis, and?\u2026", "IdName": "zhang2021urbanvr", "Citation": "", "Keywords": ""}, {"Name": "ActFloor-GAN: activity-guided adversarial networks for human-centric floorplan design", "Authors": ["Shidong Wang", "Wei Zeng", "Xi Chen", "Yu Ye", "Yu Qiao", "Chi-Wing Fu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "We present a novel two-stage approach for automated floorplan design in residential buildings with a given exterior wall boundary. Our approach has the unique advantage of being human-centric, that is, the generated floorplans can be geometrically plausible, as well as topologically reasonable to enhance resident interaction with the environment. From the input boundary, we first synthesize a human-activity map that reflects both the spatial configuration and human-environment interaction in an architectural space. We propose to produce the human-activity map either automatically by a pre-trained generative adversarial network (GAN) model, or semi-automatically by synthesizing it with user manipulation of the furniture. Second, we feed the human-activity map into our deep framework  ActFloor-GAN  to guide a pixel-wise prediction of room types. We adopt a re-formulated cycle-consistency constraint in?\u2026", "IdName": "wang2021actfloor", "Citation": "", "Keywords": ""}, {"Name": "Effects of view layout on situated analytics for multiple-view representations in immersive visualization", "Authors": ["Zhen Wen", "Wei Zeng", "Luoxuan Weng", "Yihan Liu", "Mingliang Xu", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Multiple-view (MV) representations enabling multi-perspective exploration of large and complex data are often employed on 2D displays. The technique also shows great potential in addressing complex analytic tasks in immersive visualization. However, although useful, the design space of MV representations in immersive visualization lacks in deep exploration. In this paper, we propose a new perspective to this line of research, by examining the effects of view layout for MV representations on situated analytics. Specifically, we disentangle situated analytics in perspectives of  situatedness  regarding spatial relationship between visual representations and physical referents, and  analytics  regarding cross-view data analysis including filtering, refocusing, and connecting tasks. Through an in-depth analysis of existing layout paradigms, we summarize design trade-offs for achieving high situatedness and effective?\u2026", "IdName": "wen2022effects", "Citation": "", "Keywords": ""}, {"Name": "SD-seq2seq: a deep learning model for bus bunching prediction based on smart card data", "Authors": ["Zengyang Gong", "Bo Du", "Zhidan Liu", "Wei Zeng", "Pascal Perez", "Kaishun Wu"], "Sources": "2020 29th International Conference on Computer Communications and Networks?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Bus bunching, a phenomenon due to the failure of headway or timetable adherence, often causes low level of public transit service with poor bus on-time performance and excessive passenger waiting time. To mitigate bus bunching, an accurate and real-time prediction method plays an important role. In this paper, we propose a supply-demand seq2seq model called SD-seq2seq to predict bus bunching using smart card data. Features from both supply and demand sides of bus service are taken into account, like bus stop type, dwelling time, passenger demand and type, and so on. Extensive experiments on multiple bus routes in real world demonstrate that our method outperforms other baseline methods. The proposed method is expected to provide useful online information of bus operation to both bus operators and passengers.", "IdName": "gong2020sd", "Citation": "", "Keywords": ""}, {"Name": "Exemplar-based layout fine-tuning for node-link diagrams", "Authors": ["Jiacheng Pan", "Wei Chen", "Xiaodong Zhao", "Shuyue Zhou", "Wei Zeng", "Minfeng Zhu", "Jian Chen", "Siwei Fu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.", "IdName": "pan2020exemplar", "Citation": "", "Keywords": ""}, {"Name": "Deep recognition of vanishing-point-constrained building planes in urban street views", "Authors": ["Zhiliang Zeng", "Mengyang Wu", "Wei Zeng", "Chi-Wing Fu"], "Sources": "IEEE Transactions on Image Processing 29", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper presents a new approach to recognizing vanishing-point-constrained building planes from a single image of street view. We first design a novel convolutional neural network (CNN) architecture that generates geometric segmentation of per-pixel orientations from a single street-view image. The network combines two-stream features of general visual cues and surface normals in gated convolution layers, and employs a deeply supervised loss that encapsulates multi-scale convolutional features. Our experiments on a new benchmark with fine-grained plane segmentations of real-world street views show that our network outperforms state-of-the-arts methods of both semantic and geometric segmentation. The pixel-wise segmentation exhibits coarse boundaries and discontinuities. We then propose to rectify the pixel-wise segmentation into perspectively-projected quads based on spatial proximity between?\u2026", "IdName": "zeng2020deep", "Citation": "", "Keywords": ""}, {"Name": "Modeling spatial nonstationarity via deformable convolutions for deep traffic flow prediction", "Authors": ["Wei Zeng", "Chengqiao Lin", "Kang Liu", "Juncong Lin", "Anthony KH Tung"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Deep neural networks are being increasingly used for short-term traffic flow prediction, which can be generally categorized as convolutional (CNNs) or graph neural networks (GNNs). CNNs are preferable for region-wise traffic prediction by taking advantage of localized spatial correlations, whilst GNNs achieves better performance for graph-structured traffic data. When applied to region-wise traffic prediction, CNNs typically partition an underlying territory into grid-like spatial units, and employ standard convolutions to learn spatial dependence among the units. However, standard convolutions with fixed geometric structures cannot fully model the nonstationary characteristics of local traffic flows. To overcome the deficiency, we introduce deformable convolution that augments the spatial sampling locations with additional offsets, to enhance the modeling capability of spatial nonstationarity. On this basis, we design a?\u2026", "IdName": "zeng2021modeling", "Citation": "", "Keywords": ""}, {"Name": "Let the chart spark: Embedding semantic context into chart with text-to-image generative model", "Authors": ["Shishi Xiao", "Suizi Huang", "Yue Lin", "Yilin Ye", "Wei Zeng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose  ChartSpark , a novel system that embeds semantic context into chart based on text-to-image generative models.  ChartSpark  generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground?\u2026", "IdName": "xiao2023let", "Citation": "", "Keywords": ""}, {"Name": "Creative and progressive interior color design with eye-tracked user preference", "Authors": ["Shihui Guo", "Yubin Shi", "Pintong Xiao", "Yinan Fu", "Juncong Lin", "Wei Zeng", "Tong-Yee Lee"], "Sources": "ACM transactions on computer-human interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Interior scene colorization is vastly demanded in areas such as personalized architecture design. Existing works either require manual efforts to colorize individual objects or conform to fixed color patterns automatically learned from prior knowledge, whilst neglecting user preference. Quantitatively identifying user preferences is challenging, particularly at the early stage of the design process. The 3D setup also presents new challenges as the inhabitant can observe from any possible viewpoint. We propose a representative view selection method based on visual attention and a progressive preference inference model. We particularly focus on the progressive integration of eye-tracked user preference, which enables the assistance in creativity support and allows the possibility of convergent thinking. A series of user studies have been conducted to validate the effectiveness of the proposed view selection method?\u2026", "IdName": "guo2023creative", "Citation": "", "Keywords": ""}, {"Name": "Modeling layout design for multiple-view visualization via Bayesian inference", "Authors": ["Lingdan Shao", "Zhe Chu", "Xi Chen", "Yanna Lin", "Wei Zeng"], "Sources": "Journal of Visualization", "PublishedYears": "2021", "Doi": "", "Abstracts": "Layout design for multiple-view visualization (MV) concerns primarily how to arrange views in layouts that are geometrically and topologically plausible. Guidelines for MV layout design suggest considerations on various design factors, including view (e.g., bar and line charts), viewport (e.g., mobile vs. desktop), and coordination (e.g., exploration vs. comparison), along with expertise and preference of the designer. Recent studies have revealed the diverse space of MV layout design via statistical analysis on empirical MVs, yet neglect the effects of those design factors. To address the gap, this work proposes to model the effects of design factors on MV layouts via Bayesian probabilistic inference. Specifically, we access three important properties of MV layout, i.e., maximum area ratio and weighted average aspect ratio as geometric metrics, and layout topology as a topological metric. We update the posterior?\u2026", "IdName": "shao2021modeling", "Citation": "", "Keywords": ""}, {"Name": "Semi-automatic layout adaptation for responsive multiple-view visualization design", "Authors": ["Wei Zeng", "Xi Chen", "Yihan Hou", "Lingdan Shao", "Zhe Chu", "Remco Chang"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multiple-view (MV) visualizations have become ubiquitous for visual communication and exploratory data visualization. However, most existing MV visualizations are designed for the desktop, which can be unsuitable for the continuously evolving displays of varying screen sizes. In this paper, we present a two-stage adaptation framework that supports the automated retargeting and semi-automated tailoring of a desktop MV visualization for rendering on devices with displays of varying sizes. First, we cast layout retargeting as an optimization problem and propose a simulated annealing technique that can automatically preserve the layout of multiple views. Second, we enable fine-tuning for the visual appearance of each view, using a rule-based auto configuration method complemented with an interactive interface for chart-oriented encoding adjustment. To demonstrate the feasibility and expressivity of our?\u2026", "IdName": "zeng2023semi", "Citation": "", "Keywords": ""}, {"Name": "WYTIWYR: A User Intent\u2010Aware Framework with Multi\u2010modal Inputs for Visualization Retrieval", "Authors": ["Shishi Xiao", "Yihan Hou", "Cheng Jin", "Wei Zeng"], "Sources": "Computer Graphics Forum", "PublishedYears": "2023", "Doi": "", "Abstracts": " Retrieving charts from a large corpus is a fundamental task that can benefit numerous applications such as visualization recommendations. The retrieved results are expected to conform to both explicit visual attributes (e.g., chart type, colormap) and implicit user intents (e.g., design style, context information) that vary upon application scenarios. However, existing example\u2010based chart retrieval methods are built upon non\u2010decoupled and low\u2010level visual features that are hard to interpret, while definition\u2010based ones are constrained to pre\u2010defined attributes that are hard to extend. In this work, we propose a new framework, namely WYTIWYR (What\u2010You\u2010Think\u2010Is\u2010What\u2010You\u2010Retrieve), that integrates user intents into the chart retrieval process. The framework consists of two stages: first, the Annotation stage disentangles the visual attributes within the query chart; and second, the Retrieval stage embeds the user's?\u2026", "IdName": "xiao2023wytiwyr", "Citation": "", "Keywords": ""}, {"Name": "VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models", "Authors": ["Zhan Wang", "Linping Yuan", "Liangwei Wang", "Bingchuan Jiang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2401.11923", "PublishedYears": "2024", "Doi": "", "Abstracts": "Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study?\u2026", "IdName": "wang2024virtuwander", "Citation": "", "Keywords": ""}, {"Name": "FloorLevel-Net: recognizing floor-level lines with height-attention-guided multi-task learning", "Authors": ["Mengyang Wu", "Wei Zeng", "Chi-Wing Fu"], "Sources": "IEEE Transactions on Image Processing 30", "PublishedYears": "2021", "Doi": "", "Abstracts": "The ability to recognize the position and order of the floor-level lines that divide adjacent building floors can benefit many applications, for example, urban augmented reality (AR). This work tackles the problem of locating floor-level lines in street-view images, using a supervised deep learning approach. Unfortunately, very little data is available for training such a network - current street-view datasets contain either semantic annotations that lack geometric attributes, or rectified facades without perspective priors. To address this issue, we first compile a new dataset and develop a new data augmentation scheme to synthesize training samples by harassing (i) the rich semantics of existing rectified facades and (ii) perspective priors of buildings in diverse street views. Next, we design FloorLevel-Net, a multi-task learning network that associates explicit features of building facades and implicit floor-level lines, along with?\u2026", "IdName": "wu2021floorlevel", "Citation": "", "Keywords": ""}, {"Name": "C2Ideas: Supporting Creative Interior Color Design Ideation with a Large Language Model", "Authors": ["Yihan Hou", "Manling Yang", "Hao Cui", "Lei Wang", "Jie Xu", "Wei Zeng"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Interior color design is a creative process that endeavors to allocate colors to furniture and other elements within an interior space. While much research focuses on generating realistic interior designs, these automated approaches often misalign with user intention and disregard design rationales. Informed by a need-finding preliminary study, we develop C2Ideas, an innovative system for designers to creatively ideate color schemes enabled by an intent-aligned and domain-oriented large language model. C2Ideas integrates a three-stage process: Idea Prompting stage distills user intentions into color linguistic prompts; Word-Color Association stage transforms the prompts into semantically and stylistically coherent color schemes; and Interior Coloring stage assigns colors to interior elements complying with design principles. We also develop an interactive interface that enables flexible user refinement and?\u2026", "IdName": "hou2024c2ideas", "Citation": "", "Keywords": ""}, {"Name": "TypeDance: Creating semantic typographic logos from image through personalized generation", "Authors": ["Shishi Xiao", "Liangwei Wang", "Xiaojuan Ma", "Wei Zeng"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Semantic typographic logos harmoniously blend typeface and imagery to represent semantic concepts while maintaining legibility. Conventional methods using spatial composition and shape substitution are hindered by the conflicting requirement for achieving seamless spatial fusion between geometrically dissimilar typefaces and semantics. While recent advances made AI generation of semantic typography possible, the end-to-end approaches exclude designer involvement and disregard personalized design. This paper presents TypeDance, an AI-assisted tool incorporating design rationales with the generative model for personalized semantic typographic logo design. It leverages combinable design priors extracted from uploaded image exemplars and supports type-imagery mapping at various structural granularity, achieving diverse aesthetic designs with flexible control. Additionally, we instantiate a?\u2026", "IdName": "xiao2024typedance", "Citation": "", "Keywords": ""}, {"Name": "The contemporary art of image search: Iterative user intent expansion via vision-language model", "Authors": ["Yilin Ye", "Qian Zhu", "Shishi Xiao", "Kang Zhang", "Wei Zeng"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "Image search is an essential and user-friendly method to explore vast galleries of digital images. However, existing image search methods heavily rely on proximity measurements like tag matching or image similarity, requiring precise user inputs for satisfactory results. To meet the growing demand for a contemporary image search engine that enables accurate comprehension of users' search intentions, we introduce an innovative user intent expansion framework. Our framework leverages visual-language models to parse and compose multi-modal user inputs to provide more accurate and satisfying results. It comprises two-stage processes: 1) a parsing stage that incorporates a language parsing module with large language models to enhance the comprehension of textual inputs, along with a visual parsing module that integrates an interactive segmentation module to swiftly identify detailed visual elements?\u2026", "IdName": "ye2024contemporary", "Citation": "", "Keywords": ""}, {"Name": "Generative AI for visualization: State of the art and future directions", "Authors": ["Yilin Ye", "Jianing Hao", "Yihan Hou", "Zhan Wang", "Shishi Xiao", "Yuyu Luo", "Wei Zeng"], "Sources": "Visual Informatics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Generative AI (GenAI) has witnessed remarkable progress in recent years and demonstrated impressive performance in various generation tasks in different domains such as computer vision and computational design. Many researchers have attempted to integrate GenAI into visualization framework, leveraging the superior generative capacity for different operations. Concurrently, recent major breakthroughs in GenAI like diffusion model and large language model have also drastically increase the potential of GenAI4VIS. From a technical perspective, this paper looks back on previous visualization studies leveraging GenAI and discusses the challenges and opportunities for future research. Specifically, we cover the applications of different types of GenAI methods including sequence, tabular, spatial and graph generation techniques for different tasks of visualization which we summarize into four major stages?\u2026", "IdName": "ye2024generative", "Citation": "", "Keywords": ""}, {"Name": "IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models", "Authors": ["Xingchen Zeng", "Ziyao Gao", "Yilin Ye", "Wei Zeng"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment?\u2026", "IdName": "zeng2024intenttuner", "Citation": "", "Keywords": ""}, {"Name": "TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations", "Authors": ["Jianing Hao", "Qing Shi", "Yilin Ye", "Wei Zeng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models. Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning. However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable. To improve on these limitations, this paper contributes a novel visual analytics framework, namely  TimeTuner , designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations. The system mainly consists of the following two-stage technique: We first leverage counterfactual?\u2026", "IdName": "hao2023timetuner", "Citation": "", "Keywords": ""}, {"Name": "Large-Scale Urban Multiple-Modal Transport Evacuation Model for Mass Gathering Events Considering Pedestrian and Public Transit System", "Authors": ["Jincheng Jiang", "Wei Tu", "Hui Kong", "Wei Zeng", "Rui Zhang", "Milan Konecny"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": "Mass gathering events occur frequently in urban regions. Not only serious traffic jams, but also safety risks are consequently caused. Although many evacuation strategies have been proposed, the spatiotemporal coordination issue of multiple-modal transport tools is not solved well to deal with the efficiency and safety risk during the traditional evacuations. This study presented a large-scale multi-modal transport macro-optimization evacuation model for urban mass gathering events. By taking full advantages of each kind of public transit vehicles and optimizing their spatiotemporal cooperation with pedestrian evacuation, our models can greatly improve the global evacuation efficiency. Experiments on a realistic event was carried to validate the proposed model. The numerical results demonstrated that, under the premise of no increasing additional vehicle supply, the efficiency of proposed multi-modal transport?\u2026", "IdName": "jiang2022large", "Citation": "", "Keywords": ""}, {"Name": "Make Interaction Situated: Designing User Acceptable Interaction for Situated Visualization in Public Environments", "Authors": ["Qian Zhu", "Zhuo Wang", "Wei Zeng", "Wai Tong", "Weiyue Lin", "Xiaojuan Ma"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Situated visualization blends data into the real world to fulfill individuals\u2019 contextual information needs. However, interacting with situated visualization in public environments faces challenges posed by users\u2019 acceptance and contextual constraints. To explore appropriate interaction design, we first conduct a formative study to identify users\u2019 needs for data and interaction. Informed by the findings, we summarize appropriate interaction modalities with eye-based, hand-based and spatially-aware object interaction for situated visualization in public environments. Then, through an iterative design process with six users, we explore and implement interactive techniques for activating and analyzing with situated visualization. To assess the effectiveness and acceptance of these interactions, we integrate them into an AR prototype and conduct a within-subjects study in public scenarios using conventional hand-only?\u2026", "IdName": "zhu2024make", "Citation": "", "Keywords": ""}, {"Name": "Understanding the Impact of Referent Design on Scale Perception in Immersive Data Visualization", "Authors": ["Yihan Hou", "Hao Cui", "Rongrong Chen", "Wei Zeng"], "Sources": "Extended Abstracts of the CHI Conference on Human Factors in Computing?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": " Referents are often used to enhance scale perception in immersive visualizations. Common referent designs include the considerations of referent layout (side-by-side vs. in-situ) and referent size (small vs. medium vs. large). This paper introduces a controlled user study to assess how different referent designs affect the efficiency and accuracy of scale perception across different data scales, on the performance of the size-matching task in the virtual environment. Our results reveal that in-situ layouts significantly enhance accuracy and confidence across various data scales, particularly with large referents. Linear regression analyses further confirm that in-situ layouts exhibit greater resilience to changes in data scale. For tasks requiring efficiency, medium-sized referents emerge as the preferred choice. Based on these findings, we offer design guidelines for selecting referent layouts and sizes in immersive?\u2026", "IdName": "hou2024understanding", "Citation": "", "Keywords": ""}, {"Name": "Learning High-Quality Navigation and Zooming on Omnidirectional Images in Virtual Reality", "Authors": ["Zidong Cao", "Zhan Wang", "Yexin Liu", "Yan-Pei Cao", "Ying Shan", "Wei Zeng", "Lin Wang"], "Sources": "arXiv preprint arXiv:2405.00351", "PublishedYears": "2024", "Doi": "", "Abstracts": "Viewing omnidirectional images (ODIs) in virtual reality (VR) represents a novel form of media that provides immersive experiences for users to navigate and interact with digital content. Nonetheless, this sense of immersion can be greatly compromised by a blur effect that masks details and hampers the user's ability to engage with objects of interest. In this paper, we present a novel system, called OmniVR, designed to enhance visual clarity during VR navigation. Our system enables users to effortlessly locate and zoom in on the objects of interest in VR. It captures user commands for navigation and zoom, converting these inputs into parameters for the Mobius transformation matrix. Leveraging these parameters, the ODI is refined using a learning-based algorithm. The resultant ODI is presented within the VR media, effectively reducing blur and increasing user engagement. To verify the effectiveness of our system, we first evaluate our algorithm with state-of-the-art methods on public datasets, which achieves the best performance. Furthermore, we undertake a comprehensive user study to evaluate viewer experiences across diverse scenarios and to gather their qualitative feedback from multiple perspectives. The outcomes reveal that our system enhances user engagement by improving the viewers' recognition, reducing discomfort, and improving the overall immersive experience. Our system makes the navigation and zoom more user-friendly.", "IdName": "cao2024learning", "Citation": "", "Keywords": ""}, {"Name": "CheetahTraj: Efficient Visualization for Large Trajectory Dataset With Quality Guarantee", "Authors": ["Qiaomu Shen", "Chaozu Zhang", "Xiao Yan", "Chuan Yang", "Dan Zeng", "Wei Zeng", "Bo Tang"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2024", "Doi": "", "Abstracts": "Visualizing large-scale trajectory dataset is a core subroutine for many applications. However, rendering all trajectories could result in severe visual clutter and incur long visualization delays due to large data volume. Naively sampling the trajectories reduces visualization time but usually harms visual quality, i.e., the generated visualizations may look substantially different from the exact ones without sampling. In this paper, we propose CheetahTraj, a principled sampling framework that achieves both high visualization quality and low visualization latency. We first define the  visual quality function  measuring the similarity between two visualizations, based on which we formulate the quality optimal sampling problem (QOSP). To solve QOSP, we design the  V isual  Q uality  G uaranteed  S ampling algorithms, which reduce visual clutter while guaranteeing visual quality by considering both trajectory data distribution?\u2026", "IdName": "shen2024cheetahtraj", "Citation": "", "Keywords": ""}, {"Name": "Antarctica Storytelling: Creating Interactive Story Maps for Polar Regions with Graphic-Based Approach", "Authors": ["Liangwei Wang", "Zhan Wang", "Xi Zhao", "Fugee Tsung", "Wei Zeng"], "Sources": "None", "PublishedYears": "2024", "Doi": "", "Abstracts": "Although story maps have gained popularity for storytelling related to spatial information, existing story maps authoring tools often fall short in delivering diverse narrative forms and struggle to accurately render polar regions due to the limitations of tile-based mapping. In this work, we introduce a graphic-based method to address these challenges, developing a framework specifically designed for creating story maps for polar regions. Our key contribution lies in offering heuristic strategies for story map design, emphasizing their role in effectively visualizing and disseminating polar culture. This paper outlines essential design tasks for story map creation and introduces three pivotal narrative strategies: attention cue, linkage of map with other visual elements, and cartographic interaction. Additionally, we emphasize the significance of storyboard design, focusing on aspects such as logical sequencing, temporal order, map scale and granularity, and interactive design. To validate the effectiveness of our story map design framework, we develop several story map cases centered around the exploration history of Antarctica. These examples highlight the diversity and interactivity in the story maps produced through our methodology. Finally, we explore the challenges and limitations encountered in the process of creating story maps, and from these observations, we identify prospective areas for further research.", "IdName": "wang2024antarctica", "Citation": "", "Keywords": ""}, {"Name": "MetroBUX: A Topology-Based Visual Analytics for Bus Operational Uncertainty EXploration", "Authors": ["Shishi Xiao", "Qing Shi", "Lingdan Shao", "Bo Du", "Yang Wang", "Qiaomu Shen", "Wei Zeng"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "In the public transportation system, punctuality benefits both bus operation and passengers\u2019 travel experience. However, uncertainty exists due to complex traffic conditions and heterogeneous driving behaviors. To analyze bus operational uncertainty, transport planners and bus operators need a tool that supports multi-granular modeling, spatio-temporal representation, and interactive exploration. To meet the requirement, we present MetroBUX, a visual analytics system for     us operational     ncertainty e    ploration. MetroBUX aligns daily bus trips and models stop-level uncertainty of bus arrival time. It has a consolidated interface with three main views: Map View for presenting the spatial distribution of uncertainty, Temporal View for tracking the evolution of uncertainty, and Trip View for inspecting uncertainty propagation. Specifically, MetroBUX enables integrated spatio-temporal analysis by connecting?\u2026", "IdName": "xiao2024metrobux", "Citation": "", "Keywords": ""}, {"Name": "LOOP Meditation: Enhancing Novice's VR Meditation Experience with Physical Movement", "Authors": ["Shihan Fu", "Liangliang Qiang", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Virtual reality (VR) and associated technologies have rapidly grew, creating new opportunities for improving mental health. In order to provide an immersive and concentrated meditation experience, this paper offers the idea of VR-assisted meditation, which integrates the advantages of VR technology with mindfulness techniques. The suggested technique, which is known as LOOP Meditation, is mainly aimed toward novice meditators and places a strong emphasis on the value of movement and breath awareness when meditating. Existing VR experiences and meditation applications sometimes ignore the value of including physical movement, which can improve mindful body sensations and maintain interest. By creating a software that incorporates body movement and breath sensing into virtual reality surroundings, LOOP Meditation addresses this gap. The LOOP Meditation design and implementation are?\u2026", "IdName": "fu2023loop", "Citation": "", "Keywords": ""}, {"Name": "Does Where You are Matter? A Visual Analytics System for COVID-19 Transmission Based on Social Hierarchical Perspective", "Authors": ["Jianing Hao", "Xibin Jiang", "Qing Shi", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " The COVID-19 pandemic requires multidisciplinary efforts to address its profound social and economic repercussions. Combining social hierarchical perspectives and a Multiple Coordinated View (MCV) visualization system, this paper depicts how social and physical residential environment shapes individuals\u2019 infection risk during such pandemic. Through analyzing the travel records of 8000+ confirmed cases in spatial and temporal channels, we identify that there exists segregation of virus transmission among different social classes and individuals from deprived neighborhoods exhibit a higher risk of the virus infection. Leveraging our proposed interactive visualization system, policymakers and stakeholders can make more informed decisions to effectively manage and contain the spread of infectious pandemics like COVID-19.", "IdName": "hao2023does", "Citation": "", "Keywords": ""}, {"Name": "The Rich, the Poor, and the Ugly: An Aesthetic-Perspective Assessment of NFT Values", "Authors": ["Yihan Chen", "Yilin Ye", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " The adoption of non-fungible tokens (NFTs) has revolutionized digital art transactions, providing artists with unprecedented opportunities to tokenize and monetize their generative creations, leading to increased scrutiny and demand within blockchain-oriented marketplaces. The pricing of NFT artworks, however, exhibits substantial variations within and across collections, influenced by various factors. This study aims to investigate the relationship between visual features and pricing, shedding light on the variations underlying the pricing of NFTs. First, measures of both computational aesthetics and visual complexity were applied to extract multi-faceted visual aesthetic features, encompassing aesthetic factors such as color and composition as well as complexity factors like entropy. Second, with extracted visual aesthetic features and preprocessed price data, the study proceeds to conduct correlation analysis within?\u2026", "IdName": "chen2023rich", "Citation": "", "Keywords": ""}, {"Name": "Storytelling in Frozen Frontier: Exploring Graphic-Based Approach for Creating Interactive Story Maps in Antarctica", "Authors": ["Liangwei Wang", "Zhan Wang", "Xi Zhao", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Story maps have been widely utilized to provide a visual and spatial framework for storytelling. However, existing story map tools have limitations in creating diverse narrative structures and providing interactive options, and cannot effectively render maps for polar regions due to tile-based mapping constraints. In this paper, we propose a graphic-based approach to overcome these challenges and develop a workflow for creating story maps specifically designed for polar regions. A primary contribution is to provide heuristic strategies for story map design and explore the potential of story maps in visualizing and disseminating polar culture. We summarize the main design tasks involved in story map creation and introduce three map-based visual narrative strategies, i.e., attention cue, linkage of map and other visual elements, and cartographic interaction. Additionally, we delve into the importance of storyboard design?\u2026", "IdName": "wang2023storytelling", "Citation": "", "Keywords": ""}, {"Name": "Everyone Can Be Picasso? A Computational Framework into the Myth of Human versus AI Painting", "Authors": ["Yilin Ye", "Rong Huang", "Kang Zhang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2304.07999", "PublishedYears": "2023", "Doi": "", "Abstracts": "The recent advances of AI technology, particularly in AI-Generated Content (AIGC), have enabled everyone to easily generate beautiful paintings with simple text description. With the stunning quality of AI paintings, it is widely questioned whether there still exists difference between human and AI paintings and whether human artists will be replaced by AI. To answer these questions, we develop a computational framework combining neural latent space and aesthetics features with visual analytics to investigate the difference between human and AI paintings. First, with categorical comparison of human and AI painting collections, we find that AI artworks show distributional difference from human artworks in both latent space and some aesthetic features like strokes and sharpness, while in other aesthetic features like color and composition there is less difference. Second, with individual artist analysis of Picasso, we show human artists' strength in evolving new styles compared to AI. Our findings provide concrete evidence for the existing discrepancies between human and AI paintings and further suggest improvements of AI art with more consideration of aesthetics and human artists' involvement.", "IdName": "ye2023everyone", "Citation": "", "Keywords": ""}, {"Name": "The Invisible Art of Storytelling and Media Production", "Authors": ["David Kei-Man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2020", "Doi": "", "Abstracts": " As the early filmmakers were magicians, cinema has developed from the early days of visible \u2018tricks\u2019 to invisible \u2018effects\u2019 [1]. As narrative cinema is to engage the audience with the story, many of the cinematic effects have been made to look invisible to the untrained eyes and ears. Film is both magical and make-believe. Like a magician who manages to hide his or her trick in a magic act, a filmmaker often hides his or her magic tricks from the audience. The invisible art of hiding cinematic effects is one of the important skills in media production. In storytelling, the hidden subtext can be as important as the visual text. This comprehensive article discusses the invisible art of storytelling and filmmaking.", "IdName": "yip2020invisible", "Citation": "", "Keywords": ""}, {"Name": "Visual Elements and Design Principles in Media Production", "Authors": ["David Kei-man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2020", "Doi": "", "Abstracts": " Visual elements such as dot, line, plane and color are the basic components of an image. By applying design principles to these visual elements in visual expression, the creative possibilities are infinite. Cinematic style is created by the filmmaker\u2019s control over the medium. Many visual styles of media projects are the application of the design principles to the visual elements. This systematic approach is not only confined to a shot composition but also to the whole visual structure of the work involving the development of both story and visual elements. This article analyzes this design approach to visual styles by discussing the works of several film masters as examples of how media project can use this approach to design and structure visual content. ", "IdName": "yip2020visual", "Citation": "", "Keywords": ""}, {"Name": "The hidden art of transmedia storytelling across cinema and video game", "Authors": ["David Kei-man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2021", "Doi": "", "Abstracts": " Various forms of digital media such as computer game have borrowed greatly from cinematic art and expression in terms of its world building and narrative structure [1, 2]. Cinema and video game share similar screen, character and time-based properties. They are time-based because they have time dimension in duration and structure. Time itself is invisible and intangible. Time-based media employs the dramatic art of storytelling and content design sometimes with hidden effects invisible to untrained eyes. Despite these characteristic similarities, cinema and video game as both time and character-based media do function and entertain differently. Narrative and experience design can be invisible and relevant to the creation and experience of cinematic storytelling and video game. This article aims to offer an extended perspective of transmedia storytelling [3, 4] by discussing both the differences and also?\u2026", "IdName": "yip2021hidden", "Citation": "", "Keywords": ""}, {"Name": "Cinematic Surrealism of the Interactive Virtual Space", "Authors": ["David Kei-Man Yip"], "Sources": "Reconceptualizing the Digital Humanities in Asia: New Representations of Art?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "  Surrealism has been a revolutionary art movement since the early 1920s. It transcended the boundaries of previous art movements by visualizing the uncanny subconscious mind and dream. Surrealism was also very influential in the development of cinema through the creative collaboration of legendary artist Salvador Dal\u00ed and cinema masters such as Luis Bu?uel, Alfred Hitchcock, and Walt Disney. Standing on the shoulders of these giants, this 4D project built on this collaborative tradition between surreal arts and cinematic arts by adding digital arts into this fusion of cinematic surrealism. Through the use of latest VR digital technology, this project expanded the cinematic experience from the 2D screen into a 3D environment with interactivity (3?+?1D) and invited users to be \u201cactive creative dreamers\u201d in a virtual dream designed in the style of Salvador Dal\u00ed with reference to the works of Ren\u00e9 Magritte?\u2026", "IdName": "yip2020cinematic", "Citation": "", "Keywords": ""}, {"Name": "Crossing of the Dream Fantasy: AI Technique Application for Visualizing a Fictional Character's Dream", "Authors": ["Jiayang Huang", "Yiran Chen", "David Yip"], "Sources": "2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This research explores the creative potential of artificial intelligence (AI) technology in artistic practice by testing various AI tools for their usability and capability as mediums of artistic expression. The project focuses on visualizing a dream of Mulan, a classic Chinese female figure, using the predictable features of AI generative models, with the aim of exploring whether such methods can produce amazing results. The project employs a collaborative process that combines different AI platforms to generate a range of materials, which are then with subjectively integrated into Mulan's fantasy dreamscape. The main conclusion drawn from the project is that artists guide abstract concepts and provide micro-interference, while AI produces concrete components and variations. The findings suggest that AI tools have the potential to transform artistic creation modes, and collaborative art creation can result in unique and?\u2026", "IdName": "huang2023crossing", "Citation": "", "Keywords": ""}, {"Name": "Between Passive Viewing and Active Choosing in Storytelling", "Authors": ["David Kei-Man Yip"], "Sources": "Human Factors in Communication of Design 49", "PublishedYears": "2022", "Doi": "", "Abstracts": "Since the dawn of the Internet, abundance of content and information is constantly being created and shared at the speed of light across different media. Media technologies have given us almost unlimited access to choose and interact with vast amount of content and information. We seem to be in active control in choosing what information we want to see and interact with on the internet. Ironically, with all this interactive freedom, most of us still prefer to watch their favorite TV programs or films passively on interactive media platforms. New technologies such as streaming TV have provided many new platforms to present passive content but to what extent how these new technologies have affected the form and shape of content remains a question. Simply by looking at the ratio of programs for traditional passive viewing vs. programs with interactive content, the audience has spoken by choosing to watch conventional content passively. Interacting with content is more than just choosing what pre-made content to watch, for that we always have our remote control. Interacting with content is about having our own say or control about the outcome or direction of a story (Crawford, 2013; Roth, 2015). Unlike what many media theories have predicted many years ago, interactive narrative has not become mainstream and would never replace conventional form of storytelling. Nevertheless, as more content is being delivered on mobile or personal computer in addition to the big screen, more interactive content will be made available in the foreseeable future. Many popular 4As video games have already mixed conventional storytelling elements with some?\u2026", "IdName": "yip2022between", "Citation": "", "Keywords": ""}, {"Name": "From Expanded Cinema to Extended Reality: How AI Can Expand and Extend Cinematic Experiences", "Authors": ["Junrong Song", "Bingyuan Wang", "Zeyu Wang", "David Kei-Man Yip"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " This paper explores the concept of expanded cinema and its relationship to extended reality (XR), focusing on the potential of artificial intelligence (AI) to expand and extend expressive possibilities. Expanded cinema refers to experimental film and multimedia art forms that challenge the conventions of traditional cinema by creating immersive and interactive experiences for audiences. XR, on the other hand, blurs the line between physical and virtual reality, offering immersive storytelling experiences. Both expanded cinema and XR aim to push the boundaries of traditional norms and create immersive experiences through the integration of technology, interactivity, and cross-sensory elements. The paper emphasizes the role of AI in optimizing 3D scene creation for XR and enhancing the overall experience through a case study. It also presents several AI-based techniques, such as generative models and AI?\u2026", "IdName": "song2023expanded", "Citation": "", "Keywords": ""}, {"Name": "Disruptive Innovations in Cinematic Storytelling from 2D to 3D", "Authors": ["David Kei-Man Yip"], "Sources": "Human Factors in Communication of Design 49", "PublishedYears": "2022", "Doi": "", "Abstracts": "Long before the digital revolution, communication theorist Marshall McLuhan has taught us about how the different forms of media can shape content with his famous book Medium is the Message (McLuhan et al. 1967). Over the past several decades, the theory has certainly stood the test of time. New media technologies have advanced so rapidly that many news form of content creation and expression have been made possible. New tools have offered new and diverse forms of storytelling. Nevertheless, new ways can never completely replace old ways; they just evolve and build upon the conventional practices. Do some of the new digital tools simply offer new way of doing the old thing with better technology or are they completely change the old way entirely? This paper aims to examine these issues from a historical perspective on a few past innovation disruptions that sent destructive shockwave to how things were in the beginning but brought new heights in the long run. This paper discusses historical and ongoing examples of innovation disruptions in cinematic storytelling in hopes of shedding light on the dynamic relation between art and technology. How have innovation disruptions changed the form and content of cinematic storytelling from 2D to 3D?", "IdName": "yip2022disruptive", "Citation": "", "Keywords": ""}, {"Name": "Dreaming Phantom in Immersive Experience: AIGC For Artistic Practice", "Authors": ["Jiayang Huang", "Yiran Chen", "David Yip"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Artificial Intelligent Generation Content (AIGC), has been widely disseminated in the fields of technology, academia, and the arts. This project explores the application of various AI tools and the visualization of dream experiences through multimedia. It utilizes AI-generated multimodal materials as perceptible dream content, employs light and mechanical installations to create immersive dream atmospheres, and employs a fictional AI-Mulan narrator to recount her dream story. Through artistic practice, it delves into Mulan's unconscious realm and conducts a psychoanalysis of a historical figure. It represents an interdisciplinary exploration of art and psychoanalysis through AI visualization.", "IdName": "huang2023dreaming", "Citation": "", "Keywords": ""}, {"Name": "Simonstown: An AI-facilitated Interactive Story of Love, Life, and Pandemic", "Authors": ["Bingyuan Wang", "Pinxi Zhu", "Hao Li", "David Kei-man Yip", "Zeyu Wang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We present an interactive story named Simonstown that demonstrates the love and life of ordinary people in the fictional setting of a fatal pandemic. Technically, the artwork integrates different Artificial Intelligence (AI) technologies in the whole production pipeline, including concept formation, creation, and presentation stages; artistically, this interactive film explores the relationship between human and environment in the contemporary context, especially infused with advanced technologies in daily life. The project serves as a demonstration and case study of AI-facilitated interactive storytelling, including better control with AI and how they integrate with live image projects, as well as using the stand-alone camera for real-time synchronization. Our results highlight the significant contribution of AI in visualizing intricate story branching, translation, and adaptation, presenting AI visualization as a distinct, specialized?\u2026", "IdName": "wang2023simonstown", "Citation": "", "Keywords": ""}, {"Name": "AI-Generated Content for Academic Visualization and Communication in Maker Education", "Authors": ["Qingqing Xing", "Chenghong Zheng", "Nan Zhu", "David Yip"], "Sources": "2023 3rd International Conference on Educational Technology (ICET)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Collaborative learning in higher education, such as the emerging makerspaces, has contributed to research on innovation and participant expertise. However, there is little research on knowledge management in makerspaces or how learners transfer their individual tacit knowledge in the collaborative space. In addition, the functionality of maker education to promote individualized and personalized learning still needs to be explored. This study is based on Chinese STEM graduate students\u2019 experiences with project-based learning in a Maker Education environment to test how AIGC tools help to acquire and transfer students\u2019 individual tacit knowledge. The sample was formed from 266 MPhil students taking the \"Design Thinking and Effective Academic Communication\" course in their first academic year at the world\u2019s first interdisciplinary university in southern China. The AIGC teaching intervention was based on?\u2026", "IdName": "xing2023ai", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Intersection of AI Art and Film: A Case Study of Giant", "Authors": ["Junrong Song", "David Yip"], "Sources": "2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Artificial intelligence (AI) has recently been used as a tool for various visual storytelling, but text-to-image models are a stochastic machine learning process that requires human intervention to assist creation better. As we all know, pre-visualization is an important stage in film production, involving subjective choices by the creators. This paper investigates how AI can assist filmmakers during the pre-production stage by generating mood boards from text. We propose a novel preproduction pipeline and guidelines that leverage text-to-image models to create visual previews of film projects. We also conduct a case study to validate and evaluate our approach's effectiveness. Our case study suggests that following the guidelines we have developed can assist filmmakers in generating mood boards that effectively convey the desired atmosphere of their projects and potentially contribute to enhancing the creative process?\u2026", "IdName": "song2023exploring", "Citation": "", "Keywords": ""}, {"Name": "XR is more than the sum of AR, VR, and MR", "Authors": ["David Yip"], "Sources": "Human Factors in Communication of Design", "PublishedYears": "2023", "Doi": "", "Abstracts": "Extended reality XR as the latest reality enhancement technology is regarded by many as the sum of augmented reality AR, virtual reality VR and mixed reality MR. However, this article argues otherwise. This article discusses the misconceptions of LED-based XR as the sum of AR, VR and MR. Although MR is still the combined form of AR and VR, their focuses are different from the LED-based XR. While the common features of AR, VR and MR mostly focus on the different treatments of environment as reality, their limitations lay on their inability to integrate real-time high resolution video of human figures. VR is also limited by computing power. More advanced motion and other sensory capture devices are not inaccessible to regular VR consumers. VR users can only see real-time characters or avatars in low polygon resolution. While MR is still the sum of AR and VR by combining virtual reality with the physical world?\u2026", "IdName": "yip2023xr", "Citation": "", "Keywords": ""}, {"Name": "The Dark Art of Transmedia Storytelling", "Authors": ["David Kei-man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2021", "Doi": "", "Abstracts": " As one of the major art movements, German Expressionism of composing unbalanced images of high contrast geometric line and shape can often be seen as a distinct visual style in cinema, animation and video game. This article focuses on this particular visual style highly influenced by German Expressionism and has a rather dark tone in form and content. The visual style of Film Noir has occupied a very important part of cinema history from the 40?s that tell sinister crime and mystery stories. Film Noir is also called Dark Cinema. This article discusses that Film Noir or its revived form Neo Noir as more than just a film and game genre. It is a visual linkage of digital content across media. As a visual narrative media, cinema has influenced many works of visual and time-based media in animation and game, which in turn also influence cinema. The worlds of Neo Noir created by computer animation and game?\u2026", "IdName": "yip2021dark", "Citation": "", "Keywords": ""}, {"Name": "Creative Base Design: A New Form of Self-Expression in Competitive Games", "Authors": ["David Kei-man Yip"], "Sources": "New Media Spectacles and Multimodal Creativity in a Globalised Asia: Art?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": " As part of everyday life, mobile phones allow gamers to play online games wherever and whenever they wish. Since the first generation of smartphones, many of the most popular applications have been mobile games, with base defence games among the favourites, particularly with the implementation of real-time Player vs. Player (PvP) features. To protect their bases, gamers must not only strategically place their defence weapons in the base to guard against unpredictable attack and looting, but also launch attacks to loot others\u2019 bases for upgrades. Each base houses necessities collected from lootings and upgrades, and also provides a personal space for the individual gamer\u2019s creative expression and visual statement. Although strategic base creation is part of the core gameplay, the creative design of the base is not. Between 2013 and 2018, the game Clash of Clans (COC) has inspired many creative?\u2026", "IdName": "yip2020creative", "Citation": "", "Keywords": ""}, {"Name": "A survey on ML4VIS: Applying machine learning advances to data visualization", "Authors": ["Qianwen Wang", "Zhutian Chen", "Yong Wang", "Huamin Qu"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Inspired by the great success of machine learning (ML), researchers have applied ML techniques to visualizations to achieve a better design, development, and evaluation of visualizations. This branch of studies, known as ML4VIS, is gaining increasing research attention in recent years. To successfully adapt ML techniques for visualizations, a structured understanding of the integration of ML4VIS is needed. In this article, we systematically survey 88 ML4VIS studies, aiming to answer two motivating questions:  \u201cwhat visualization processes can be assisted by ML?\u201d  and  \u201chow ML techniques can be used to solve visualization problems? \u201d This survey reveals seven main processes where the employment of ML techniques can benefit visualizations:  Data Processing4VIS, Data-VIS Mapping, Insight Communication, Style Imitation, VIS Interaction, VIS Reading, and User Profiling . The seven processes are related to?\u2026", "IdName": "wang2021survey", "Citation": "", "Keywords": ""}, {"Name": "Ai4vis: Survey on artificial intelligence approaches for data visualization", "Authors": ["Aoyu Wu", "Yun Wang", "Xinhuan Shu", "Dominik Moritz", "Weiwei Cui", "Haidong Zhang", "Dongmei Zhang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Visualizations themselves have become a data format. Akin to other data formats such as text and images, visualizations are increasingly created, stored, shared, and (re-)used with artificial intelligence (AI) techniques. In this survey, we probe the underlying vision of formalizing visualizations as an emerging data format and review the recent advance in applying AI techniques to visualization data (AI4VIS). We define visualization data as the digital representations of visualizations in computers and focus on data visualization (e.g., charts and infographics). We build our survey upon a corpus spanning ten different fields in computer science with an eye toward identifying important common interests. Our resulting taxonomy is organized around WHAT is visualization data and its representation, WHY and HOW to apply AI to visualization data. We highlight a set of common tasks that researchers apply to the?\u2026", "IdName": "wu2021ai4vis", "Citation": "", "Keywords": ""}, {"Name": "Dece: Decision explorer with counterfactual explanations for machine learning models", "Authors": ["Furui Cheng", "Yao Ming", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable-a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports?\u2026", "IdName": "cheng2020dece", "Citation": "", "Keywords": ""}, {"Name": "KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation", "Authors": ["Haotian Li", "Yong Wang", "Songheng Zhang", "Yangqiu Song", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data?\u2026", "IdName": "li2021kg4vis", "Citation": "", "Keywords": ""}, {"Name": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos", "Authors": ["Haipeng Zeng", "Xinhuan Shu", "Yanbang Wang", "Yong Wang", "Liguo Zhang", "Ting-Chuen Pong", "Huamin Qu"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Analyzing students\u2019 emotions from classroom videos can help both teachers and parents quickly know the engagement of students in class. The availability of high-definition cameras creates opportunities to record class scenes. However, watching videos is time-consuming, and it is challenging to gain a quick overview of the emotion distribution and find abnormal emotions. In this article, we propose  EmotionCues , a visual analytics system to easily analyze classroom videos from the perspective of emotion summary and detailed analysis, which integrates emotion recognition algorithms with visualizations. It consists of three coordinated views: a summary view depicting the overall emotions and their dynamic evolution, a character view presenting the detailed emotion status of an individual, and a video view enhancing the video analysis with further details. Considering the possible inaccuracy of emotion?\u2026", "IdName": "zeng2020emotioncues", "Citation": "", "Keywords": ""}, {"Name": "M2lens: Visualizing and explaining multimodal models for sentiment analysis", "Authors": ["Xingbo Wang", "Jianben He", "Zhihua Jin", "Muqiao Yang", "Yong Wang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Multimodal sentiment analysis aims to recognize people's attitudes from multiple communication channels such as verbal content (i.e., text), voice, and facial expressions. It has become a vibrant and important research topic in natural language processing. Much research focuses on modeling the complex intra- and inter-modal interactions between different communication channels. However, current multimodal models with strong performance are often deep-learning-based techniques and work like black boxes. It is not clear how models utilize multimodal information for sentiment predictions. Despite recent advances in techniques for enhancing the explainability of machine learning models, they often target unimodal scenarios (e.g., images, sentences), and little research has been done on explaining multimodal models. In this paper, we present an interactive visual analytics system, M2 Lens, to visualize and?\u2026", "IdName": "wang2021m2lens", "Citation": "", "Keywords": ""}, {"Name": "A visual analytics approach to facilitate the proctoring of online exams", "Authors": ["Haotian Li", "Min Xu", "Yong Wang", "Huan Wei", "Huamin Qu"], "Sources": "Proceedings of the 2021 CHI conference on human factors in computing systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " Online exams have become widely used to evaluate students\u2019 performance in mastering knowledge in recent years, especially during the pandemic of COVID-19. However, it is challenging to conduct proctoring for online exams due to the lack of face-to-face interaction. Also, prior research has shown that online exams are more vulnerable to various cheating behaviors, which can damage their credibility. This paper presents a novel visual analytics approach to facilitate the proctoring of online exams by analyzing the exam video records and mouse movement data of each student. Specifically, we detect and visualize suspected head and mouse movements of students in three levels of detail, which provides course instructors and teachers with convenient, efficient and reliable proctoring for online exams. Our extensive evaluations, including usage scenarios, a carefully-designed user study and expert interviews?\u2026", "IdName": "li2021visual", "Citation": "", "Keywords": ""}, {"Name": "Augmenting static visualizations with paparvis designer", "Authors": ["Zhutian Chen", "Wai Tong", "Qianwen Wang", "Benjamin Bach", "Huamin Qu"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper presents an authoring environment for augmenting static visualizations with virtual content in augmented reality.Augmenting static visualizations can leverage the best of both physical and digital worlds, but its creation currently involves different tools and devices, without any means to explicitly design and debug both static and virtual content simultaneously. To address these issues, we design an environment that seamlessly integrates all steps of a design and deployment workflow through its main features: i) an extension to Vega, ii) a preview, and iii) debug hints that facilitate valid combinations of static and augmented content. We inform our design through a design space with four ways to augment static visualizations. We demonstrate the expressiveness of our tool through examples, including books, posters, projections, wall-sized visualizations. A user study shows high user satisfaction of our?\u2026", "IdName": "chen2020augmenting", "Citation": "", "Keywords": ""}, {"Name": "Augmenting sports videos with viscommentator", "Authors": ["Zhutian Chen", "Shuainan Ye", "Xiangtong Chu", "Haijun Xia", "Hui Zhang", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level  (what the constituents are)  and clip-level  (how those constituents are organized) . We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis?\u2026", "IdName": "chen2021augmenting", "Citation": "", "Keywords": ""}, {"Name": "What makes a data-GIF understandable?", "Authors": ["Xinhuan Shu", "Aoyu Wu", "Junxiu Tang", "Benjamin Bach", "Yingcai Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "GIFs are enjoying increasing popularity on social media as a format for data-driven storytelling with visualization; simple visual messages are embedded in short animations that usually last less than 15 seconds and are played in automatic repetition. In this paper, we ask the question, \u201cWhat makes a data-GIF understandable?\u201d While other storytelling formats such as data videos, infographics, or data comics are relatively well studied, we have little knowledge about the design factors and principles for \u201cdata-GIFs\u201d. To close this gap, we provide results from semi-structured interviews and an online study with a total of 118 participants investigating the impact of design decisions on the understandability of data-GIFs. The study and our consequent analysis are informed by a systematic review and structured design space of 108 data-GIFs that we found online. Our results show the impact of design dimensions from our?\u2026", "IdName": "shu2020makes", "Citation": "", "Keywords": ""}, {"Name": "PRAISE-HK: A personalized real-time air quality informatics system for citizen participation in exposure and health risk management", "Authors": ["Wenwei Che", "H Christopher Frey", "Jimmy CH Fung", "Zhi Ning", "Huamin Qu", "Hong Kam Lo", "Lei Chen", "Tze-Wai Wong", "Michelle KM Wong", "Ophelia CW Lee", "David Carruthers", "Freeman Cheung", "Jimmy WM Chan", "David W Yeung", "Yik Him Fung", "Xuguo Zhang", "Jenny Stocker", "Christina Hood", "Tilman Leo Hohenberger", "King Wai Leung", "Phillip YK Louie", "Alison TY Li", "Li Sun", "Peng Wei", "Zhiyuan Li", "Yumiao Zhang", "Meilan Wang", "Qiaomu Shen", "Wei Huang", "Enoch Lee", "Ashraf Patwary", "Xiayu Lei", "Steven Cheng", "Md Shakhaoat Hossain", "Kimberly Tasha Jiayi Tang", "XiangQian Lao", "Rae Leung", "Denise Chan", "Ying Li", "Zibing Yuan", "Alexis KH Lau"], "Sources": "Sustainable Cities and Society 54", "PublishedYears": "2020", "Doi": "", "Abstracts": "Exposure to air pollutants causes a range of adverse health effects. These harmful effects occur whenever and wherever people come into direct contact with air pollution. Therefore, individual actions that reduce the frequency, duration, and severity of personal contact with air pollution can reduce health risks. We developed a system that empowers the public with personalized information on air quality and exposure health risk. This system, the Personalised Real-Time Air Quality Informatics System for Exposure \u2013 Hong Kong (PRAISE-HK, http://praise.ust.hk/), is embodied in an interactive mobile application. PRAISE-HK is based on real-time data on emissions, high resolution urban morphology, meteorology, physical and chemical processes affecting pollutant transport and transformations, extensive measurements of air pollution concentrations in typical locations such as homes, schools, offices, and?\u2026", "IdName": "che2020praise", "Citation": "", "Keywords": ""}, {"Name": "Visual analysis of discrimination in machine learning", "Authors": ["Qianwen Wang", "Zhenhua Xu", "Zhutian Chen", "Yong Wang", "Shixia Liu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in?\u2026", "IdName": "wang2020visual", "Citation": "", "Keywords": ""}, {"Name": "MultiVision: Designing analytical dashboards with deep learning based recommendation", "Authors": ["Aoyu Wu", "Yun Wang", "Mengyu Zhou", "Xinyi He", "Haidong Zhang", "Huamin Qu", "Dongmei Zhang"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model?\u2026", "IdName": "wu2021multivision", "Citation": "", "Keywords": ""}, {"Name": "A design space for applying the freytag's pyramid structure to data stories", "Authors": ["Leni Yang", "Xian Xu", "XingYu Lan", "Ziyan Liu", "Shunan Guo", "Yang Shi", "Huamin Qu", "Nan Cao"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Data stories integrate compelling visual content to communicate data insights in the form of narratives. The narrative structure of a data story serves as the backbone that determines its expressiveness, and it can largely influence how audiences perceive the insights. Freytag's Pyramid is a classic narrative structure that has been widely used in film and literature. While there are continuous recommendations and discussions about applying Freytag's Pyramid to data stories, little systematic and practical guidance is available on how to use Freytag's Pyramid for creating structured data stories. To bridge this gap, we examined how existing practices apply Freytag's Pyramid by analyzing stories extracted from 103 data videos. Based on our findings, we proposed a design space of narrative patterns, data flows, and visual communications to provide practical guidance on achieving narrative intents, organizing data facts?\u2026", "IdName": "yang2021design", "Citation": "", "Keywords": ""}, {"Name": "Mobilevisfixer: Tailoring web visualizations for mobile phones leveraging an explainable reinforcement learning framework", "Authors": ["Aoyu Wu", "Wai Tong", "Tim Dwyer", "Bongshin Lee", "Petra Isenberg", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view?\u2026", "IdName": "wu2020mobilevisfixer", "Citation": "", "Keywords": ""}, {"Name": "Infocolorizer: Interactive recommendation of color palettes for infographics", "Authors": ["Lin-Ping Yuan", "Ziqi Zhou", "Jian Zhao", "Yiqiu Guo", "Fan Du", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "When designing infographics, general users usually struggle with getting desired color palettes using existing infographic authoring tools, which sometimes sacrifice customizability, require design expertise, or neglect the influence of elements\u2019 spatial arrangement. We propose a data-driven method that provides flexibility by considering users\u2019 preferences, lowers the expertise barrier via automation, and tailors suggested palettes to the spatial layout of elements. We build a recommendation engine by utilizing deep learning techniques to characterize good color design practices from data, and further develop InfoColorizer, a tool that allows users to obtain color palettes for their infographics in an interactive and dynamic manner. To validate our method, we conducted a comprehensive four-part evaluation, including case studies, a controlled user study, a survey study, and an interview study. The results indicate that?\u2026", "IdName": "yuan2021infocolorizer", "Citation": "", "Keywords": ""}, {"Name": "Development of a back-propagation neural network and adaptive grey wolf optimizer algorithm for thermal comfort and energy consumption prediction and optimization", "Authors": ["Lu Li", "Yunfei Fu", "Jimmy CH Fung", "Huamin Qu", "Alexis KH Lau"], "Sources": "Energy and Buildings 253", "PublishedYears": "2021", "Doi": "", "Abstracts": "Heating ventilation and air conditioning (HVAC) systems provide a comfortable indoor thermal environment, but in the process of attaining appropriate indoor thermal comfort levels, they usually entail high energy consumptions. It is therefore imperative to balance thermal comfort value with energy consumption. However, such research currently faces two problems: one, it is difficult to obtain accurate parameters pertaining to the indoor environment of buildings, particularly near heat source areas; two, it is the diametrical nature of having to simultaneously maintain thermal comfort and keep energy consumption low. Therefore, this study aims to propose a rapid thermal comfort level prediction and optimization algorithm, as well as a method to minimize the energy consumption using only a computational fluid dynamic (CFD) database that is compact in size. Firstly, CFD is used to implement the database that stores?\u2026", "IdName": "li2021development", "Citation": "", "Keywords": ""}, {"Name": "A coupled computational fluid dynamics and back-propagation neural network-based particle swarm optimizer algorithm for predicting and optimizing indoor air quality", "Authors": ["Lu Li", "Yumiao Zhang", "Jimmy CH Fung", "Huamin Qu", "Alexis KH Lau"], "Sources": "Building and Environment 207", "PublishedYears": "2022", "Doi": "", "Abstracts": "In the modern era, people spend approximately 90% of their time in indoor settings, such as offices and residential buildings. As prolonged exposure to indoor environments can significantly impact health outcomes, it is important to ensure that good indoor air quality (IAQ) is achieved. The main obstacles to achieving effective control of IAQ are twofold. First, it is very difficult to monitor the values of IAQ parameters, especially within a person's breathing zone. Second, current heating ventilation and air conditioning systems are unable to rapidly predict and optimize IAQ. This study aims to obtain accurate indoor environmental parameters for rapidly predicting and optimizing IAQ. To achieve this, a computational fluid dynamics (CFD)-based back propagation neural network (BPNN) combined with a particle swarm optimizer (PSO) algorithm is proposed. Notably, the BPNN-PSO algorithm can rapidly predict and?\u2026", "IdName": "li2022coupled", "Citation": "", "Keywords": ""}, {"Name": "Vbridge: Connecting the dots between features and data to explain healthcare models", "Authors": ["Furui Cheng", "Dongyu Liu", "Fan Du", "Yanna Lin", "Alexandra Zytek", "Haomin Li", "Huamin Qu", "Kalyan Veeramachaneni"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Machine learning (ML) is increasingly applied to Electronic Health Records (EHRs) to solve clinical prediction tasks. Although many ML models perform promisingly, issues with model transparency and interpretability limit their adoption in clinical practice. Directly using existing explainable ML techniques in clinical settings can be challenging. Through literature surveys and collaborations with six clinicians with an average of 17 years of clinical experience, we identified three key challenges, including clinicians' unfamiliarity with ML features, lack of contextual information, and the need for cohort-level evidence. Following an iterative design process, we further designed and developed VBridge, a visual analytics tool that seamlessly incorporates ML explanations into clinicians' decision-making workflow. The system includes a novel hierarchical display of contribution-based feature explanations and enriched?\u2026", "IdName": "cheng2021vbridge", "Citation": "", "Keywords": ""}, {"Name": "Topology density map for urban data visualization and analysis", "Authors": ["Zezheng Feng", "Haotian Li", "Wei Zeng", "Shuang-Hua Yang", "Huamin Qu"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density?\u2026", "IdName": "feng2020topology", "Citation": "", "Keywords": ""}, {"Name": "Predicting student performance in interactive online question pools using mouse interaction features", "Authors": ["Huan Wei", "Haotian Li", "Meng Xia", "Yong Wang", "Huamin Qu"], "Sources": "Proceedings of the tenth international conference on learning analytics?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Modeling student learning and further predicting the performance is a well-established task in online learning and is crucial to personalized education by recommending different learning resources to different students based on their needs. Interactive online question pools (e.g., educational game platforms), an important component of online education, have become increasingly popular in recent years. However, most existing work on student performance prediction targets at online learning platforms with a well-structured curriculum, predefined question order and accurate knowledge tags provided by domain experts. It remains unclear how to conduct student performance prediction in interactive online question pools without such well-organized question orders or knowledge tags by experts. In this paper, we propose a novel approach to boost student performance prediction in interactive online question pools?\u2026", "IdName": "wei2020predicting", "Citation": "", "Keywords": ""}, {"Name": "Gnnlens: A visual analytics approach for prediction error diagnosis of graph neural networks", "Authors": ["Zhihua Jin", "Yong Wang", "Qianwen Wang", "Yao Ming", "Tengfei Ma", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph data and have achieved significant progress in graph analysis tasks (e.g., node classification) in recent years. However, similar to other deep neural networks like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), GNNs behave like a black box with their details hidden from model developers and users. It is therefore difficult to diagnose possible errors of GNNs. Despite many visual analytics studies being done on CNNs and RNNs, little research has addressed the challenges for GNNs. This paper fills the research gap with an interactive visual analysis tool,  GNNLens , to assist model developers and users in understanding and analyzing GNNs. Specifically, Parallel Sets View and Projection View enable users to quickly identify and validate error patterns in the set of wrong predictions; Graph View and?\u2026", "IdName": "jin2022gnnlens", "Citation": "", "Keywords": ""}, {"Name": "Visual interpretation of recurrent neural network on multi-dimensional time-series forecast", "Authors": ["Qiaomu Shen", "Yanhong Wu", "Yuzhe Jiang", "Wei Zeng", "KH Alexis", "Anna Vianova", "Huamin Qu"], "Sources": "2020 IEEE Pacific visualization symposium (PacificVis)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent attempts at utilizing visual analytics to interpret Recurrent Neural Networks (RNNs) mainly focus on natural language processing (NLP) tasks that take symbolic sequences as input. However, many real-world problems like environment pollution forecasting apply RNNs on sequences of multi-dimensional data where each dimension represents an individual feature with semantic meaning such as PM 2.5  and SO 2 . RNN interpretation on multi-dimensional sequences is challenging as users need to analyze what features are important at different time steps to better understand model behavior and gain trust in prediction. This requires effective and scalable visualization methods to reveal the complex many-to-many relations between hidden units and features. In this work, we propose a visual analytics system to interpret RNNs on multi-dimensional time-series forecasts. Specifically, to provide an overview to?\u2026", "IdName": "shen2020visual", "Citation": "", "Keywords": ""}, {"Name": "Voicecoach: Interactive evidence-based training for voice modulation skills in public speaking", "Authors": ["Xingbo Wang", "Haipeng Zeng", "Yong Wang", "Aoyu Wu", "Zhida Sun", "Xiaojuan Ma", "Huamin Qu"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "The modulation of voice properties, such as pitch, volume, and speed, is crucial for delivering a successful public speech. However, it is challenging to master different voice modulation skills. Though many guidelines are available, they are often not practical enough to be applied in different public speaking situations, especially for novice speakers. We present VoiceCoach, an interactive evidence-based approach to facilitate the effective training of voice modulation skills. Specifically, we have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically recommends good voice modulation examples from the dataset based on the similarity of both sentence structures and voice modulation skills. Immediate and quantitative visual feedback is provided to guide further improvement. The expert interviews?\u2026", "IdName": "wang2020voicecoach", "Citation": "", "Keywords": ""}, {"Name": "Misinformed by visualization: What do we learn from misinformative visualizations?", "Authors": ["Leo Yu\u2010Ho Lo", "Ayush Gupta", "Kento Shigyo", "Aoyu Wu", "Enrico Bertini", "Huamin Qu"], "Sources": "Computer Graphics Forum", "PublishedYears": "2022", "Doi": "", "Abstracts": " Data visualization is powerful in persuading an audience. However, when it is done poorly or maliciously, a visualization may become misleading or even deceiving. Visualizations give further strength to the dissemination of misinformation on the Internet. The visualization research community has long been aware of visualizations that misinform the audience, mostly associated with the terms \u201clie\u201d and \u201cdeceptive.\u201d Still, these discussions have focused only on a handful of cases. To better understand the landscape of misleading visualizations, we open\u2010coded over one thousand real\u2010world visualizations that have been reported as misleading. From these examples, we discovered 74 types of issues and formed a taxonomy of misleading elements in visualizations. We found four directions that the research community can follow to widen the discussion on misleading visualizations: (1) informal fallacies in?\u2026", "IdName": "lo2022misinformed", "Citation": "", "Keywords": ""}, {"Name": "Dashbot: Insight-driven dashboard generation based on deep reinforcement learning", "Authors": ["Dazhen Deng", "Aoyu Wu", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Analytical dashboards are popular in business intelligence to facilitate insight discovery with multiple charts. However, creating an effective dashboard is highly demanding, which requires users to have adequate data analysis background and be familiar with professional tools, such as Power BI. To create a dashboard, users have to configure charts by selecting data columns and exploring different chart combinations to optimize the communication of insights, which is trial-and-error. Recent research has started to use deep learning methods for dashboard generation to lower the burden of visualization creation. However, such efforts are greatly hindered by the lack of large-scale and high-quality datasets of dashboards. In this work, we propose using deep reinforcement learning to generate analytical dashboards that can use well-established visualization knowledge and the estimation capacity of reinforcement?\u2026", "IdName": "deng2022dashbot", "Citation": "", "Keywords": ""}, {"Name": "Interactive visual exploration of longitudinal historical career mobility data", "Authors": ["Yifang Wang", "Hongye Liang", "Xinhuan Shu", "Jiachen Wang", "Ke Xu", "Zikun Deng", "Cameron Campbell", "Bijia Chen", "Yingcai Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "The increased availability of quantitative historical datasets has provided new research opportunities for multiple disciplines in social science. In this article, we work closely with the constructors of a new dataset, CGED-Q (China Government Employee Database-Qing), that records the career trajectories of over 340,000 government officials in the Qing bureaucracy in China from 1760 to 1912. We use these data to study career mobility from a historical perspective and understand social mobility and inequality. However, existing statistical approaches are inadequate for analyzing career mobility in this historical dataset with its fine-grained attributes and long time span, since they are mostly hypothesis-driven and require substantial effort. We propose  CareerLens , an interactive visual analytics system for assisting experts in exploring, understanding, and reasoning from historical career data. With  CareerLens?\u2026", "IdName": "wang2021interactive", "Citation": "", "Keywords": ""}, {"Name": "Peer-inspired student performance prediction in interactive online question pools with graph neural network", "Authors": ["Haotian Li", "Huan Wei", "Yong Wang", "Yangqiu Song", "Huamin Qu"], "Sources": "Proceedings of the 29th ACM International Conference on Information?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Student performance prediction is critical to online education. It can benefit many downstream tasks on online learning platforms, such as estimating dropout rates, facilitating strategic intervention, and enabling adaptive online learning. Interactive online question pools provide students with interesting interactive questions to practice their knowledge in online education. However, little research has been done on student performance prediction in interactive online question pools. Existing work on student performance prediction targets at online learning platforms with predefined course curriculum and accurate knowledge labels like MOOC platforms, but they are not able to fully model knowledge evolution of students in interactive online question pools. In this paper, we propose a novel approach using Graph Neural Networks (GNNs) to achieve better student performance prediction in interactive online question?\u2026", "IdName": "li2020peer", "Citation": "", "Keywords": ""}, {"Name": "Dfseer: A visual analytics approach to facilitate model selection for demand forecasting", "Authors": ["Dong Sun", "Zezheng Feng", "Yuanzhe Chen", "Yong Wang", "Jia Zeng", "Mingxuan Yuan", "Ting-Chuen Pong", "Huamin Qu"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Selecting an appropriate model to forecast product demand is critical to the manufacturing industry. However, due to the data complexity, market uncertainty and users' demanding requirements for the model, it is challenging for demand analysts to select a proper model. Although existing model selection methods can reduce the manual burden to some extent, they often fail to present model performance details on individual products and reveal the potential risk of the selected model. This paper presents DFSeer, an interactive visualization system to conduct reliable model selection for demand forecasting based on the products with similar historical demand. It supports model comparison and selection with different levels of details. Besides, it shows the difference in model performance on similar products to reveal the risk of model selection and increase users' confidence in choosing a forecasting model. Two case?\u2026", "IdName": "sun2020dfseer", "Citation": "", "Keywords": ""}, {"Name": "Learning to automate chart layout configurations using crowdsourced paired comparison", "Authors": ["Aoyu Wu", "Liwenhan Xie", "Bongshin Lee", "Yun Wang", "Weiwei Cui", "Huamin Qu"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " We contribute a method to automate parameter configurations for chart layouts by learning from human preferences. Existing charting tools usually determine the layout parameters using predefined heuristics, producing sub-optimal layouts. People can repeatedly adjust multiple parameters (e.g., chart size, gap) to achieve visually appealing layouts. However, this trial-and-error process is unsystematic and time-consuming, without a guarantee of improvement. To address this issue, we develop Layout Quality Quantifier (LQ2), a machine learning model that learns to score chart layouts from paired crowdsourcing data. Combined with optimization techniques, LQ2 recommends layout parameters that improve the charts\u2019 layout quality. We apply LQ2 on bar charts and conduct user studies to evaluate its effectiveness by examining the quality of layouts it produces. Results show that LQ2 can generate more visually?\u2026", "IdName": "wu2021learning", "Citation": "", "Keywords": ""}, {"Name": "Survey on artificial intelligence approaches for visualization data", "Authors": ["Aoyu Wu", "Yun Wang", "Xinhuan Shu", "Dominik Moritz", "Weiwei Cui", "Haidong Zhang", "Dongmei Zhang", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2102.01330 2", "PublishedYears": "2021", "Doi": "", "Abstracts": "", "IdName": "wu2021survey", "Citation": "", "Keywords": ""}, {"Name": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "Authors": ["Yating Lin", "Kamkwai Wong", "Yong Wang", "Rong Zhang", "Bo Dong", "Huamin Qu", "Qinghua Zheng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related?\u2026", "IdName": "lin2020taxthemis", "Citation": "", "Keywords": ""}, {"Name": "Using information visualization to promote students' reflection on\" gaming the system\" in online learning", "Authors": ["Meng Xia", "Yuya Asano", "Joseph Jay Williams", "Huamin Qu", "Xiaojuan Ma"], "Sources": "Proceedings of the seventh ACM conference on Learning@ Scale", "PublishedYears": "2020", "Doi": "", "Abstracts": "\"Gaming the system\" is the phenomenon where students attempt to perform well by systematically exploiting properties of the learning system, rather than learning the material. Frequent gaming tends to cause bad learning outcomes. Though existing studies tackle the problem by redesigning the system workflow to change students' behaviors automatically, gaming students discover new ways to game. We instead propose a novel way, reflective nudge, to reflectively influence students' attitudes by conveying reasons not to game via information visualizations. Particularly, we identify three common gaming contexts and involve students and instructors in co-designing three context-specific persuasive visualizations. We deploy our information visualizations in a real online learning platform. Through embedded surveys and in-person interviews, we find some evidence that the designs can promote students' reflection?\u2026", "IdName": "xia2020using", "Citation": "", "Keywords": ""}, {"Name": "Xnli: Explaining and diagnosing nli-based visual data analysis", "Authors": ["Yingchaojie Feng", "Xingbo Wang", "Bo Pan", "Kam Kwai Wong", "Yi Ren", "Shi Liu", "Zihan Yan", "Yuxin Ma", "Huamin Qu", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Natural language interfaces (NLIs) enable users to flexibly specify analytical intentions in data visualization. However, diagnosing the visualization results without understanding the underlying generation process is challenging. Our research explores how to provide explanations for NLIs to help users locate the problems and further revise the queries. We present XNLI, an explainable NLI system for visual data analysis. The system introduces a Provenance Generator to reveal the detailed process of visual transformations, a suite of interactive widgets to support error adjustments, and a Hint Generator to provide query revision hints based on the analysis of user queries and interactions. Two usage scenarios of XNLI and a user study verify the effectiveness and usability of the system. Results suggest that XNLI can significantly enhance task accuracy without interrupting the NLI-based analysis process.", "IdName": "feng2023xnli", "Citation": "", "Keywords": ""}, {"Name": "Structure-aware visualization retrieval", "Authors": ["Haotian Li", "Yong Wang", "Aoyu Wu", "Huan Wei", "Huamin Qu"], "Sources": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " With the wide usage of data visualizations, a huge number of Scalable Vector Graphic?(SVG)-based visualizations have been created and shared online. Accordingly, there has been an increasing interest in exploring how to retrieve perceptually similar visualizations from a large corpus, since it can benefit various downstream applications such as visualization recommendation. Existing methods mainly focus on the visual appearance of visualizations by regarding them as bitmap images. However, the structural information intrinsically existing in SVG-based visualizations is ignored. Such structural information can delineate the spatial and hierarchical relationship among visual elements, and characterize visualizations thoroughly from a new perspective. This paper presents a structure-aware method to advance the performance of visualization retrieval by collectively considering both the visual and structural?\u2026", "IdName": "li2022structure", "Citation": "", "Keywords": ""}, {"Name": "Explaining with examples: Lessons learned from crowdsourced introductory description of information visualizations", "Authors": ["Leni Yang", "Cindy Xiong", "Jason K Wong", "Aoyu Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Data visualizations have been increasingly used in oral presentations to communicate data patterns to the general public. Clear verbal introductions of visualizations to explain how to interpret the visually encoded information are essential to convey the takeaways and avoid misunderstandings. We contribute a series of studies to investigate how to effectively introduce visualizations to the audience with varying degrees of visualization literacy. We begin with understanding how people are introducing visualizations. We crowdsource 110 introductions of visualizations and categorize them based on their content and structures. From these crowdsourced introductions, we identify different introduction strategies and generate a set of introductions for evaluation. We conduct experiments to systematically compare the effectiveness of different introduction strategies across four visualizations with 1,080 participants. We?\u2026", "IdName": "yang2021explaining", "Citation": "", "Keywords": ""}, {"Name": "Cohortva: A visual analytic system for interactive exploration of cohorts based on historical data", "Authors": ["Wei Zhang", "Jason K Wong", "Xumeng Wang", "Youcheng Gong", "Rongchen Zhu", "Kai Liu", "Zihan Yan", "Siwei Tan", "Huamin Qu", "Siming Chen", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In history research, cohort analysis seeks to identify social structures and figure mobilities by studying the group-based behavior of historical figures. Prior works mainly employ automatic data mining approaches, lacking effective visual explanation. In this paper, we present CohortVA, an interactive visual analytic approach that enables historians to incorporate expertise and insight into the iterative exploration process. The kernel of CohortVA is a novel identification model that generates candidate cohorts and constructs cohort features by means of pre-built knowledge graphs constructed from large-scale history databases. We propose a set of coordinated views to illustrate identified cohorts and features coupled with historical events and figure profiles. Two case studies and interviews with historians demonstrate that CohortVA can greatly enhance the capabilities of cohort identifications, figure authentications, and?\u2026", "IdName": "zhang2022cohortva", "Citation": "", "Keywords": ""}, {"Name": "Deep colormap extraction from visualizations", "Authors": ["Lin-Ping Yuan", "Wei Zeng", "Siwei Fu", "Zhiliang Zeng", "Haotian Li", "Chi-Wing Fu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "This article presents a new approach based on deep learning to automatically extract colormaps from visualizations. After summarizing colors in an input visualization image as a Lab color histogram, we pass the histogram to a pre-trained deep neural network, which learns to predict the colormap that produces the visualization. To train the network, we create a new dataset of   64K visualizations that cover a wide variety of data distributions, chart types, and colormaps. The network adopts an atrous spatial pyramid pooling module to capture color features at multiple scales in the input color histograms. We then classify the predicted colormap as discrete or continuous, and refine the predicted colormap based on its color histogram. Quantitative comparisons to existing methods show the superior performance of our approach on both synthetic and real-world visualizations. We further demonstrate the utility of our?\u2026", "IdName": "yuan2021deep", "Citation": "", "Keywords": ""}, {"Name": "Dancingwords: exploring animated word clouds to tell stories", "Authors": ["Xinhuan Shu", "Jiang Wu", "Xinke Wu", "Hongye Liang", "Weiwei Cui", "Yingcai Wu", "Huamin Qu"], "Sources": "Journal of Visualization 24", "PublishedYears": "2021", "Doi": "", "Abstracts": " Abstract By encoding semantic relations into relative positions, word clouds have shown the capability to deliver richer messages than purely visualizing word frequencies. Existing studies mainly focus on layout algorithms that cluster related words, preserve temporal coherence, and optimize spatial shapes. However, they cannot fully convey multiple relations among words and their evolvement through relative positions and static representations. In this paper, we explore animated word clouds that take advantage of storytelling strategies to present interactions between words and show the dynamic process of content changes, thus communicating the underlying stories. We initially create several exemplars of animated word clouds with designers through a structured iterative design process. These exemplars lead to a preliminary design space that distills essential narrative elements with design?\u2026", "IdName": "shu2021dancingwords", "Citation": "", "Keywords": ""}, {"Name": "Qlens: Visual analytics of multi-step problem-solving behaviors for improving question design", "Authors": ["Meng Xia", "Reshika Palaniyappan Velumani", "Yong Wang", "Huamin Qu", "Xiaojuan Ma"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "With the rapid development of online education in recent years, there has been an increasing number of learning platforms that provide students with multi-step questions to cultivate their problem-solving skills. To guarantee the high quality of such learning materials, question designers need to inspect how students' problem-solving processes unfold step by step to infer whether students' problem-solving logic matches their design intent. They also need to compare the behaviors of different groups (e.g., students from different grades) to distribute questions to students with the right level of knowledge. The availability of fine-grained interaction data, such as mouse movement trajectories from the online platforms, provides the opportunity to analyze problem-solving behaviors. However, it is still challenging to interpret, summarize, and compare the high dimensional problem-solving sequence data. In this paper, we?\u2026", "IdName": "xia2020qlens", "Citation": "", "Keywords": ""}, {"Name": "Seek for success: A visualization approach for understanding the dynamics of academic careers", "Authors": ["Yifang Wang", "Tai-Quan Peng", "Huihua Lu", "Haoren Wang", "Xiao Xie", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "How to achieve academic career success has been a long-standing research question in social science research. With the growing availability of large-scale well-documented academic profiles and career trajectories, scholarly interest in career success has been reinvigorated, which has emerged to be an active research domain called the Science of Science (i.e., SciSci). In this study, we adopt an innovative dynamic perspective to examine how individual and social factors will influence career success over time. We propose  ACSeeker , an interactive visual analytics approach to explore the potential factors of success and how the influence of multiple factors changes at different stages of academic careers. We first applied a Multi-factor Impact Analysis framework to estimate the effect of different factors on academic career success over time. We then developed a visual analytics system to understand the dynamic?\u2026", "IdName": "wang2021seek", "Citation": "", "Keywords": ""}, {"Name": "In defence of visual analytics systems: Replies to critics", "Authors": ["Aoyu Wu", "Dazhen Deng", "Furui Cheng", "Yingcai Wu", "Shixia Liu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "The last decade has witnessed many visual analytics (VA) systems that make successful applications to wide-ranging domains like urban analytics and explainable AI. However, their research rigor and contributions have been extensively challenged within the visualization community. We come in defence of VA systems by contributing two interview studies for gathering critics and responses to those criticisms. First, we interview 24 researchers to collect criticisms the review comments on their VA work. Through an iterative coding and refinement process, the interview feedback is summarized into a list of 36 common criticisms. Second, we interview 17 researchers to validate our list and collect their responses, thereby discussing implications for defending and improving the scientific values and rigor of VA systems. We highlight that the presented knowledge is deep, extensive, but also imperfect, provocative, and?\u2026", "IdName": "wu2022defence", "Citation": "", "Keywords": ""}, {"Name": "Why is ai not a panacea for data workers? an interview study on human-ai collaboration in data storytelling", "Authors": ["Haotian Li", "Yun Wang", "Q Vera Liao", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2304.08366", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data storytelling plays an important role in data workers' daily jobs since it boosts team collaboration and public communication. However, to make an appealing data story, data workers spend tremendous efforts on various tasks, including outlining and styling the story. Recently, a growing research trend has been exploring how to assist data storytelling with advanced artificial intelligence (AI). However, existing studies may focus on individual tasks in the workflow of data storytelling and do not reveal a complete picture of humans' preference for collaborating with AI. To better understand real-world needs, we interviewed eighteen data workers from both industry and academia to learn where and how they would like to collaborate with AI. Surprisingly, though the participants showed excitement about collaborating with AI, many of them also expressed reluctance and pointed out nuanced reasons. Based on their responses, we first characterize stages and tasks in the practical data storytelling workflows and the desired roles of AI. Then the preferred collaboration patterns in different tasks are identified. Next, we summarize the interviewees' reasons why and why not they would like to collaborate with AI. Finally, we provide suggestions for human-AI collaborative data storytelling to hopefully shed light on future related research.", "IdName": "li2023ai", "Citation": "", "Keywords": ""}, {"Name": "DMiner: Dashboard design mining and recommendation", "Authors": ["Yanna Lin", "Haotian Li", "Aoyu Wu", "Yong Wang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Dashboards, which comprise multiple views on a single display, help analyze and communicate multiple perspectives of data simultaneously. However, creating effective and elegant dashboards is challenging since it requires careful and logical arrangement and coordination of multiple visualizations. To solve the problem, we propose a data-driven approach for mining design rules from dashboards and automating dashboard organization. Specifically, we focus on two prominent aspects of the organization:  arrangement , which describes the position, size, and layout of each view in the display space; and  coordination , which indicates the interaction between pairwise views. We build a new dataset containing 854 dashboards crawled online, and develop feature engineering methods for describing the single views and view-wise relationships in terms of data, encoding, layout, and interactions. Further, we?\u2026", "IdName": "lin2023dashboard", "Citation": "", "Keywords": ""}, {"Name": "From \u2018wow\u2019to \u2018why\u2019: Guidelines for creating the opening of a data video with cinematic styles", "Authors": ["Xian Xu", "Leni Yang", "David Yip", "Mingming Fan", "Zheng Wei", "Huamin Qu"], "Sources": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Data videos are an increasingly popular storytelling form. The opening of a data video critically influences its success as the opening either attracts the audience to continue watching or bores them to abandon watching. However, little is known about how to create an attractive opening. We draw inspiration from the openings of famous films to facilitate designing data video openings. First, by analyzing over 200 films from several sources, we derived six primary cinematic opening styles adaptable to data videos. Then, we consulted eight experts from the film industry to formulate 28 guidelines. To validate the usability and effectiveness of the guidelines, we asked participants to create data video openings with and without the guidelines, which were then evaluated by experts and the general public. Results showed that the openings designed with the guidelines were perceived to be more attractive, and the?\u2026", "IdName": "xu2022wow", "Citation": "", "Keywords": ""}, {"Name": "Numgpt: Improving numeracy ability of generative pre-trained models", "Authors": ["Zhihua Jin", "Xin Jiang", "Xingbo Wang", "Qun Liu", "Yong Wang", "Xiaozhe Ren", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2109.03137", "PublishedYears": "2021", "Doi": "", "Abstracts": "Existing generative pre-trained language models (e.g., GPT) focus on modeling the language structure and semantics of general texts. However, those models do not consider the numerical properties of numbers and cannot perform robustly on numerical reasoning tasks (e.g., math word problems and measurement estimation). In this paper, we propose NumGPT, a generative pre-trained model that explicitly models the numerical properties of numbers in texts. Specifically, it leverages a prototype-based numeral embedding to encode the mantissa of the number and an individual embedding to encode the exponent of the number. A numeral-aware loss function is designed to integrate numerals into the pre-training objective of NumGPT. We conduct extensive experiments on four different datasets to evaluate the numeracy ability of NumGPT. The experiment results show that NumGPT outperforms baseline models (e.g., GPT and GPT with DICE) on a range of numerical reasoning tasks such as measurement estimation, number comparison, math word problems, and magnitude classification. Ablation studies are also conducted to evaluate the impact of pre-training and model hyperparameters on the performance.", "IdName": "jin2021numgpt", "Citation": "", "Keywords": ""}, {"Name": "Notable: On-the-fly assistant for data storytelling in computational notebooks", "Authors": ["Haotian Li", "Lu Ying", "Haidong Zhang", "Yingcai Wu", "Huamin Qu", "Yun Wang"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Computational notebooks are widely used for data analysis. Their interleaved displays of code and execution results (e.g., visualizations) are welcomed since they enable iterative analysis and preserve the exploration process. However, the communication of data findings remains challenging in computational notebooks. Users have to carefully identify useful findings from useless ones, document them with texts and visual embellishments, and then organize them in different tools. Such workflow greatly increases their workload, according to our interviews with practitioners. To address the challenge, we designed Notable to offer on-the-fly assistance for data storytelling in computational notebooks. It provides intelligent support to minimize the work of documenting and organizing data findings and diminishes the cost of switching between data exploration and storytelling. To evaluate Notable, we conducted a user?\u2026", "IdName": "li2023notable", "Citation": "", "Keywords": ""}, {"Name": "Persua: A visual interactive system to enhance the persuasiveness of arguments in online discussion", "Authors": ["Meng Xia", "Qian Zhu", "Xingbo Wang", "Fei Nie", "Huamin Qu", "Xiaojuan Ma"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Persuading people to change their opinions is a common practice in online discussion forums on topics ranging from political campaigns to relationship consultation. Enhancing people's ability to write persuasive arguments could not only practice their critical thinking and reasoning but also contribute to the effectiveness and civility in online communication. It is, however, not an easy task in online discussion settings where written words are the primary communication channel. In this paper, we derived four design goals for a tool that helps users improve the persuasiveness of arguments in online discussions through a survey with 123 online forum users and interviews with five debating experts. To satisfy these design goals, we analyzed and built a labeled dataset of fine-grained persuasive strategies (i.e., logos, pathos, ethos, and evidence) in 164 arguments with high ratings on persuasiveness from?\u2026", "IdName": "xia2022persua", "Citation": "", "Keywords": ""}, {"Name": "Storyfier: Exploring Vocabulary Learning Support with Text Generation Models", "Authors": ["Zhenhui Peng", "Xingbo Wang", "Qiushi Han", "Junkai Zhu", "Xiaojuan Ma", "Huamin Qu"], "Sources": "Proceedings of the 36th Annual ACM Symposium on User Interface Software and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Vocabulary learning support tools have widely exploited existing materials, e.g., stories or video clips, as contexts to help users memorize each target word. However, these tools could not provide a coherent context for any target words of learners\u2019 interests, and they seldom help practice word usage. In this paper, we work with teachers and students to iteratively develop Storyfier, which leverages text generation models to enable learners to read a generated story that covers any target words, conduct a story cloze test, and use these words to write a new story with adaptive AI assistance. Our within-subjects study (N=28) shows that learners generally favor the generated stories for connecting target words and writing assistance for easing their learning workload. However, in the read-cloze-write learning sessions, participants using Storyfier perform worse in recalling and using target words than learning with a?\u2026", "IdName": "peng2023storyfier", "Citation": "", "Keywords": ""}, {"Name": "Towards an understanding of distributed asymmetric collaborative visualization on problem-solving", "Authors": ["Wai Tong", "Meng Xia", "Kam Kwai Wong", "Doug A Bowman", "Ting-Chuen Pong", "Huamin Qu", "Yalong Yang"], "Sources": "2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper provided empirical knowledge of the user experience for using collaborative visualization in a distributed asymmetrical setting through controlled user studies. With the ability to access various computing devices, such as Virtual Reality (VR) head-mounted displays, scenarios emerge when collaborators have to or prefer to use different computing environments in different places. However, we still lack an understanding of using VR in an asymmetric setting for collaborative visualization. To get an initial understanding and better inform the designs for asymmetric systems, we first conducted a formative study with 12 pairs of participants. All participants collaborated in asymmetric (PC-VR) and symmetric settings (PC-PC and VR-VR). We then improved our asymmetric design based on the key findings and observations from the first study. Another ten pairs of participants collaborated with enhanced PC-VR?\u2026", "IdName": "tong2023towards", "Citation": "", "Keywords": ""}, {"Name": "Anchorage: Visual analysis of satisfaction in customer service videos via anchor events", "Authors": ["Kam Kwai Wong", "Xingbo Wang", "Yong Wang", "Jianben He", "Rong Zhang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Delivering customer services through video communications has brought new opportunities to analyze customer satisfaction for quality management. However, due to the lack of reliable self-reported responses, service providers are troubled by the inadequate estimation of customer services and the tedious investigation into multimodal video recordings. We introduce  Anchorage , a visual analytics system to evaluate customer satisfaction by summarizing multimodal behavioral features in customer service videos and revealing abnormal operations in the service process. We leverage the semantically meaningful operations to introduce structured event understanding into videos which help service providers quickly navigate to events of their interest.  Anchorage  supports a comprehensive evaluation of customer satisfaction from the service and operation levels and efficient analysis of customer behavioral?\u2026", "IdName": "wong2023anchorage", "Citation": "", "Keywords": ""}, {"Name": "Exploring interactions with printed data visualizations in augmented reality", "Authors": ["Wai Tong", "Zhutian Chen", "Meng Xia", "Leo Yu-Ho Lo", "Linping Yuan", "Benjamin Bach", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "This paper presents a design space of interaction techniques to engage with visualizations that are printed on paper and augmented through Augmented Reality. Paper sheets are widely used to deploy visualizations and provide a rich set of tangible affordances for interactions, such as touch, folding, tilting, or stacking. At the same time, augmented reality can dynamically update visualization content to provide  commands  such as pan, zoom, filter, or detail on demand. This paper is the first to provide a structured approach to mapping possible actions with the paper to interaction commands. This design space and the findings of a controlled user study have implications for future designs of augmented reality systems involving paper sheets and visualizations. Through workshops (  ) and ideation, we identified 81 interactions that we classify in three dimensions: 1)  commands  that can be supported by an?\u2026", "IdName": "tong2022exploring", "Citation": "", "Keywords": ""}, {"Name": "Interactive data analysis with next-step natural language query recommendation", "Authors": ["Xingbo Wang", "Furui Cheng", "Yong Wang", "Ke Xu", "Jiang Long", "Hong Lu", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2201.04868", "PublishedYears": "2022", "Doi": "", "Abstracts": "Natural language interfaces (NLIs) provide users with a convenient way to interactively analyze data through natural language queries. Nevertheless, interactive data analysis is a demanding process, especially for novice data analysts. When exploring large and complex SQL databases from different domains, data analysts do not necessarily have sufficient knowledge about different data tables and application domains. It makes them unable to systematically elicit a series of topically-related and meaningful queries for insight discovery in target domains. We develop a NLI with a step-wise query recommendation module to assist users in choosing appropriate next-step exploration actions. The system adopts a data-driven approach to suggest semantically relevant and context-aware queries for application domains of users' interest based on their query logs. Also, the system helps users organize query histories and results into a dashboard to communicate the discovered data insights. With a comparative user study, we show that our system can facilitate a more effective and systematic data analysis process than a baseline without the recommendation module.", "IdName": "wang2022interactive", "Citation": "", "Keywords": ""}, {"Name": "DeHumor: Visual analytics for decomposing humor", "Authors": ["Xingbo Wang", "Yao Ming", "Tongshuang Wu", "Haipeng Zeng", "Yong Wang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Despite being a critical communication skill, grasping humor is challenging\u2014a successful use of humor requires a mixture of both engaging content build-up and an appropriate vocal delivery (e.g., pause). Prior studies on computational humor emphasize the textual and audio features immediately next to the punchline, yet overlooking longer-term context setup. Moreover, the theories are usually too abstract for understanding each concrete humor snippet. To fill in the gap, we develop  DeHumor , a visual analytical system for analyzing humorous behaviors in public speaking. To intuitively reveal the building blocks of each concrete example,  DeHumor  decomposes each humorous video into multimodal features and provides inline annotations of them on the video script. In particular, to better capture the build-ups, we introduce content repetition as a complement to features introduced in theories of computational?\u2026", "IdName": "wang2021dehumor", "Citation": "", "Keywords": ""}, {"Name": "Tradao: A visual analytics system for trading algorithm optimization", "Authors": ["Ka Wing Tsang", "Haotian Li", "Fuk Ming Lam", "Yifan Mu", "Yong Wang", "Huamin Qu"], "Sources": "2020 IEEE Visualization Conference (VIS)", "PublishedYears": "2020", "Doi": "", "Abstracts": "With the wide applications of algorithmic trading, it has become critical for traders to build a winning trading algorithm to beat the market. However, due to the lack of efficient tools, traders mainly rely on their memory to manually compare the algorithm instances of a trading algorithm and further select the best trading algorithm instance for the real trading deployment. We work closely with industry practitioners to discover and consolidate user requirements and develop an interactive visual analytics system for trading algorithm optimization. Structured expert interviews are conducted to evaluate TradAO and a representative case study is documented for illustrating the system effectiveness. To the best of our knowledge, previous financial data visual analyses have mainly aimed to assist investment managers in investment portfolio analysis but have neglected the need of traders in developing trading algorithms for?\u2026", "IdName": "tsang2020tradao", "Citation": "", "Keywords": ""}, {"Name": "Dpviscreator: Incorporating pattern constraints to privacy-preserving visualizations via differential privacy", "Authors": ["Jiehui Zhou", "Xumeng Wang", "Jason K Wong", "Huanliang Wang", "Zhongwei Wang", "Xiaoyu Yang", "Xiaoran Yan", "Haozhe Feng", "Huamin Qu", "Haochao Ying", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Data privacy is an essential issue in publishing data visualizations. However, it is challenging to represent multiple data patterns in privacy-preserving visualizations. The prior approaches target specific chart types or perform an anonymization model uniformly without considering the importance of data patterns in visualizations. In this paper, we propose a visual analytics approach that facilitates data custodians to generate multiple private charts while maintaining user-preferred patterns. To this end, we introduce pattern constraints to model users' preferences over data patterns in the dataset and incorporate them into the proposed Bayesian network-based Differential Privacy (DP) model  PriVis . A prototype system,  DPVisCreator , is developed to assist data custodians in implementing our approach. The effectiveness of our approach is demonstrated with quantitative evaluation of pattern utility under the different?\u2026", "IdName": "zhou2022dpviscreator", "Citation": "", "Keywords": ""}, {"Name": "SeqDynamics: Visual Analytics for Evaluating Online Problem\u2010solving Dynamics", "Authors": ["Meng Xia", "Min Xu", "Chuan\u2010en Lin", "Ta Ying Cheng", "Huamin Qu", "Xiaojuan Ma"], "Sources": "Computer Graphics Forum", "PublishedYears": "2020", "Doi": "", "Abstracts": " Problem\u2010solving dynamics refers to the process of solving a series of problems over time, from which a student's cognitive skills and non\u2010cognitive traits and behaviors can be inferred. For example, we can derive a student's learning curve (an indicator of cognitive skill) from the changes in the difficulty level of problems solved, or derive a student's self\u2010regulation patterns (an example of non\u2010cognitive traits and behaviors) based on the problem\u2010solving frequency over time. Few studies provide an integrated overview of both aspects by unfolding the problem\u2010solving process. In this paper, we present a visual analytics system named SeqDynamics that evaluates students \u2018problem\u2010solving dynamics from both cognitive and non\u2010cognitive perspectives. The system visualizes the chronological sequence of learners\u2019 problem\u2010solving behavior through a set of novel visual designs and coordinated contextual views?\u2026", "IdName": "xia2020seqdynamics", "Citation": "", "Keywords": ""}, {"Name": "Gesturelens: Visual analysis of gestures in presentation videos", "Authors": ["Haipeng Zeng", "Xingbo Wang", "Yong Wang", "Aoyu Wu", "Ting-Chuen Pong", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Appropriate gestures can enhance message delivery and audience engagement in both daily communication and public presentations. In this article, we contribute a visual analytic approach that assists professional public speaking coaches in improving their practice of gesture training through analyzing presentation videos. Manually checking and exploring gesture usage in the presentation videos is often tedious and time-consuming. There lacks an efficient method to help users conduct gesture exploration, which is challenging due to the intrinsically temporal evolution of gestures and their complex correlation to speech content. In this article, we propose  GestureLens , a visual analytics system to facilitate gesture-based and content-based exploration of gesture usage in presentation videos. Specifically, the exploration view enables users to obtain a quick overview of the spatial and temporal distributions of?\u2026", "IdName": "zeng2022gesturelens", "Citation": "", "Keywords": ""}, {"Name": "Improving engagement of animated visualization with visual foreshadowing", "Authors": ["Wenchao Li", "Yun Wang", "Haidong Zhang", "Huamin Qu"], "Sources": "2020 IEEE Visualization Conference (VIS)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Animated visualization is becoming increasingly popular as a compelling way to illustrate changes in time series data. However, maintaining the viewer's focus throughout the entire animation is difficult because of its time-consuming nature. Viewers are likely to become bored and distracted during the ever-changing animated visualization. Informed by the role of foreshadowing that builds the expectation in film and literature, we introduce visual foreshadowing to improve the engagement of animated visualizations. In specific, we propose designs of visual foreshadowing that engage the audience while watching the animation. To demonstrate our approach, we built a proof-of-concept animated visualization authoring tool that incorporates visual foreshadowing techniques with various styles. Our user study indicates the effectiveness of our foreshadowing techniques on improving engagement for animated?\u2026", "IdName": "li2020improving", "Citation": "", "Keywords": ""}, {"Name": "Inksight: Leveraging sketch interaction for documenting chart findings in computational notebooks", "Authors": ["Yanna Lin", "Haotian Li", "Leni Yang", "Aoyu Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Computational notebooks have become increasingly popular for exploratory data analysis due to their ability to support data exploration and explanation within a single document. Effective documentation for explaining chart findings during the exploration process is essential as it helps recall and share data analysis. However, documenting chart findings remains a challenge due to its time-consuming and tedious nature. While existing automatic methods alleviate some of the burden on users, they often fail to cater to users' specific interests. In response to these limitations, we present InkSight, a mixed-initiative computational notebook plugin that generates finding documentation based on the user's intent. InkSight allows users to express their intent in specific data subsets through sketching atop visualizations intuitively. To facilitate this, we designed two types of sketches, i.e., open-path and closed-path sketch?\u2026", "IdName": "lin2023inksight", "Citation": "", "Keywords": ""}, {"Name": "ShortcutLens: A visual analytics approach for exploring shortcuts in natural language understanding dataset", "Authors": ["Zhihua Jin", "Xingbo Wang", "Furui Cheng", "Chunhui Sun", "Qun Liu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Benchmark datasets play an important role in evaluating Natural Language Understanding (NLU) models. However, shortcuts\u2014unwanted biases in the benchmark datasets\u2014can damage the effectiveness of benchmark datasets in revealing models' real capabilities. Since shortcuts vary in coverage, productivity, and semantic meaning, it is challenging for NLU experts to systematically understand and avoid them when creating benchmark datasets. In this paper, we develop a visual analytics system,  ShortcutLens , to help NLU experts explore shortcuts in NLU benchmark datasets. The system allows users to conduct multi-level exploration of shortcuts. Specifically, Statistics View helps users grasp the statistics such as coverage and productivity of shortcuts in the benchmark dataset. Template View employs hierarchical and interpretable templates to summarize different types of shortcuts. Instance View allows users?\u2026", "IdName": "jin2023shortcutlens", "Citation": "", "Keywords": ""}, {"Name": "Polyphony: An interactive transfer learning framework for single-cell data analysis", "Authors": ["Furui Cheng", "Mark S Keller", "Huamin Qu", "Nils Gehlenborg", "Qianwen Wang"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Reference-based cell-type annotation can significantly reduce time and effort in single-cell analysis by transferring labels from a previously-annotated dataset to a new dataset. However, label transfer by end-to-end computational methods is challenging due to the entanglement of technical ( e.g. , from different sequencing batches or techniques) and biological ( e.g. , from different cellular microenvironments) variations, only the first of which must be removed. To address this issue, we propose  Polyphony , an interactive transfer learning (ITL) framework, to complement biologists' knowledge with advanced computational methods.  Polyphony  is motivated and guided by domain experts' needs for a controllable, interactive, and algorithm-assisted annotation process, identified through interviews with seven biologists. We introduce anchors,  i.e. , analogous cell populations across datasets, as a paradigm to explain the?\u2026", "IdName": "cheng2022polyphony", "Citation": "", "Keywords": ""}, {"Name": "Causal perception in question-answering systems", "Authors": ["Po-Ming Law", "Leo Yu-Ho Lo", "Alex Endert", "John Stasko", "Huamin Qu"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Root cause analysis is a common data analysis task. While question-answering systems enable people to easily articulate a why question (e.g., why students in Massachusetts have high ACT Math scores on average) and obtain an answer, these systems often produce questionable causal claims. To investigate how such claims might mislead users, we conducted two crowdsourced experiments to study the impact of showing different information on user perceptions of a question-answering system. We found that in a system that occasionally provided unreasonable responses, showing a scatterplot increased the plausibility of unreasonable causal claims. Also, simply warning participants that correlation is not causation seemed to lead participants to accept reasonable causal claims more cautiously. We observed a strong tendency among participants to associate correlation with causation. Yet, the warning?\u2026", "IdName": "law2021causal", "Citation": "", "Keywords": ""}, {"Name": "Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration", "Authors": ["Haotian Li", "Yun Wang", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2309.15723", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.", "IdName": "li2023we", "Citation": "", "Keywords": ""}, {"Name": "Creating emordle: Animating word cloud for emotion expression", "Authors": ["Liwenhan Xie", "Xinhuan Shu", "Jeon Cheol Su", "Yun Wang", "Siming Chen", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "We propose emordle, a conceptual design that animates wordles (compact word clouds) to deliver their emotional context to audiences. To inform the design, we first reviewed online examples of animated texts and animated wordles, and summarized strategies for injecting emotion into the animations. We introduced a composite approach that extends an existing animation scheme for one word to multiple words in a wordle with two global factors: the randomness of text animation (entropy) and the animation speed (speed). To create an emordle, general users can choose one predefined animated scheme that matches the intended emotion class and fine-tune the emotion intensity with the two parameters. We designed proof-of-concept emordle examples for four basic emotion classes, namely happiness, sadness, anger, and fear. We conducted two controlled crowdsourcing studies to evaluate our approach. The?\u2026", "IdName": "xie2023creating", "Citation": "", "Keywords": ""}, {"Name": "Computableviz: Mathematical operators as a formalism for visualisation processing and analysis", "Authors": ["Aoyu Wu", "Wai Tong", "Haotian Li", "Dominik Moritz", "Yong Wang", "Huamin Qu"], "Sources": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Data visualizations are created and shared on the web at an unprecedented speed, raising new needs and questions for processing and analyzing visualizations after they have been generated and digitized. However, existing formalisms focus on operating on a single visualization instead of multiple visualizations, making it challenging to perform analysis tasks such as sorting and clustering visualizations. Through a systematic analysis of previous work, we abstract visualization-related tasks into mathematical operators such as union and propose a design space of visualization operations. We realize the design by developing ComputableViz, a library that supports operations on multiple visualization specifications. To demonstrate its usefulness and extensibility, we present multiple usage scenarios concerning processing and analyzing visualization, such as generating visualization embeddings and?\u2026", "IdName": "wu2022computableviz", "Citation": "", "Keywords": ""}, {"Name": "AQX: Explaining air quality forecast for verifying domain knowledge using feature importance visualization", "Authors": ["Reshika Palaniyappan Velumani", "Meng Xia", "Jun Han", "Chaoli Wang", "ALEXIS K LAU", "Huamin Qu"], "Sources": "27th International Conference on Intelligent User Interfaces", "PublishedYears": "2022", "Doi": "", "Abstracts": " Air pollution forecast has become critical because of its direct impact on human health and its increased production caused by rapid industrialization. Machine learning (ML) solutions are being drastically explored in this domain because they can potentially produce highly accurate results with access to historical data. However, experts in the environmental area are skeptical about adopting ML solutions in real-world applications and policy making due to their black-box nature. In contrast, despite having low accuracy sometimes, the existing traditional simulation model (e.g., CMAQ) are widely used and follows well-defined and transparent equations. Therefore, presenting the knowledge learned by the ML model can make it transparent as well as comprehensible. In addition, validating the ML model\u2019s learning with the existing domain knowledge might aid in addressing their skepticism, building appropriate trust?\u2026", "IdName": "palaniyappan2022aqx", "Citation": "", "Keywords": ""}, {"Name": "iQUANT: interactive quantitative investment using sparse regression factors", "Authors": ["Xuanwu Yue", "Qiao Gu", "Deyun Wang", "Huamin Qu", "Yong Wang"], "Sources": "Computer Graphics Forum", "PublishedYears": "2021", "Doi": "", "Abstracts": " The model\u2010based investing using financial factors is evolving as a principal method for quantitative investment. The main challenge lies in the selection of effective factors towards excess market returns. Existing approaches, either hand\u2010picking factors or applying feature selection algorithms, do not orchestrate both human knowledge and computational power. This paper presents iQUANT, an interactive quantitative investment system that assists equity traders to quickly spot promising financial factors from initial recommendations suggested by algorithmic models, and conduct a joint refinement of factors and stocks for investment portfolio composition. We work closely with professional traders to assemble empirical characteristics of \u201cgood\u201d factors and propose effective visualization designs to illustrate the collective performance of financial factors, stock portfolios, and their interactions. We evaluate iQUANT?\u2026", "IdName": "yue2021iquant", "Citation": "", "Keywords": ""}, {"Name": "HypoML: Visual analysis for hypothesis-based evaluation of machine learning models", "Authors": ["Qianwen Wang", "William Alexander", "Jack Pegg", "Huamin Qu", "Min Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a \u201cconcept\u201d or \u201cfeature\u201d may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have?\u2026", "IdName": "wang2020hypoml", "Citation": "", "Keywords": ""}, {"Name": "Rankbooster: Visual analysis of ranking predictions", "Authors": ["Abishek Puri", "Bon Kyung Ku", "Yong Wang", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2004.06435", "PublishedYears": "2020", "Doi": "", "Abstracts": "Ranking is a natural and ubiquitous way to facilitate decision-making in various applications. However, different rankings are often used for the same set of entities, with each ranking method placing emphasis on different factors. These factors can also be multi-dimensional in nature, compounding the problem. This complexity can make it challenging for an entity which is being ranked to understand what they can do to improve their rankings, and to analyze the effect of changes in various factors to their overall rank. In this paper, we present RankBooster, a novel visual analytics system to help users conveniently investigate ranking predictions. We take university rankings as an example and focus on helping universities to better explore their rankings, where they can compare themselves to their rivals in key areas as well as overall. Novel visualizations are proposed to enable efficient analysis of rankings, including a Scenario Analysis View to show a high-level summary of different ranking scenarios, a Relationship View to visualize the influence of each attribute on different indicators and a Rival View to compare the ranking of a university and those of its rivals. A case study demonstrates the usefulness and effectiveness of RankBooster in facilitating the visual analysis of ranking predictions and helping users better understand their current situation.", "IdName": "puri2020rankbooster", "Citation": "", "Keywords": ""}, {"Name": "Reviving static charts into live charts", "Authors": ["Lu Ying", "Yun Wang", "Haotian Li", "Shuguang Dou", "Haidong Zhang", "Xinyang Jiang", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Data charts are prevalent across various fields due to their efficacy in conveying complex data relationships. However, static charts may sometimes struggle to engage readers and efficiently present intricate information, potentially resulting in limited understanding. We introduce \u201cLive Charts,\u201d a new format of presentation that decomposes complex information within a chart and explains the information pieces sequentially through rich animations and accompanying audio narration. We propose an automated approach to revive static charts into Live Charts. Our method integrates GNN-based techniques to analyze the chart components and extract data from charts. Then we adopt large natural language models to generate appropriate animated visuals along with a voice-over to produce Live Charts from static ones. We conducted a thorough evaluation of our approach, which involved the model performance, use?\u2026", "IdName": "ying2024reviving", "Citation": "", "Keywords": ""}, {"Name": "Geocamera: Telling stories in geographic visualizations with camera movements", "Authors": ["Wenchao Li", "Zhan Wang", "Yun Wang", "Di Weng", "Liwenhan Xie", "Siming Chen", "Haidong Zhang", "Huamin Qu"], "Sources": "Proceedings of the 2023 CHI conference on human factors in computing systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "In geographic data videos, camera movements are frequently used and combined to present information from multiple perspectives. However, creating and editing camera movements requires significant time and professional skills. This work aims to lower the barrier of crafting diverse camera movements for geographic data videos. First, we analyze a corpus of 66 geographic data videos and derive a design space of camera movements with a dimension for geospatial targets and one for narrative purposes. Based on the design space, we propose a set of adaptive camera shots and further develop an interactive tool called GeoCamera. This interactive tool allows users to flexibly design camera movements for geographic visualizations. We verify the expressiveness of our tool through case studies and evaluate its usability with a user study. The participants find that the tool facilitates the design of camera movements. ", "IdName": "li2023geocamera", "Citation": "", "Keywords": ""}, {"Name": "Rankfirst: Visual analysis for factor investment by ranking stock timeseries", "Authors": ["Huijie Guo", "Meijun Liu", "Bowen Yang", "Ye Sun", "Huamin Qu", "Lei Shi"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In the era of quantitative investment, factor-based investing models are widely adopted in the construction of stock portfolios. These models explain the performance of individual stocks by a set of financial factors, e.g., market beta and company size. In industry, open investment platforms allow the online building of factor-based models, yet set a high bar on the engineering expertise of end-users. State-of-the-art visualization systems integrate the whole factor investing pipeline, but do not directly address domain users' core requests on ranking factors and stocks for portfolio construction. The current model lacks explainability, which downgrades its credibility with stock investors. To fill the gap in modeling, ranking, and visualizing stock time series for factor investment, we designed and implemented a visual analytics system, namely RankFIRST. The system offers built-in support for an established factor collection and?\u2026", "IdName": "guo2022rankfirst", "Citation": "", "Keywords": ""}, {"Name": "Saliency-aware color harmony models for outdoor signboard", "Authors": ["Yanna Lin", "Wei Zeng", "Yu Ye", "Huamin Qu"], "Sources": "Computers & Graphics 105", "PublishedYears": "2022", "Doi": "", "Abstracts": "This paper introduces a geometric approach for assessing color harmony of a signboard, and color coherence of a signboard with the environment. We propose to incorporate visual saliency as an inherent color characteristic residing in the image space, to better cope with the attention mechanism when people view a scene. In doing so, our color harmony models consider saliency-weighted color differences and area balance in CIELab color space. We collect 5.2?K valid subjective ratings on 375 diverse signboards in the real world, and translate them into quantitative measures for model construction. Experimental results show that our models improve the overall performance, especially for modeling color coherence between a signboard and the environment. The study also reveals that color combinations with similar chroma but distinctive lightness lead to harmonic signboards, while simple color patches in?\u2026", "IdName": "lin2022saliency", "Citation": "", "Keywords": ""}, {"Name": "Blocklens: visual analytics of student coding behaviors in block-based programming environments", "Authors": ["Sean Tsung", "Huan Wei", "Haotian Li", "Yong Wang", "Meng Xia", "Huamin Qu"], "Sources": "Proceedings of the Ninth ACM Conference on Learning@ Scale", "PublishedYears": "2022", "Doi": "", "Abstracts": "Block-based programming environments have been widely used to introduce K-12 students to coding. To guide students effectively, instructors and platform owners often need to understand behaviors like how students solve certain questions or where they get stuck and why. However, it is challenging for them to effectively analyze students' coding data. To this end, we propose BlockLens, a novel visual analytics system to assist instructors and platform owners in analyzing students' block-based coding behaviors, mistakes, and problem-solving patterns. BlockLens enables the grouping of students by question progress and performance, identification of common problem-solving strategies and pitfalls, and presentation of insights at multiple granularity levels, from a high-level overview of all students to a detailed analysis of one student's behavior and performance. A usage scenario using real-world data?\u2026", "IdName": "tsung2022blocklens", "Citation": "", "Keywords": ""}, {"Name": "Scrolltimes: Tracing the provenance of paintings as a window into history", "Authors": ["Wei Zhang", "Wong Kam-Kwai", "Yitian Chen", "Ailing Jia", "Luwei Wang", "Jian-Wei Zhang", "Lechao Cheng", "Huamin Qu", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "The study of cultural artifact provenance, tracing ownership and preservation, holds significant importance in archaeology and art history. Modern technology has advanced this field, yet challenges persist, including recognizing evidence from diverse sources, integrating sociocultural context, and enhancing interactive automation for comprehensive provenance analysis. In collaboration with art historians, we examined the handscroll, a traditional Chinese painting form that provides a rich source of historical data and a unique opportunity to explore history through cultural artifacts. We present a three-tiered methodology encompassing artifact, contextual, and provenance levels, designed to create a \u201cBiography\u201d for handscroll. Our approach incorporates the application of image processing techniques and language models to extract, validate, and augment elements within handscroll using various cultural heritage?\u2026", "IdName": "zhang2024scrolltimes", "Citation": "", "Keywords": ""}, {"Name": "A survey of visual analytics in urban area", "Authors": ["Zezheng Feng", "Huamin Qu", "Shuang\u2010Hua Yang", "Yulong Ding", "Jie Song"], "Sources": "Expert Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": " Nowadays, the population has been overgrowing due to urbanization, yielding many severe problems in the urban area, including traffic congestion, unbalanced distribution of urban hotspots, air pollution and so on. Due to the uncertainty of the urban environment, it always needs to integrate experts' domain knowledge into solving these issues. In recent years, the visual analytics method has been widely used to assist domain experts in solving urban problems with its intuitiveness, interactivity and interpretability. In this survey, we first introduce the background of urban computing, present the motivation of visual analytics in the urban area and point out the characteristics of visual analytics methods. Second, we introduce the most frequently used urban data, analyse the main properties and provide an overview on how to use these data. Thereafter, we propose our taxonomy for visual analytics in the urban area?\u2026", "IdName": "feng2022survey", "Citation": "", "Keywords": ""}, {"Name": "Aqeyes: visual analytics for anomaly detection and examination of air quality data", "Authors": ["Dongyu Liu", "Kalyan Veeramachaneni", "Alexander Geiger", "Victor OK Li", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2103.12910", "PublishedYears": "2021", "Doi": "", "Abstracts": "Anomaly detection plays a key role in air quality analysis by enhancing situational awareness and alerting users to potential hazards. However, existing anomaly detection approaches for air quality analysis have their own limitations regarding parameter selection (e.g., need for extensive domain knowledge), computational expense, general applicability (e.g., require labeled data), interpretability, and the efficiency of analysis. Furthermore, the poor quality of collected air quality data (inconsistently formatted and sometimes missing) also increases the difficulty of analysis substantially. In this paper, we systematically formulate design requirements for a system that can solve these limitations and then propose AQEyes, an integrated visual analytics system for efficiently monitoring, detecting, and examining anomalies in air quality data. In particular, we propose a unified end-to-end tunable machine learning pipeline that includes several data pre-processors and featurizers to deal with data quality issues. The pipeline integrates an efficient unsupervised anomaly detection method that works without the use of labeled data and overcomes the limitations of existing approaches. Further, we develop an interactive visualization system to visualize the outputs from the pipeline. The system incorporates a set of novel visualization and interaction designs, allowing analysts to visually examine air quality dynamics and anomalous events in multiple scales and from multiple facets. We demonstrate the performance of this pipeline through a quantitative evaluation and show the effectiveness of the visualization system using qualitative case studies on real-world?\u2026", "IdName": "liu2021aqeyes", "Citation": "", "Keywords": ""}, {"Name": "PoeticAR: Reviving traditional poetry of the heritage site of jichang garden via augmented reality", "Authors": ["Jin Tian", "Yifan Cao", "Lingyi Feng", "Dongting Fu", "Linping Yuan", "Huamin Qu", "Yang Wang", "Mingming Fan"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "As a famed Chinese classical garden, the Jichang Garden was a constant inspiration to many poets in its hundreds of years\u2019 history, who composed a rich body of poems\u2014a valuable intangible cultural heritage. While tourists tend to pay attention to tangible natural scenery and historical architectures, they often neglect intangible cultural heritage\u2014poems. We interviewed 23 tourists and found that augmented reality (AR) was viable for tourists to enjoy the physical scenery and the poetry simultaneously. We developed an initial prototype of PoeticAR, which presents poems based on physical scenery to enhance tourists\u2019 cultural and aesthetic experience. We further revised the prototype based on the ideas generated from a workshop with 18 tourists. We conducted a between-subject user study with 30 tourists to compare PoeticAR with Video. Results showed that PoeticAR significantly motivated tourists\u2019 interest in?\u2026", "IdName": "tian2024poeticar", "Citation": "", "Keywords": ""}, {"Name": "CommonsenseVIS: Visualizing and Understanding Commonsense Reasoning Capabilities of Natural Language Models", "Authors": ["Xingbo Wang", "Renfei Huang", "Zhihua Jin", "Tianqing Fang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, large pretrained language models have achieved compelling performance on commonsense benchmarks. Nevertheless, it is unclear what commonsense knowledge the models learn and whether they solely exploit spurious patterns. Feature attributions are popular explainability techniques that identify important input concepts for model outputs. However, commonsense knowledge tends to be implicit and rarely explicitly presented in inputs. These methods cannot infer models' implicit reasoning over mentioned concepts. We present  CommonsenseVIS , a visual explanatory system that utilizes external commonsense knowledge bases to contextualize model behavior for commonsense question-answering. Specifically, we extract relevant commonsense knowledge in inputs as references to align model behavior with human knowledge. Our system features multi-level visualization and interactive model?\u2026", "IdName": "wang2023commonsensevis", "Citation": "", "Keywords": ""}, {"Name": "VideoPro: A Visual Analytics Approach for Interactive Video Programming", "Authors": ["Jianben He", "Xingbo Wang", "Kam Kwai Wong", "Xijie Huang", "Changjian Chen", "Zixin Chen", "Fengjie Wang", "Min Zhu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Constructing supervised machine learning models for real-world video analysis require substantial labeled data, which is costly to acquire due to scarce domain expertise and laborious manual inspection. While data programming shows promise in generating labeled data at scale with user-defined labeling functions, the high dimensional and complex temporal information in videos poses additional challenges for effectively composing and evaluating labeling functions. In this paper, we propose  VideoPro , a visual analytics approach to support flexible and scalable video data programming for model steering with reduced human effort. We first extract human-understandable events from videos using computer vision techniques and treat them as atomic components of labeling functions. We further propose a two-stage template mining algorithm that characterizes the sequential patterns of these events to serve as?\u2026", "IdName": "he2023videopro", "Citation": "", "Keywords": ""}, {"Name": "Cinematography in the Metaverse: Exploring the Lighting Education on a Soundstage", "Authors": ["Xian Xu", "Wai Tong", "Zheng Wei", "Meng Xia", "Lik-Hang Lee", "Huamin Qu"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Lighting education is a foundational component of cinematography education. However, there is still a lack of knowledge on the design of a VR system for teaching cinematography. In this work, we present our VR soundstage system for instructors and learners to emulate cinematography lighting in virtual scenarios and then evaluate it from five aspects in the user study. Qualitative and quantitative feedback in our user study shows promising results. We further discuss the benefits of the approach and opportunities for future research.", "IdName": "xu2023cinematography", "Citation": "", "Keywords": ""}, {"Name": "Designing a game for pre-screening students with specific learning disabilities in Chinese", "Authors": ["Ka Yan Fung", "Kuen Fung Sin", "Zikai Alex Wen", "Lik-Hang Lee", "Shenghui Song", "Huamin Qu"], "Sources": "Proceedings of the 24th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Most students with specific learning disabilities (SLDs) have difficulties in reading and writing. The SLDs pre-screening is crucial because the golden period for therapy is before six years old. However, many students in Hong Kong receive SLDs assessments after the golden period. Also, the SLDs pre-screening is challenging, especially in a language with the logographic script but without prominent sound-script correspondence (e.g., Chinese, Japanese). To make pre-screening SLDs in Chinese more effective and efficient, we designed a new comprehensive pre-screening game for SLDs in Chinese (i.e., dyslexia, dysgraphia, and dyspraxia). Notably, we designed a Chinese morphological awareness puzzle that challenges students to recognize different words made up with the first character that is identical and the second character that is different, such as\u6a39\u679d (literally means tree branch),\u6a39\u5e79 (literally means?\u2026", "IdName": "fung2022designing", "Citation": "", "Keywords": ""}, {"Name": "Method and system for analyzing user activities related to a video", "Authors": ["Huamin Qu", "Conglei Shi", "Siwei Fu", "Qing Chen"], "Sources": "US Patent 10", "PublishedYears": "2020", "Doi": "", "Abstracts": "The present teaching relates to analyzing user activities related to a video. The video is provided to a plurality of users. The plurality of users is monitored to detect one or more types of user activities performed in time with respect to different portions of the video. One or more visual representations of the monitored one or more types of user activities are generated. The one or more visual representations capture a level of attention paid by the plurality of users to the different portions of the video at any time instance. Interests of at least some of the plurality of users are determined with respect to the different portions of the video based on the one or more visual representations.", "IdName": "qu2020method", "Citation": "", "Keywords": ""}, {"Name": "Understanding 3D Data Videos: From Screens to Virtual Reality", "Authors": ["Leni Yang", "Aoyu Wu", "Wai Tong", "Xian Xu", "Zheng Wei", "Huamin Qu"], "Sources": "2023 IEEE 16th Pacific Visualization Symposium (PacificVis)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data storytelling explores how to communicate data insights to the general public engagingly and effectively. It combines the power of data visualizations and storytelling techniques and is popular in various media such as newspapers, interactive websites, and videos. Recently, virtual reality has brought new opportunities to enhance data storytelling with an incomparable sense of immersion. However, there exists a limited understanding of data stories in virtual reality (VR) as they are still in the early stage. In this paper, we investigated the idea of VR data videos by drawing inspiration from popular 3D data videos and studying how to transfer them from screens to VR. We systematically analyzed 100 highly-watched 3D data videos from Youtube and Tiktok channels to derive their design space. We then conducted a user study with 12 participants to explore the effects of four design factors on user experience?\u2026", "IdName": "yang2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Kb4va: A knowledge base of visualization designs for visual analytics", "Authors": ["Dazhen Deng", "Aoyu Wu", "Haotian Li", "Ji Lan", "Yong Wang", "Huamin Qu", "Yingcai Wu"], "Sources": "arXiv preprint arXiv:2211.02567", "PublishedYears": "2022", "Doi": "", "Abstracts": "Visual analytics (VA) systems have been widely used to facilitate decision-making and analytical reasoning in various application domains. VA involves visual designs, interaction designs, and data mining, which is a systematic and complex paradigm. In this work, we focus on the design of effective visualizations for complex data and analytical tasks, which is a critical step in designing a VA system. This step is challenging because it requires extensive knowledge about domain problems and visualization to design effective encodings. Existing visualization designs published in top venues are valuable resources to inspire designs for problems with similar data structures and tasks. However, those designs are hard to understand, parse, and retrieve due to the lack of specifications. To address this problem, we build KB4VA, a knowledge base of visualization designs in VA systems with comprehensive labels about their analytical tasks and visual encodings. Our labeling scheme is inspired by a workshop study with 12 VA researchers to learn user requirements in understanding and retrieving professional visualization designs in VA systems. The theme extends Vega-Lite specifications for describing advanced and composited visualization designs in a declarative manner, thus facilitating human understanding and automatic indexing. To demonstrate the usefulness of our knowledge base, we present a user study about design inspirations for VA tasks. In summary, our work opens new perspectives for enhancing the accessibility and reusability of professional visualization designs.", "IdName": "deng2022kb4va", "Citation": "", "Keywords": ""}, {"Name": "AniVis: Generating Animated Transitions Between Statistical Charts with a Tree Model", "Authors": ["Wenchao Li", "Yun Wang", "He Huang", "Weiwei Cui", "Haidong Zhang", "Huamin Qu", "Dongmei Zhang"], "Sources": "arXiv preprint arXiv:2106.14313", "PublishedYears": "2021", "Doi": "", "Abstracts": "Animated transitions help viewers understand changes between related visualizations. To clearly present the underlying relations between statistical charts, animation authors need to have a high level of expertise and a considerable amount of time to describe the relations with reasonable animation stages. We present AniVis, an automated approach for generating animated transitions to demonstrate the changes between two statistical charts. AniVis models each statistical chart into a tree-based structure. Given an input chart pair, the differences of data and visual properties of the chart pair are formalized as tree edit operations. The edit operations can be mapped to atomic transition units. Through this approach, the animated transition between two charts can be expressed as a set of transition units. Then, we conduct a formative study to understand people's preferences for animation sequences. Based on the study, we propose a set of principles and a sequence composition algorithm to compose the transition units into a meaningful animation sequence. Finally, we synthesize these units together to deliver a smooth and intuitive animated transition between charts. To test our approach, we present a prototype system and its generated results to illustrate the usage of our framework. We perform a comparative study to assess the transition sequence derived from the tree model. We further collect qualitative feedback to evaluate the effectiveness and usefulness of our method.", "IdName": "li2021anivis", "Citation": "", "Keywords": ""}, {"Name": "SirenLess: Reveal the intention behind news", "Authors": ["Xumeng Chen", "Leo Yu-Ho Lo", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2001.02731", "PublishedYears": "2020", "Doi": "", "Abstracts": "News articles tend to be increasingly misleading nowadays, preventing readers from making subjective judgments towards certain events. While some machine learning approaches have been proposed to detect misleading news, most of them are black boxes that provide limited help for humans in decision making. In this paper, we present SirenLess, a visual analytical system for misleading news detection by linguistic features. The system features article explorer, a novel interactive tool that integrates news metadata and linguistic features to reveal semantic structures of news articles and facilitate textual analysis. We use SirenLess to analyze 18 news articles from different sources and summarize some helpful patterns for misleading news detection. A user study with journalism professionals and university students is conducted to confirm the usefulness and effectiveness of our system.", "IdName": "chen2020sirenless", "Citation": "", "Keywords": ""}, {"Name": "Prismatic: Interactive Multi-View Cluster Analysis of Concept Stocks", "Authors": ["Wong Kam-Kwai", "Yan Luo", "Xuanwu Yue", "Wei Chen", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2402.08978", "PublishedYears": "2024", "Doi": "", "Abstracts": "Financial cluster analysis allows investors to discover investment alternatives and avoid undertaking excessive risks. However, this analytical task faces substantial challenges arising from many pairwise comparisons, the dynamic correlations across time spans, and the ambiguity in deriving implications from business relational knowledge. We propose Prismatic, a visual analytics system that integrates quantitative analysis of historical performance and qualitative analysis of business relational knowledge to cluster correlated businesses interactively. Prismatic features three clustering processes: dynamic cluster generation, knowledge-based cluster exploration, and correlation-based cluster validation. Utilizing a multi-view clustering approach, it enriches data-driven clusters with knowledge-driven similarity, providing a nuanced understanding of business correlations. Through well-coordinated visual views, Prismatic facilitates a comprehensive interpretation of intertwined quantitative and qualitative features, demonstrating its usefulness and effectiveness via case studies on formulating concept stocks and extensive interviews with domain experts.", "IdName": "kam2024prismatic", "Citation": "", "Keywords": ""}, {"Name": "Wakey-Wakey: Animate Text by Mimicking Characters in a GIF", "Authors": ["Liwenhan Xie", "Zhaoyu Zhou", "Kerun Yu", "Yun Wang", "Huamin Qu", "Siming Chen"], "Sources": "Proceedings of the 36th Annual ACM Symposium on User Interface Software and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "With appealing visual effects, kinetic typography (animated text) has prevailed in movies, advertisements, and social media. However, it remains challenging and time-consuming to craft its animation scheme. We propose an automatic framework to transfer the animation scheme of a rigid body on a given meme GIF to text in vector format. First, the trajectories of key points on the GIF anchor are extracted and mapped to the text\u2019s control points based on local affine transformation. Then the temporal positions of the control points are optimized to maintain the text topology. We also develop an authoring tool that allows intuitive human control in the generation process. A questionnaire study provides evidence that the output results are aesthetically pleasing and well preserve the animation patterns in the original GIF, where participants were impressed by a similar emotional semantics of the original GIF. In addition, we?\u2026", "IdName": "xie2023wakey", "Citation": "", "Keywords": ""}, {"Name": "Why Change My Design: Explaining Poorly Constructed Visualization Designs with Explorable Explanations", "Authors": ["Leo Yu-Ho Lo", "Yifan Cao", "Leni Yang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Although visualization tools are widely available and accessible, not everyone knows the best practices and guidelines for creating accurate and honest visual representations of data. Numerous books and articles have been written to expose the misleading potential of poorly constructed charts and teach people how to avoid being deceived by them or making their own mistakes. These readings use various rhetorical devices to explain the concepts to their readers. In our analysis of a collection of books, online materials, and a design workshop, we identified six common explanation methods. To assess the effectiveness of these methods, we conducted two crowdsourced studies (each with   ) to evaluate their ability to teach and persuade people to make design changes. In addition to these existing methods, we brought in the idea of Explorable Explanations, which allows readers to experiment with?\u2026", "IdName": "lo2023change", "Citation": "", "Keywords": ""}, {"Name": "Adavis: Adaptive and explainable visualization recommendation for tabular data", "Authors": ["Songheng Zhang", "Yong Wang", "Haotian Li", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Automated visualization recommendation facilitates the rapid creation of effective visualizations, which is especially beneficial for users with limited time and limited knowledge of data visualization. There is an increasing trend in leveraging machine learning (ML) techniques to achieve an end-to-end visualization recommendation. However, existing ML-based approaches implicitly assume that there is only one appropriate visualization for a specific dataset, which is often not true for real applications. Also, they often work like a black box, and are difficult for users to understand the reasons for recommending specific visualizations. To fill the research gap, we propose AdaVis, an adaptive and explainable approach to recommend one or multiple appropriate visualizations for a tabular dataset. It leverages a box embedding-based knowledge graph to well model the possible one-to-many mapping relations among?\u2026", "IdName": "zhang2023adavis", "Citation": "", "Keywords": ""}, {"Name": "FoodWise: Food Waste Reduction and Behavior Change on Campus with Data Visualization and Gamification", "Authors": ["Yue Yu", "Sophia Yi", "Xi Nan", "Leo Yu-Ho Lo", "Kento Shigyo", "Liwenhan Xie", "Jeffry Wicaksana", "Kwang-Ting Cheng", "Huamin Qu"], "Sources": "Proceedings of the 6th ACM SIGCAS/SIGCHI Conference on Computing and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Food waste presents a substantial challenge with significant environmental and economic ramifications, and its severity on campus environments is of particular concern. In response to this, we introduce FoodWise, a dual-component system tailored to inspire and incentivize campus communities to reduce food waste. The system consists of a data storytelling dashboard that graphically displays food waste information from university canteens, coupled with a mobile web application that encourages users to log their food waste reduction actions and rewards active participants for their efforts.  Deployed during a two-week food-saving campaign at The Hong Kong University of Science and Technology (HKUST) in March 2023, FoodWise engaged over 200 participants from the university community, resulting in the logging of over 800 daily food-saving actions. Feedback collected post-campaign underscores the?\u2026", "IdName": "yu2023foodwise", "Citation": "", "Keywords": ""}, {"Name": "Tax-Scheduler: An interactive visualization system for staff shifting and scheduling at tax authorities", "Authors": ["Linping Yuan", "Boyu Li", "Siqi Li", "Kam Kwai Wong", "Rong Zhang", "Huamin Qu"], "Sources": "Visual Informatics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Given a large number of applications and complex processing procedures, how to efficiently shift and schedule tax officers to provide good services to taxpayers is now receiving more attention from tax authorities. The availability of historical application data makes it possible for tax managers to shift and schedule staff with data support, but it is unclear how to properly leverage the historical data. To investigate the problem, this study adopts a user-centered design approach. We first collect user requirements by conducting interviews with tax managers and characterize their requirements of shifting and scheduling into time series prediction and resource scheduling problems. Then, we propose Tax-Scheduler, an interactive visualization system with a time-series prediction algorithm and genetic algorithm to support staff shifting and scheduling in the tax scenarios. To evaluate the effectiveness of the system and?\u2026", "IdName": "yuan2023tax", "Citation": "", "Keywords": ""}, {"Name": "Networknarratives: Data tours for visual network exploration and analysis", "Authors": ["Wenchao Li", "Sarah Sch?ttler", "James Scott-Brown", "Yun Wang", "Siming Chen", "Huamin Qu", "Benjamin Bach"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " This paper introduces semi-automatic data tours to aid the exploration of complex networks. Exploring networks requires significant effort and expertise and can be time-consuming and challenging. Distinct from guidance and recommender systems for visual analytics, we provide a set of goal-oriented tours for network overview, ego-network analysis, community exploration, and other tasks. Based on interviews with five network analysts, we developed a user interface (NetworkNarratives) and 10 example tours. The interface allows analysts to navigate an interactive slideshow featuring facts about the network using visualizations and textual annotations. On each slide, an analyst can freely explore the network and specify nodes, links, or subgraphs as seed elements for follow-up tours. Two studies, comprising eight expert and 14 novice analysts, show that data tours reduce exploration effort, support learning about?\u2026", "IdName": "li2023networknarratives", "Citation": "", "Keywords": ""}, {"Name": "ProtoSteer:Steering deep sequence model with prototypes", "Authors": ["Panpan Xu", "Liu Ren", "MING Yao", "Furui Cheng", "Huamin Qu"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "Int. Cl. G06F 3/04847(2022.01) G06N 3/08(2006.01) G06F 370482(2013.01)(52) US CI. CPC G06F 3/04847 (2013.01); G06F 3/0482 (2013.01); GOON 3/08 (2013.01)", "IdName": "xu2022steering", "Citation": "", "Keywords": ""}, {"Name": "Let Every Seat Be Perfect! A Case Study on Combining BIM and VR for Room Planning", "Authors": ["Wai Tong", "Haotian Li", "Huan Wei", "Liwenhan Xie", "Yanna Lin", "Huamin Qu"], "Sources": "2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "When communicating indoor room design, professional designers normally rely on software like Revit to export walk-through videos for their clients. However, a lack of in-situ experience restricts the ultimate users from evaluating the design and hence provides limited feedback, which may lead to a rework after actual construction. In this case study, we explore empowering end-users by exposing rich design details through a Virtual Reality (VR) application based on building an information model. Qualitative feedback in our user study shows promising results. We further discuss the benefits of the approach and opportunities for future research.", "IdName": "tong2022let", "Citation": "", "Keywords": ""}, {"Name": "ICE: Identify and compare event sequence sets through multi-scale matrix and unit visualizations", "Authors": ["Siwei Fu", "Jian Zhao", "Linping Yuan", "Zhicheng Liu", "Kwan-Liu Ma", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2006.12718", "PublishedYears": "2020", "Doi": "", "Abstracts": "Comparative analysis of event sequence data is essential in many application domains, such as website design and medical care. However, analysts often face two challenges: they may not always know which sets of event sequences in the data are useful to compare, and the comparison needs to be achieved at different granularity, due to the volume and complexity of the data. This paper presents, ICE, an interactive visualization that allows analysts to explore an event sequence dataset, and identify promising sets of event sequences to compare at both the pattern and sequence levels. More specifically, ICE incorporates a multi-level matrix-based visualization for browsing the entire dataset based on the prefixes and suffixes of sequences. To support comparison at multiple levels, ICE employs the unit visualization technique, and we further explore the design space of unit visualizations for event sequence comparison tasks. Finally, we demonstrate the effectiveness of ICE with three real-world datasets from different domains.", "IdName": "fu2020ice", "Citation": "", "Keywords": ""}, {"Name": "Visual analytics tool for proctoring online exams", "Authors": ["LI Haotian", "Min Xu", "Huan Wei", "Huamin Qu", "Yong Wang"], "Sources": "US Patent 11", "PublishedYears": "2024", "Doi": "", "Abstracts": "A system for proctoring online exams includes a client-side computing system and a visual analytics system. The client-side computing system includes a camera configured to obtain video data corresponding to a user while taking an exam and one or more input devices configured to obtain interaction data, wherein the interaction data includes mouse movements of the user while taking the exam. The visual analytics system is configured to obtain the video data and the interaction data from the client-side computing system, analyze the exam data to detect abnormal behavior by the user based at least in part on mouse movement data, and generate one or more visualizations of the analyzed exam data to be used in determining whether or not the user has cheated during the exam.", "IdName": "haotian2024visual", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults Explore and Learn Smartphone Applications", "Authors": ["Xiaofu Jin", "Wai Tong", "Xiaoying Wei", "Xian Wang", "Emily Kuang", "Xiaoyu Mo", "Huamin Qu", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2402.04991", "PublishedYears": "2024", "Doi": "", "Abstracts": "The global aging trend compels older adults to navigate the evolving digital landscape, presenting a substantial challenge in mastering smartphone applications. While Augmented Reality (AR) holds promise for enhancing learning and user experience, its role in aiding older adults' smartphone app exploration remains insufficiently explored. Therefore, we conducted a two-phase study: (1) a workshop with 18 older adults to identify app exploration challenges and potential AR interventions, and (2) tech-probe participatory design sessions with 15 participants to co-create AR support tools. Our research highlights AR's effectiveness in reducing physical and cognitive strain among older adults during app exploration, especially during multi-app usage and the trial-and-error learning process. We also examined their interactional experiences with AR, yielding design considerations on tailoring AR tools for smartphone app exploration. Ultimately, our study unveils the prospective landscape of AR in supporting the older demographic, both presently and in future scenarios.", "IdName": "jin2024exploring", "Citation": "", "Keywords": ""}, {"Name": "Feeling Present! From Physical to Virtual Cinematography Lighting Education with Metashadow", "Authors": ["Zheng Wei", "Xian Xu", "Lik-Hang Lee", "Wai Tong", "Huamin Qu", "Pan Hui"], "Sources": "Proceedings of the 31st ACM International Conference on Multimedia", "PublishedYears": "2023", "Doi": "", "Abstracts": "The high cost and limited availability of soundstages for cinematography lighting education pose significant challenges for art institutions. Traditional teaching methods, combining basic lighting equipment operation with slide lectures, often yield unsatisfactory results, hindering students' mastery of cinematography lighting techniques. Therefore, we propose Metashadow, a virtual reality (VR) cinematography lighting education system demonstrating the feasibility of learning in a virtual soundstage. Based on the presence theory, Metashadow features high-fidelity lighting devices that enable users to adjust multiple parameters, providing a quantifiable learning approach. We evaluated Metashadow with 24 participants and found that it provides better learning outcomes than traditional teaching methods regarding presence, collaboration, usability, realism, creativity, and flexibility. Six experts also praised the?\u2026", "IdName": "wei2023feeling", "Citation": "", "Keywords": ""}, {"Name": "iFUNDit: Visual Profiling of Fund Investment Styles", "Authors": ["Rong Zhang", "Bon Kyung Ku", "Yong Wang", "Xuanwu Yue", "Siyuan Liu", "Ke Li", "Huamin Qu"], "Sources": "Computer Graphics Forum", "PublishedYears": "2023", "Doi": "", "Abstracts": " Mutual funds are becoming increasingly popular with the emergence of Internet finance. Clear profiling of a fund's investment style is crucial for fund managers to evaluate their investment strategies, and for investors to understand their investment. However, it is challenging to profile a fund's investment style as it requires a comprehensive analysis of complex multi\u2010dimensional temporal data. In addition, different fund managers and investors have different focuses when analysing a fund's investment style. To address the issue, we propose iFUNDit, an interactive visual analytic system for fund investment style analysis. The system decomposes a fund's critical features into performance attributes and investment style factors, and visualizes them in a set of coupled views: a fund and manager view, to delineate the distribution of funds' and managers' critical attributes on the market; a cluster view, to show the similarity?\u2026", "IdName": "zhang2023ifundit", "Citation": "", "Keywords": ""}, {"Name": "Is It the End? Guidelines for Cinematic Endings in Data Videos", "Authors": ["Xian Xu", "Aoyu Wu", "Leni Yang", "Zheng Wei", "Rong Huang", "David Yip", "Huamin Qu"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Data videos are becoming increasingly popular in society and academia. Yet little is known about how to create endings that strengthen a lasting impression and persuasion. To fulfill the gap, this work aims to develop guidelines for data video endings by drawing inspiration from cinematic arts. To contextualize cinematic endings in data videos, 111 film endings and 105 data video endings are first analyzed to identify four common styles using the framework of ending punctuation marks. ?We conducted expert interviews (N=11) and formulated 20 guidelines for creating cinematic endings in data videos. To validate our guidelines, we conducted a user study where 24 participants were invited to design endings with and without our guidelines, which are evaluated by experts and the general public. The participants praise the clarity and usability of the guidelines, and results show that the endings with guidelines are?\u2026", "IdName": "xu2023end", "Citation": "", "Keywords": ""}, {"Name": "System and a method for speech analysis", "Authors": ["Huamin Qu", "Yuanzhe Chen", "Siwei Fu", "Linping Yuan", "WU Aoyu"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "A computer implemented method and system for processing an audio signal. The method includes the steps of extracting prosodic features from the audio signal, aligning the extracted prosodic features with a script derived from or associated with the audio signal, and segmenting the script with the aligned extracted prosodic features into structural blocks of a first type. The method may further include determining a distance measure between a structural block of a first type derived from the script with another structural block of the first type using, for example, the Damerau-Levenshtein distance.", "IdName": "qu2022system", "Citation": "", "Keywords": ""}, {"Name": "Explore Mindfulness Without Deflection: A Data Art Based On The Book Of Songs", "Authors": ["Yifang Wang", "Yang Wang", "Yifan Cao", "Huamin Qu", "Junxiu Tang", "Yingcai Wu"], "Sources": "2021 IEEE VIS Arts Program (VISAP)", "PublishedYears": "2021", "Doi": "", "Abstracts": "The Book of Songs is regarded as the origin of Chinese literature and has a prolonged impact on Chinese culture, aesthetics, and morality. In this work, we have analyzed the 305 poems in The Book of Songs from different dimensions. We aim to learn how various poetic imageries connect abstract themes and subjective emotions at the micro level, and how the poems connect people today and ancestors to understand the universal, everlasting, and poetical human lives at the macro level.", "IdName": "wang2021explore", "Citation": "", "Keywords": ""}, {"Name": "Save It for the\" Hot\" Day: An LLM-Empowered Visual Analytics System for Heat Risk Management", "Authors": ["Haobo Li", "Wong Kam-Kwai", "Yan Luo", "Juntong Chen", "Chengzhong Liu", "Yaxuan Zhang", "Alexis Kai Hon Lau", "Huamin Qu", "Dongyu Liu"], "Sources": "arXiv preprint arXiv:2406.03317", "PublishedYears": "2024", "Doi": "", "Abstracts": "The escalating frequency and intensity of heat-related climate events, particularly heatwaves, emphasize the pressing need for advanced heat risk management strategies. Current approaches, primarily relying on numerical models, face challenges in spatial-temporal resolution and in capturing the dynamic interplay of environmental, social, and behavioral factors affecting heat risks. This has led to difficulties in translating risk assessments into effective mitigation actions. Recognizing these problems, we introduce a novel approach leveraging the burgeoning capabilities of Large Language Models (LLMs) to extract rich and contextual insights from news reports. We hence propose an LLM-empowered visual analytics system, Havior, that integrates the precise, data-driven insights of numerical models with nuanced news report information. This hybrid approach enables a more comprehensive assessment of heat risks and better identification, assessment, and mitigation of heat-related threats. The system incorporates novel visualization designs, such as \"thermoglyph\" and news glyph, enhancing intuitive understanding and analysis of heat risks. The integration of LLM-based techniques also enables advanced information retrieval and semantic knowledge extraction that can be guided by experts' analytics needs. Our case studies on two cities that faced significant heatwave events and interviews with five experts have demonstrated the usefulness of our system in providing in-depth and actionable insights for heat risk management.", "IdName": "li2024save", "Citation": "", "Keywords": ""}, {"Name": "NFTracer: Tracing NFT Impact Dynamics in Transaction-flow Substitutive Systems with Visual Analytics", "Authors": ["Yifan Cao", "Qing Shi", "Lue Shen", "Kani Chen", "Yang Wang", "Wei Zeng", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Impact dynamics are crucial for estimating the growth patterns of NFT projects by tracking the diffusion and decay of their relative appeal among stakeholders. Machine learning methods for impact dynamics analysis are incomprehensible and rigid in terms of their interpretability and transparency, whilst stakeholders require interactive tools for informed decision-making. Nevertheless, developing such a tool is challenging due to the substantial, heterogeneous NFT transaction data and the requirements for flexible, customized interactions. To this end, we integrate intuitive visualizations to unveil the impact dynamics of NFT projects. We first conduct a formative study and summarize analysis criteria, including substitution mechanisms, impact attributes, and design requirements from stakeholders. Next, we propose the Minimal Substitution Model to simulate substitutive systems of NFT projects that can be feasibly?\u2026", "IdName": "cao2024nftracer", "Citation": "", "Keywords": ""}, {"Name": "Exploring Stage Lighting Education in Metaverse", "Authors": ["Wai Tong", "Meng Xia", "Huamin Qu"], "Sources": "Extended Abstracts of the CHI Conference on Human Factors in Computing?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": " This paper investigates stage lighting education in the metaverse from a practical perspective. We conducted participatory design with practitioners and stakeholders from a local university to develop a VR-based stage lighting system for the Technical Theater Arts course. Over six months, we derived a list of design requirements (e.g., Level of realism serves the purpose of learning) and developed a prototype VR system for stage lighting education. Our contributions include the establishment of design requirements for stage lighting education in the metaverse, the development of a prototype system, and insights from integrating VR in course development. This research paves the way for further exploration and refinement of VR applications in educational settings.", "IdName": "tong2024exploring", "Citation": "", "Keywords": ""}, {"Name": "OutlineSpark: Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines", "Authors": ["Fengjie Wang", "Yanna Lin", "Leni Yang", "Haotian Li", "Mingyang Gu", "Min Zhu", "Huamin Qu"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Computational notebooks are widely utilized for exploration and analysis. However, creating slides to communicate analysis results from these notebooks is quite tedious and time-consuming. Researchers have proposed automatic systems for generating slides from notebooks, which, however, often do not consider the process of users conceiving and organizing their messages from massive code cells. Those systems ask users to go directly into the slide creation process, which causes potentially ill-structured slides and burdens in further refinement. Inspired by the common and widely recommended slide creation practice: drafting outlines first and then adding concrete content, we introduce OutlineSpark, an AI-powered slide creation tool that generates slides from a slide outline written by the user. The tool automatically retrieves relevant notebook cells based on the outlines and converts them into slide content?\u2026", "IdName": "wang2024outlinespark", "Citation": "", "Keywords": ""}, {"Name": "VAID: Indexing View Designs in Visual Analytics System", "Authors": ["Lu Ying", "Aoyu Wu", "Haotian Li", "Zikun Deng", "Ji Lan", "Jiang Wu", "Yong Wang", "Huamin Qu", "Dazhen Deng", "Yingcai Wu"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Visual analytics (VA) systems have been widely used in various application domains. However, VA systems are complex in design, which imposes a serious problem: although the academic community constantly designs and implements new designs, the designs are difficult to query, understand, and refer to by subsequent designers. To mark a major step forward in tackling this problem, we index VA designs in an expressive and accessible way, transforming the designs into a structured format. We first conducted a workshop study with VA designers to learn user requirements for understanding and retrieving professional designs in VA systems. Thereafter, we came up with an index structure VAID to describe advanced and composited visualization designs with comprehensive labels about their analytical tasks and visual designs. The usefulness of VAID was validated through user studies. Our work opens new?\u2026", "IdName": "ying2024vaid", "Citation": "", "Keywords": ""}, {"Name": "Dynamic Typography: Bringing Words to Life", "Authors": ["Zichen Liu", "Yihao Meng", "Hao Ouyang", "Yue Yu", "Bolin Zhao", "Daniel Cohen-Or", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2404.11614", "PublishedYears": "2024", "Doi": "", "Abstracts": "Text animation serves as an expressive medium, transforming static communication into dynamic experiences by infusing words with motion to evoke emotions, emphasize meanings, and construct compelling narratives. Crafting animations that are semantically aware poses significant challenges, demanding expertise in graphic design and animation. We present an automated text animation scheme, termed \"Dynamic Typography\", which combines two challenging tasks. It deforms letters to convey semantic meaning and infuses them with vibrant movements based on user prompts. Our technique harnesses vector graphics representations and an end-to-end optimization-based framework. This framework employs neural displacement fields to convert letters into base shapes and applies per-frame motion, encouraging coherence with the intended textual concept. Shape preservation techniques and perceptual loss regularization are employed to maintain legibility and structural integrity throughout the animation process. We demonstrate the generalizability of our approach across various text-to-video models and highlight the superiority of our end-to-end methodology over baseline methods, which might comprise separate tasks. Through quantitative and qualitative evaluations, we demonstrate the effectiveness of our framework in generating coherent text animations that faithfully interpret user prompts while maintaining readability. Our code is available at: https://animate-your-word.github.io/demo/.", "IdName": "liu2024dynamic", "Citation": "", "Keywords": ""}, {"Name": "TacPrint: Visualizing the Biomechanical Fingerprint in Table Tennis", "Authors": ["Jiachen Wang", "Ji Ma", "Zheng Zhou", "Xiao Xie", "Hui Zhang", "Yingcai Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Table tennis is a sport that demands high levels of technical proficiency and body coordination from players. Biomechanical fingerprints can provide valuable insights into players' habitual movement patterns and characteristics, allowing them to identify and improve technical weaknesses. Despite the potential, few studies have developed effective methods for generating such fingerprints. To address this gap, we propose TacPrint, a framework for generating a biomechanical fingerprint for each player. TacPrint leverages machine learning techniques to extract comprehensive features from biomechanics data collected by inertial measurement units (IMU) and employs the attention mechanism to enhance model interpretability. After generating fingerprints, TacPrint provides a visualization system to facilitate the exploration and investigation of these fingerprints. In order to validate the effectiveness of the framework?\u2026", "IdName": "wang2024tacprint", "Citation": "", "Keywords": ""}, {"Name": "ADPS\u2013A Pre-screening Tool for Students with Dyslexia in Learning Traditional Chinese", "Authors": ["Ka-Yan Fung", "Kit-Yi Tang", "Tze Leung Rick Lui", "Kuen-Fung Sin", "Lik-Hang Lee", "Huamin Qu", "Shenghui Song"], "Sources": "IEEE Transactions on Learning Technologies", "PublishedYears": "2024", "Doi": "", "Abstracts": "Prescreening children for specific learning disabilities, e.g., dyslexia, is essential for effective intervention. With a quick and reliable prescreening result, special education coordinators (SENCOs) can provide students with early intervention and relieve their learning pressure. Unfortunately, due to the limited resources, many students in Hong Kong receive dyslexia assessments beyond the golden period, i.e., under the age of six. To this end, information technology could establish automatic prescreening tools to address this issue. However, dyslexia prescreening for children learning Chinese is challenging due to the lack of sound\u2013script correlation in Chinese. In this article, an automatic dyslexia prescreening system (ADPS) is developed to provide a quick test to identify at-risk children. Through a two-stage approach, we first develop a gamified tool based on linguistic characteristics and then evaluate the result by?\u2026", "IdName": "fung2024adps", "Citation": "", "Keywords": ""}, {"Name": "Generating Virtual Reality Stroke Gesture Data from Out-of-Distribution Desktop Stroke Gesture Data", "Authors": ["Lin-Ping Yuan", "Boyu Li", "Jindong Wang", "Huamin Qu", "Wei Zeng"], "Sources": "2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2024", "Doi": "", "Abstracts": "This paper exploits ubiquitous desktop interaction data as an input source for generating virtual reality (VR) interaction data, which can benefit tasks like user behavior analysis and experience enhancement. Time-varying stroke gestures are selected as the primary focus because of their prevalence across various applications and their diverse patterns. The commonalities (e.g., features like velocity and curvature) between desktop and VR strokes allow the generation of additional dimensions (e.g., z vectors) in VR strokes. However, distribution shifts exist between different interaction environments (i.e., desktop vs. VR), and within the same interaction environment for different strokes by various users, making it challenging to build models capable of generalizing to unseen distributions. To address the challenges, we formulate the problem of generating VR strokes from desktop strokes as a conditional time series?\u2026", "IdName": "yuan2024generating", "Citation": "", "Keywords": ""}, {"Name": "Humanoid robot-empowered language learning based on self-determination theory", "Authors": ["Ka Yan Fung", "Lik Hang Lee", "Kuen Fung Sin", "Shenghui Song", "Huamin Qu"], "Sources": "Education and Information Technologies", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the ability to provide feedback and assistance, humanoid educational robots have been proven effective in assisting students to overcome learning challenges and enhancing individual learning outcomes. However, the strength of humanoid robots in promoting social and emotional skills has not been well investigated. Socially supportive behaviour can contribute more to students\u2019 learning engagement than knowledge transfer. This study focuses on the design of humanoid robots to engage students from functional and affective perspectives. To this end, a pilot test is conducted on 64 primary school students in Hong Kong, comprising a control group (N?=?33) and an experimental group (N?=?31). Questionnaires, observations, and language proficiency test are done to ensure the validity of the findings. The results show that the experimental group, which learned with the humanoid robots, significantly?\u2026", "IdName": "fung2024humanoid", "Citation": "", "Keywords": ""}, {"Name": "TrafPS: A Shapley-based Visual Analytics Approach to Interpret Traffic", "Authors": ["Zezheng Feng", "Yifan Jiang", "Hongjun Wang", "Zipei Fan", "Yuxin Ma", "Shuang-Hua Yang", "Huamin Qu", "Xuan Song"], "Sources": "arXiv preprint arXiv:2403.04812", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent achievements in deep learning (DL) have shown its potential for predicting traffic flows. Such predictions are beneficial for understanding the situation and making decisions in traffic control. However, most state-of-the-art DL models are considered \"black boxes\" with little to no transparency for end users with respect to the underlying mechanisms. Some previous work tried to \"open the black boxes\" and increase the interpretability of how predictions are generated. However, it still remains challenging to handle complex models on large-scale spatio-temporal data and discover salient spatial and temporal patterns that significantly influence traffic flows. To overcome the challenges, we present TrafPS, a visual analytics approach for interpreting traffic prediction outcomes to support decision-making in traffic management and urban planning. The measurements, region SHAP and trajectory SHAP, are proposed to quantify the impact of flow patterns on urban traffic at different levels. Based on the task requirement from the domain experts, we employ an interactive visual interface for multi-aspect exploration and analysis of significant flow patterns. Two real-world case studies demonstrate the effectiveness of TrafPS in identifying key routes and decision-making support for urban planning.", "IdName": "feng2024trafps", "Citation": "", "Keywords": ""}, {"Name": "HoLens: A Visual Analytics Design for Higher-order Movement Modeling and Visualization", "Authors": ["Zezheng Feng", "Fang Zhu", "Hongjun Wang", "Jianing Hao", "ShuangHua Yang", "Wei Zeng", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2403.03822", "PublishedYears": "2024", "Doi": "", "Abstracts": "Higher-order patterns reveal sequential multistep state transitions, which are usually superior to origin-destination analysis, which depicts only first-order geospatial movement patterns. Conventional methods for higher-order movement modeling first construct a directed acyclic graph (DAG) of movements, then extract higher-order patterns from the DAG. However, DAG-based methods heavily rely on the identification of movement keypoints that are challenging for sparse movements and fail to consider the temporal variants that are critical for movements in urban environments. To overcome the limitations, we propose HoLens, a novel approach for modeling and visualizing higher-order movement patterns in the context of an urban environment. HoLens mainly makes twofold contributions: first, we design an auto-adaptive movement aggregation algorithm that self-organizes movements hierarchically by considering spatial proximity, contextual information, and temporal variability; second, we develop an interactive visual analytics interface consisting of well-established visualization techniques, including the H-Flow for visualizing the higher-order patterns on the map and the higher-order state sequence chart for representing the higher-order state transitions. Two real-world case studies manifest that the method can adaptively aggregate the data and exhibit the process of how to explore the higher-order patterns by HoLens. We also demonstrate our approach's feasibility, usability, and effectiveness through an expert interview with three domain experts.", "IdName": "feng2024holens", "Citation": "", "Keywords": ""}, {"Name": "VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality", "Authors": ["Wai Tong", "Kento Shigyo", "Lin-Ping Yuan", "Mingming Fan", "Ting-Chuen Pong", "Huamin Qu", "Meng Xia"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the rise of short-form video platforms and the increasing availability of data, we see the potential for people to share short-form videos embedded with data in situ (e.g., daily steps when running) to increase the credibility and expressiveness of their stories. However, creating and sharing such videos in situ is challenging since it involves multiple steps and skills (e.g., data visualization creation and video editing), especially for amateurs. By conducting a formative study (N=10) using three design probes, we collected the motivations and design requirements. We then built VisTellAR, a mobile AR authoring tool, to help amateur video creators embed data visualizations in short-form videos in situ. A two-day user study shows that participants (N=12) successfully created various videos with data visualizations in situ and they confirmed the ease of use and learning. AR pre-stage authoring was useful to assist people?\u2026", "IdName": "tong2024vistellar", "Citation": "", "Keywords": ""}, {"Name": "Towards an Exploratory Visual Analytics System for Griefer Identification in MOBA Games", "Authors": ["Zixin Chen", "Shiyi Liu", "Zhihua Jin", "Gaoping Huang", "Yang Chao", "Zhenchuan Yang", "Quan Li", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2312.14401", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multiplayer Online Battle Arenas (MOBAs) have gained a significant player base worldwide, generating over two billion US dollars in annual game revenue. However, the presence of griefers, who deliberately irritate and harass other players within the game, can have a detrimental impact on players' experience, compromising game fairness and potentially leading to the emergence of gray industries. Unfortunately, the absence of a standardized criterion, and the lack of high-quality labeled and annotated data has made it challenging to detect the presence of griefers. Given the complexity of the multivariant spatiotemporal data for MOBA games, game developers heavily rely on manual review of entire game video recordings to label and annotate griefers, which is a time-consuming process. To alleviate this issue, we have collaborated with a team of game specialists to develop an interactive visual analysis interface, called GrieferLens. It overviews players' behavior analysis and synthesizes their key match events. By presenting multiple views of information, GrieferLens can help the game design team efficiently recognize and label griefers in MOBA games and build up a foundation for creating a more enjoyable and fair gameplay environment.", "IdName": "chen2023towards", "Citation": "", "Keywords": ""}, {"Name": "System and A Method for Analyzing A Video", "Authors": ["Xingbo Wang", "Yong Wang", "WU Aoyu", "Huamin Qu"], "Sources": "US Patent App. 17/829", "PublishedYears": "2023", "Doi": "", "Abstracts": "The invention relates to a computer implemented method and system for analyzing a video. The method comprises the steps of receiving, via a receiving module, a video data comprising a series of images showing a subject; extracting, via an extracting module, a transcript derived from an audio data associated with the video data; aligning, via an aligning module, the series of images of the video data with the transcript derived from the audio data associated with the video data based on timestamps derived from the video data; analyzing, via an analyzing module, gestures of the subject from the series of images, comprising the steps of: identifying a plurality of reference points from each of the series of images showing the subject; segmenting the series of images in accordance with one or more selected texts comprising the transcript; identifying a defined gesture type for each of the segmented images based on?\u2026", "IdName": "wang2023system", "Citation": "", "Keywords": ""}, {"Name": "Knowledge Compass: A Question Answering System Guiding Students with Follow-Up Question Recommendations", "Authors": ["Rui Sheng", "Leni Yang", "Haotian Li", "Yan Luo", "Ziyang Xu", "Zhilan Zhou", "David Gotz", "Huamin Qu"], "Sources": "Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Pedagogical question-answering (QA) systems have been utilized for providing individual support in online learning courses. However, existing systems often neglect the education practice of guiding and encouraging students to think of relevant questions for deeper and more comprehensive learning. To address this gap, we introduce Knowledge Compass, an interactive QA system. The system can recommend follow-up questions that provide potential further explorations of the topics students ask about. Additionally, the system applies a course outline visualization and a set of interactive features for students to track the relationship between their questions and the course content.", "IdName": "sheng2023knowledge", "Citation": "", "Keywords": ""}, {"Name": "NeighViz: Towards Better Understanding of Neighborhood Effects on Social Groups with Spatial Data", "Authors": ["Yue Yu", "Yifang Wang", "Qisen Yang", "Di Weng", "Yongjun Zhang", "Xiaogang Wu", "Yingcai Wu", "Huamin Qu"], "Sources": "2023 IEEE Visualization in Data Science (VDS)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Understanding how local environments influence individual behaviors, such as voting patterns or suicidal tendencies, is crucial in social science to reveal and reduce spatial disparities and promote social well-being. With the increasing availability of large-scale individual-level census data, new analytical opportunities arise for social scientists to explore human behaviors (e.g., political engagement) among social groups at a fine-grained level. However, traditional statistical methods mostly focus on global, aggregated spatial correlations, which are limited to understanding and comparing the impact of local environments (e.g., neighborhoods) on human behaviors among social groups. In this study, we introduce a new analytical framework for analyzing multi-variate neighborhood effects between social groups. We then propose NeighViz, an interactive visual analytics system that helps social scientists explore?\u2026", "IdName": "yu2023neighviz", "Citation": "", "Keywords": ""}, {"Name": "NFTeller: Dual-centric Visual Analytics for Assessing Market Performance of NFT Collectibles", "Authors": ["Yifan Cao", "Meng Xia", "Kento Shigyo", "Furui Cheng", "Qianhang Yu", "Xingxing Yang", "Yang Wang", "Wei Zeng", "Huamin Qu"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Non-fungible tokens (NFTs) have recently gained widespread popularity as an alternative investment. However, the lack of assessment criteria has caused intense volatility in NFT marketplaces. Identifying attributes impacting the market performance of NFT collectibles is crucial but challenging due to the massive amount of heterogeneous and multi-modal data in NFT transactions, e.g., social media texts, numerical trading data, and images. To address this challenge, we introduce an interactive dual-centric visual analytics system, NFTeller, to facilitate users\u2019 analysis. First, we collaborate with five domain experts to distill static and dynamic impact attributes and collect relevant data. Next, we derive six analysis tasks and develop NFTeller to present the evolution of NFT transactions and correlate NFTs\u2019 market performance with impact attributes. Notably, we create an augmented chord diagram with a radial stacked?\u2026", "IdName": "cao2023nfteller", "Citation": "", "Keywords": ""}, {"Name": "ActorLens: Visual Analytics for High-level Actor Identification in MOBA Games", "Authors": ["Zhihua Jin", "Gaoping Huang", "Zixin Chen", "Shiyi Liu", "Yang Chao", "Zhenchuan Yang", "Quan Li", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2307.09699", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multiplayer Online Battle Arenas (MOBAs) have garnered a substantial player base worldwide. Nevertheless, the presence of noxious players, commonly referred to as \"actors\", can significantly compromise game fairness by exhibiting negative behaviors that diminish their team's competitive edge. Furthermore, high-level actors tend to engage in more egregious conduct to evade detection, thereby causing harm to the game community and necessitating their identification. To tackle this urgent concern, a partnership was formed with a team of game specialists from a prominent company to facilitate the identification and labeling of high-level actors in MOBA games. We first characterize the problem and abstract data and events from the game scene to formulate design requirements. Subsequently, ActorLens, a visual analytics system, was developed to exclude low-level actors, detect potential high-level actors, and assist users in labeling players. ActorLens furnishes an overview of players' status, summarizes behavioral patterns across three player cohorts (namely, focused players, historical matches of focused players, and matches of other players who played the same hero), and synthesizes key match events. By incorporating multiple views of information, users can proficiently recognize and label high-level actors in MOBA games. We conducted case studies and user studies to demonstrate the efficacy of the system.", "IdName": "jin2023actorlens", "Citation": "", "Keywords": ""}, {"Name": "HAPI explorer: comprehension, discovery, and explanation on history of ML APIs", "Authors": ["Lingjiao Chen", "Zhihua Jin", "Sabri Eyuboglu", "Huamin Qu", "Christopher R\u00e9", "Matei Zaharia", "James Zou"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Machine learning prediction APIs offered by Google, Microsoft, Amazon, and many other providers have been continuously adopted in a plethora of applications, such as visual object detection, natural language comprehension, and speech recognition. Despite the importance of a systematic study and comparison of different APIs over time, this topic is currently under-explored because of the lack of data and user-friendly exploration tools. To address this issue, we present HAPI Explorer (History of API Explorer), an interactive system that offers easy access to millions of instances of commercial API applications collected in three years, prioritize attention on user-defined instance regimes, and explain interesting patterns across different APIs, subpopulations, and time periods via visual and natural languages. HAPI Explorer can facilitate further comprehension and exploitation of ML prediction APIs.", "IdName": "chen2023hapi", "Citation": "", "Keywords": ""}, {"Name": "System and method for visual analysis of emotional coherence in videos", "Authors": ["Haipeng Zeng", "Xingbo Wang", "WU Aoyu", "Yong Wang", "Quan Li", "Huamin Qu"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "A computer implemented method and system processing a video signal. The method comprises comprising the steps of: detecting a human face displayed in the video signal and extracting physiological, biological, or behavior state information from the displayed face at a first level of granularity of the video signal; processing any two or more of:(i) a script derived from or associated with the video signal to extract language tone information from said script at a first level of granularity of the script;(ii) an audio signal derived from or associated with the video signal to derive behavior state information from said audio signal at a first level of granularity of the audio signal;(iii) a video image derived from the video signal to detect one or more human gestures of the person whose face is displayed in the video signal; and merging said physiological, biological, or behavior state information extracted from the displayed face in?\u2026", "IdName": "zeng2022system", "Citation": "", "Keywords": ""}, {"Name": "All one needs to know about metaverse: A complete survey on technological singularity, virtual ecosystem, and research agenda", "Authors": ["Lik-Hang Lee", "Tristan Braud", "Pengyuan Zhou", "Lin Wang", "Dianlei Xu", "Zijun Lin", "Abhishek Kumar", "Carlos Bermejo", "Pan Hui"], "Sources": "arXiv preprint arXiv:2110.05352", "PublishedYears": "2021", "Doi": "", "Abstracts": "Since the popularisation of the Internet in the 1990s, the cyberspace has kept evolving. We have created various computer-mediated virtual environments including social networks, video conferencing, virtual 3D worlds (e.g., VR Chat), augmented reality applications (e.g., Pokemon Go), and Non-Fungible Token Games (e.g., Upland). Such virtual environments, albeit non-perpetual and unconnected, have bought us various degrees of digital transformation. The term `metaverse' has been coined to further facilitate the digital transformation in every aspect of our physical lives. At the core of the metaverse stands the vision of an immersive Internet as a gigantic, unified, persistent, and shared realm. While the metaverse may seem futuristic, catalysed by emerging technologies such as Extended Reality, 5G, and Artificial Intelligence, the digital `big bang' of our cyberspace is not far away. This survey paper presents the first effort to offer a comprehensive framework that examines the latest metaverse development under the dimensions of state-of-the-art technologies and metaverse ecosystems, and illustrates the possibility of the digital `big bang'. First, technologies are the enablers that drive the transition from the current Internet to the metaverse. We thus examine eight enabling technologies rigorously - Extended Reality, User Interactivity (Human-Computer Interaction), Artificial Intelligence, Blockchain, Computer Vision, IoT and Robotics, Edge and Cloud computing, and Future Mobile Networks. In terms of applications, the metaverse ecosystem allows human users to live and play within a self-sustaining, persistent, and shared realm. Therefore, we?\u2026", "IdName": "lee2021all", "Citation": "", "Keywords": ""}, {"Name": "Edge intelligence: Empowering intelligence to the edge of network", "Authors": ["Dianlei Xu", "Tong Li", "Yong Li", "Xiang Su", "Sasu Tarkoma", "Tao Jiang", "Jon Crowcroft", "Pan Hui"], "Sources": "Proceedings of the IEEE", "PublishedYears": "2021", "Doi": "", "Abstracts": "Edge intelligence refers to a set of connected systems and devices for data collection, caching, processing, and analysis proximity to where data are captured based on artificial intelligence. Edge intelligence aims at enhancing data processing and protects the privacy and security of the data and users. Although recently emerged, spanning the period from 2011 to now, this field of research has shown explosive growth over the past five years. In this article, we present a thorough and comprehensive survey of the literature surrounding edge intelligence. We first identify four fundamental components of edge intelligence, i.e., edge caching, edge training, edge inference, and edge offloading based on theoretical and practical results pertaining to proposed and deployed systems. We then aim for a systematic classification of the state of the solutions by examining research results and observations for each of the four?\u2026", "IdName": "xu2021edge", "Citation": "", "Keywords": ""}, {"Name": "Life, the metaverse and everything: An overview of privacy, ethics, and governance in metaverse", "Authors": ["Carlos Bermejo Fernandez", "Pan Hui"], "Sources": "2022 IEEE 42nd international conference on distributed computing systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The metaverse is expected to be the next major evolution phase of the internet. The metaverse will impact human society, production, and life. In this work, we analyze the current trends and challenges that building such a virtual environment will face. We focus on three major pillars to guide the development of the metaverse: privacy, governance, and ethical design, to guide the development of the metaverse. Finally, we propose a preliminary modular-based framework for an ethical design of the metaverse.", "IdName": "fernandez2022life", "Citation": "", "Keywords": ""}, {"Name": "Privacy-preserving asynchronous federated learning mechanism for edge network computing", "Authors": ["Xiaofeng Lu", "Yuying Liao", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "In the traditional cloud architecture, data needs to be uploaded to the cloud for processing, bringing delays in transmission and response. Edge network emerges as the times require. Data processing on the edge nodes can reduce the delay of data transmission and improve the response speed. In recent years, the need for artificial intelligence of edge network has been proposed. However, the data of a single, individual edge node is limited and does not satisfy the conditions of machine learning. Therefore, performing edge network machine learning under the premise of data confidentiality became a research hotspot. This paper proposes a Privacy-Preserving Asynchronous Federated Learning Mechanism for Edge Network Computing (PAFLM), which can allow multiple edge nodes to achieve more efficient federated learning without sharing their private data. Compared with the traditional distributed learning?\u2026", "IdName": "lu2020privacy", "Citation": "", "Keywords": ""}, {"Name": "A survey on haptic technologies for mobile augmented reality", "Authors": ["Carlos Bermejo", "Pan Hui"], "Sources": "ACM Computing Surveys (CSUR)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Augmented reality (AR) applications have gained much research and industry attention. Moreover, the mobile counterpart\u2014mobile augmented reality (MAR) is one of the most explosive growth areas for AR applications in the mobile environment (e.g., smartphones). The technical improvements in the hardware of smartphones, tablets, and smart-glasses provide an advantage for the wide use of mobile AR in the real world and experience these AR applications anywhere. However, the mobile nature of MAR applications can limit users\u2019 interaction capabilities, such as input and haptic feedback. In this survey, we analyze current research issues in the area of human-computer interaction for haptic technologies in MAR scenarios. The survey first presents human sensing capabilities and their applicability in AR applications. We classify haptic devices into two groups according to the triggered sense: cutaneous/tactile?\u2026", "IdName": "bermejo2021survey", "Citation": "", "Keywords": ""}, {"Name": "One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc era", "Authors": ["Chaoning Zhang", "Chenshuang Zhang", "Chenghao Li", "Yu Qiao", "Sheng Zheng", "Sumit Kumar Dam", "Mengchun Zhang", "Jung Uk Kim", "Seong Tae Kim", "Jinwoo Choi", "Gyeong-Moon Park", "Sung-Ho Bae", "Lik-Hang Lee", "Pan Hui", "In So Kweon", "Choong Seon Hong"], "Sources": "arXiv preprint arXiv:2304.06488", "PublishedYears": "2023", "Doi": "", "Abstracts": "OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is demonstrated to be one small step for generative AI (GAI), but one giant leap for artificial general intelligence (AGI). Since its official release in November 2022, ChatGPT has quickly attracted numerous users with extensive media coverage. Such unprecedented attention has also motivated numerous researchers to investigate ChatGPT from various aspects. According to Google scholar, there are more than 500 articles with ChatGPT in their titles or mentioning it in their abstracts. Considering this, a review is urgently needed, and our work fills this gap. Overall, this work is the first to survey ChatGPT with a comprehensive review of its underlying technology, applications, and challenges. Moreover, we present an outlook on how ChatGPT might evolve to realize general-purpose AIGC (a.k.a. AI-generated content), which will be a significant milestone for the development of AGI.", "IdName": "zhang2023one", "Citation": "", "Keywords": ""}, {"Name": "Automatic mandibular canal detection using a deep convolutional neural network", "Authors": ["Gloria Hyunjung Kwak", "Eun-Jung Kwak", "Jae Min Song", "Hae Ryoun Park", "Yun-Hoa Jung", "Bong-Hae Cho", "Pan Hui", "Jae Joon Hwang"], "Sources": "Scientific Reports", "PublishedYears": "2020", "Doi": "", "Abstracts": "The practicability of deep learning techniques has been demonstrated by their successful implementation in varied fields, including diagnostic imaging for clinicians. In accordance with the increasing demands in the healthcare industry, techniques for automatic prediction and detection are being widely researched. Particularly in dentistry, for various reasons, automated mandibular canal detection has become highly desirable. The positioning of the inferior alveolar nerve (IAN), which is one of the major structures in the mandible, is crucial to prevent nerve injury during surgical procedures. However, automatic segmentation using Cone beam computed tomography (CBCT) poses certain difficulties, such as the complex appearance of the human skull, limited number of datasets, unclear edges, and noisy images. Using work-in-progress automation software, experiments were conducted with models based on 2D?\u2026", "IdName": "kwak2020automatic", "Citation": "", "Keywords": ""}, {"Name": "When creators meet the metaverse: A survey on computational arts", "Authors": ["Lik-Hang Lee", "Zijun Lin", "Rui Hu", "Zhengya Gong", "Abhishek Kumar", "Tangyao Li", "Sijia Li", "Pan Hui"], "Sources": "arXiv preprint arXiv:2111.13486", "PublishedYears": "2021", "Doi": "", "Abstracts": "The metaverse, enormous virtual-physical cyberspace, has brought unprecedented opportunities for artists to blend every corner of our physical surroundings with digital creativity. This article conducts a comprehensive survey on computational arts, in which seven critical topics are relevant to the metaverse, describing novel artworks in blended virtual-physical realities. The topics first cover the building elements for the metaverse, e.g., virtual scenes and characters, auditory, textual elements. Next, several remarkable types of novel creations in the expanded horizons of metaverse cyberspace have been reflected, such as immersive arts, robotic arts, and other user-centric approaches fuelling contemporary creative outputs. Finally, we propose several research agendas: democratising computational arts, digital privacy, and safety for metaverse artists, ownership recognition for digital artworks, technological challenges, and so on. The survey also serves as introductory material for artists and metaverse technologists to begin creations in the realm of surrealistic cyberspace.", "IdName": "lee2021creators", "Citation": "", "Keywords": ""}, {"Name": "ChatGPT in education: A blessing or a curse? A qualitative study exploring early adopters\u2019 utilization and perceptions", "Authors": ["Reza Hadi Mogavi", "Chao Deng", "Justin Juho Kim", "Pengyuan Zhou", "Young D Kwon", "Ahmed Hosny Saleh Metwally", "Ahmed Tlili", "Simone Bassanelli", "Antonio Bucchiarone", "Sujit Gujar", "Lennart E Nacke", "Pan Hui"], "Sources": "Computers in Human Behavior: Artificial Humans", "PublishedYears": "2024", "Doi": "", "Abstracts": "To foster the development of pedagogically potent and ethically sound AI-integrated learning landscapes, it is pivotal to critically explore the perceptions and experiences of the users immersed in these contexts. In this study, we perform a thorough qualitative content analysis across four key social media platforms. Our goal is to understand the user experience (UX) and views of early adopters of ChatGPT across different educational sectors. The results of our research show that ChatGPT is most commonly used in the domains of higher education, K-12 education, and practical skills training. In social media dialogues, the topics most frequently associated with ChatGPT are productivity, efficiency, and ethics. Early adopters' attitudes towards ChatGPT are multifaceted. On one hand, some users view it as a transformative tool capable of amplifying student self-efficacy and learning motivation. On the other hand, there?\u2026", "IdName": "mogavi2024chatgpt", "Citation": "", "Keywords": ""}, {"Name": "Trustworthy AI in the age of pervasive computing and big data", "Authors": ["Abhishek Kumar", "Tristan Braud", "Sasu Tarkoma", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "The era of pervasive computing has resulted in countless devices that continuously monitor users and their environment, generating an abundance of user behavioural data. Such data may support improving the quality of service, but may also lead to adverse usages such as surveillance and advertisement. In parallel, Artificial Intelligence (AI) systems are being applied to sensitive fields such as healthcare, justice, or human resources, raising multiple concerns on the trustworthiness of such systems. Trust in AI systems is thus intrinsically linked to ethics, including the ethics of algorithms, the ethics of data, or the ethics of practice. In this paper, we formalise the requirements of trustworthy AI systems through an ethics perspective. We specifically focus on the aspects that can be integrated into the design and development of AI systems. After discussing the state of research and the remaining challenges, we show how?\u2026", "IdName": "kumar2020trustworthy", "Citation": "", "Keywords": ""}, {"Name": "Smartphone app usage analysis: datasets, methods, and applications", "Authors": ["Tong Li", "Tong Xia", "Huandong Wang", "Zhen Tu", "Sasu Tarkoma", "Zhu Han", "Pan Hui"], "Sources": "IEEE Communications Surveys & Tutorials", "PublishedYears": "2022", "Doi": "", "Abstracts": "As smartphones have become indispensable personal devices, the number of smartphone users has increased dramatically over the last decade. These personal devices, which are supported by a variety of smartphone apps, allow people to access Internet services in a convenient and ubiquitous manner. App developers and service providers can collect fine-grained app usage traces, revealing connections between users, apps, and smartphones. We present a comprehensive review of the most recent research on smartphone app usage analysis in this survey. Our survey summarizes advanced technologies and key patterns in smartphone app usage behaviors, all of which have significant implications for all relevant stakeholders, including academia and industry. We begin by describing four data collection methods: surveys, monitoring apps, network operators, and app stores, as well as nine publicly available?\u2026", "IdName": "li2022smartphone", "Citation": "", "Keywords": ""}, {"Name": "Urban anomaly analytics: Description, detection, and prediction", "Authors": ["Mingyang Zhang", "Tong Li", "Yue Yu", "Yong Li", "Pan Hui", "Yu Zheng"], "Sources": "IEEE Transactions on Big Data", "PublishedYears": "2020", "Doi": "", "Abstracts": "Urban anomalies may result in loss of life or property if not handled properly. Automatically alerting anomalies in their early stage or even predicting anomalies before happening is of great value for populations. Recently, data-driven urban anomaly analysis frameworks have been forming, which utilize urban big data and machine learning algorithms to detect and predict urban anomalies automatically. In this survey, we make a comprehensive review of the state-of-the-art research on urban anomaly analytics. We first give an overview of four main types of urban anomalies, traffic anomaly, unexpected crowds, environment anomaly, and individual anomaly. Next, we summarize various types of urban datasets obtained from diverse devices, i.e., trajectory, trip records, CDRs, urban sensors, event records, environment data, social media and surveillance cameras. Subsequently, a comprehensive survey of issues on?\u2026", "IdName": "zhang2020urban", "Citation": "", "Keywords": ""}, {"Name": "A multi-stream feature fusion approach for traffic prediction", "Authors": ["Zhishuai Li", "Gang Xiong", "Yonglin Tian", "Yisheng Lv", "Yuanyuan Chen", "Pan Hui", "Xiang Su"], "Sources": "IEEE transactions on intelligent transportation systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Accurate and timely traffic flow prediction is crucial for intelligent transportation systems (ITS). Recent advances in graph-based neural networks have achieved promising prediction results. However, some challenges remain, especially regarding graph construction and the time complexity of models. In this paper, we propose a multi-stream feature fusion approach to extract and integrate rich features from traffic data and leverage a data-driven adjacent matrix instead of the distance-based matrix to construct graphs. We calculate the Spearman rank correlation coefficient between monitor stations to obtain the initial adjacent matrix and fine-tune it while training. As to the model, we construct a multi-stream feature fusion block (MFFB) module, which includes a three-channel network and the soft-attention mechanism. The three-channel networks are graph convolutional neural network (GCN), gated recurrent unit?\u2026", "IdName": "li2020multi", "Citation": "", "Keywords": ""}, {"Name": "Can chatgpt reproduce human-generated labels? a study of social computing tasks", "Authors": ["Yiming Zhu", "Peixian Zhang", "Ehsan-Ul Haq", "Pan Hui", "Gareth Tyson"], "Sources": "arXiv preprint arXiv:2304.10145", "PublishedYears": "2023", "Doi": "", "Abstracts": "The release of ChatGPT has uncovered a range of possibilities whereby large language models (LLMs) can substitute human intelligence. In this paper, we seek to understand whether ChatGPT has the potential to reproduce human-generated label annotations in social computing tasks. Such an achievement could significantly reduce the cost and complexity of social computing research. As such, we use ChatGPT to re-label five seminal datasets covering stance detection (2x), sentiment analysis, hate speech, and bot detection. Our results highlight that ChatGPT does have the potential to handle these data annotation tasks, although a number of challenges remain. ChatGPT obtains an average precision 0.609. Performance is highest for the sentiment analysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we show that performance varies substantially across individual labels. We believe this work can open up new lines of analysis and act as a basis for future research into the exploitation of ChatGPT for human annotation tasks.", "IdName": "zhu2023can", "Citation": "", "Keywords": ""}, {"Name": "Re-shaping Post-COVID-19 teaching and learning: A blueprint of virtual-physical blended classrooms in the metaverse era", "Authors": ["Yuyang Wang", "Lik-Hang Lee", "Tristan Braud", "Pan Hui"], "Sources": "2022 IEEE 42nd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "During the COVID-19 pandemic, most countries have experienced some form of remote education through video conferencing software platforms. However, these software platforms fail to reduce immersion and replicate the classroom experience. The currently emerging Metaverse addresses many of such limitations by offering blended physical-digital environments. This paper aims to assess how the Metaverse can support and improve e-learning. We first survey the latest applications of blended environments in education and highlight the primary challenges and opportunities. Accordingly, we derive our proposal for a virtual-physical blended classroom configuration that brings students and teachers into a shared educational Metaverse. We focus on the system architecture of the Metaverse classroom to achieve real-time synchronization of a large number of participants and activities across physical (mixed?\u2026", "IdName": "wang2022re", "Citation": "", "Keywords": ""}, {"Name": "To what extent we repeat ourselves? Discovering daily activity patterns across mobile app usage", "Authors": ["Tong Li", "Yong Li", "Mohammad Ashraful Hoque", "Tong Xia", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "With the prevalence of smartphones, people have left abundant behavior records in cyberspace. Discovering and understanding individuals\u2019 cyber activities can provide useful implications for policymakers, service providers, and app developers. In this paper, we propose a framework to discover daily cyber activity patterns across people's mobile app usage. The framework first segments app usage traces into short time windows and then applies a probabilistic topic model to infer users\u2019 cyber activities in each window. By constructing and exploring the coherence of users\u2019 activity sequences, the framework can identify individuals\u2019 daily patterns. Next, the framework uses a hierarchical clustering algorithm to recognize the common patterns across diverse groups of individuals. We apply the framework on a large-scale and real-world dataset, consisting of 653,092 users with 971,818,946 usage records of 2,000?\u2026", "IdName": "li2020extent", "Citation": "", "Keywords": ""}, {"Name": "Multi-view joint graph representation learning for urban region embedding", "Authors": ["Mingyang Zhang", "Tong Li", "Yong Li", "Pan Hui"], "Sources": "Proceedings of the Twenty-Ninth International Conference on International?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "The increasing amount of urban data enables us to investigate urban dynamics, assist urban planning, and, eventually, make our cities more livable and sustainable. In this paper, we focus on learning an embedding space from urban data for urban regions. For the first time, we propose a multi-view joint learning model to learn comprehensive and representative urban region embeddings. We first model different types of region correlations based on both human mobility and inherent region properties. Then, we apply a graph attention mechanism in learning region representations from each view of the built correlations. Moreover, we introduce a joint learning module that boosts the region embedding learning by sharing cross-view information and fuses multi-view embeddings by learning adaptive weights. Finally, we exploit the learned embeddings in the downstream applications of land usage classification and crime prediction in urban areas with real-world data. Extensive experiment results demonstrate that by exploiting our proposed joint learning model, the performance is improved by a large margin on both tasks compared with the state-of-the-art methods.", "IdName": "zhang2021multi", "Citation": "", "Keywords": ""}, {"Name": "Continuous authentication by free-text keystroke based on CNN and RNN", "Authors": ["Xiaofeng Lu", "Shengfei Zhang", "Pan Hui", "Pietro Lio"], "Sources": "Computers & Security 96", "PublishedYears": "2020", "Doi": "", "Abstracts": "Personal keystroke modes are difficult to imitate and can therefore be used for identity authentication. The keystroke habits of a person can be learned according to the keystroke data generated when the person inputs free text. Detecting a user's keystroke habits as the user enters text can continuously verify the user's identity without affecting user input. The method proposed in this paper authenticates users via their keystrokes when they type free text. The user keystroke data is divided into a fixed-length keystroke sequence, which is then converted into a keystroke vector sequence according to the time feature of the keystroke. A model that combines a convolutional neural network and a recursive neural network is used to learn a sequence of individual keystroke vectors to obtain individual keystroke features for identity authentication. The model is tested using two open datasets, and the best false rejection rate?\u2026", "IdName": "lu2020continuous", "Citation": "", "Keywords": ""}, {"Name": "Agora: A privacy-aware data marketplace", "Authors": ["Vlasis Koutsos", "Dimitrios Papadopoulos", "Dimitris Chatzopoulos", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Dependable and Secure Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "We propose Agora, the first blockchain-based data marketplace that enables multiple privacy-concerned parties to get compensated for contributing and exchanging data, without relying on a trusted third party during the exchange. Agora achieves  data privacy ,  output verifiability , and  atomicity of payments  by leveraging cryptographic techniques, and is designed as a decentralized application via smart contracts. Particularly, data generators provide encrypted data to data brokers who use a  functional secret key  to learn nothing but the output of a specific, agreed upon, function over the raw data. Data consumers can purchase decrypted outputs from the brokers, accompanied by corresponding  proofs of correctness . We implement a working prototype of Agora on Ethereum and experimentally evaluate its performance and deployment costs. As a core building block of Agora, we propose a new  functional?\u2026", "IdName": "koutsos2021agora", "Citation": "", "Keywords": ""}, {"Name": "Mobile augmented reality: User interfaces, frameworks, and intelligence", "Authors": ["Jacky Cao", "Kit-Yung Lam", "Lik-Hang Lee", "Xiaoli Liu", "Pan Hui", "Xiang Su"], "Sources": "ACM Computing Surveys", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) integrates computer-generated virtual objects with physical environments for mobile devices. MAR systems enable users to interact with MAR devices, such as smartphones and head-worn wearables, and perform seamless transitions from the physical world to a mixed world with digital entities. These MAR systems support user experiences using MAR devices to provide universal access to digital content. Over the past 20 years, several MAR systems have been developed, however, the studies and design of MAR frameworks have not yet been systematically reviewed from the perspective of user-centric design. This article presents the first effort of surveying existing MAR frameworks (count: 37) and further discusses the latest studies on MAR through a top-down approach: (1) MAR applications; (2) MAR visualisation techniques adaptive to user mobility and contexts; (3) systematic?\u2026", "IdName": "cao2023mobile", "Citation": "", "Keywords": ""}, {"Name": "Multipath computation offloading for mobile augmented reality", "Authors": ["Tristan Braud", "ZHOU Pengyuan", "Jussi Kangasharju", "HUI Pan"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) applications employ computationally demanding vision algorithms on resource-limited devices. In parallel, communication networks are becoming more ubiquitous. Offloading to distant servers can thus overcome the device limitations at the cost of network delays. Multipath networking has been proposed to overcome network limitations but it is not easily adaptable to edge computing due to the server proximity and networking differences. In this article, we extend the current mobile edge offloading models and present a model for multi-server device-to-device, edge, and cloud offloading. We then introduce a new task allocation algorithm exploiting this model for MAR offloading. Finally, we evaluate the allocation algorithm against naive multipath scheduling and single path models through both a real-life experiment and extensive simulations. In case of sub-optimal network?\u2026", "IdName": "braud2020multipath", "Citation": "", "Keywords": ""}, {"Name": "\u201d what apps did you use?\u201d: Understanding the long-term evolution of mobile app usage", "Authors": ["Tong Li", "Mingyang Zhang", "Hancheng Cao", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the web conference 2020", "PublishedYears": "2020", "Doi": "", "Abstracts": "The prevalence of smartphones has promoted the popularity of mobile apps in recent years. Although significant effort has been made to understand mobile app usage, existing studies are based primarily on short-term datasets with limited time span, e.g., a few months. Therefore, many basic facts about the long-term evolution of mobile app usage are unknown. In this paper, we study how mobile app usage evolves over a long-term period. We first introduce an app usage collection platform named carat, from which we have gathered app usage records of 1,465 users from 2012 to 2017. We then conduct the first study on the long-term evolution processes on a macro-level, i.e., app-category, and micro-level, i.e., individual app. We discover that, on both levels, there is a growth stage enabled by the introduction of new technologies. Then there is a plateau stage caused by high correlations between app categories?\u2026", "IdName": "li2020apps", "Citation": "", "Keywords": ""}, {"Name": "DRLE: Decentralized reinforcement learning at the edge for traffic light control in the IoV", "Authors": ["Pengyuan Zhou", "Xianfu Chen", "Zhi Liu", "Tristan Braud", "Pan Hui", "Jussi Kangasharju"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "The Internet of Vehicles (IoV) enables real-time data exchange among vehicles and roadside units and thus provides a promising solution to alleviate traffic jams in the urban area. Meanwhile, better traffic management via efficient traffic light control can benefit the IoV as well by enabling a better communication environment and decreasing the network load. As such, IoV and efficient traffic light control can formulate a virtuous cycle. Edge computing, an emerging technology to provide low-latency computation capabilities at the edge of the network, can further improve the performance of this cycle. However, while the collected information is valuable, an efficient solution for better utilization and faster feedback has yet to be developed for edge-empowered IoV. To this end, we propose a Decentralized Reinforcement Learning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits the ubiquity of the IoV to?\u2026", "IdName": "zhou2020drle", "Citation": "", "Keywords": ""}, {"Name": "Understanding the long-term evolution of mobile app usage", "Authors": ["Tong Li", "Yali Fan", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "The prevalence of smartphones has promoted the popularity of mobile apps in recent years. Although significant effort has been made to understand mobile app usage, existing studies are based primarily on short-term datasets with a limited time span, e.g., a few months. Therefore, many basic facts about the long-term evolution of mobile app usage are unknown. In this paper, we study how mobile app usage evolves over a long-term period. We first introduce an app usage collection platform named carat, from which we have gathered app usage records of 1,465 users from 2012 to 2017. We then conduct the first study on the long-term evolution processes on a macro-level, i.e., app-category, and micro-level, i.e., individual app. We discover that, on both levels, there is a growth stage enabled by the introduction of new technologies. Then there is a plateau stage caused by high correlations between app categories?\u2026", "IdName": "li2021understanding", "Citation": "", "Keywords": ""}, {"Name": "This website uses nudging: Mturk workers' behaviour on cookie consent notices", "Authors": ["Carlos Bermejo Fernandez", "Dimitris Chatzopoulos", "Dimitrios Papadopoulos", "Pan Hui"], "Sources": "Proceedings of the ACM on human-computer interaction", "PublishedYears": "2021", "Doi": "", "Abstracts": "Data protection regulatory policies, such as the European Union's General Data Protection Regulation (GDPR), force website operators to request users' consent before collecting any personal information revealed through their web browsing. Website operators, motivated by the potential value of the collected personal data, employ various methods when designing consent notices (e.g., dark patterns) in order to convince users to allow the collection of as much of their personal data as possible. In this paper, we design and conduct a user study where 1100 MTurk workers interact with eight different designs of cookie consent notices. We show that the nudging designs used in the different cookie consent notices have a large effect on the choices user make. Our results show that color-based nudging bars can significantly impact the participants' decisions to change the default cookie settings, despite using dark?\u2026", "IdName": "bermejo2021website", "Citation": "", "Keywords": ""}, {"Name": "Towards augmented reality driven human-city interaction: Current research on mobile headsets and future challenges", "Authors": ["Lik-Hang Lee", "Tristan Braud", "Simo Hosio", "Pan Hui"], "Sources": "ACM Computing Surveys (CSUR)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Interaction design for Augmented Reality (AR) is gaining attention from both academia and industry. This survey discusses 260 articles (68.8% of articles published between 2015\u20132019) to review the field of human interaction in connected cities with emphasis on augmented reality-driven interaction. We provide an overview of Human-City Interaction and related technological approaches, followed by reviewing the latest trends of information visualization, constrained interfaces, and embodied interaction for AR headsets. We highlight under-explored issues in interface design and input techniques that warrant further research and conjecture that AR with complementary Conversational User Interfaces (CUIs) is a crucial enabler for ubiquitous interaction with immersive systems in smart cities. Our work helps researchers understand the current potential and future needs of AR in Human-City Interaction.", "IdName": "lee2021towards", "Citation": "", "Keywords": ""}, {"Name": "Identity, crimes, and law enforcement in the metaverse", "Authors": ["Hua Xuan Qin", "Yuyang Wang", "Pan Hui"], "Sources": "arXiv preprint arXiv:2210.06134", "PublishedYears": "2022", "Doi": "", "Abstracts": "With the boom in metaverse-related projects in major areas of the public's life, the safety of users becomes a pressing concern. We believe that an international legal framework should be established to promote collaboration among nations, facilitate crime investigation, and support democratic governance. In this paper, we discuss the legal concerns of identity, crimes that could occur based on incidents in existing virtual worlds, and challenges to unified law enforcement in the metaverse.", "IdName": "qin2022identity", "Citation": "", "Keywords": ""}, {"Name": "Enhancing the internet of things with knowledge-driven software-defined networking technology: Future perspectives", "Authors": ["Yuhong Li", "Xiang Su", "Aaron Yi Ding", "Anders Lindgren", "Xiaoli Liu", "Christian Prehofer", "Jukka Riekki", "Rahim Rahmani", "Sasu Tarkoma", "Pan Hui"], "Sources": "Sensors", "PublishedYears": "2020", "Doi": "", "Abstracts": "The Internet of Things (IoT) connects smart devices to enable various intelligent services. The deployment of IoT encounters several challenges, such as difficulties in controlling and managing IoT applications and networks, problems in programming existing IoT devices, long service provisioning time, underused resources, as well as complexity, isolation and scalability, among others. One fundamental concern is that current IoT networks lack flexibility and intelligence. A network-wide flexible control and management are missing in IoT networks. In addition, huge numbers of devices and large amounts of data are involved in IoT, but none of them have been tuned for supporting network management and control. In this paper, we argue that Software-defined Networking (SDN) together with the data generated by IoT applications can enhance the control and management of IoT in terms of flexibility and intelligence. We present a review for the evolution of SDN and IoT and analyze the benefits and challenges brought by the integration of SDN and IoT with the help of IoT data. We discuss the perspectives of knowledge-driven SDN for IoT through a new IoT architecture and illustrate how to realize Industry IoT by using the architecture. We also highlight the challenges and future research works toward realizing IoT with the knowledge-driven SDN.", "IdName": "li2020enhancing", "Citation": "", "Keywords": ""}, {"Name": "A survey on edge intelligence", "Authors": ["Dianlei Xu", "Tong Li", "Yong Li", "Xiang Su", "Sasu Tarkoma", "Pan Hui"], "Sources": "arXiv preprint arXiv:2003.12172", "PublishedYears": "2020", "Doi": "", "Abstracts": "Edge intelligence refers to a set of connected systems and devices for data collection, caching, processing, and analysis in locations close to where data is captured based on artificial intelligence. The aim of edge intelligence is to enhance the quality and speed of data processing and protect the privacy and security of the data. Although recently emerged, spanning the period from 2011 to now, this field of research has shown explosive growth over the past five years. In this paper, we present a thorough and comprehensive survey on the literature surrounding edge intelligence. We first identify four fundamental components of edge intelligence, namely edge caching, edge training, edge inference, and edge offloading, based on theoretical and practical results pertaining to proposed and deployed systems. We then aim for a systematic classification of the state of the solutions by examining research results and observations for each of the four components and present a taxonomy that includes practical problems, adopted techniques, and application goals. For each category, we elaborate, compare and analyse the literature from the perspectives of adopted techniques, objectives, performance, advantages and drawbacks, etc. This survey article provides a comprehensive introduction to edge intelligence and its application areas. In addition, we summarise the development of the emerging research field and the current state-of-the-art and discuss the important open issues and possible theoretical and technical solutions.", "IdName": "xu2020survey", "Citation": "", "Keywords": ""}, {"Name": "A deep learning method for improving the classification accuracy of SSMVEP-based BCI", "Authors": ["Zhongke Gao", "Tao Yuan", "Xinjun Zhou", "Chao Ma", "Kai Ma", "Pan Hui"], "Sources": "IEEE Transactions on Circuits and Systems II: Express Briefs", "PublishedYears": "2020", "Doi": "", "Abstracts": "Steady State Motion Visual Evoked Potential (SSMVEP)-based Brain Computer Interface (BCI) is widely studied and has been used to varies of occasions on account of its good performance, mild stimulation, and free of additional training. We design a trolley control system based on SSMVEP signals and observe a phenomenon named \u201cBCI Illiterate,\u201d in which case some subjects present unsatisfactory performance with low classification accuracies. In order to cope with this challenging problem in real-world contexts, we introduce a deep learning (DL) method. The method allows improving the accuracies for both EEG literate and EEG illiterate. In particular, we firstly conduct SSMVEP experiments to obtain EEG signals from 10 subjects, including 5 EEG literates and 5 EEG illiterates. Then we construct a convolutional neural network with long short-term memory (CNN-LSTM) framework, which allows extracting the?\u2026", "IdName": "gao2020deep", "Citation": "", "Keywords": ""}, {"Name": "Scaling-up ar: University campus as a physical-digital metaverse", "Authors": ["Tristan Braud", "Carlos Bermejo Fern\u00e1ndez", "Pan Hui"], "Sources": "2022 ieee conference on virtual reality and 3d user interfaces abstracts and?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The metaverse promises large-scale and persistent environments for users to share experiences at the intersection between physical and digital. Augmented reality (AR) is one of the primary technologies that supports blending digital content with physical environments. However, most AR applications are currently single-user and present significant constraints in terms of time and location. Scaling up the technology to large-sized environments and massively multi-user experiences thus represents one of the primary challenges to achieving such a vision. Due to these constraints, current proposals for the metaverse primarily consist of virtual worlds with little duality between physical and digital. This paper studies the feasibility of a large-scale and persistent AR experience shared among all visitors on our university campus. We define an integrated framework to enable the first AR campus metaverse by considering?\u2026", "IdName": "braud2022scaling", "Citation": "", "Keywords": ""}, {"Name": "Contauth: Continual learning framework for behavioral-based user authentication", "Authors": ["Jagmohan Chauhan", "Young D Kwon", "Pan Hui", "Cecilia Mascolo"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "User authentication is key in user authorization on smart and personal devices. Over the years, several authentication mechanisms have been proposed: these also include behavioral-based biometrics. However, behavioral-based biometrics suffer from two issues: they are prone to degradation in performance (accuracy) over time (e.g., due to data distribution changes arising from user behavior) and the need to learn the machine learning model from scratch, when adding new users. In this paper, we propose ContAuth, a system that can enhance the robustness of behavioral-based authentication. ContAuth continuously adapts to new incoming data (data incremental learning) and is able to add new users without retraining (class incremental learning). Specifically, ContAuth combines deep learning models with online learning models to achieve learning on the fly, thereby preventing a severe drop in the accuracy?\u2026", "IdName": "chauhan2020contauth", "Citation": "", "Keywords": ""}, {"Name": "Twitter dataset for 2022 russo-ukrainian crisis", "Authors": ["Ehsan-Ul Haq", "Gareth Tyson", "Lik-Hang Lee", "Tristan Braud", "Pan Hui"], "Sources": "arXiv preprint arXiv:2203.02955", "PublishedYears": "2022", "Doi": "", "Abstracts": "Online Social Networks (OSNs) play a significant role in information sharing during a crisis. The data collected during such a crisis can reflect the large scale public opinions and sentiment. In addition, OSN data can also be used to study different campaigns that are employed by various entities to engineer public opinions. Such information sharing campaigns can range from spreading factual information to propaganda and misinformation. We provide a Twitter dataset of the 2022 Russo-Ukrainian conflict. In the first release, we share over 1.6 million tweets shared during the 1st week of the crisis.", "IdName": "haq2022twitter", "Citation": "", "Keywords": ""}, {"Name": "3dgcn: 3-dimensional dynamic graph convolutional network for citywide crowd flow prediction", "Authors": ["Tong Xia", "Junjie Lin", "Yong Li", "Jie Feng", "Pan Hui", "Funing Sun", "Diansheng Guo", "Depeng Jin"], "Sources": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Crowd flow prediction is an essential task benefiting a wide range of applications for the transportation system and public safety. However, it is a challenging problem due to the complex spatio-temporal dependence and the complicated impact of urban structure on the crowd flow patterns. In this article, we propose a novel framework, 3-Dimensional Graph Convolution Network (3DGCN), to predict citywide crowd flow. We first model it as a dynamic spatio-temporal graph prediction problem, where each node represents a region with time-varying flows, and each edge represents the origin\u2013destination (OD) flow between its corresponding regions. As such, OD flows among regions are treated as a proxy for the spatial interactions among regions. To tackle the complex spatio-temporal dependence, our proposed 3DGCN can model the correlation among graph spatial and temporal neighbors simultaneously. To learn?\u2026", "IdName": "xia20213dgcn", "Citation": "", "Keywords": ""}, {"Name": "A survey on computational politics", "Authors": ["Ehsan Ul Haq", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "Computational Politics is the study of computational methods to analyze and moderate users' behaviors related to political activities such as election campaign persuasion, political affiliation, and opinion mining. With the rapid development and ease of access to the Internet, Information Communication Technologies (ICT) have given rise to massive numbers of users joining online communities and the digitization of political practices such as debates. These communities and digitized data contain both explicit and latent information about users and their behaviors related to politics and social movements. For researchers, it is essential to utilize data from these sources to develop and design systems that not only provide solutions to computational politics but also help other businesses, such as marketers, to increase users' participation and interactions. In this survey, we attempt to categorize main areas in?\u2026", "IdName": "haq2020survey", "Citation": "", "Keywords": ""}, {"Name": "Edge-facilitated augmented vision in vehicle-to-everything networks", "Authors": ["Pengyuan Zhou", "Tristan Braud", "Aleksandr Zavodovski", "Zhi Liu", "Xianfu Chen", "Pan Hui", "Jussi Kangasharju"], "Sources": "IEEE Transactions on Vehicular Technology", "PublishedYears": "2020", "Doi": "", "Abstracts": "Vehicular communication applications require an efficient communication architecture for timely information delivery. Centralized, cloud-based infrastructures present latencies too high to satisfy the requirements of emergency information processing and transmission, while Vehicle-to-Vehicle communication is too variable for reliable in-time information transmission. In this paper, we present EAVVE, a novel Vehicle-to-Everything system, consisting of vehicles with and without comprehensive data processing capabilities, facilitated by edge servers co-located with roadside units. Adding computation capabilities at the edge of the network allows reducing the overall latency compared to vehicle-to-cloud and makes up for scenarios in which in-vehicle computational power is not sufficient to satisfy the service demand. To improve the offloading efficiency, we propose a decentralized algorithm for real-time task?\u2026", "IdName": "zhou2020edge", "Citation": "", "Keywords": ""}, {"Name": "Deep reinforcement learning approaches for global public health strategies for COVID-19 pandemic", "Authors": ["Gloria Hyunjung Kwak", "Lowell Ling", "Pan Hui"], "Sources": "PloS one", "PublishedYears": "2021", "Doi": "", "Abstracts": " Background Unprecedented public health measures have been used during this coronavirus 2019 (COVID-19) pandemic to control the spread of SARS-CoV-2 virus. It is a challenge to implement timely and appropriate public health interventions. Methods and findings Population and COVID-19 epidemiological data between 21st January 2020 to 15th November 2020 from 216 countries and territories were included with the implemented public health interventions. We used deep reinforcement learning, and the algorithm was trained to enable agents to try to find optimal public health strategies that maximized total reward on controlling the spread of COVID-19. The results suggested by the algorithm were analyzed against the actual timing and intensity of lockdown and travel restrictions. Early implementations of the actual lockdown and travel restriction policies, usually at the time of local index case were associated with less burden of COVID-19. In contrast, our agent suggested to initiate at least minimal intensity of lockdown or travel restriction even before or on the day of the index case in each country and territory. In addition, the agent mostly recommended a combination of lockdown and travel restrictions and higher intensity policies than the policies implemented by governments, but did not always encourage rapid full lockdown and full border closures. The limitation of this study was that it was done with incomplete data due to the emerging COVID-19 epidemic, inconsistent testing and reporting. In addition, our research focuses only on population health benefits by controlling the spread of COVID-19 without balancing the negative?\u2026", "IdName": "kwak2021deep", "Citation": "", "Keywords": ""}, {"Name": "Distributed vehicular computing at the dawn of 5G: A survey", "Authors": ["Ahmad Alhilal", "Benjamin Finley", "Tristan Braud", "Dongzhe Su", "Pan Hui"], "Sources": "arXiv preprint arXiv:2001.07077", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent advances in information technology have revolutionized the automotive industry, paving the way for next-generation smart vehicular mobility. Vehicles, roadside units, and other road users can collaborate to deliver novel services and applications. These services and applications require 1) massive volumes of heterogeneous and continuous data to perceive the environment, 2) reliable and low-latency communication networks, 3) real-time data processing that provides decision support under application-specific constraints. Addressing such constraints introduces significant challenges for current communication and computing technologies. Relatedly, the fifth generation of cellular networks (5G) was developed to respond to communication challenges by providing for low-latency, high-reliability, and high bandwidth communications. As a major part of 5G, edge computing allows data offloading and computation at the edge of the network, ensuring low-latency and context-awareness, and 5G efficiency. In this work, we aim at providing a comprehensive overview of the state of research on vehicular computing in the emerging age of 5G and big data.", "IdName": "alhilal2020distributed", "Citation": "", "Keywords": ""}, {"Name": "6G mobile-edge empowered metaverse: Requirements, technologies, challenges and research directions", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Pan Hui", "Danny HK Tsang"], "Sources": "arXiv preprint arXiv:2211.04854", "PublishedYears": "2022", "Doi": "", "Abstracts": "The Metaverse has emerged as the successor of the conventional mobile internet to change people's lifestyles. It has strict visual and physical requirements to ensure an immersive experience (i.e., high visual quality, low motion-to-photon latency, and real-time tactile and control experience). However, the current technologies fall short to satisfy these requirements. Mobile edge computing (MEC) has been indispensable to enable low latency and powerful computing. Moreover, the sixth generation (6G) networks promise to provide end users with seamless communications. In this paper, we explore and demonstrate the synergistic relationship between 6G and mobile-edge technologies in empowering the Metaverse with ubiquitous communications and computation. This includes the usage of heterogeneous radios, intelligent reflecting surfaces (IRS), non-orthogonal multiple access (NOMA), and digital twins (DTs) - assisted MEC. We also discuss emerging communication paradigms (i.e., semantic communication, holographic-type communication, and haptic communication) to further satisfy the demand for human-type communications and fulfill user preferences and immersive experiences in the Metaverse.", "IdName": "yu20226g", "Citation": "", "Keywords": ""}, {"Name": "Para: Privacy management and control in emerging iot ecosystems using augmented reality", "Authors": ["Carlos Bermejo Fernandez", "Lik Hang Lee", "Petteri Nurmi", "Pan Hui"], "Sources": "Proceedings of the 2021 International Conference on Multimodal Interaction?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " The ubiquity of smart devices, combined with a lack of information about data garnered by them, make privacy a significant challenge for adopting smart devices. Ensuring users can safeguard their privacy without compromising the devices\u2019 functionality requires effective yet intuitive ways to manage personal privacy preferences. Current solutions for privacy management are severely lacking as they are ineffective in making users aware of potential privacy risks or how to mitigate them and as they offer limited support for interaction. As our first contribution, we develop a novel AR privacy management interface (PARA) that uses AR visualization to contextualize data disclosure and improve user\u2019s perceptions of privacy threats. Besides offering support for enhancing user\u2019s privacy perceptions, our interface supports privacy control on compatible devices through privacy-enhancing technologies. As our second?\u2026", "IdName": "bermejo2021privacy", "Citation": "", "Keywords": ""}, {"Name": "A2w: Context-aware recommendation system for mobile augmented reality web browser", "Authors": ["Kit Yung Lam", "Lik Hang Lee", "Pan Hui"], "Sources": "Proceedings of the 29th ACM international conference on multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Augmented Reality (AR) offers new capabilities for blurring the boundaries between physical reality and digital media. However, the capabilities of integrating web contents and AR remain underexplored. This paper presents an AR web browser with an integrated context-aware AR-to-Web content recommendation service named as A2W browser, to provide continuously user-centric web browsing experiences driven by AR headsets. We implement the A2W browser on an AR headset as our demonstration application, demonstrating the features and performance of A2W framework. The A2W browser visualizes the AR-driven web contents to the user, which is suggested by the content-based filtering model in our recommendation system. In our experiments, 20 participants with the adaptive UIs and recommendation system in A2W browser achieve up to 30.69% time saving compared to smartphone conditions?\u2026", "IdName": "lam2021a2w", "Citation": "", "Keywords": ""}, {"Name": "Intelligent and scalable air quality monitoring with 5G edge", "Authors": ["Xiang Su", "Xiaoli Liu", "Naser Hossein Motlagh", "Jacky Cao", "Peifeng Su", "Petri Pellikka", "Yongchun Liu", "Tuukka Pet?j?", "Markku Kulmala", "Pan Hui", "Sasu Tarkoma"], "Sources": "IEEE Internet Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "Air pollution introduces a major challenge for societies, where it leads to the premature deaths of millions of people each year globally. Massive deployment of air quality sensing devices and data analysis for the resultant data will pave the way for the development of real-time intelligent applications and services, e.g., minimization of exposure to poor air quality either on an individual or city scale. 5G and edge computing supports dense deployments of sensors at high resolution with ubiquitous connectivity, high bandwidth, high-speed gigabit connections, and ultralow latency analysis. This article conceptualizes AI-powered scalable air quality monitoring and presents two systems of calibrating low-cost air quality sensors and the image processing of pictures captured by hyperspectral cameras to better detect air quality. We develop and deploy different AI algorithms in these two systems on a 5G edge testbed and?\u2026", "IdName": "su2021intelligent", "Citation": "", "Keywords": ""}, {"Name": "Emgauth: An emg-based smartphone unlocking system using siamese network", "Authors": ["Boyu Fan", "Xuefeng Liu", "Xiang Su", "Pan Hui", "Jianwei Niu"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Screen lock is a critical security feature for smart-phones to prevent unauthorized access. Although various screen unlocking technologies including fingerprint and facial recognition have been widely adopted, they still have some limitations. For example, fingerprints can be stolen by special material stickers and facial recognition systems can be cheated by 3D-printed head models. In this paper, we propose EmgAuth, a novel electromyography(EMG)-based smartphone unlocking system based on the Siamese network. EmgAuth leverages the Myo armband to collect the EMG data of smartphone users and enables users to unlock their smartphones when picking up and watching their smartphones. In particular, when training the Siamese network, we design a special data augmentation technique to make the system resilient to the rotation of the armband. We conduct experiments including 40 participants and the?\u2026", "IdName": "fan2020emgauth", "Citation": "", "Keywords": ""}, {"Name": "Dios-an extended reality operating system for the metaverse", "Authors": ["Tristan Braud", "Lik-Hang Lee", "Ahmad Alhilal", "Carlos Bermejo Fern\u00e1ndez", "Pan Hui"], "Sources": "IEEE multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Driven by the recent improvements in device and networks capabilities, extended reality (XR) is becoming more pervasive; industry and academia alike envision ambitious projects, such as the metaverse. However, XR is still limited by the current architecture of mobile systems. This article makes the case for an XR-specific operating system (XROS). An XROS integrates hardware-support, computer vision algorithms, and XR-specific networking as the primitives supporting XR technology. These primitives represent the physical\u2013digital world as a single shared resource among applications. Such an XROS allows for the development of coherent and system-wide interaction and display methods, systematic privacy preservation on sensor data, and performance improvement while simplifying application development.", "IdName": "braud2022dios", "Citation": "", "Keywords": ""}, {"Name": "What is the metaverse? an immersive cyberspace and open challenges", "Authors": ["Lik-Hang Lee", "Pengyuan Zhou", "Tristan Braud", "Pan Hui"], "Sources": "arXiv preprint arXiv:2206.03018", "PublishedYears": "2022", "Doi": "", "Abstracts": "The Metaverse refers to a virtual-physical blended space in which multiple users can concurrently interact with a unified computer-generated environment and other users, which can be regarded as the next significant milestone of the current cyberspace. This article primarily discusses the development and challenges of the Metaverse. We first briefly describe the development of cyberspace and the necessity of technology enablers. Accordingly, our bottom-up approach highlights three critical technology enablers for the Metaverse: networks, systems, and users. Also, we highlight a number of indispensable issues, under technological and ecosystem perspectives, that build and sustain the Metaverse.", "IdName": "lee2022metaverse", "Citation": "", "Keywords": ""}, {"Name": "Exploring button designs for mid-air interaction in virtual reality: A hexa-metric evaluation of key representations and multi-modal cues", "Authors": ["Carlos Bermejo", "Lik Hang Lee", "Paul Chojecki", "David Przewozny", "Pan Hui"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2021", "Doi": "", "Abstracts": "The continued advancement in user interfaces comes to the era of virtual reality that requires a better understanding of how users will interact with 3D buttons in mid-air. Although virtual reality owns high levels of expressiveness and demonstrates the ability to simulate the daily objects in the physical environment, the most fundamental issue of designing virtual buttons is surprisingly ignored. To this end, this paper presents four variants of virtual buttons, considering two design dimensions of key representations and multi-modal cues (audio, visual, haptic). We conduct two multi-metric assessments to evaluate the four virtual variants and the baselines of physical variants. Our results indicate that the 3D-lookalike buttons help users with more refined and subtle mid-air interactions (i.e. lesser press depth) when haptic cues are available; while the users with 2D-lookalike buttons unintuitively achieve better keystroke?\u2026", "IdName": "bermejo2021exploring", "Citation": "", "Keywords": ""}, {"Name": "The impact of COVID-19 on smartphone usage", "Authors": ["Tong Li", "Mingyang Zhang", "Yong Li", "Eemil Lagerspetz", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": "The outbreak of Covid-19 changed the world as well as human behavior. In this article, we study the impact of Covid-19 on smartphone usage. We gather smartphone usage records from a global data collection platform called Carat, including the usage of mobile users in North America from November 2019 to April 2020. We then conduct the first study on the differences in smartphone usage across the outbreak of Covid-19. We discover that Covid-19 leads to a decrease in users\u2019 smartphone engagement and network switches, but an increase in WiFi usage. Also, its outbreak causes new typical diurnal patterns of both memory usage and WiFi usage. Additionally, we investigate the correlations between smartphone usage and daily confirmed cases of Covid-19. The results reveal that memory usage, WiFi usage, and network switches of smartphones have significant correlations, whose absolute values of Pearson?\u2026", "IdName": "li2021impact", "Citation": "", "Keywords": ""}, {"Name": "Sketching an ai marketplace: Tech, economic, and regulatory aspects", "Authors": ["Abhishek Kumar", "Benjamin Finley", "Tristan Braud", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Access 9", "PublishedYears": "2021", "Doi": "", "Abstracts": "Artificial intelligence shows promise for solving many practical societal problems in areas such as healthcare and transportation. However, the current mechanisms for AI model diffusion such as Github code repositories, academic project webpages, and commercial AI marketplaces have some limitations; for example, a lack of monetization methods, model traceability, and model auditabilty. In this work, we sketch guidelines for a new AI diffusion method based on a decentralized online marketplace. We consider the technical, economic, and regulatory aspects of such a marketplace including a discussion of solutions for problems in these areas. Finally, we include a comparative analysis of several current AI marketplaces that are already available or in development. We find that most of these marketplaces are centralized commercial marketplaces with relatively few models.", "IdName": "kumar2021sketching", "Citation": "", "Keywords": ""}, {"Name": "Predicting the need for intubation in the first 24 h after critical care admission using machine learning approaches", "Authors": ["Benjamin Ming Kit Siu", "Gloria Hyunjung Kwak", "Lowell Ling", "Pan Hui"], "Sources": "Scientific reports", "PublishedYears": "2020", "Doi": "", "Abstracts": "Early and accurate prediction of the need for intubation may provide more time for preparation and increase safety margins by avoiding high risk late intubation. This study evaluates whether machine learning can predict the need for intubation within 24?h using commonly available bedside and laboratory parameters taken at critical care admission. We extracted data from 2 large critical care databases (MIMIC-III and eICU-CRD). Missing variables were imputed using autoencoder. Machine learning classifiers using logistic regression and random forest were trained using 60% of the data and tested using the remaining 40% of the?data. We compared the performance of logistic regression and random forest models to predict intubation in critically ill patients. After excluding patients with limitations of therapy and missing data, we included 17,616 critically ill patients in this retrospective cohort. Within 24?h of admission?\u2026", "IdName": "siu2020predicting", "Citation": "", "Keywords": ""}, {"Name": "Genetic meta-structure search for recommendation on heterogeneous information network", "Authors": ["Zhenyu Han", "Fengli Xu", "Jinghan Shi", "Yu Shang", "Haorui Ma", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the 29th ACM international conference on information?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "In the past decade, the heterogeneous information network (HIN) has become an important methodology for modern recommender systems. To fully leverage its power, manually designed network templates, i.e., meta-structures, are introduced to filter out semantic-aware information. The hand-crafted meta-structure rely on intense expert knowledge, which is both laborious and data-dependent. On the other hand, the number of meta-structures grows exponentially with its size and the number of node types, which prohibits brute-force search. To address these challenges, we propose Genetic Meta-Structure Search (GEMS) to automatically optimize meta-structure designs for recommendation on HINs. Specifically, GEMS adopts a parallel genetic algorithm to search meaningful meta-structures for recommendation, and designs dedicated rules and a meta-structure predictor to efficiently explore the search space?\u2026", "IdName": "han2020genetic", "Citation": "", "Keywords": ""}, {"Name": "Vetaverse: A survey on the intersection of Metaverse, vehicles, and transportation systems", "Authors": ["Pengyuan Zhou", "Jinjing Zhu", "Yiting Wang", "Yunfan Lu", "Zixiang Wei", "Haolin Shi", "Yuchen Ding", "Yu Gao", "Qinglong Huang", "Yan Shi", "Ahmad Alhilal", "Lik-Hang Lee", "Tristan Braud", "Pan Hui", "Lin Wang"], "Sources": "arXiv preprint arXiv:2210.15109", "PublishedYears": "2022", "Doi": "", "Abstracts": "Since 2021, the term \"Metaverse\" has been the most popular one, garnering a lot of interest. Because of its contained environment and built-in computing and networking capabilities, a modern car makes an intriguing location to host its own little metaverse. Additionally, the travellers don't have much to do to pass the time while traveling, making them ideal customers for immersive services. Vetaverse (Vehicular-Metaverse), which we define as the future continuum between vehicular industries and Metaverse, is envisioned as a blended immersive realm that scales up to cities and countries, as digital twins of the intelligent Transportation Systems, referred to as \"TS-Metaverse\", as well as customized XR services inside each Individual Vehicle, referred to as \"IV-Metaverse\". The two subcategories serve fundamentally different purposes, namely long-term interconnection, maintenance, monitoring, and management on scale for large transportation systems (TS), and personalized, private, and immersive infotainment services (IV). By outlining the framework of Vetaverse and examining important enabler technologies, we reveal this impending trend. Additionally, we examine unresolved issues and potential routes for future study while highlighting some intriguing Vetaverse services.", "IdName": "zhou2022vetaverse", "Citation": "", "Keywords": ""}, {"Name": "Aicp: Augmented informative cooperative perception", "Authors": ["Pengyuan Zhou", "Pranvera Korto?i", "Yui-Pan Yau", "Benjamin Finley", "Xiujun Wang", "Tristan Braud", "Lik-Hang Lee", "Sasu Tarkoma", "Jussi Kangasharju", "Pan Hui"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": "Connected vehicles, whether equipped with advanced driver-assistance systems or fully autonomous, require human driver supervision and are currently constrained to visual information in their line-of-sight. A cooperative perception system among vehicles increases their situational awareness by extending their perception range. Existing solutions focus on improving perspective transformation and fast information collection. However, such solutions fail to filter out large amounts of less relevant data and thus impose significant network and computation load. Moreover, presenting all this less relevant data can overwhelm the driver and thus actually hinder them. To address such issues, we present Augmented Informative Cooperative Perception (AICP), the first fast-filtering system which optimizes the informativeness of shared data at vehicles to improve the fused presentation. To this end, an informativeness?\u2026", "IdName": "zhou2022aicp", "Citation": "", "Keywords": ""}, {"Name": "Sear: Scaling experiences in multi-user augmented reality", "Authors": ["Wenxiao Zhang", "Bo Han", "Pan Hui"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In this paper, we present the design, implementation, and evaluation of SEAR, a collaborative framework for Scaling Experiences in multi-user Augmented Reality (AR). Most AR systems benefit from computer vision (CV) algorithms to detect, classify, or recognize physical objects for augmentation. A widely used acceleration method for mobile AR is to offload the compute-intensive tasks ( e.g. , CV algorithms) to the network edge. However, we show that the end-to-end latency, an important metric of mobile AR, may dramatically increase when offloading AR tasks from a large number of concurrent users to the edge. SEAR tackles this scalability issue through the innovation of a lightweight collaborative local caching scheme. Our key observation is that nearby AR users may share some common interests, and may even have overlapped views to augment ( e.g. , when playing a multi-user AR game). Thus, SEAR?\u2026", "IdName": "zhang2022sear", "Citation": "", "Keywords": ""}, {"Name": "Student barriers to active learning in Synchronous online classes: Characterization, reflections, and suggestions", "Authors": ["Reza Hadi Mogavi", "Yankun Zhao", "Ehsan Ul Haq", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the Eighth ACM Conference on Learning@ Scale", "PublishedYears": "2021", "Doi": "", "Abstracts": "As more and more face-to-face classes move to online environments, it becomes increasingly important to explore any emerging barriers to students' learning. This work focuses on characterizing student barriers to active learning in synchronous online environments. The aim is to help novice educators develop a better understanding of those barriers and prepare more student-centered course plans for their active online classes. Towards this end, we adopt a qualitative research approach and study information from different sources: social media content, interviews, and surveys from students and expert educators. Through a thematic analysis, we craft a nuanced list of students' online active learning barriers within the themes of human-side, technological, and environmental barriers. Each barrier is explored from the three aspects of frequency, importance, and exclusiveness to active online classes. Finally, we?\u2026", "IdName": "hadi2021student", "Citation": "", "Keywords": ""}, {"Name": "Strategic COVID-19 vaccine distribution can simultaneously elevate social utility and equity", "Authors": ["Lin Chen", "Fengli Xu", "Zhenyu Han", "Kun Tang", "Pan Hui", "James Evans", "Yong Li"], "Sources": "Nature Human Behaviour", "PublishedYears": "2022", "Doi": "", "Abstracts": "Balancing social utility and equity in distributing limited vaccines is a critical policy concern for protecting against the prolonged COVID-19 pandemic and future health emergencies. What is the nature of the trade-off between maximizing collective welfare and minimizing disparities between more and less privileged communities? To evaluate vaccination strategies, we propose an epidemic model that explicitly accounts for both demographic and mobility differences among communities and their associations with heterogeneous COVID-19 risks, then calibrate it with large-scale data. Using this model, we find that social utility and equity can be simultaneously improved when vaccine access is prioritized for the most disadvantaged communities, which holds even when such communities manifest considerable vaccine reluctance. Nevertheless, equity among distinct demographic features may conflict; for example, low?\u2026", "IdName": "chen2022strategic", "Citation": "", "Keywords": ""}, {"Name": "Exploring system performance of continual learning for mobile and embedded sensing applications", "Authors": ["Young D Kwon", "Jagmohan Chauhan", "Abhishek Kumar", "Pan Hui HKUST", "Cecilia Mascolo"], "Sources": "2021 IEEE/ACM Symposium on Edge Computing (SEC)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Continual learning approaches help deep neural network models adapt and learn incrementally by trying to solve catastrophic forgetting. However, whether these existing approaches, applied traditionally to image-based tasks, work with the same efficacy to the sequential time series data generated by mobile or embedded sensing systems remains an unanswered question. To address this void, we conduct the first comprehensive empirical study that quantifies the performance of three predominant continual learning schemes (i.e., regularization, replay, and replay with examples) on six datasets from three mobile and embedded sensing applications in a range of scenarios having different learning complexities. More specifically, we implement an end-to-end continual learning framework on edge devices. Then we investigate the generalizability, trade-offs between performance, storage, computational costs, and?\u2026", "IdName": "kwon2021exploring", "Citation": "", "Keywords": ""}, {"Name": "One-thumb text acquisition on force-assisted miniature interfaces for mobile headsets", "Authors": ["LEE Lik-Hang", "ZHU Yiming", "YAU Yui-Pan", "Tristan Braud", "SU Xiang", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Touchscreen interfaces are shrinking and even dis-appearing on mobile headsets. The existing approaches for text acquisition on mobile headsets, for instance, speech commands and hand gestures, are cumbersome and coarse. In this paper, we show the feasibility of interaction on a miniature area as small as 12 * 13 mm 2  that offers an input alternative on small form-factor devices such as smartwatches, smart rings, or the spectacles frames of mobile headsets. To this end, we propose and implement two interaction approaches, namely FRS and DupleFR, for acquiring textual contents on mobile headsets. Both approaches leverage force-assisted interaction on a miniature-size interface. They enable the user to acquire textual content with various granularities such as characters, words, sentences, paragraphs, and the entire text. After 8 sessions, 22 participants with FRS and DupleFR achieve the peak?\u2026", "IdName": "lik2020one", "Citation": "", "Keywords": ""}, {"Name": "Are you left out? an efficient and fair federated learning for personalized profiles on wearable devices of inferior networking conditions", "Authors": ["Pengyuan Zhou", "Hengwei Xu", "Lik Hang Lee", "Pei Fang", "Pan Hui"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2022", "Doi": "", "Abstracts": "Wearable computers engage in percutaneous interactions with human users and revolutionize the way of learning human activities. Due to rising privacy concerns, federated learning has been recently proposed to train wearable data with privacy preservation collaboratively. However, under the state-of-the-art (SOTA) schemes, user profiles on wearable devices of inferior networking conditions are regarded as 'left out'. Such schemes suffer from three fundamental limitations: (1) the widely adopted network-capacity-based client selection leads to biased training; (2) the aggregation has low communication efficiency; (3) users lack convenient channels for providing feedback on wearable devices. Therefore, this paper proposes a Fair and Communication-efficient Federated Learning scheme, namely FCFL. FCFL is a full-stack learning system specifically designed for wearable computers, improving the SOTA?\u2026", "IdName": "zhou2022you", "Citation": "", "Keywords": ""}, {"Name": "Analyzing smart contract interactions and contract level state consensus", "Authors": ["Yao\u2010Chieh Hu", "Ting\u2010Ting Lee", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "Concurrency and Computation: Practice and Experience", "PublishedYears": "2020", "Doi": "", "Abstracts": " Although the primary function of distributed ledgers is to store data related to users' interactions, their capabilities allow them to offer more sophisticated functionalities. Advances in blockchain technologies introduced smart contracts, software programs that define immutable rules as functions stored on the blockchain and can be executed on demand. Smart contracts can interact not only with users but also with each other via message exchange. We compare existing smart contract interactions, and develop an architecture for asynchronous state consensus, a novel type of smart contract interaction required in applications but had rarely been addressed. The proposed architecture is composed of two types of smart contracts, ie, Custodian and Client. Client smart contracts serve as network participants reaching a particular consensus collectively by forming a cluster and issuing votes towards a final state agreement?\u2026", "IdName": "hu2020analyzing", "Citation": "", "Keywords": ""}, {"Name": "When gamification spoils your learning: A qualitative case study of gamification misuse in a language-learning app", "Authors": ["Reza Hadi Mogavi", "Bingcan Guo", "Yuanhao Zhang", "Ehsan-Ul Haq", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the Ninth ACM Conference on Learning@ Scale", "PublishedYears": "2022", "Doi": "", "Abstracts": "More and more learning apps like Duolingo are using some form of gamification (e.g., badges, points, and leaderboards) to enhance user learning. However, they are not always successful. Gamification misuse is a phenomenon that occurs when users become too fixated on gamification and get distracted from learning. This undesirable phenomenon wastes users' precious time and negatively impacts their learning performance. However, there has been little research in the literature to understand gamification misuse and inform future gamification designs. Therefore, this paper aims to fill this knowledge gap by conducting the first extensive qualitative research on gamification misuse in a popular learning app called Duolingo. Duolingo is currently the world's most downloaded learning app used to learn languages. This study consists of two phases: (I)a content analysis of data from Duolingo forums (from the past?\u2026", "IdName": "hadi2022gamification", "Citation": "", "Keywords": ""}, {"Name": "Beyond the first law of geography: Learning representations of satellite imagery by leveraging point-of-interests", "Authors": ["Yanxin Xi", "Tong Li", "Huandong Wang", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the ACM Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": " Satellite imagery depicts the earth\u2019s surface remotely and provides comprehensive information for many applications, such as land use monitoring and urban planning. Existing studies on unsupervised representation learning for satellite images only take into account the images\u2019 geographic information, ignoring human activity factors. To bridge this gap, we propose using Point-of-Interest (POI) data to capture human factors and design a contrastive learning-based framework to consolidate the representation of satellite imagery with POI information. Also, we design an attention model that merges the representations from the geographic and POI perspectives adaptively. On the basis of real-world datasets collected from Beijing, we evaluate our method for predicting socioeconomic indicators. The results show that the representation containing POI information outperforms the geographic representation in estimating?\u2026", "IdName": "xi2022beyond", "Citation": "", "Keywords": ""}, {"Name": "5G MEC computation handoff for mobile augmented reality", "Authors": ["Pengyuan Zhou", "Shuhao Fu", "Benjamin Finley", "Xuebing Li", "Sasu Tarkoma", "Jussi Kangasharju", "Mostafa Ammar", "Pan Hui"], "Sources": "arXiv preprint arXiv:2101.00256", "PublishedYears": "2021", "Doi": "", "Abstracts": "The combination of 5G and Multi-access Edge Computing (MEC) can significantly reduce application delay by lowering transmission delay and bringing computational capabilities closer to the end user. Therefore, 5G MEC could enable excellent user experience in applications like Mobile Augmented Reality (MAR), which are computation-intensive, and delay and jitter-sensitive. However, existing 5G handoff algorithms often do not consider the computational load of MEC servers, are too complex for real-time execution, or do not integrate easily with the standard protocol stack. Thus they can impair the performance of 5G MEC. To address this gap, we propose Comp-HO, a handoff algorithm that finds a local solution to the joint problem of optimizing signal strength and computational load. Additionally, Comp-HO can easily be integrated into current LTE and 5G base stations thanks to its simplicity and standard-friendly deployability. Specifically, we evaluate Comp-HO through a custom NS-3 simulator which we calibrate via MAR prototype measurements from a real-world 5G testbed. We simulate both Comp-HO and several classic handoff algorithms. The results show that, even without a global optimum, the proposed algorithm still significantly reduces the number of large delays, caused by congestion at MECs, at the expense of a small increase in transmission delay.", "IdName": "zhou20215g", "Citation": "", "Keywords": ""}, {"Name": "Eyeshopper: Estimating shoppers' gaze using cctv cameras", "Authors": ["Carlos Bermejo", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "Proceedings of the 28th ACM international conference on multimedia", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent advances in machine and deep learning allow for enhanced retail analytics by applying object detection techniques. However, existing approaches either require laborious installation processes to function or lack precision when the customers turn their back in the installed cameras. In this paper, we present EyeShopper, an innovative system that tracks the gaze of shoppers when facing away from the camera and provides insights about their behavior in physical stores. EyeShopper is readily deployable in existing surveillance systems and robust against low-resolution video inputs. At the same time, its accuracy is comparable to state-of-the-art gaze estimation frameworks that require high-resolution and continuous video inputs to function. Furthermore, EyeShopper is more robust than state-of-the-art gaze tracking techniques for back head images. Extensive evaluation with different real video datasets and?\u2026", "IdName": "bermejo2020eyeshopper", "Citation": "", "Keywords": ""}, {"Name": "How subtle can it get? a trimodal study of ring-sized interfaces for one-handed drone control", "Authors": ["Yui-Pan Yau", "Lik Hang Lee", "Zheng Li", "Tristan Braud", "Yi-Hsuan Ho", "Pan Hui"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "Flying drones have become common objects in our daily lives, serving a multitude of purposes. Many of these purposes involve outdoor scenarios where the user combines drone control with another activity. Traditional interaction methods rely on physical or virtual joysticks that occupy both hands, thus restricting drone usability. In this paper, we investigate one-handed human-to-drone-interaction by leveraging three modalities: force, touch, and IMU. After prototyping three different combinations of these modalities on a smartphone, we evaluate them against the current commercial standard through two user experiments. These experiments help us to find the combination of modalities that strikes a compromise between user performance, perceived task load, wrist rotation, and interaction area size. Accordingly, we select a method that achieves faster task completion times than the two-handed commercial baseline?\u2026", "IdName": "yau2020subtle", "Citation": "", "Keywords": ""}, {"Name": "Nebula: Reliable low-latency video transmission for mobile cloud gaming", "Authors": ["Ahmad Alhilal", "Tristan Braud", "Bo Han", "Pan Hui"], "Sources": "Proceedings of the ACM Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": " Mobile cloud gaming enables high-end games on constrained devices by streaming the game content from powerful servers through mobile networks. Mobile networks suffer from highly variable bandwidth, latency, and losses that affect the gaming experience. This paper introduces , an end-to-end cloud gaming framework to minimize the impact of network conditions on the user experience. relies on an end-to-end distortion model adapting the video source rate and the amount of frame-level redundancy based on the measured network conditions. As a result, it minimizes the motion-to-photon (MTP) latency while protecting the frames from losses. We fully implement and evaluate its performance against the state-of-the-art techniques and latest research in real-time mobile cloud gaming transmission on a physical testbed over emulated and real wireless networks. consistently balances MTP latency (<140?ms) and?\u2026", "IdName": "alhilal2022nebula", "Citation": "", "Keywords": ""}, {"Name": "Vibroweight: Simulating weight and center of gravity changes of objects in virtual reality for enhanced realism", "Authors": ["Xian Wang", "Diego Monteiro", "Lik-Hang Lee", "Pan Hui", "Hai-Ning Liang"], "Sources": "2022 IEEE haptics symposium (HAPTICS)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Haptic feedback in virtual reality (VR) allows users to perceive the physical properties of virtual objects (e.g., their weight and motion patterns). However, the lack of haptic sensations deteriorates users' immersion and overall experience. In this work, we designed and implemented a low-cost hardware prototype with liquid metal, VibroWeight, which can work in complementarity with commercial VR handheld controllers. VibroWeight is characterized by bimodal feedback cues in VR, driven by adaptive absolute mass (weights) and gravity shift. To our knowledge, liquid metal is used in a VR haptic device for the first time. Our 29 participants show that VibroWeight delivers significantly better VR experiences in realism and comfort.", "IdName": "wang2022vibroweight", "Citation": "", "Keywords": ""}, {"Name": "Heterogeneous model fusion federated learning mechanism based on model mapping", "Authors": ["Xiaofeng Lu", "Yuying Liao", "Chao Liu", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": "The computing power of various Internet of Things (IoT) devices is quite different. To enable IoT devices with lower computing power to perform machine learning, all nodes can only train smaller models, which results in the waste of computing power for high-performance devices. In this article, a heterogeneous model fusion federated learning (HFL) mechanism is proposed. Each node trains learning models of different scales according to its own computing capabilities. After receiving the gradient trained by each node, the parameter server (PS) corrects the received gradient with the repeat matrix, and then update the corresponding region of the global model according to the mapping matrix. After all update operations are over, the PS assigns the compressed model to the corresponding node. This article uses a variety of experimental schemes to evaluate the proposed method, including three data sets, two model?\u2026", "IdName": "lu2021heterogeneous", "Citation": "", "Keywords": ""}, {"Name": "Deepvista: 16k panoramic cinema on your mobile device", "Authors": ["Wenxiao Zhang", "Feng Qian", "Bo Han", "Pan Hui"], "Sources": "Proceedings of the Web Conference 2021", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, we design, implement, and evaluate , which is to our knowledge the first consumer-class system that streams panoramic videos far beyond the ultra high-definition resolution (up to 16K) to mobile devices, offering truly immersive experiences. Such an immense resolution makes streaming video-on-demand (VoD) content extremely resource-demanding. To tackle this challenge, introduces a novel framework that leverages an edge server to perform efficient, intelligent, and quality-guaranteed content transcoding, by extracting from panoramic frames the viewport stream that will be delivered to the client. To support real-time transcoding of 16K content, employs several key mechanisms such as dual-GPU acceleration, lossless viewport extraction, deep viewport prediction, and a two-layer streaming design. Our extensive evaluations using real users\u2019 viewport movement data indicate that outperforms?\u2026", "IdName": "zhang2021deepvista", "Citation": "", "Keywords": ""}, {"Name": "Understanding the user behavior of foursquare: A data-driven study on a global scale", "Authors": ["Yang Chen", "Jiyao Hu", "Yu Xiao", "Xiang Li", "Pan Hui"], "Sources": "IEEE Transactions on Computational Social Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Being a leading online service providing both local search and social networking functions, Foursquare has attracted tens of millions of users all over the world. Understanding the user behavior of Foursquare is helpful to gain insights for location-based social networks (LBSNs). Most of the existing studies focus on a biased subset of users, which cannot give a representative view of the global user base. Meanwhile, although the user-generated content (UGC) is very important to reflect user behavior, most of the existing UGC studies of Foursquare are based on the check-ins. There is a lack of a thorough study on tips, the primary type of UGC on Foursquare. In this article, by crawling and analyzing the global social graph and all published tips, we conduct the first comprehensive user behavior study of all 60+ million Foursquare users around the world. We have made the following three main contributions. First, we?\u2026", "IdName": "chen2020understanding", "Citation": "", "Keywords": ""}, {"Name": "From seen to unseen: Designing keyboard-less interfaces for text entry on the constrained screen real estate of Augmented Reality headsets", "Authors": ["Lik Hang Lee", "Tristan Braud", "Kit Yung Lam", "Yui Pan Yau", "Pan Hui"], "Sources": "Pervasive and Mobile Computing 64", "PublishedYears": "2020", "Doi": "", "Abstracts": "Text input is a very challenging task in the constrained screen real-estate of Augmented Reality headsets. Typical keyboards spread over multiple lines and occupy a significant portion of the screen. In this article, we explore the feasibility of single-line text entry systems for smartglasses. We first design FITE, a dynamic keyboard where the characters are positioned depending on their probability within the current input. However, the dynamic layout leads to mediocre text input and low accuracy. We then introduce HIBEY, a fixed 1-line solution that further decreases the screen real-estate usage by hiding the layout. Despite its hidden layout, HIBEY surprisingly performs much better than FITE, and achieves a mean text entry rate of 9.95 words per minute (WPM) with 96.06% accuracy, which is comparable to other state-of-the-art approaches. After 8 days, participants achieve an average of 13.19 WPM. In addition?\u2026", "IdName": "lee2020seen", "Citation": "", "Keywords": ""}, {"Name": "Collaborative augmented reality system", "Authors": ["Bo Han", "Vijay Gopalakrishnan", "Eric Zavesky", "Wenxiao Zhang", "Pan Hui"], "Sources": "US Patent 10", "PublishedYears": "2020", "Doi": "", "Abstracts": "An augmented reality device computationally processes an image frame against a first augmented reality profile stored in a local database. The first augmented reality profile includes first annotation content associated with a first object and is obtained from a second user device. In response to an object computationally processed from the first image frame satisfying a predetermined threshold of similarity with the first object in the first augmented reality profile, the first annotation content is rendered, on a display of the first user device, relative to the first object according to rendering instructions for the first annotation content.", "IdName": "han2020collaborative", "Citation": "", "Keywords": ""}, {"Name": "Cross-site prediction on social influence for cold-start users in online social networks", "Authors": ["Qingyuan Gong", "Yang Chen", "Xinlei He", "Yu Xiao", "Pan Hui", "Xin Wang", "Xiaoming Fu"], "Sources": "ACM Transactions on the Web (TWEB)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Online social networks (OSNs) have become a commodity in our daily life. As an important concept in sociology and viral marketing, the study of social influence has received a lot of attentions in academia. Most of the existing proposals work well on dominant OSNs, such as Twitter, since these sites are mature and many users have generated a large amount of data for the calculation of social influence. Unfortunately, cold-start users on emerging OSNs generate much less activity data, which makes it challenging to identify potential influential users among them. In this work, we propose a practical solution to predict whether a cold-start user will become an influential user on an emerging OSN, by opportunistically leveraging the user\u2019s information on dominant OSNs. A supervised machine learning-based approach is adopted, transferring the knowledge of both the descriptive information and dynamic activities on?\u2026", "IdName": "gong2021cross", "Citation": "", "Keywords": ""}, {"Name": "Characterizing student engagement moods for dropout prediction in question pool websites", "Authors": ["Reza Hadi Mogavi", "Xiaojuan Ma", "Pan Hui"], "Sources": "arXiv preprint arXiv:2102.00423", "PublishedYears": "2021", "Doi": "", "Abstracts": "Problem-Based Learning (PBL) is a popular approach to instruction that supports students to get hands-on training by solving problems. Question Pool websites (QPs) such as LeetCode, Code Chef, and Math Playground help PBL by supplying authentic, diverse, and contextualized questions to students. Nonetheless, empirical findings suggest that 40% to 80% of students registered in QPs drop out in less than two months. This research is the first attempt to understand and predict student dropouts from QPs via exploiting students' engagement moods. Adopting a data-driven approach, we identify five different engagement moods for QP students, which are namely challenge-seeker, subject-seeker, interest-seeker, joy-seeker, and non-seeker. We find that students have collective preferences for answering questions in each engagement mood, and deviation from those preferences increases their probability of dropping out significantly. Last but not least, this paper contributes by introducing a new hybrid machine learning model (we call Dropout-Plus) for predicting student dropouts in QPs. The test results on a popular QP in China, with nearly 10K students, show that Dropout-Plus can exceed the rival algorithms' dropout prediction performance in terms of accuracy, F1-measure, and AUC. We wrap up our work by giving some design suggestions to QP managers and online learning professionals to reduce their student dropouts.", "IdName": "mogavi2021characterizing", "Citation": "", "Keywords": ""}, {"Name": "Notice of Retraction: Steal Your Life Using 5 Cents: Hacking Android Smartphones with NFC Tags", "Authors": ["Carlos Bermejo", "Huber Flores", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Retracted.", "IdName": "bermejo2020notice", "Citation": "", "Keywords": ""}, {"Name": "Decentralized, not dehumanized in the metaverse: Bringing utility to NFTs through multimodal interaction", "Authors": ["Anqi Wang", "Ze Gao", "Lik Hang Lee", "Tristan Braud", "Pan Hui"], "Sources": "Proceedings of the 2022 international conference on multimodal interaction?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "User Interaction for NFTs (Non-fungible Tokens) is gaining increasing attention. Although NFTs have been traditionally single-use and monolithic, recent applications aim to connect multimodal interaction with human behavior. This paper reviews the related technological approaches and business practices in NFT art. We highlight that multimodal interaction is a currently under-studied issue in mainstream NFT art, and conjecture that multimodal interaction is a crucial enabler for decentralization in the NFT community. We present a continuum theory and propose a framework combining a bottom-up approach with AI multimodal process. Through this framework, we put forward integrating human behavior data into generative NFT units, as \"multimodal interactive NFT.\" Our work displays the possibilities of NFTs in the art world, beyond the traditional 2D and 3D static content. ", "IdName": "wang2022decentralized", "Citation": "", "Keywords": ""}, {"Name": "UbiPoint: towards non-intrusive mid-air interaction for hardware constrained smart glasses", "Authors": ["Lik Hang Lee", "Tristan Braud", "Farshid Hassani Bijarbooneh", "Pan Hui"], "Sources": "Proceedings of the 11th ACM Multimedia Systems Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": "Throughout the past decade, numerous interaction techniques have been designed for mobile and wearable devices. Among these devices, smartglasses mostly rely on hardware interfaces such as touchpad and buttons, which are often cumbersome and counterintuitive to use. Furthermore, smartglasses feature cheap and low-power hardware preventing the use of advanced pointing techniques. To overcome these issues, we introduce UbiPoint, a freehand mid-air interaction technique. UbiPoint uses the monocular camera embedded in smartglasses to detect the user's hand without relying on gloves, markers, or sensors, enabling intuitive and non-intrusive interaction. We introduce a computationally fast and light-weight algorithm for fingertip detection, which is especially suited for the limited hardware specifications and the short battery life of smartglasses. UbiPoint processes pictures at a rate of 20 frames per?\u2026", "IdName": "lee2020ubipoint", "Citation": "", "Keywords": ""}, {"Name": "Street smart in 5G: Vehicular applications, communication, and computing", "Authors": ["Ahmad Yousef Alhilal", "Benjamin Finley", "Tristan Braud", "Dongzhe Su", "Pan Hui"], "Sources": "IEEE Access 10", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recent advances in information technology have revolutionized the automotive industry, paving the way for next-generation smart vehicular mobility. Specifically, vehicles, roadside units, and other road users can collaborate to deliver novel services and applications that leverage, for example, big vehicular data and machine learning. Relatedly, fifth-generation cellular networks (5G) are being developed and deployed for low-latency, high-reliability, and high bandwidth communications. While 5G adjacent technologies such as edge computing allow for data offloading and computation at the edge of the network thus ensuring even lower latency and context-awareness. Overall, these developments provide a rich ecosystem for the evolution of vehicular applications, communications, and computing. Therefore in this work, we aim at providing a comprehensive overview of the state of research on vehicular computing?\u2026", "IdName": "alhilal2022street", "Citation": "", "Keywords": ""}, {"Name": "Human-avatar interaction in metaverse: Framework for full-body interaction", "Authors": ["Kit Yung Lam", "Liang Yang", "Ahmad Alhilal", "Lik-Hang Lee", "Gareth Tyson", "Pan Hui"], "Sources": "Proceedings of the 4th ACM International Conference on Multimedia in Asia", "PublishedYears": "2022", "Doi": "", "Abstracts": "The metaverse is a network of shared virtual environments where people can interact synchronously through their avatars. To enable this, it is necessary to accurately capture and recreate (physical) human motion. This is used to render avatars correctly, reflecting the motion of their corresponding users. In large-scale environments this must be done in real-time. This paper proposes a human-avatar framework with full-body motion capture. Its goal is to deliver high-accuracy capture with low computational and network overheads. It relies on a lightweight Octree data structure to record and transmit motion to other users. We conduct a user study with 22 participants and perform a preliminary evaluation of its scalability. Our user study shows that Octree with Inverse Kinematic achieves the best trade-off, achieving low delay and high accuracy. Our proposed solution delivers the lowest delay, with an average of 67ms in?\u2026", "IdName": "lam2022human", "Citation": "", "Keywords": ""}, {"Name": "Loss tolerant federated learning", "Authors": ["Pengyuan Zhou", "Pei Fang", "Pan Hui"], "Sources": "arXiv preprint arXiv:2105.03591", "PublishedYears": "2021", "Doi": "", "Abstracts": "Federated learning has attracted attention in recent years for collaboratively training data on distributed devices with privacy-preservation. The limited network capacity of mobile and IoT devices has been seen as one of the major challenges for cross-device federated learning. Recent solutions have been focusing on threshold-based client selection schemes to guarantee the communication efficiency. However, we find this approach can cause biased client selection and results in deteriorated performance. Moreover, we find that the challenge of network limit may be overstated in some cases and the packet loss is not always harmful. In this paper, we explore the loss tolerant federated learning (LT-FL) in terms of aggregation, fairness, and personalization. We use ThrowRightAway (TRA) to accelerate the data uploading for low-bandwidth-devices by intentionally ignoring some packet losses. The results suggest that, with proper integration, TRA and other algorithms can together guarantee the personalization and fairness performance in the face of packet loss below a certain fraction (10%-30%).", "IdName": "zhou2021loss", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical reinforcement learning for scarce medical resource allocation with imperfect information", "Authors": ["Qianyue Hao", "Fengli Xu", "Lin Chen", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Facing the outbreak of COVID-19, shortage in medical resources becomes increasingly outstanding. Therefore, efficient strategies for medical resource allocation are urgently called for. Reinforcement learning (RL) is powerful for decision making, but three key challenges exist in solving this problem via RL: (1) complex situation and countless choices for decision making in the real world; (2) only imperfect information are available due to the latency of pandemic spreading; (3) limitations on conducting experiments in real world since we cannot set pandemic outbreaks arbitrarily. In this paper, we propose a hierarchical reinforcement learning method with a corresponding training algorithm. We design a decomposed action space to deal with the countless choices to ensure efficient and real time strategies. We also design a recurrent neural network based framework to utilize the imperfect information obtained from?\u2026", "IdName": "hao2021hierarchical", "Citation": "", "Keywords": ""}, {"Name": "Bayesian inference federated learning for heart rate prediction", "Authors": ["Lei Fang", "Xiaoli Liu", "Xiang Su", "Juan Ye", "Simon Dobson", "Pan Hui", "Sasu Tarkoma"], "Sources": "Wireless Mobile Communication and Healthcare: 9th EAI International?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " The advances of sensing and computing technologies pave the way to develop novel applications and services for wearable devices. For example, wearable devices measure heart rate, which accurately reflects the intensity of physical exercise. Therefore, heart rate prediction from wearable devices benefits users with optimization of the training process. Conventionally, Cloud collects user data from wearable devices and conducts inference. However, this paradigm introduces significant privacy concerns. Federated learning is an emerging paradigm that enhances user privacy by remaining the majority of personal data on users\u2019 devices. In this paper, we propose a statistically sound, Bayesian inference federated learning for heart rate prediction with autoregression with exogenous variable (ARX) model. The proposed privacy-preserving method achieves accurate and robust heart rate prediction. To?\u2026", "IdName": "fang2021bayesian", "Citation": "", "Keywords": ""}, {"Name": "Lifecycle-aware online video caching", "Authors": ["Tong Li", "Tristan Braud", "Yong Li", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "The current explosion of video traffic compels service providers to deploy caches at edge networks. Nowadays, most caching systems store data with a high programming voltage corresponding to the largest possible \u2018expiry date\u2019, typically on the order of years, which maximizes the cache damage. However, popular videos rarely exhibit lifecycles longer than a couple of months. Consequently, the programming voltage can instead be adapted to fit the lifecycle and mitigate the cache damage accordingly. In this paper, we propose LiA-cache, a Lifecycle-Aware caching policy for online videos. LiA-cache finds both near-optimal caching retention times and cache eviction policies by optimizing traffic delivery cost and cache damage cost conjointly. We first investigate temporal patterns of video access from a real-world dataset covering 10 million online videos collected by one of the largest mobile network operators in?\u2026", "IdName": "li2020lifecycle", "Citation": "", "Keywords": ""}, {"Name": "Bi-directional digital twin and edge computing in the metaverse", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Pan Hui", "Danny HK Tsang"], "Sources": "IEEE Internet of Things Magazine", "PublishedYears": "2024", "Doi": "", "Abstracts": "The Metaverse has emerged to extend our lifestyle beyond physical limitations. As essential components in the Metaverse, digital twins (DTs) are the real-time digital replicas of physical items. Multi-access edge computing (MEC) provides responsive services to the end users, ensuring an immersive and interactive Metaverse experience. While the digital representation (DT) of physical objects, end users, and edge computing systems is crucial in the Metaverse, the construction of these DTs and the interplay between them have not been well-investigated. In this article, we discuss the bidirectional reliance between the DT and the MEC system and investigate the creation of DTs of objects and users on the MEC servers and DT-assisted edge computing (DTEC). To ensure seamless handover among MEC servers and to avoid intermittent Metaverse services, we also explore the interaction between local DTECs on?\u2026", "IdName": "yu2024bi", "Citation": "", "Keywords": ""}, {"Name": "Weaponising social media for information divide and warfare", "Authors": ["Ehsan-Ul Haq", "Gareth Tyson", "Tristan Braud", "Pan Hui"], "Sources": "Proceedings of the 33rd ACM Conference on Hypertext and Social Media", "PublishedYears": "2022", "Doi": "", "Abstracts": "Social media is often used to disseminate information during crises, including wars, natural disasters and pandemics. This paper discusses the challenges faced during crisis situations, which social media can both contribute to and ameliorate. We discuss the role that information polarisation plays in exacerbating problems. We then discuss how certain mal-actors exploit these divides. We conclude by detailing future avenues of work that can help mitigate these issues. ", "IdName": "haq2022weaponising", "Citation": "", "Keywords": ""}, {"Name": "Theophany: Multimodal speech augmentation in instantaneous privacy channels", "Authors": ["Abhishek Kumar", "Tristan Braud", "Lik Hang Lee", "Pan Hui"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Many factors affect speech intelligibility in face-to-face conversations. These factors lead conversation participants to speak louder and more distinctively, exposing the content to potential eavesdroppers. To address these issues, we introduce Theophany, a privacy-preserving framework for augmenting speech. Theophany establishes ad-hoc social networks between conversation participants to exchange contextual information, improving speech intelligibility in real-time. At the core of Theophany, we develop the first privacy perception model that assesses the privacy risk of a face-to-face conversation based on its topic, location, and participants. This framework allows to develop any privacy-preserving application for face-to-face conversation. We implement the framework within a prototype system that augments the speaker's speech with real-life subtitles to overcome the loss of contextual cues brought by mask?\u2026", "IdName": "kumar2021theophany", "Citation": "", "Keywords": ""}, {"Name": "A roadmap toward a unified space communication architecture", "Authors": ["Ahmad Yousef Alhilal", "Tristan Braud", "Pan Hui"], "Sources": "IEEE Access 9", "PublishedYears": "2021", "Doi": "", "Abstracts": "In recent years, the number of space exploration missions has multiplied. Such an increase raises the question of effective communication between the multitude of human-made objects spread across our solar system. An efficient and scalable communication architecture presents multiple challenges, including the distance between planetary entities, their motion and potential obstruction, the limited available payload on satellites, and the high mission cost. This paper brings together recent relevant specifications, standards, mission demonstrations, and the most recent proposals to develop a unified architecture for deep-space internetworked communication. After characterizing the transmission medium and its unique challenges, we explore the available communication technologies and frameworks to establish a reliable communication architecture across the solar system. We then draw an evolutive roadmap for?\u2026", "IdName": "alhilal2021roadmap", "Citation": "", "Keywords": ""}, {"Name": "Cosine: Collaborator selector for cooperative multi-device sensing and computing", "Authors": ["Huber Flores", "Agustin Zuniga", "Farbod Faghihi", "Xin Li", "Samuli Hemminki", "Sasu Tarkoma", "Pan Hui", "Petteri Nurmi"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Pervasive availability of programmable smart de-vices is giving rise to sensing and computing scenarios that involve collaboration between multiple devices. Maximizing the benefits of collaboration requires careful selection of devices with whom to collaborate as otherwise collaboration may be interrupted prematurely or be sub-optimal for the characteristics of the task at hand. Existing research on collaborative scenarios has mostly focused on providing mechanisms that can establish and harness collaboration, without considering how to maximally benefit from it. In this paper, we contribute by developing COSINE as a novel approach for selecting collaborators in multi-device computing scenarios. COSINE identifies and recommends collaborators based on a novel information theoretic measure based on Markov trajectory entropy. Rigorous experimental benchmarks carried out using a large-scale dataset of?\u2026", "IdName": "flores2020cosine", "Citation": "", "Keywords": ""}, {"Name": "Marketplace for AI models", "Authors": ["Abhishek Kumar", "Benjamin Finley", "Tristan Braud", "Sasu Tarkoma", "Pan Hui"], "Sources": "arXiv preprint arXiv:2003.01593", "PublishedYears": "2020", "Doi": "", "Abstracts": "Artificial intelligence shows promise for solving many practical societal problems in areas such as healthcare and transportation. However, the current mechanisms for AI model diffusion such as Github code repositories, academic project webpages, and commercial AI marketplaces have some limitations; for example, a lack of monetization methods, model traceability, and model auditabilty. In this work, we sketch guidelines for a new AI diffusion method based on a decentralized online marketplace. We consider the technical, economic, and regulatory aspects of such a marketplace including a discussion of solutions for problems in these areas. Finally, we include a comparative analysis of several current AI marketplaces that are already available or in development. We find that most of these marketplaces are centralized commercial marketplaces with relatively few models.", "IdName": "kumar2020marketplace", "Citation": "", "Keywords": ""}, {"Name": "The dark side of augmented reality: Exploring manipulative designs in ar", "Authors": ["Xian Wang", "Lik-Hang Lee", "Carlos Bermejo Fernandez", "Pan Hui"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Augmented Reality (AR) applications are becoming more mainstream, with successful examples in the mobile environment like Pokemon GO. Current malicious techniques can exploit these environments\u2019 immersive and mixed nature (physical-virtual) to trick users into providing more personal information, i.e., dark patterns. Dark patterns are deceiving techniques (e.g., interface tricks) designed to influence individuals\u2019 behavioural decisions. However, there are few studies regarding dark patterns\u2019 potential issues in AR environments. In this work, using scenario construction to build our prototypes, we investigate the potential future approaches that dark patterns can have. We use VR mockups in our user study to analyze the effects of dark patterns in AR. Our study indicates that dark patterns are effective in immersive scenarios, and the use of novel techniques, such as \u201chaptic grabbing\u201d to draw participants\u2019 attention?\u2026", "IdName": "wang2023dark", "Citation": "", "Keywords": ""}, {"Name": "Predicting multi-level socioeconomic indicators from structural urban imagery", "Authors": ["Tong Li", "Shiduo Xin", "Yanxin Xi", "Sasu Tarkoma", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the 31st ACM International Conference on Information?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Understanding economic development and designing government policies requires accurate and timely measurements of socioeconomic activities. In this paper, we show how to leverage city structural information and urban imagery like satellite images and street view images to accurately predict multi-level socioeconomic indicators. Our framework consists of four steps. First, we extract structural information from cities by transforming real-world street networks into city graphs (GeoStruct). Second, we design a contrastive learning-based model to refine urban image features by looking at geographic similarity between images, with images that are geographically close together having similar features (GeoCLR). Third, we propose using street segments as containers to adaptively fuse the features of multi-view urban images, including satellite images and street view images (GeoFuse). Finally, given the city graph?\u2026", "IdName": "li2022predicting", "Citation": "", "Keywords": ""}, {"Name": "Fras: Federated reinforcement learning empowered adaptive point cloud video streaming", "Authors": ["Yu Gao", "Pengyuan Zhou", "Zhi Liu", "Bo Han", "Pan Hui"], "Sources": "arXiv preprint arXiv:2207.07394", "PublishedYears": "2022", "Doi": "", "Abstracts": "Point cloud video transmission is challenging due to high encoding/decoding complexity, high video bitrate, and low latency requirement. Consequently, conventional adaptive streaming methodologies often find themselves unsatisfactory to meet the requirements in threefold: 1) current algorithms reuse existing quality of experience (QoE) definitions while overlooking the unique features of point cloud video thus failing to provide optimal user experience, 2) most deep learning approaches require long-span data collections to learn sufficiently varied network conditions and result in long training periods and capacity occupation, 3) cloud training approaches pose privacy risks caused by leakage of user reported service usage and networking conditions. To overcome the limitations, we present FRAS, the first federated reinforcement learning framework, to the best of our knowledge, for adaptive point cloud video streaming. We define a new QoE model which takes the unique features of point cloud video into account. Each client uses reinforcement learning (RL) to train video quality selection with the objective of optimizing the user's QoE under multiple constraints. Then, a federated learning framework is integrated with the RL algorithm to enhance training performance with privacy preservation. Extensive simulations using real point cloud videos and network traces reveal the superiority of the proposed scheme over baseline schemes. We also implement a prototype that demonstrates the performance of FRAS via real-world tests.", "IdName": "gao2022fras", "Citation": "", "Keywords": ""}, {"Name": "Edgexar: A 6-dof camera multi-target interaction framework for mar with user-friendly latency compensation", "Authors": ["Wenxiao Zhang", "Sikun Lin", "Farshid Hassani Bijarbooneh", "Hao-Fei Cheng", "Tristan Braud", "Pengyuan Zhou", "Lik-Hang Lee", "Pan Hui"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "The computational capabilities of recent mobile devices enable the processing of natural features for Augmented Reality (AR), but the scalability is still limited by the devices' computation power and available resources. In this paper, we propose EdgeXAR, a mobile AR framework that utilizes the advantages of edge computing through task offloading to support flexible camera-based AR interaction. We propose a hybrid tracking system for mobile devices that provides lightweight tracking with 6 Degrees of Freedom and hides the offloading latency from users' perception. A practical, reliable and unreliable communication mechanism is used to achieve fast response and consistency of crucial information. We also propose a multi-object image retrieval pipeline that executes fast and accurate image recognition tasks on the cloud and edge servers. Extensive experiments are carried out to evaluate the performance of?\u2026", "IdName": "zhang2022edgexar", "Citation": "", "Keywords": ""}, {"Name": "A reddit dataset for the russo-ukrainian conflict in 2022", "Authors": ["Yiming Zhu", "Ehsan-ul Haq", "Lik-Hang Lee", "Gareth Tyson", "Pan Hui"], "Sources": "arXiv preprint arXiv:2206.05107", "PublishedYears": "2022", "Doi": "", "Abstracts": "Reddit consists of sub-communities that cover a focused topic. This paper provides a list of relevant subreddits for the ongoing Russo-Ukrainian crisis. We perform an exhaustive subreddit exploration using keyword search and shortlist 12 subreddits as potential candidates that contain nominal discourse related to the crisis. These subreddits contain over 300,000 posts and 8 million comments collectively. We provide an additional categorization of content into two categories, \"R-U Conflict\", and \"Military Related\", based on their primary focus. We further perform content characterization of those subreddits. The results show a surge of posts and comments soon after Russia launched the invasion. \"Military Related\" posts are more likely to receive more replies than \"R-U Conflict\" posts. Our textual analysis shows an apparent preference for the Pro-Ukraine stance in \"R-U Conflict\", while \"Military Related\" retain a neutral stance.", "IdName": "zhu2022reddit", "Citation": "", "Keywords": ""}, {"Name": "Myokey: Surface electromyography and inertial motion sensing-based text entry in ar", "Authors": ["Young D Kwon", "Kirill A Shatilov", "Lik-Hang Lee", "Serkan Kumyol", "Kit-Yung Lam", "Yui-Pan Yau", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "The seamless textual input in Augmented Reality (AR) is very challenging and essential for enabling user-friendly AR applications. Existing approaches such as speech input and vision-based gesture recognition suffer from environmental obstacles and the large default keyboard size, sacrificing the majority of the screen's real estate in AR. In this paper, we propose MyoKey, a system that enables users to effectively and unobtrusively input text in a constrained environment of AR by jointly leveraging surface Electromyography (sEMG) and Inertial Motion Unit (IMU) signals transmitted by wearable sensors on a user's forearm. MyoKey adopts a deep learning-based classifier to infer hand gestures using sEMG. In order to show the feasibility of our approach, we implement a mobile AR application using the Unity application building framework. We present novel interaction and system designs to incorporate information?\u2026", "IdName": "kwon2020myokey", "Citation": "", "Keywords": ""}, {"Name": "Short, colorful, and irreverent! a comparative analysis of new users on wallstreetbets during the gamestop short-squeeze", "Authors": ["Ehsan-Ul Haq", "Tristan Braud", "Lik-Hang Lee", "Anish K Vallapuram", "Yue Yu", "Gareth Tyson", "Pan Hui"], "Sources": "Companion Proceedings of the Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": " WallStreetBets (WSB) is a Reddit community that primarily discusses high-risk options and stock trading. In January 2021, it attracted worldwide attention as one of the epicentres of a significant short squeeze on US markets. Following this event, the number of users and their activity increased exponentially. In this paper, we study the changes caused in the WSB community by such an increase in activity. We perform a comparative analysis between long-term users and newcomers and examine their respective writing styles, topics, and susceptibility to community feedback. We report a significant difference in the post length and the number of emojis between the regular and new users joining WSB. Newer users\u2019 activity also closely follows the affected companies\u2019 stock prices. Finally, although community feedback affects the choices of topics for all users, new users are less prone to select their subsequent?\u2026", "IdName": "haq2022short", "Citation": "", "Keywords": ""}, {"Name": "Predicting the need for vasopressors in the intensive care unit using an attention based deep learning model", "Authors": ["Gloria Hyunjung Kwak", "Lowell Ling", "Pan Hui"], "Sources": "Shock", "PublishedYears": "2021", "Doi": "", "Abstracts": "Background:Previous models on prediction of shock mostly focused on septic shock and often required laboratory results in their models. The purpose of this study was to use deep learning approaches to predict vasopressor requirement for critically ill patients within 24 h of intensive care unit (ICU) admission using only vital signs.Methods:We used data from the Medical Information Mart for Intensive Care III database and the eICU Collaborative Research Database to develop a vasopressor prediction model. We performed systematic data preprocessing using matching of cohorts, oversampling, and imputation to control for bias, class imbalance, and missing data. Bidirectional long short-term memory (Bi-LSTM), a multivariate time series model, was used to predict the need for vasopressor therapy using serial physiological data collected 21 h prior to prediction time.Results:Using data from 10,941 critically ill?\u2026", "IdName": "kwak2021predicting", "Citation": "", "Keywords": ""}, {"Name": "Community matters more than anonymity: analysis of user interactions on the Quora Q&A platform", "Authors": ["Ehsan ul Haq", "Tristan Braud", "Pan Hui"], "Sources": "2020 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Question-and-answer (Q&A) websites are one of the latest evolutions in crowdsourced knowledge aggregation. Q&A websites provide more diverse opinions, as they involve the entire community. Quora made its reputation out of enhancing the traditional Q&A model with popular aspects of social media and incites its users to provide their names, locations, and references. This model allows higher quality control - including anonymous content, but more importantly, it leads users to form communities based on other criteria (e.g. profession, city) than similar interests. In this paper, we study the interactions among Quorans to unveil how such communities emerge. We perform both quantitative and qualitative analysis on the user-generated content and relate this content to social and demographic features. We show that being anonymous significantly affects the answers' length and subjectivity. On the other hand, most?\u2026", "IdName": "ul2020community", "Citation": "", "Keywords": ""}, {"Name": "Empowering the metaverse with generative ai: Survey and future directions", "Authors": ["Hua Xuan Qin", "Pan Hui"], "Sources": "2023 IEEE 43rd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper aims to motivate the development of the metaverse by highlighting the potential of artificial-intelligence-generated content (AIGC) for the metaverse. We present the first literature review on AIGC in the metaverse with state-of-the-art research classified into 5 key application areas (avatars and Non-player Characters (NPCs), content creation, virtual world generation, automatic digital twin, and personalization). Having noticed a notable gap in research through our review, we propose ways in which state-of-the-art generative AI can be applied to the metaverse. Additionally, we offer a roadmap for future research with related ethical implications.", "IdName": "qin2023empowering", "Citation": "", "Keywords": ""}, {"Name": "Reducing stress and anxiety in the metaverse: A systematic review of meditation, mindfulness and virtual reality", "Authors": ["Xian Wang", "Xiaoyu Mo", "Mingming Fan", "Lik-Hang Lee", "Bertram Shi", "Pan Hui"], "Sources": "Proceedings of the Tenth International Symposium of Chinese CHI", "PublishedYears": "2022", "Doi": "", "Abstracts": " Meditation, or mindfulness, is widely used to improve mental health. With the emergence of Virtual Reality technology, many studies have provided evidence that meditation with VR can bring health benefits. However, to our knowledge, there are no guidelines and comprehensive reviews in the literature on how to conduct such research in virtual reality. In order to understand the role of VR technology in meditation and future research opportunities, we conducted a systematic literature review in the IEEE and ACM databases. Our process yielded 19 eligible papers and we conducted a structured analysis. We understand the state-of-art of meditation type, design consideration and VR and technology through these papers and conclude research opportunities and challenges for the future.", "IdName": "wang2022reducing", "Citation": "", "Keywords": ""}, {"Name": "Aquilis: Using contextual integrity for privacy protection on mobile devices", "Authors": ["Abhishek Kumar", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "Smartphones are nowadays the dominant end-user device. As a result, they have become gateways to all users' communications, including sensitive personal data. In this paper, we present Aquilis, a privacy-preserving system for mobile platforms following the principles of contextual integrity to define the appropriateness of an information flow. Aquilis takes the form of a keyboard that reminds users of potential privacy leakages through a simple three-colour code. Aquilis considers the instantaneous privacy risk related to posting information (Local Sensitivity), the risk induced by repeating information over time (Longitudinal Sensitivity) and on different platforms (Cross-platform Sensitivity). Considering 50% of Aquilis warnings decreases the proportion of inappropriate information by up to 30%. Repeating information over time or in a broader exposure context increases the risk by 340% in a one-to-one context. We?\u2026", "IdName": "kumar2020aquilis", "Citation": "", "Keywords": ""}, {"Name": "VIMES: A wearable memory assistance system for automatic information retrieval", "Authors": ["Carlos Bermejo", "Tristan Braud", "Ji Yang", "Shayan Mirjafari", "Bowen Shi", "Yu Xiao", "Pan Hui"], "Sources": "Proceedings of the 28th ACM International Conference on Multimedia", "PublishedYears": "2020", "Doi": "", "Abstracts": "The advancement of artificial intelligence and wearable computing triggers the radical innovation of cognitive applications. In this work, we propose VIMES, an augmented reality-based memory assistance system that helps recall declarative memory, such as whom the user meets and what they chat. Through a collaborative method with 20 participants, we design VIMES, a system that runs on smartglasses, takes the first-person audio and video as input, and extracts personal profiles and event information to display on the embedded display or a smartphone. We perform an extensive evaluation with 50 participants to show the effectiveness of VIMES for memory recall. VIMES outperforms (90% memory accuracy) other traditional methods such as self-recall (34%) while offering the best memory experience (Vividness, Coherence, and Visual Perspective all score over 4/5). The user study results show that most?\u2026", "IdName": "bermejo2020vimes", "Citation": "", "Keywords": ""}, {"Name": "What do users think of promotional gamification schemes? a qualitative case study in a question answering website", "Authors": ["Reza Hadi Mogavi", "Yuanhao Zhang", "Ehsan-Ul Haq", "Yongjin Wu", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "In recent years, studies on the user experience have emerged as an indispensable part of any gamification research. The study of user experience enables gamification designers and practitioners to design or adapt their gamification schemes in a more knowledgeable and efficacious manner. However, one popular gamification scheme that has largely remained under-researched in terms of user experience is promotional gamification, which refers to an optional and time-limited gamification program that usually mounts an already gamified platform to increase user incentive and engagement for a short span of time (e.g., during the holiday season). The current study undertakes the first steps necessary to explore users' experiences of working with a promotional gamification scheme in a large-scale online community. To this end, we conduct an extensive qualitative case study of users' experiences with a?\u2026", "IdName": "hadi2022users", "Citation": "", "Keywords": ""}, {"Name": "Automorphic equivalence-aware graph neural network", "Authors": ["Fengli Xu", "Quanming Yao", "Pan Hui", "Yong Li"], "Sources": "Advances in Neural Information Processing Systems 34", "PublishedYears": "2021", "Doi": "", "Abstracts": "Distinguishing the automorphic equivalence of nodes in a graph plays an essential role in many scientific domains, eg, computational biologist and social network analysis. However, existing graph neural networks (GNNs) fail to capture such an important property. To make GNN aware of automorphic equivalence, we first introduce a localized variant of this concept---ego-centered automorphic equivalence (Ego-AE). Then, we design a novel variant of GNN, ie, GRAPE, that uses learnable AE-aware aggregators to explicitly differentiate the Ego-AE of each node's neighbors with the aids of various subgraph templates. While the design of subgraph templates can be hard, we further propose a genetic algorithm to automatically search them from graph data. Moreover, we theoretically prove that GRAPE is expressive in terms of generating distinct representations for nodes with different Ego-AE features, which fills in a fundamental gap of existing GNN variants. Finally, we empirically validate our model on eight real-world graph data, including social network, e-commerce co-purchase network, and citation network, and show that it consistently outperforms existing GNNs. The source code is public available at https://github. com/tsinghua-fib-lab/GRAPE.", "IdName": "xu2021automorphic", "Citation": "", "Keywords": ""}, {"Name": "Redundancy removing aggregation network with distance calibration for video face recognition", "Authors": ["Zhonghong Ou", "Yucheng Hu", "Meina Song", "Zheng Yan", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2020", "Doi": "", "Abstracts": "Attention-based techniques have been successfully used for rating image quality, and have been widely employed for set-based face recognition. Nevertheless, for video face recognition, where the base convolutional neural network (CNN) trained on large-scale data already provides discriminative features, fusing features with only predicted quality scores to generate representation are likely to cause duplicate sample dominant problem, and degrade performance correspondingly. To resolve the problem mentioned above, we propose a redundancy removing aggregation network (RRAN) for video face recognition. Compared with other quality-aware aggregation schemes, RRAN can take advantage of similarity information to tackle the noise introduced by redundant video frames. By leveraging metric learning, RRAN introduces a distance calibration scheme to align distance distributions of negative pairs of?\u2026", "IdName": "ou2020redundancy", "Citation": "", "Keywords": ""}, {"Name": "Preference-based privacy markets", "Authors": ["Ranjan Pal", "Jon Crowcroft", "Yixuan Wang", "Yong Li", "Swades De", "Sasu Tarkoma", "Mingyan Liu", "Bodhibrata Nag", "Abhishek Kumar", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "In the modern era of the mobile apps (the era of surveillance capitalism - as termed by Shoshana Zuboff) huge quantities of surveillance data about consumers and their activities offer a wave of opportunities for economic and societal value creation. ln-app advertising - a multi-billion dollar industry, is an essential part of the current digital ecosystem driven by free mobile applications, where the ecosystem entities usually comprise consumer apps, their clients (consumers), ad-networks, and advertisers. Sensitive consumer information is often being sold downstream in this ecosystem without the knowledge of consumers, and in many cases to their annoyance. While this practice, in cases, may result in long-term benefits for the consumers, it can result in serious information privacy breaches of very significant impact (e.g., breach of genetic data) in the short term. The question we raise through this paper is: Is it?\u2026", "IdName": "pal2020preference", "Citation": "", "Keywords": ""}, {"Name": "(m) ad to see me? intelligent advertisement placement: Balancing user annoyance and advertising effectiveness", "Authors": ["Ngoc Thi Nguyen", "Agustin Zuniga", "Hyowon Lee", "Pan Hui", "Huber Flores", "Petteri Nurmi"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "Advertising is an unavoidable albeit a frustrating part of mobile interactions. Due to limited form factor, mobile advertisements often resort to intrusive strategies where they temporarily block the user's view in an attempt to increase effectiveness by forcing the user's attention. While such strategies contribute to advertising awareness and effectiveness, they do so at the cost of degrading the user's overall experience and can lead to frustration and annoyance. In this paper, we contribute by developing Perceptive Ads as an intelligent advertisement placement strategy that minimizes disruptions caused by ads while preserving their effectiveness. Our work is the first to simultaneously consider the needs of users, app developers, and advertisers. Ensuring the needs of all stakeholders are taken into account is essential for the adoption of advertising strategies as users (and indirectly developers) would reject strategies?\u2026", "IdName": "nguyen2020m", "Citation": "", "Keywords": ""}, {"Name": "Edge Intelligence: Architectures, Challenges, and\nApplications", "Authors": ["Dianlei Xu", "Tong Li", "Yong Li", "Xiang Su", "Sasu Tarkoma", "Tao Jiang", "Jon Crowcroft", "Pan Hui"], "Sources": "Challenges", "PublishedYears": "2020", "Doi": "", "Abstracts": "None", "IdName": "xu2020edge", "Citation": "", "Keywords": ""}, {"Name": "An asynchronous federated learning mechanism for edge network computing", "Authors": ["X Lu", "Y Liao", "Pietro Lio", "H Pan"], "Sources": "Journal of Computer Research and Development", "PublishedYears": "2020", "Doi": "", "Abstracts": "None", "IdName": "lu2020asynchronous", "Citation": "", "Keywords": ""}, {"Name": "Exploring gaze-assisted and hand-based region selection in augmented reality", "Authors": ["Rongkai Shi", "Yushi Wei", "Xueying Qin", "Pan Hui", "Hai-Ning Liang"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Region selection is a fundamental task in interactive systems. In 2D user interfaces, users typically use a rectangle selection tool to formulate a region using a mouse or touchpad. Region selection in 3D spaces, especially in Augmented Reality (AR) Head-Mounted Displays (HMDs) is different and challenging because users need to select an intended region via freehand mid-air gestures or eye-based actions that are touchless interactions. In this work, we aim to fill in the gap in the design of region selection techniques in AR HMDs. We first analyzed and discretized the interaction procedure of region selection and explored design possibilities for each step. We then developed four techniques for region selection in AR HMDs, which leveraged users' hand and gaze for unimodal or multimodal interaction. The techniques were evaluated via a user study with a controlled region selection task. The findings led to three?\u2026", "IdName": "shi2023exploring", "Citation": "", "Keywords": ""}, {"Name": "More gamification is not always better: A case study of promotional gamification in a question answering website", "Authors": ["Reza Hadi Mogavi", "Ehsan-Ul Haq", "Sujit Gujar", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Community Question Answering Websites (CQAs) like Stack Overflow rely on continuous user contributions to keep their services active. Nevertheless, they often undergo a sharp decline in their user participation during the holiday season, undermining their performance. To address this issue, some CQAs have developed their own special promotional gamification schemes to incentivize users to maintain their contributions throughout the holiday season. These promotional gamification schemes are often time-limited, optional, and run alongside the default gamification schemes of their websites. However, the impact of such promotional gamification schemes on user behavior remains largely unexplored in the existing literature. This paper takes the first steps toward filling this knowledge gap by conducting a large-scale empirical study of a particular promotional gamification scheme called Winter Bash (WB) on the?\u2026", "IdName": "hadi2022more", "Citation": "", "Keywords": ""}, {"Name": "PassWalk: spatial authentication leveraging lateral shift and gaze on mobile headsets", "Authors": ["Abhishek Kumar", "Lik-Hang Lee", "Jagmohan Chauhan", "Xiang Su", "Mohammad A Hoque", "Susanna Pirttikangas", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the 30th ACM International Conference on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Secure and usable user authentication on mobile headsets is a challenging problem. The miniature-sized touchpad on such devices becomes a hurdle to user interactions that impact usability. However, the most common authentication methods, i.e., the standard QWERTY virtual keyboard or mid-air inputs to enter passwords are highly vulnerable to shoulder surfing attacks. In this paper, we present PassWalk, a keyboard-less authentication system leveraging multi-modal inputs on mobile headsets. PassWalk demonstrates the feasibility of user authentication driven by the user's gaze and lateral shifts (i.e., footsteps) simultaneously. The keyboard-less authentication interface in PassWalk enables users to accomplish highly mobile inputs of graphical passwords, containing digital overlays and physical objects. We conduct an evaluation with 22 recruited participants (15 legitimate users and 7 attackers). Our results?\u2026", "IdName": "kumar2022passwalk", "Citation": "", "Keywords": ""}, {"Name": "Hidenseek: Federated lottery ticket via server-side pruning and sign supermask", "Authors": ["Anish K Vallapuram", "Pengyuan Zhou", "Young D Kwon", "Lik Hang Lee", "Hengwei Xu", "Pan Hui"], "Sources": "arXiv preprint arXiv:2206.04385", "PublishedYears": "2022", "Doi": "", "Abstracts": "Federated learning alleviates the privacy risk in distributed learning by transmitting only the local model updates to the central server. However, it faces challenges including statistical heterogeneity of clients' datasets and resource constraints of client devices, which severely impact the training performance and user experience. Prior works have tackled these challenges by combining personalization with model compression schemes including quantization and pruning. However, the pruning is data-dependent and thus must be done on the client side which requires considerable computation cost. Moreover, the pruning normally trains a binary supermask  which significantly limits the model capacity yet with no computation benefit. Consequently, the training requires high computation cost and a long time to converge while the model performance does not pay off. In this work, we propose HideNseek which employs one-shot data-agnostic pruning at initialization to get a subnetwork based on weights' synaptic saliency. Each client then optimizes a sign supermask  multiplied by the unpruned weights to allow faster convergence with the same compression rates as state-of-the-art. Empirical results from three datasets demonstrate that compared to state-of-the-art, HideNseek improves inferences accuracies by up to 40.6\\% while reducing the communication cost and training time by up to 39.7\\% and 46.8\\% respectively.", "IdName": "vallapuram2022hidenseek", "Citation": "", "Keywords": ""}, {"Name": "Screenshots, symbols, and personal thoughts: The role of instagram for social activism", "Authors": ["Ehsan-Ul Haq", "Tristan Braud", "Yui-Pan Yau", "Lik-Hang Lee", "Franziska B Keller", "Pan Hui"], "Sources": "Proceedings of the ACM Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "In this paper, we highlight the use of Instagram for social activism, taking 2019 Hong Kong protests as a case study. Instagram focuses on image content and provides users with few features to share or repost, limiting information propagation. Nevertheless, users who are politically active offline also share their activism on Instagram. We first evaluate the effect of protests on social media activity for protesters and non-protesters over two significant protests. Protesters\u2019 exposure to protest-related posts is much higher than non-protesters, and their network activity follows the protest schedule. They are also much more active on posts related to the protest that they participate in than the other protest. We then analyze the images posted by the users. Users predominantly use symbols related to protests and share personal thoughts on its primary actors. Users primarily share content to raise their network\u2019s awareness, and?\u2026", "IdName": "haq2022screenshots", "Citation": "", "Keywords": ""}, {"Name": "Seeing is believing? Effects of visualization on smart device privacy perceptions", "Authors": ["Carlos Bermejo Fernandez", "Petteri Nurmi", "Pan Hui"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Research on smart device privacy has consistently highlighted how privacy is an important concern for users, but they fail to act on their concerns. While this discrepancy between user perceptions and actions has been consistently reported, currently there is a limited understanding of why this is the case or how the situation can be ameliorated. This paper systematically studies how visualizations in privacy assistants can improve the situation, reporting on two studies that explore the users' privacy perceptions in smart device ecosystems. The first study shows that displaying device location and data type reduces the users' privacy perceptions. Participants also weigh the use of media such as online news as a source to inform users about the possible inferences. The second study analyzes participants' preferences to visualize smart device information and privacy policies using augmented reality. Through these two?\u2026", "IdName": "bermejo2021seeing", "Citation": "", "Keywords": ""}, {"Name": "Persuade to click: Context-aware persuasion model for online textual advertisement", "Authors": ["Yuan Yuan", "Fengli Xu", "Hancheng Cao", "Guozhen Zhang", "Pan Hui", "Yong Li", "Depeng Jin"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "In recent years, due to the prevalence of online textual advertisements, increasing businesses recognize their huge potential in product promotion. The high-quality textual content has been empirically shown to have a substantial impact on consumers\u2019 attitudes and decisions. As a result, persuasive tactics play an essential role in online textual advertisements, which are employed to increase the attractiveness, and sequentially increase the conversion rate and sales volume. As the context of persuasion, product attributes, e.g., category and price, also greatly influence the persuasion outcomes. However, they are largely overlooked by existing works. In this paper, we propose a novel framework to study context-aware persuasion by designing a multi-task learning model and performing extensive causal analysis. First, the prediction model recognizes the persuasive tactics employed in an advertising text and?\u2026", "IdName": "yuan2021persuade", "Citation": "", "Keywords": ""}, {"Name": "Emerging exg-based nui inputs in extended realities: A bottom-up survey", "Authors": ["Kirill A Shatilov", "Dimitris Chatzopoulos", "Lik-Hang Lee", "Pan Hui"], "Sources": "ACM Transactions on Interactive Intelligent Systems (TiiS)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Incremental and quantitative improvements of two-way interactions with extended realities (XR) are contributing toward a qualitative leap into a state of XR ecosystems being efficient, user-friendly, and widely adopted. However, there are multiple barriers on the way toward the omnipresence of XR; among them are the following: computational and power limitations of portable hardware, social acceptance of novel interaction protocols, and usability and efficiency of interfaces. In this article, we overview and analyse novel natural user interfaces based on sensing electrical bio-signals that can be leveraged to tackle the challenges of XR input interactions. Electroencephalography-based brain-machine interfaces that enable thought-only hands-free interaction, myoelectric input methods that track body gestures employing electromyography, and gaze-tracking electrooculography input interfaces are the examples of?\u2026", "IdName": "shatilov2021emerging", "Citation": "", "Keywords": ""}, {"Name": "Who will survive and revive undergoing the epidemic: Analyses about poi visit behavior in Wuhan via check-in records", "Authors": ["Zhenyu Han", "Haohao Fu", "Fengli Xu", "Zhen Tu", "Yang Yu", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2021", "Doi": "", "Abstracts": "A rapid-spreading epidemic of COVID-19 hit China at the end of 2019, resulting in unignorable social and economic damage in the epicenter, Wuhan. POIs capture the microscopic behavior of citizens, providing valuable information to understand city reactions toward the epidemic. Leveraging large-scale check-in records, we analyze the POI visit trends over the epidemic period and normal times. We demonstrate that COVID-19 greatly influences the society, where most POIs demonstrate more than 60% of visit drops during the city lockdown period. Among them, Tourist Attractions received greatest impact with a 78.8% drop. Entertainment, Food, Medical and Shopping are sensible to the disease before lockdown, and we identify these \"early birds\" to investigate the public reaction in the early stage of the epidemic. We further analyze the revival trends, generating four different revival patterns that correlated with the?\u2026", "IdName": "han2021will", "Citation": "", "Keywords": ""}, {"Name": "DeepPredict: A zone preference prediction system for online lodging platforms", "Authors": ["Yihan Ma", "Hua Sun", "Yang Chen", "Jiayun Zhang", "Yang Xu", "Xin Wang", "Pan Hui"], "Sources": "Journal of Social Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "Online lodging platforms have become more and more popular around the world. To make a booking in these platforms, a user usually needs to select a city first, then browses among all the prospective options. To improve the user experience, understanding the zone preferences of a user's booking behavior will be helpful. In this work, we aim to predict the zone preferences of users when booking accommodations for the next travel. We have two main challenges: (1) The previous works about next information of Points Of Interest (POIs) recommendation are mainly focused on users' historical records in the same city, while in practice, the historical records of a user in the same city would be very sparse. (2) Since each city has its own specific geographical entities, it is hard to extract the structured geographical features of accommodation in different cities. Towards the difficulties, we propose DeepPredict, a zone?\u2026", "IdName": "ma2021deeppredict", "Citation": "", "Keywords": ""}, {"Name": "5G edge enhanced mobile augmented reality", "Authors": ["Xiang Su", "Jacky Cao", "Pan Hui"], "Sources": "Proceedings of the 26th Annual International Conference on Mobile Computing?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) provides a unique experience where the physical world is augmented with virtual annotations. MAR involves computation-heavy algorithms that could potentially be offloaded to edge servers on 5G networks, which significantly enhances MAR with reduced communication latency and more stable network connections, therefore leading to seamless MAR user experiences. In this demo, we show a running MAR system deployed on a 5G edge test bed and present latency results.", "IdName": "su20205g", "Citation": "", "Keywords": ""}, {"Name": "Guest editorial special issue on advances in artificial intelligence and machine learning for networking", "Authors": ["Prosper Chemouil", "Pan Hui", "Wolfgang Kellerer", "Noura Limam", "Rolf Stadler", "Yonggang Wen"], "Sources": "IEEE Journal on Selected Areas in Communications", "PublishedYears": "2020", "Doi": "", "Abstracts": "I. INTRODUCTION ARTIFICIAL Intelligence (AI) and Machine Learn-ing (ML) approaches have emerged in the networking domain with great expectation. They can be broadly divided into AI/ML techniques for network engineering and management, network designs for AI/ML applications, and system concepts. AI/ML techniques for networking and management improve the way we address networking. They support efficient, rapid, and trustworthy engineering, operations, and management. As such, they meet the current interest in softwarization and network programmability that fuels the need for improved network automation in agile infrastructures, including edge and fog environments. Network design and optimization for AI/ML applications addresses the complementary topic of supporting AI/ML-based systems through novel networking techniques, including new architectures and algorithms. The third topic area is system implementation and open-source software development. This evolution draws particular attention to interdisciplinary approaches. Researchers in communication networks apply ML and AI concepts to optimize and automate network architecture, control, and management. Similarly, AI experts collaborate with networking researchers to optimize network support for architecture and design of data communication and processing for AI purposes. This special issue is a follow-up to the JSAC\u2019s Special Issue on Artificial Intelligence and Machine Learning for Networking and Communications published in June 2019 [1]. It has been organized by the same core team of researchers.", "IdName": "chemouil2020guest", "Citation": "", "Keywords": ""}, {"Name": "Domain-oriented topic discovery based on features extraction and topic clustering", "Authors": ["Xiaofeng Lu", "Xiao Zhou", "Wenting Wang", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "Topic detection technology can automatically discover new topics on the Internet. This paper investigates domain-oriented feature extraction methods, and proposes a keyword feature extraction method ITFIDF-LP, a subject word feature extraction method LDA-SLP and a topic clustering model based on vector product similarity. A novel Domain-oriented Topic Discovery based on Features Extraction and Topic Clustering (DTD-FETC) model is proposed to analyze open source web of a domain and identify emerging topics in the domain in real time. This article describes a DTD-FETC system built for cyber security domain. It filters and aggregates web for specical security threat topics such as vulnerability and malware, and helps security staff respond quickly and defends against the emerging cyber threats as early as possible. The recall rate, accuracy and F1 value results of the DTD-FETC method applied to the?\u2026", "IdName": "lu2020domain", "Citation": "", "Keywords": ""}, {"Name": "Mneme: A mobile distributed ledger", "Authors": ["Dimitris Chatzopoulos", "Sujit Gujar", "Boi Faltings", "Pan Hui"], "Sources": "Ieee Infocom 2020-Ieee Conference On Computer Communications", "PublishedYears": "2020", "Doi": "", "Abstracts": "Advances in mobile computing have paved the way for new types of distributed applications that can be executed solely by mobile devices on device-to-device (D2D) ecosystems (e.g., crowdsensing). More sophisticated applications, like cryptocurrencies, need distributed ledgers to function. Distributed ledgers, such as blockchains and directed acyclic graphs (DAGs), employ consensus protocols to add data in the form of blocks. However such protocols are designed for resourceful devices that are interconnected via the Internet. Moreover, existing distributed ledgers are not deployable to D2D ecosystems since their storage needs are continuously increasing. In this work, we introduce Mneme, a DAG-based distributed ledger that can be maintained solely by mobile devices and operates via two consensus protocols: Proof-of-Context (PoC) and Proof-of-Equivalence (PoE). PoC employs users' context to add data?\u2026", "IdName": "chatzopoulos2020mneme", "Citation": "", "Keywords": ""}, {"Name": "Towards augmented reality-driven human-city interaction: Current research and future challenges", "Authors": ["Lik-Hang Lee", "Tristan Braud", "Simo Hosio", "Pan Hui"], "Sources": "ArXiv", "PublishedYears": "2020", "Doi": "", "Abstracts": "Authors\u2019 addresses: Lik-Hang Lee Center for Ubiquitous Computing, The University of Oulu, Finland; Tristan Braud Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong; Simo Hosio Center for Ubiquitous Computing, The University of Oulu, Finland; Pan Hui Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong Department of Computer Science, The University of Helsinki, Finland.", "IdName": "lee2020towards", "Citation": "", "Keywords": ""}, {"Name": "A survey on generative ai and llm for video generation, understanding, and streaming", "Authors": ["Pengyuan Zhou", "Lin Wang", "Zhi Liu", "Yanbin Hao", "Pan Hui", "Sasu Tarkoma", "Jussi Kangasharju"], "Sources": "arXiv preprint arXiv:2404.16038", "PublishedYears": "2024", "Doi": "", "Abstracts": "This paper offers an insightful examination of how currently top-trending AI technologies, i.e., generative artificial intelligence (Generative AI) and large language models (LLMs), are reshaping the field of video technology, including video generation, understanding, and streaming. It highlights the innovative use of these technologies in producing highly realistic videos, a significant leap in bridging the gap between real-world dynamics and digital creation. The study also delves into the advanced capabilities of LLMs in video understanding, demonstrating their effectiveness in extracting meaningful information from visual content, thereby enhancing our interaction with videos. In the realm of video streaming, the paper discusses how LLMs contribute to more efficient and user-centric streaming experiences, adapting content delivery to individual viewer preferences. This comprehensive review navigates through the current achievements, ongoing challenges, and future possibilities of applying Generative AI and LLMs to video-related tasks, underscoring the immense potential these technologies hold for advancing the field of video technology related to multimedia, networking, and AI communities.", "IdName": "zhou2024survey", "Citation": "", "Keywords": ""}, {"Name": "Large-scale urban cellular traffic generation via knowledge-enhanced gans with multi-periodic patterns", "Authors": ["Shuodi Hui", "Huandong Wang", "Tong Li", "Xinghao Yang", "Xing Wang", "Junlan Feng", "Lin Zhu", "Chao Deng", "Pan Hui", "Depeng Jin", "Yong Li"], "Sources": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "With the rapid development of the cellular network, network planning is increasingly important. Generating large-scale urban cellular traffic contributes to network planning via simulating the behaviors of the planned network. Existing methods fail in simulating the long-term temporal behaviors of cellular traffic while cannot model the influences of the urban environment on the cellular networks. We propose a knowledge-enhanced GAN with multi-periodic patterns to generate large-scale cellular traffic based on the urban environment. First, we design a GAN model to simulate the multi-periodic patterns and long-term aperiodic temporal dynamics of cellular traffic via learning the daily patterns, weekly patterns, and residual traffic between long-term traffic and periodic patterns step by step. Then, we leverage urban knowledge to enhance traffic generation via constructing a knowledge graph containing multiple factors?\u2026", "IdName": "hui2023large", "Citation": "", "Keywords": ""}, {"Name": "Envisioning an Inclusive Metaverse: Student Perspectives on Accessible and Empowering Metaverse-Enabled Learning", "Authors": ["Reza Hadi Mogavi", "Jennifer Hoffman", "Chao Deng", "Yiwei Du", "Ehsan-Ul Haq", "Pan Hui"], "Sources": "Proceedings of the Tenth ACM Conference on Learning@ Scale", "PublishedYears": "2023", "Doi": "", "Abstracts": "The emergence of the metaverse is being widely viewed as a revolutionary technology owing to a myriad of factors, particularly the potential to increase the accessibility of learning for students with disabilities. However, not much is yet known about the views and expectations of disabled students in this regard. The fact that the metaverse is still in its nascent stage exemplifies the need for such timely discourse. To bridge this important gap, we conducted a series of semi-structured interviews with 56 university students with disabilities in the United States and Hong Kong to understand their views and expectations concerning the future of metaverse-driven education. We have distilled student expectations into five thematic categories, referred to as the REEPS framework: Recognition, Empowerment, Engagement, Privacy, and Safety. Additionally, we have summarized the main design considerations in eight concise?\u2026", "IdName": "hadi2023envisioning", "Citation": "", "Keywords": ""}, {"Name": "Ad-rcnn: Adaptive dynamic neural network for small object detection", "Authors": ["Zhonghong Ou", "Zhaofengnian Wang", "Fenrui Xiao", "Baiqiao Xiong", "Hongxing Zhang", "Meina Song", "Yan Zheng", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2022", "Doi": "", "Abstracts": "With the large-scale commercialization of 5G networks, Internet of Things (IoT) applications keep on emerging in recent years. Real-time environmental awareness is an essential part of various IoT applications, e.g., self-driving vehicles. Object detection plays a fundamental role in real-time environmental awareness, which is responsible for acquiring valuable object information from the environment automatically. Despite of the fast progress for object detection in general, small object detection still faces challenges. Because of the restricted scales, small objects are only capable of generating relatively week features after multiple convolutional layers, thus causing low detection accuracy. Existing schemes mostly focus on extracting rich multiscale features, e.g., generating high-resolution features through generative adversarial networks (GANs), or generating multiscale features through feature combination?\u2026", "IdName": "ou2022ad", "Citation": "", "Keywords": ""}, {"Name": "Talaria: In-engine synchronisation for seamless migration of mobile edge gaming instances", "Authors": ["Tristan Braud", "Ahmad Alhilal", "Pan Hui"], "Sources": "Proceedings of the 17th International Conference on emerging Networking?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Mobile cloud gaming requires a very low end-to-end latency. Edge computing significantly reduces network latency. However, in mobility scenarios, the user will frequently move out of the edge server's coverage area, requiring frequent migration of the game instance. This paper presents Talaria, an in-engine content synchronisation solution for unnoticeable game instance migration between edge servers. Talaria creates a minimal instance with content immediately relevant to the game experience, allowing the client to switch servers in a minimal amount of time. The remaining content is then synchronised according to priority until the game's state is coherent between both instances. Our implementation of Talaria as a Unity engine plugin reduces the game's downtime by 61% compared to one-off server migration, with an average latency below 25 ms for the server migration, and 87 ms for the entire game?\u2026", "IdName": "braud2021talaria", "Citation": "", "Keywords": ""}, {"Name": "Enemy at the gate: evolution of Twitter user's polarization during national crisis", "Authors": ["Ehsan ul Haq", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "Proceedings of the 12th IEEE/ACM International Conference on Advances in?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Social networks are effective platforms to study the real-life behavior of users. In this paper, we study users' political polarization during the times of crisis and its relation to nationalism. To this purpose, we focus on the reaction of Indian and Pakistani Twitter users during February 2019 crisis and the ensuing Indian General Elections in 2019. We show that a national crisis affects the polarization and discourse in both countries. Also, we show that user activities increase during a national crisis, and political discourse strengthens while polarization decreases on critical days. Finally, we highlight the links between this crisis and the Indian elections and show how the political parties discussed the crisis in their campaigns.", "IdName": "haq2020enemy", "Citation": "", "Keywords": ""}, {"Name": "Demo Abstract: Federated Learning on Wearable Devices", "Authors": ["Xiaoxin He", "Xiang Su", "Yang Chen", "Pan Hui"], "Sources": "Proceedings of the 18th Conference on Embedded Networked Sensor Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Wearable devices collect user information about their activities and provide insights to improve their daily lifestyles. Smart health applications have achieved great success by training Machine Learning (ML) models on a large quantity of user data from wearables. However, user privacy and scalability are becoming critical challenges for training ML models in a centralized way. Federated learning (FL) is a novel ML paradigm with the goal of training high quality models while distributing training data over a large number of devices. In this demo, we present FL4W, a FL system with wearable devices enabling training a human activity recognition classifier. We also perform preliminary analytics to investigate the model performance with increasing computation of clients.", "IdName": "he2020federated", "Citation": "", "Keywords": ""}, {"Name": "IoT vs. human: A comparison of mobility", "Authors": ["Dianlei Xu", "Huandong Wang", "Yong Li", "Sasu Tarkoma", "Depeng Jin", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "Internet of Thing (IoT) devices are rapidly becoming an indispensable part of our life with their increasing deployment in many promising areas, including tele-health, smart city, intelligent agriculture. Understanding the mobility of IoT devices is essential to improve quality of service in IoT applications, such as route planning in logistic management, infrastructure deployment, cellular network update and congestion detection in intelligent traffic. Despite its importance, there are not many results pertaining to the mobility of IoT devices. In this article, we aim to answer three research questions: (i) what are the mobility patterns of IoT device? (ii) what are the differences between IoT device and smartphone mobility patterns? (iii) how the IoT device mobility patterns differ among device types and usage scenarios? We present a comprehensive characterization of IoT device mobility patterns from the perspective of cellular?\u2026", "IdName": "xu2020iot", "Citation": "", "Keywords": ""}, {"Name": "Understanding the working time of developers in it companies in China and the United States", "Authors": ["Jiayun Zhang", "Yang Chen", "Qingyuan Gong", "Xin Wang", "Aaron Yi Ding", "Yu Xiao", "Pan Hui"], "Sources": "IEEE Software", "PublishedYears": "2020", "Doi": "", "Abstracts": "We identified three temporal patterns shown in commit activities among Chinese and American companies and found that Chinese businesses are more likely to follow long work hours than American ones. We also conducted a survey on the trends of, reasons for, and results of overtime work. Our study could provide references for developers to choose workplaces and for companies to make regulations.", "IdName": "zhang2020understanding", "Citation": "", "Keywords": ""}, {"Name": "You are how you use apps: user profiling based on spatiotemporal app usage behavior", "Authors": ["Tong Li", "Yong Li", "Mingyang Zhang", "Sasu Tarkoma", "Pan Hui"], "Sources": "ACM Transactions on Intelligent Systems and Technology", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile apps have become an indispensable part of people\u2019s daily lives. Users determine what apps to use and when and where to use them based on their tastes, interests, and personal demands, depending on their personality traits. This article aims to infer user profiles from their spatiotemporal mobile app usage behavior. Specifically, we first transform mobile app usage records into a heterogeneous graph. On the graph, nodes represent users, apps, locations, and time slots. Edges describe the co-occurrence of entities in usage records. We then develop a multi-relational heterogeneous graph attention network (MRel-HGAN), an end-to-end system for user profiling. MRel-HGAN first adopts a neighbor sampling strategy based on bootstrapping to sample heavily connected neighbors of a fixed size for each node. Next, we design a relational graph convolutional operation and a multi-relational attention operation?\u2026", "IdName": "li2023you", "Citation": "", "Keywords": ""}, {"Name": "Network Traffic in the Metaverse: The Case of Social VR", "Authors": ["Ahmad Alhilal", "Kirill Shatilov", "Gareth Tyson", "Tristan Braud", "Pan Hui"], "Sources": "2023 IEEE 43rd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The Metaverse connects our physical reality with virtual worlds. Social VR platforms facilitate the creation of such virtual worlds, enabling activities such as interactive teaching, conferences, and community gatherings. These activities can be performed in mixed mode, with some participants physically present in the same location. In this paper, we evaluate the feasibility of such mixed-mode events by studying three leading social VR platforms. We uncover the network traffic patterns generated by these platforms, which affect the user experience when multiple users share the same network. We explore the traffic patterns to show that model loading creates a significant overhead and impacts user quality of experience. When the number of simultaneously connected users increases, some operations lead to network congestion that degrades or even interrupts service for most users. From these observations, we derive?\u2026", "IdName": "alhilal2023network", "Citation": "", "Keywords": ""}, {"Name": "Your favorite gameplay speaks volumes about you: Predicting user behavior and hexad type", "Authors": ["Reza Hadi Mogavi", "Chao Deng", "Jennifer Hoffman", "Ehsan-Ul Haq", "Sujit Gujar", "Antonio Bucchiarone", "Pan Hui"], "Sources": "International Conference on Human-Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "In recent years, the gamification research community has widely and frequently questioned the effectiveness of one-size-fits-all gamification schemes. In consequence, personalization seems to be an important part of any successful gamification design. Personalization can be improved by understanding user behavior and Hexad player/user type. This paper comes with an original research idea: It investigates whether users\u2019 game-related data (collected via various gamer-archetype surveys) can be used to predict their behavioral characteristics and Hexad user types in non-game (but gamified) contexts. The affinity that exists between the concepts of gamification and gaming provided us with the impetus for running this exploratory research.We conducted an initial survey study with 67 Stack Exchange users (as a case study). We discovered that users\u2019 gameplay information could reveal valuable and helpful?\u2026", "IdName": "hadi2023your", "Citation": "", "Keywords": ""}, {"Name": "Deepfake in the Metaverse: An Outlook Survey", "Authors": ["Haojie Wu", "Pan Hui", "Pengyuan Zhou"], "Sources": "arXiv preprint arXiv:2306.07011", "PublishedYears": "2023", "Doi": "", "Abstracts": "We envision deepfake technologies, which synthesize realistic fake images and videos, will play an important role in the future metaverse. While enhancing users' immersion and experience with synthesized virtual characters and scenes, deepfake can cause serious consequences if used for fraud, impersonation, and dissemination of fake information. In this paper, we introduce the principles, applications, and risks of deepfake technology, and propose some countermeasures to help users and developers in the metaverse deal with the challenges brought by deepfake technologies. Further, we provide an outlook on the future development of deepfake in the metaverse.", "IdName": "wu2023deepfake", "Citation": "", "Keywords": ""}, {"Name": "Tangible web: An interactive immersion virtual reality creativity system that travels across reality", "Authors": ["Simin Yang", "Ze Gao", "Reza Hadi Mogavi", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the ACM Web Conference 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": " With the advancement of virtual reality (VR) technology, virtual displays have become integral to how museums, galleries, and other tourist destinations present their collections to the public. However, the current lack of immersion in virtual reality displays limits the user\u2019s ability to experience and appreciate its aesthetics. This paper presents a case study of a creative approach taken by a tourist attraction venue in developing a physical network system that allows visitors to enhance VR\u2019s aesthetic aspects based on environmental parameters gathered by external sensors. Our system was collaboratively developed through interviews and sessions with twelve stakeholder groups interested in art and exhibitions. This paper demonstrates how our technological advancements in interaction, immersion and visual attractiveness surpass those of earlier virtual display generations. Through multimodal interaction, we aim to?\u2026", "IdName": "yang2023tangible", "Citation": "", "Keywords": ""}, {"Name": "Fedclean: A defense mechanism against parameter poisoning attacks in federated learning", "Authors": ["Abhishek Kumar", "Vivek Khimani", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "ICASSP 2022-2022 IEEE International Conference on Acoustics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In Federated learning (FL) systems, a centralized entity (server), instead of access to the training data, has access to model parameter updates computed by each participant independently and based solely on their samples. Unfortunately, FL is susceptible to model poisoning attacks, in which malicious or malfunctioning entities share polluted updates that can compromise the model\u2019s accuracy. In this study, we propose FedClean, an FL mechanism that is robust to model poisoning attacks. The accuracy of the models trained with the assistance of FedClean is close to the one where malicious entities do not participate.", "IdName": "kumar2022fedclean", "Citation": "", "Keywords": ""}, {"Name": "Implementing GDPR for mobile and ubiquitous computing", "Authors": ["Carlos Bermejo Fernandez", "Tristan Braud", "Pan Hui"], "Sources": "Proceedings of the 23rd Annual International Workshop on Mobile Computing?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The General Data Protection Regulation (GDPR) presents directives to give data subjects control over their personal data. These directives impose data-collecting and processing organizations to take concrete actions for privacy preservation of users and non-users alike. Significant challenges arise when applying these directives to mobile and ubiquitous computing. Mobile and ubiquitous computing aim for computer use to be as transparent and seamless as possible. Inconspicuous devices continually sense their environment, often without the data subject's knowledge. This context significantly complicates the implementation of core GDPR directives, such as informing the user and collecting consent. In this paper, we challenge the mobile computing research community on how to address such issues in practical implementations that combine the philosophy of mobile and ubiquitous computing with often?\u2026", "IdName": "fernandez2022implementing", "Citation": "", "Keywords": ""}, {"Name": "Evaluating multimedia protocols on 5g edge for mobile augmented reality", "Authors": ["Jacky Cao", "Xiang Su", "Benjamin Finley", "Antti Pauanne", "Mostafa Ammar", "Pan Hui"], "Sources": "2021 17th International Conference on Mobility", "PublishedYears": "2021", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) mixes physical environments with user-interactive virtual annotations. Immersive MAR experiences are supported by computation-intensive tasks, which are typically offloaded to cloud or edge servers. Such offloading introduces additional network traffic and influences the motion-to-photon latency (a determinant of user-perceived quality of experience). Therefore, proper multimedia protocols are crucial to minimise transmission latency and ensure sufficient throughput to support MAR performance. Relatedly, 5G is a potential MAR supporting technology and is widely believed to be faster and more efficient than its predecessors. However, the suitability and performance of existing multimedia protocols for MAR in the 5G edge context have not been explored. In this work, we present a detailed evaluation of several popular multimedia protocols (HLS, MPEG-DASH, RTP, RTMP, RTMFP?\u2026", "IdName": "cao2021evaluating", "Citation": "", "Keywords": ""}, {"Name": "CAD3: Edge-facilitated real-time collaborative abnormal driving distributed detection", "Authors": ["Ahmad Alhilal", "Tristan Braud", "Xiang Su", "Luay Al Asadi", "Pan Hui"], "Sources": "2021 IEEE 41st International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Speeding, slowing down, and sudden acceleration are the leading causes of fatal accidents on highways. Anomalous driving behavior detection can improve road safety by informing drivers who are in the vicinity of dangerous vehicles. However, detecting abnormal driving behavior at the city-scale in a centralized fashion results in considerable network and computation load, that would significantly restrict the scalability of the system. In this paper, we propose CAD3, a distributed collaborative system for road-aware and driver-aware anomaly driving detection. CAD3 considers a decentralized deployment of edge computation nodes on the roadside and combines collaborative and context-aware computation with low-latency communication to detect and inform nearby drivers of unsafe behaviors of other vehicles in real-time. Adjacent edge nodes collaborate to improve the detection of abnormal driving behavior at?\u2026", "IdName": "alhilal2021cad3", "Citation": "", "Keywords": ""}, {"Name": "Enemy at the Gate: Evolution of Twitter User's Polarization During National Crisis", "Authors": ["Ehsan ul Haq", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "2020 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Social networks are effective platforms to study the real-life behavior of users. In this paper, we study users' political polarization during the times of crisis and its relation to nationalism. To this purpose, we focus on the reaction of Indian and Pakistani Twitter users during February 2019 crisis and the ensuing Indian General Elections in 2019. We show that a national crisis affects the polarization and discourse in both countries. Also, we show that user activities increase during a national crisis, and political discourse strengthens while polarization decreases on critical days. Finally, we highlight the links between this crisis and the Indian elections and show how the political parties discussed the crisis in their campaigns.", "IdName": "ul2020enemy", "Citation": "", "Keywords": ""}, {"Name": "Force9: Force-assisted miniature keyboard on smart wearables", "Authors": ["Lik Hang Lee", "Ngo Yan Yeung", "Tristan Braud", "Tong Li", "Xiang Su", "Pan Hui"], "Sources": "Proceedings of the 2020 International Conference on Multimodal Interaction?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Smartwatches and other wearables are characterized by small-scale touchscreens that complicate the interaction with content. In this paper, we present Force9, the first optimized miniature keyboard leveraging force-sensitive touchscreens on wrist-worn computers. Force9 enables character selection in an ambiguous layout by analyzing the trade-off between interaction space and the easiness of force-assisted interaction. We argue that dividing the screen's pressure range into three contiguous force levels is sufficient to differentiate characters for fast and accurate text input. Our pilot study captures and calibrates the ability of users to perform force-assisted touches on miniature-sized keys on touchscreen devices. We then optimize the keyboard layout considering the goodness of character pairs (with regards to the selected English corpus) under the force-based configuration and the users? familiarity with the?\u2026", "IdName": "lee2020force9", "Citation": "", "Keywords": ""}, {"Name": "Attention-based QoE-aware digital twin empowered edge computing for immersive virtual reality", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Tailin Zhou", "Pan Hui", "Danny HK Tsang"], "Sources": "IEEE Transactions on Wireless Communications", "PublishedYears": "2024", "Doi": "", "Abstracts": "Metaverse applications such as virtual reality (VR) content streaming, require optimal resource allocation strategies for mobile edge computing (MEC) to ensure a high-quality user experience. In contrast to online reinforcement learning (RL) algorithms, which can incur substantial communication overheads and longer delays, the majority of existing works employ offline-trained RL algorithms for resource allocation decisions in MEC systems. However, they neglect the impact of desynchronization between the physical and digital worlds on the effectiveness of the allocation strategy. In this paper, we tackle this desynchronization using a continual RL (CRL) framework that facilitates the resource allocation dynamically for MEC-enabled VR content streaming. We first design a digital twin-empowered edge computing (DTEC) system and formulate a quality of experience (QoE) maximization problem based on attention?\u2026", "IdName": "yu2024attention", "Citation": "", "Keywords": ""}, {"Name": "Quantum bandit with amplitude amplification exploration in an adversarial environment", "Authors": ["Byungjin Cho", "Yu Xiao", "Pan Hui", "Daoyi Dong"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "The rapid proliferation of learning systems in an arbitrarily changing environment mandates the need to manage tensions between exploration and exploitation. This work proposes a quantum-inspired bandit learning approach for the learning-and-adapting-based offloading problem where a client observes and learns the costs of each task offloaded to the candidate resource providers, e.g., fog nodes. In this approach, a new action update strategy and novel probabilistic action selection are adopted, provoked by the amplitude amplification and collapse postulate in quantum computation theory. We devise a locally linear mapping between a quantum-mechanical phase in a quantum domain, e.g., Grover-type search algorithm, and a distilled probability-magnitude in a value-based decision-making domain, e.g., adversarial multi-armed bandit algorithm. The proposed algorithm is generalized, via the devised?\u2026", "IdName": "cho2023quantum", "Citation": "", "Keywords": ""}, {"Name": "Can underprivileged children learn effectively at home? A six-month study of game-based traditional Chinese learning during the pandemic lockdown", "Authors": ["Ka-Yan Fung", "Lik-Hang Lee", "Pan Hui", "Shenghui Song"], "Sources": "IEEE Transactions on Learning Technologies", "PublishedYears": "2023", "Doi": "", "Abstracts": "The COVID-19 pandemic has suspended physical classes and influenced students from underprivileged groups more seriously due to their poor living conditions and digital disadvantages. To understand the impact of the constrained learning, we conducted a study on game-based learning to examine the effectiveness of computer-aided and autonomous learning of traditional Chinese by underprivileged students. From December 2020 to May 2021, we collected 3245 quiz results from 26 underprivileged students over six months. The quizzes systematically covered the fundamentals of learning traditional Chinese in six aspects, i.e., literacy, orthography, phonology, morphology, speaking, and writing. We analyzed the results to understand the learning efficacy of students. Remarkably, students can significantly improve their skills in literacy and phonology through unsupervised game-based learning. Furthermore?\u2026", "IdName": "fung2023can", "Citation": "", "Keywords": ""}, {"Name": "It's All Relative! A Method to Counter Human Bias in Crowdsourced Stance Detection of News Articles", "Authors": ["Ehsan-Ul Haq", "Yang K Lu", "Pan Hui"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Using human intelligence to identify news articles' political stances is common in research and practical applications. But human judgement can be biased and prone to errors stemming from the comprehension of tasks and political alignment. This paper proposes a relative rating method based on news articles' stances relative to raters' own stances to avoid comprehension inconsistency and to control for human bias in crowdsourced stance detection of news articles. We also show how to use the relative ratings to construct a measure for raters' stances on a political topic and to identify raters whose ratings are of higher quality than others. We implement our proposed methods in an online experiment that recruits Amazon Mechanical Turk users as raters for news articles on Gun Control. Using the data from the experiment, we find evidence that raters' own stances on Gun Control significantly impact ratings of?\u2026", "IdName": "haq2022s", "Citation": "", "Keywords": ""}, {"Name": "Tips, tidings, and tech: Governmental communication on facebook during the covid-19 pandemic", "Authors": ["Ehsan-Ul Haq", "Tristan Braud", "Lik Hang Lee", "Reza Hadi Mogavi", "He Zhang", "Pan Hui"], "Sources": "DG. O 2022: The 23rd Annual International Conference on Digital Government?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " The COVID-19 pandemic led governments to rely on the versatility of social media to communicate with their citizens. This paper analyzes the Facebook communication of political leaders and health departments from 17 countries during the COVID-19 pandemic. We evaluate the citizen\u2019s response under the frameworks of media richness and user engagement. We note that governments and leaders communicate primarily through richer media (photos and videos), despite a negative correlation between media richness and user engagement. Plain-text messages posted by country leaders attract the most engagement, while their COVID-19 communication tends to generate lower engagement. On the other hand, health departments\u2019 pages experienced a sharp increase in engagement around COVID-19 communication as citizens sought information during the pandemic. Finally, topical analysis shows that?\u2026", "IdName": "haq2022tips", "Citation": "", "Keywords": ""}, {"Name": "MyoKey: Inertial motion sensing and gesture-based QWERTY keyboard for extended realities", "Authors": ["Kirill A Shatilov", "Young D Kwon", "Lik-Hang Lee", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Usability challenges and social acceptance of textual input in a context of extended realities (XR) motivate the research of novel input modalities. We investigate the fusion of inertial measurement unit (IMU) control and surface electromyography (sEMG) gesture recognition applied to text entry using a QWERTY-layout virtual keyboard. We design, implement, and evaluate the proposed multi-modal solution named MyoKey. The user can select characters with a combination of arm movements and hand gestures. MyoKey employs a lightweight convolutional neural network classifier that can be deployed on a mobile device with insignificant inference time. We demonstrate the practicality of interruption-free text entry with MyoKey, by recruiting 12 participants and by testing three sets of grasp micro-gestures in three scenarios: empty hand text input, tripod grasp (e.g., pen), and a cylindrical grasp (e.g., umbrella). With?\u2026", "IdName": "shatilov2022myokey", "Citation": "", "Keywords": ""}, {"Name": "Adaptive spatio-temporal convolutional network for traffic prediction", "Authors": ["Mingyang Zhang", "Yong Li", "Funing Sun", "Diansheng Guo", "Pan Hui"], "Sources": "2021 IEEE International Conference on Data Mining (ICDM)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Traffic prediction is a crucial task in many real-world applications. The task is challenging due to the implicit and dynamic spatio-temporal dependencies among traffic data. On the one hand, the spatial dependencies among traffic flows are latent and fluctuate with environmental conditions. On the other hand, the temporal dependencies among traffic flows also vary significantly over time and locations. In this paper, we propose Adaptive Spatio-Temporal Convolutional Network (ASTCN) to tackle these challenges. First, we propose a spatial graph learning module that learns the dynamic spatial relations among traffic data based on multiple influential factors. Furthermore, we design an adaptive temporal convolution module that captures complex temporal traffic dependencies with environment-aware dynamic filters. We conduct extensive experiments on three real-world traffic datasets. The results demonstrate that?\u2026", "IdName": "zhang2021adaptive", "Citation": "", "Keywords": ""}, {"Name": "Context-aware augmented reality with 5G edge", "Authors": ["Jacky Cao", "Xiaoli Liu", "Xiang Su", "Sasu Tarkoma", "Pan Hui"], "Sources": "2021 IEEE Global Communications Conference (GLOBECOM)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Augmented Reality (AR) provides immersive user experiences by overlaying digital information on physical environments. Context-awareness is crucial for delivering relevant augmentations that best suit users' requirements and their en-vironments. In this article, we combine context-aware reasoning with emerging AR applications to provide the most relevant infor-mation according to user and environment contexts. To support the best possible quality of experience, 5G edge computing enables the distribution of computation-intensive AR tasks to edge servers through 5G networks. We develop ConAR, a context-aware head-mounted display AR system that is deployed on the edge and cloud leveraging both environmental sensors and user profile context for navigation. ConAR is composed of a HoloLens application and a paired mobile client, which contains a context model for air quality forecasting, and?\u2026", "IdName": "cao2021context", "Citation": "", "Keywords": ""}, {"Name": "Finding spatiotemporal patterns of mobile application usage", "Authors": ["Tong Li", "Yong Li", "Tong Xia", "Pan Hui"], "Sources": "IEEE Transactions on Network Science and Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Understanding mobile application usage patterns is significant for producing better services and enriching user experience. The understanding of spatiotemporal patterns of application usage is still limited. In this paper, we aim at finding spatiotemporal mobile app usage patterns and propose a framework to capture who, when, where, and what applications are used. We first collect a large-scale and real-world application usage dataset covering over 400 thousand active users and 600 million records. In order to introduce spatial features, we partition the collection area into small regions. By grouping regions of similar point-of-interest attributes, we then map 796 regions onto 13 region clusters with semantic meanings. As a result, the original data is reformed as a tensor of four dimensions, i.e., users, application categories, region clusters, and time-slots. We then leverage a multi-way clustering algorithm on the?\u2026", "IdName": "li2021finding", "Citation": "", "Keywords": ""}, {"Name": "Press-n-paste: Copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile augmented reality", "Authors": ["Lik Hang Lee", "Yiming Zhu", "Yui-Pan Yau", "Pan Hui", "Susanna Pirttikangas"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2021", "Doi": "", "Abstracts": "Copy-and-paste operations are the most popular features on computing devices such as desktop computers, smartphones and tablets. However, the copy-and-paste operations are not sufficiently addressed on the Augmented Reality (AR) smartglasses designated for real-time interaction with texts in physical environments. This paper proposes two system solutions, namely Granularity Scrolling (GS) and Two Ends (TE), for the copy-and-paste operations on AR smartglasses. By leveraging a thumb-size button on a touch-sensitive and pressure-sensitive surface, both the multi-step solutions can capture the target texts through indirect manipulation and subsequently enables the copy-and-paste operations. Based on the system solutions, we implemented an experimental prototype named Press-n-Paste (PnP). After the eight-session evaluation capturing 1,296 copy-and-paste operations, 18 participants with GS and?\u2026", "IdName": "lee2021press", "Citation": "", "Keywords": ""}, {"Name": "Augmented informative cooperative perception", "Authors": ["Pengyuan Zhou", "Pranvera Korto?i", "Yui-Pan Yau", "Tristan Braud", "Xiujun Wang", "Benjamin Finley", "Lik-Hang Lee", "Sasu Tarkoma", "Jussi Kangasharju", "Pan Hui"], "Sources": "ICDCS\u201921", "PublishedYears": "2021", "Doi": "", "Abstracts": "Connected vehicles, whether equipped with advanced driver-assistance systems or fully autonomous, are currently constrained to visual information in their lines-of-sight. A cooperative perception system among vehicles increases their situational awareness by extending their perception ranges. Existing solutions imply significant network and computation load, as well as high flow of not-always-relevant data received by vehicles. To address such issues, and thus account for the inherently diverse informativeness of the data, we present Augmented Informative Cooperative Perception (AICP) as the first fast-filtering system which optimizes the informativeness of shared data at vehicles. AICP displays the filtered data to the drivers in augmented reality head-up display.To this end, an informativeness maximization problem is presented for vehicles to select a subset of data to display to their drivers. Specifically, we propose (i) a dedicated system design with custom data structure and light-weight routing protocol for convenient data encapsulation, fast interpretation and transmission, and (ii) a comprehensive problem formulation and efficient fitness-based sorting algorithm to select the most valuable data to display at the application layer. We implement a proof-of-concept prototype of AICP with a bandwidth-hungry, latency-constrained real-life augmented reality application. The prototype realizes the informative-optimized cooperative perception with only 12.6 milliseconds additional latency. Next, we test the networking performance of AICP at scale and show that AICP effectively filter out less relevant packets and decreases the channel busy time.", "IdName": "zhou2021augmented", "Citation": "", "Keywords": ""}, {"Name": "Context-driven encrypted multimedia traffic classification on mobile devices", "Authors": ["Mohammad A Hoque", "Benjamin Finley", "Ashwin Rao", "Abhishek Kumar", "Pan Hui", "Mostafa Ammar", "Sasu Tarkoma"], "Sources": "Pervasive and Mobile Computing 88", "PublishedYears": "2023", "Doi": "", "Abstracts": "The Internet has been experiencing immense growth in multimedia traffic from mobile devices. The increase in traffic presents many challenges to user-centric networks, network operators, and service providers. Foremost among these challenges is the inability of networks to determine the types of encrypted traffic and thus the level of network service the traffic needs to maintain an acceptable quality of experience. Therefore, end devices are a natural fit for performing traffic classification since end devices have more contextual information about device usage and traffic. This paper proposes a novel approach that classifies multimedia traffic types produced and consumed on mobile devices. The technique relies on a mobile device\u2019s detection of its multimedia context characterized by its utilization of different media input/output (I/O) components, e.g., camera, microphone, and speaker. We develop an algorithm?\u2026", "IdName": "hoque2023context", "Citation": "", "Keywords": ""}, {"Name": "Federated Split GANs", "Authors": ["Pranvera Korto?i", "Yilei Liang", "Pengyuan Zhou", "Lik-Hang Lee", "Abbas Mehrabi", "Pan Hui", "Sasu Tarkoma", "Jon Crowcroft"], "Sources": "Proceedings of the 1st ACM Workshop on Data Privacy and Federated Learning?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Mobile devices and the immense amount and variety of data they generate are key enablers of machine learning (ML)-based applications. Traditional ML techniques have shifted toward new paradigms such as federated learning (FL) and split learning (SL) to improve the protection of user's data privacy. However, SL often relies on server(s) located in the edge or cloud to train computationally-heavy parts of an ML model to avoid draining the limited resource on client devices, potentially resulting in exposure of device data to such third parties. This work proposes an alternative approach to train computationally heavy ML models in user's devices themselves, where corresponding device data resides. Specifically, we focus on GANs (generative adversarial networks) and leverage their network architecture to preserve data privacy. We train the discriminative part of a GAN on user's devices with their data, whereas?\u2026", "IdName": "kortocci2022federated", "Citation": "", "Keywords": ""}, {"Name": "Meditation in Motion: Interactive Media Art Visualization Based on Ancient Tai Chi Chuan", "Authors": ["Ze Gao", "Anqi Wang", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the 30th ACM International Conference on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Tai Chi is an essential concept of Chinese philosophy which refers to the universe's most primitive state of order. Tai Chi Chuan is a martial art and meditative practice that incorporates the Tai Chi philosophy. With the advent of the digital media age, this traditional martial art is falling into disuse, and most contemporary youths are losing interest. \"Meditation in Motion\" is an interactive media art installation inspired by the Tai Chi Chuan forms. It aims to convey the central concepts of balance, narrative, and universe of Tai Chi Chuan by breaking down its movements into overlapping circles, building a visual representation of the energy flows in the body.", "IdName": "gao2022meditation", "Citation": "", "Keywords": ""}, {"Name": "Collaboration stability: Quantifying the success and failure of opportunistic collaboration", "Authors": ["Huber Flores", "Agustin Zuniga", "Sasu Tarkoma", "Leonardo Tonetto", "Tristan Braud", "Pan Hui", "Yong Li", "Mostafa Ammar", "Petteri Nurmi"], "Sources": "Computer", "PublishedYears": "2022", "Doi": "", "Abstracts": "We quantify and derive a general model for the collaboration stability of human mobility and demonstrate its importance for networking applications. Our results demonstrate that collaboration opportunities are highly dependent on the context where they take place, with diurnal patterns and spatial characteristics being particularly important.", "IdName": "flores2022collaboration", "Citation": "", "Keywords": ""}, {"Name": "3DeformR: freehand 3D model editing in virtual environments considering head movements on mobile headsets", "Authors": ["Kit Yung Lam", "Lik-Hang Lee", "Pan Hui"], "Sources": "Proceedings of the 13th ACM Multimedia Systems Conference", "PublishedYears": "2022", "Doi": "", "Abstracts": "3D objects are the primary media in virtual reality environments in immersive cyberspace, also known as the Metaverse. Users, through editing such objects, can communicate with other individuals on mobile headsets. Knowing that the tangible controllers cause the burden to carry such addendum devices, the body-centric interaction techniques, such as hand gestures, get rid of such burdens. However, object editing with hand gestures is usually overlooked. Accordingly, we propose and implement a palm-based virtual embodiment for hand gestural model editing, namely 3DeformR. We employ three optimized hand gestures on bi-harmonic deformation algorithms that enable selecting and editing 3D models in fine granularity. Our evaluation with nine participants considers three interaction techniques (two-handed tangible controller (OMC), a naive implementation of hand gestures (SH), and 3DeformR. Two?\u2026", "IdName": "lam20223deformr", "Citation": "", "Keywords": ""}, {"Name": "EmgAuth: Unlocking smartphones with EMG signals", "Authors": ["Boyu Fan", "Xiang Su", "Jianwei Niu", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Screen lock is a critical security feature for smartphones to prevent unauthorized access. Although various screen unlocking technologies, including fingerprint and facial recognition, have been widely adopted, they still have some limitations. For example, fingerprints can be stolen by special material stickers and facial recognition systems can be cheated by 3D-printed head models. In this paper, we propose EmgAuth, a novel electromyography(EMG)-based smartphone unlocking system based on the Siamese network. EmgAuth enables users to unlock their smartphones by leveraging the EMG data of the smartphone users collected from Myo armbands. When training the Siamese network, we design a special data augmentation technique to make the system resilient to the rotation of the armband, which makes EmgAuth free of calibration. We conduct extensive experiments including 80 participants and the?\u2026", "IdName": "fan2022emgauth", "Citation": "", "Keywords": ""}, {"Name": "Toward city-scale litter monitoring using autonomous ground vehicles", "Authors": ["Zhigang Yin", "Mayowa Olapade", "Mohan Liyanage", "Farooq Dar", "Agustin Zuniga", "Naser Hossein Motlagh", "Xiang Su", "Sasu Tarkoma", "Pan Hui", "Petteri Nurmi", "Huber Flores"], "Sources": "IEEE Pervasive Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Littering is a significant challenge for environmental sustainability and a major burden for cities and densely populated areas. Current solutions for litter monitoring, such as litter watch campaigns and city-operated litter collection, are costly and challenging to conduct at a large scale. This article presents a vision for using autonomous ground vehicles (AGVs) for litter monitoring and removal and introduces a mechanism for AGVs that uses thermal dissipation resulting from sunlight to identify and remove litter objects. We identify and highlight key challenges for deploying the envisioned solution on a city scale, and demonstrate the feasibility of the solution through extensive experiments.", "IdName": "yin2022toward", "Citation": "", "Keywords": ""}, {"Name": "Interpretable business survival prediction", "Authors": ["Anish K Vallapuram", "Nikhil Nanda", "Young D Kwon", "Pan Hui"], "Sources": "Proceedings of the 2021 IEEE/ACM International Conference on Advances in?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "The survival of a business is undeniably pertinent to its success. A key factor contributing to its continuity depends on its customers. The surge of location-based social networks such as Yelp, Diangping, and Foursquare has paved the way for leveraging user-generated content on these platforms to predict business survival. Prior works in this area have developed several quantitative features to capture geography and user mobility among businesses. However, the development of qualitative features is minimal. In this work, we thus perform extensive feature engineering across four feature sets, namely, geography, user mobility, business attributes, and linguistic modelling to develop classifiers for business survival prediction. We additionally employ an interpretability framework to generate explanations and qualitatively assess the classifiers' predictions. Experimentation among the feature sets reveals that?\u2026", "IdName": "vallapuram2021interpretable", "Citation": "", "Keywords": ""}, {"Name": "Toward Mobile Distributed Ledgers", "Authors": ["Dimitris Chatzopoulos", "Anurag Jain", "Sujit Gujar", "Boi Faltings", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": "Advances in mobile computing have paved the way for new types of distributed applications that can be executed solely by mobile devices on Device-to-Device (D2D) ecosystems (e.g., crowdsensing). Sophisticated applications, like cryptocurrencies, need distributed ledgers (DLs) to function. DLs, such as blockchains and directed acyclic graphs (DAGs), employ consensus protocols to add data in the form of blocks. However, such protocols are designed for resourceful devices that are interconnected via the Internet. Moreover, existing DLs are not deployable to D2D ecosystems since their storage needs are continuously increasing. In this work, we introduce and analyze Mneme, a DAG-based DL that can be maintained solely by mobile devices. Mneme utilizes two novel consensus protocols: 1) Proof of Context (PoC) and 2) Proof of Equivalence (PoE). PoC employs users\u2019 context to add data on Mneme. PoE is?\u2026", "IdName": "chatzopoulos2021toward", "Citation": "", "Keywords": ""}, {"Name": "Interoperability of the Metaverse: A Digital Ecosystem Perspective Review", "Authors": ["Liang Yang", "Shi-Ting Ni", "Yuyang Wang", "Ao Yu", "Jyh-An Lee", "Pan Hui"], "Sources": "arXiv preprint arXiv:2403.05205", "PublishedYears": "2024", "Doi": "", "Abstracts": "The Metaverse is at the vanguard of the impending digital revolution, with the potential to significantly transform industries and lifestyles. However, in 2023, skepticism surfaced within industrial and academic spheres, raising concerns that excitement may outpace actual technological progress. Interoperability, recognized as a major barrier to the Metaverse's full potential, is central to this debate. CoinMarketCap's report in February 2023 indicated that of over 240 metaverse initiatives, most existed in isolation, underscoring the interoperability challenge. Despite consensus on its critical role, there is a research gap in exploring the impact on the Metaverse, significance, and developmental extent. Our study bridges this gap via a systematic literature review and content analysis of the Web of Science (WoS) and Scopus databases, yielding 74 publications after a rigorous selection process. Interoperability, difficult to define due to varied contexts and lack of standardization, is central to the Metaverse, often seen as a digital ecosystem. Urs Gasser's framework from Harvard Law School, outlining technological, data, human, and institutional dimensions, systematically addresses interoperability complexities. Incorporating this framework, we dissect literature for a comprehensive Metaverse interoperability overview. Our study seeks to establish benchmarks for future inquiries, navigating the complex field of Metaverse interoperability studies and contributing to academic advancement.", "IdName": "yang2024interoperability", "Citation": "", "Keywords": ""}, {"Name": "Learning representations of satellite imagery by leveraging point-of-interests", "Authors": ["Tong Li", "Yanxin Xi", "Huandong Wang", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "ACM Transactions on Intelligent Systems and Technology", "PublishedYears": "2023", "Doi": "", "Abstracts": "Satellite imagery depicts the Earth\u2019s surface remotely and provides comprehensive information for many applications, such as land use monitoring and urban planning. Existing studies on unsupervised representation learning for satellite images only take into account the images\u2019 geographic information, ignoring human activity factors. To bridge this gap, we propose using the Point-of-Interest (POI) data to capture human factors and designing a contrastive learning-based framework to consolidate the representation of satellite imagery with POI information. Besides, we introduce a season-invariant representation learning model on satellite imagery, considering that human factors are mostly unchanging with respect to seasons. An attention model is designed at last to merge the representations from the geographic, seasonal, and POI perspectives adaptively. On the basis of real-world datasets collected from Beijing?\u2026", "IdName": "li2023learning", "Citation": "", "Keywords": ""}, {"Name": "Towards Trustworthy Augmented Reality in The Metaverse Era: Probing Manipulative Designs in Virtual-Physical Commercial Platforms", "Authors": ["Esm\u00e9e De Haas", "Huang Yiming", "Carlos Bermejo", "Zijun Lin", "Pan Hui", "Lik-Hang Lee"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "E-commerce has become an important activity where new advances in technology shape the shopper experience. At the same time, the metaverse is seen as the next milestone to revolutionize the e-commerce experience, where immersion, realism, and ubiquity are its main features. However, under such circumstances, manipulative designs to \u2018trick\u2019 users toward intended choices or outcomes can become more effective. This paper sheds light on the design space of manipulative techniques in e-commerce applications for the meta-verse, reinforcing our understanding of interface design guidelines and counteracting malicious practices.", "IdName": "de2023towards", "Citation": "", "Keywords": ""}, {"Name": "Bridging curatorial intent and visiting experience: Using ar guidance as a storytelling tool", "Authors": ["Ze Gao", "Anqi Wang", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Augmented Reality (AR) visits enhances the art exhibition experience by overlaying digital content. Although there has been significant interest in AR guides, few works leverage AR to bridge curatorial intent and audiences understanding. This paper focuses on integrating the curatorial intent within the AR overlays by developing the narrative layers established by the relationships between works. We develop a narrative system that identifies and links the primary art pieces of the exhibition within a digital story consistent with the curator\u2019s perspective. The system is applied to a physical exhibition composed of seven art pieces. We evaluate the impact of AR overlays through two user experiments, conducted on art professionals and general audience, respectively. Both groups considered that the AR tour system improved interactivity, self-reported learning, and user satisfaction significantly (> 4/5). Besides, visitors?\u2026", "IdName": "gao2022bridging", "Citation": "", "Keywords": ""}, {"Name": "Beyond the Blue Sky of Multimodal Interaction: A Centennial Vision of Interplanetary Virtual Spaces in Turn-based Metaverse", "Authors": ["Lik-Hang Lee", "Carlos Bermejo Fernandez", "Ahmad Alhilal", "Tristan Braud", "Simo Hosio", "Esm\u00e9e Henrieke Anne De Haas", "Pan Hui"], "Sources": "Proceedings of the 2022 International Conference on Multimodal Interaction?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Human habitation across multiple planets requires communication and social connection between planets. When the infrastructure of a deep space network becomes mature, immersive cyberspace, known as the Metaverse, can exchange diversified user data and host multitudinous virtual worlds. Nevertheless, such immersive cyberspace unavoidably encounters latency in minutes, and thus operates in a turn-taking manner. This Blue Sky paper illustrates a vision of an interplanetary Metaverse that connects Earthian and Martian users in a turn-based Metaverse. Accordingly, we briefly discuss several grand challenges to catalyze research initiatives for the \u2018Digital Big Bang\u2019 on Mars.", "IdName": "lee2022beyond", "Citation": "", "Keywords": ""}, {"Name": "Free  Net: Gliding Free, Orientation Free, and Anchor Free Network for Oriented Object Detection", "Authors": ["Zhonghong Ou", "Zhongjie Chen", "Shengyi Shen", "Lina Fan", "Siyuan Yao", "Meina Song", "Pan Hui"], "Sources": "IEEE Transactions on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Object detection for aerial images has achieved remarkable progress in recent years. Nevertheless, most exiting studies do not differentiate oriented object detection from horizontal detection. Certain schemes ignore the ambiguity of oriented object representation and leverage label assignment designed for horizontal object detection directly. Consequently, it leads to unstable training and causes performance degradation, because high-quality samples surrounding the oriented bounding boxes can not be leveraged effectively. To address this problem, we propose a gliding Free, orientation Free, and anchor Free Network (Free  Net) with high-efficiency for oriented object detection. Specifically, we propose an unambiguous oriented object representation scheme, named FreeGliding, by gliding the projection points of samples on each edge of horizontal bounding boxes. It makes the detection largely free from?\u2026", "IdName": "ou2022free", "Citation": "", "Keywords": ""}, {"Name": "An LTE Authentication and Key Agreement Protocol Based on the ECC Self-Certified Public Key", "Authors": ["Xiaofeng Lu", "Fan Yang", "Luwen Zou", "Pietro Lio", "Pan Hui"], "Sources": "IEEE/ACM Transactions on Networking", "PublishedYears": "2022", "Doi": "", "Abstracts": "After analyzing the long-term evolution (LTE) authentication and key agreement process (EPS-AKA), its existing security vulnerabilities are pointed out. Based on elliptic curve cryptography (ECC) self-certified public keys, this paper proposes an ECC self-certified authentication key agreement scheme (ESC-AKA). This scheme includes the addition of a trusted center (TC), which generates the public keys for the home subscriber server (HSS), the mobility management entity (MME), and the user equipment (UE). Three communication protocols are designed, including MME/HSS registration, UE registration, and UE access. A strand space model is used to carry out the formal analysis, and performance and security analyses are carried out. The results show that this scheme can compensate for the security vulnerabilities of the original EPS-AKA scheme. It implements the encrypted transmission of the international?\u2026", "IdName": "lu2022lte", "Citation": "", "Keywords": ""}, {"Name": "Video content placement at the network edge: Centralized and distributed algorithms", "Authors": ["Yanan Gao", "Song Yang", "Fan Li", "Stojan Trajanovski", "Pan Zhou", "Pan Hui", "Xiaoming Fu"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "In the traditional video streaming service paradigm, content providers typically provision the requested video content to viewers through a central content delivery network (CDN). However, remote viewers usually experience long video streaming delay due to uncertain wide area network delay, which severely affects the quality of experience. Multi-Access Edge Computing (MEC) offers a way to shorten the video streaming delay by building small-scale cloud infrastructures at the network edge, which are in close proximity to the viewers. In this paper, we present novel centralized and distributed algorithms for the video content placement problem in MEC. In the proposed centralized video content placement algorithm, we leverage the Lyapunov optimization technique to formulate the video content placement problem as a series of one-time-slot optimization problems and apply an Alternating Direction Method of?\u2026", "IdName": "gao2022video", "Citation": "", "Keywords": ""}, {"Name": "Ian: Interpretable attention network for churn prediction in lbsns", "Authors": ["Liang-yu Chen", "Yutong Chen", "Young D Kwon", "Youwen Kang", "Pan Hui"], "Sources": "Proceedings of the 2021 IEEE/ACM International Conference on Advances in?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "With the rise of Location-Based Social Networks (LBSNs) and their heavy reliance on User-Generated Content, it has become essential to attract and keep more users, which makes the churn prediction problem interesting. Recent research focuses on solving the task by utilizing complex neural networks. However, due to the black-box nature of those proposed deep learning algorithms, it is still a challenge for LBSN managers to interpret the prediction results and design strategies to prevent churning behavior. Therefore, in this paper, we perform the first investigation into the interpretability of the churn prediction in LBSNs. We proposed a novel attention-based deep learning network, Interpretable Attention Network (IAN), to achieve high performance while ensuring interpretability. The network is capable to process the complex temporal multivariate multidimensional user data from LBSN datasets (i.e. Yelp and?\u2026", "IdName": "chen2021ian", "Citation": "", "Keywords": ""}, {"Name": "Identifying mis-configured author profiles on Google Scholar using deep learning", "Authors": ["Jiaxin Tang", "Yang Chen", "Guozhen She", "Yang Xu", "Kewei Sha", "Xin Wang", "Yi Wang", "Zhenhua Zhang", "Pan Hui"], "Sources": "Applied Sciences", "PublishedYears": "2021", "Doi": "", "Abstracts": "Google Scholar has been a widely used platform for academic performance evaluation and citation analysis. The issue about the mis-configuration of author profiles may seriously damage the reliability of the data, and thus affect the accuracy of analysis. Therefore, it is important to detect the mis-configured author profiles. Dealing with this issue is challenging because the scale of the dataset is large and manual annotation is time-consuming and relatively subjective. In this paper, we first collect a dataset of Google Scholar\u2019s author profiles in the field of computer science and compare the mis-configured author profiles with the reliable ones. Then, we propose an integrated model that utilizes machine learning and node embedding to automatically detect mis-configured author profiles. Additionally, we conduct two application case studies based on the data of Google Scholar, i.e., outstanding scholar searching and university ranking, to demonstrate how the improved dataset after filtering out the mis-configured author profiles will change the results. The two case studies validate the importance and meaningfulness of the detection of mis-configured author profiles.", "IdName": "tang2021identifying", "Citation": "", "Keywords": ""}, {"Name": "Decentralizing indexing and bootstrapping for online applications", "Authors": ["Pierre Schutz", "Stanislas Gal", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "IET Blockchain", "PublishedYears": "2021", "Doi": "", "Abstracts": " Peer\u2010to\u2010peer (P2P) networks utilize centralized entities (trackers) to assist peers in finding and exchanging information. Although modern P2P protocols are now trackerless and their function relies on distributed hash tables (DHTs), centralized entities are still needed to build file indices (indexing) and assist users in joining DHT swarms (bootstrapping). Although the functionality of these centralized entities are limited, every peer in the network is expected to trust them to function as expected (e.g. to correctly index new files). In this work, a new approach for designing and building decentralized online applications is proposed by introducing DIBDApp. The approach combines blockchain, smart contracts and BitTorrent for building up a combined technology that permits to create decentralized applications that do not require any assistance from centralized entities. DIBDApp is a software library composed of?\u2026", "IdName": "schutz2021decentralizing", "Citation": "", "Keywords": ""}, {"Name": "Context-aware telco outdoor localization", "Authors": ["Yige Zhang", "Weixiong Rao", "Mingxuan Yuan", "Jia Zeng", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent years have witnessed the fast growth in telecommunication (Telco) techniques from 2G to upcoming 5G. Precise outdoor localization is important for Telco operators to manage, operate and optimize Telco networks. Differing from GPS, Telco localization is a technique employed by Telco operators to localize outdoor mobile devices by using measurement report (MR) data. When given MR samples containing noisy signals (e.g., caused by Telco signal interference and attenuation), Telco localization often suffers from high errors. To this end, the main focus of this paper is how to improve Telco localization accuracy via the algorithms to detect and repair outlier positions with high errors. Specifically, we propose a context-aware Telco localization technique, namely   , which consists of three main components: a machine-learning-based localization algorithm, a detection algorithm to find flawed samples, and a?\u2026", "IdName": "zhang2020context", "Citation": "", "Keywords": ""}, {"Name": "Sensing multimedia contexts on mobile devices", "Authors": ["Mohammad A Hoque", "Ashwin Rao", "Abhishek Kumar", "Mostafa Ammar", "Pan Hui", "Sasu Tarkoma"], "Sources": "Proceedings of the 30th ACM Workshop on Network and Operating Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "We use various multimedia applications on smart devices to consume multimedia content, to communicate with our peers, and to broadcast our events live. This paper investigates the utilization of different media input/output devices, e.g., camera, microphone, and speaker, by different types of multimedia applications, and introduces the notion of multimedia context. Our measurements lead to a sensing algorithm called MediaSense, which senses the states of multiple I/O devices and identifies eleven multimedia contexts of a mobile device in real time. The algorithm distinguishes stored content playback from streaming, live broadcasting from local recording, and conversational multimedia sessions from GSM/VoLTE calls on mobile devices.", "IdName": "hoque2020sensing", "Citation": "", "Keywords": ""}, {"Name": "A satellite imagery dataset for long-term sustainable development in united states cities", "Authors": ["Yanxin Xi", "Yu Liu", "Tong Li", "Jingtao Ding", "Yunke Zhang", "Sasu Tarkoma", "Yong Li", "Pan Hui"], "Sources": "Scientific data", "PublishedYears": "2023", "Doi": "", "Abstracts": "Cities play an important role in achieving sustainable development goals (SDGs) to promote economic growth and meet social needs. Especially satellite imagery is a potential data source for studying sustainable urban development. However, a comprehensive dataset in the United States (U.S.) covering multiple cities, multiple years, multiple scales, and multiple indicators for SDG monitoring is lacking. To support the research on SDGs in U.S. cities, we develop a satellite imagery dataset using deep learning models for five SDGs containing 25 sustainable development indicators. The proposed dataset covers the 100 most populated U.S. cities and corresponding Census Block Groups from 2014 to 2023. Specifically, we collect satellite imagery and identify objects with state-of-the-art object detection and semantic segmentation models to observe cities\u2019 bird\u2019s-eye view. We further gather population, nighttime light?\u2026", "IdName": "xi2023satellite", "Citation": "", "Keywords": ""}, {"Name": "Symbiotic Hands: A virtual reality interactive system that traverses reality", "Authors": ["Ze Gao", "Simin Yang", "Xingxing Yang", "Hui Pan"], "Sources": "Proceedings of EVA London 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "\" Symbiotic Hands\" is a virtual reality interactive installation consisting of 3d reconstructed point cloud images and a temperature sensor fitted to an Oculus Quest2 and designed to emphasize the changes that affect the scene in the virtual environment through the behaviour in reality. The viewer experiences this device as a hand crossing from reality to the virtual, causing the virtual environment to undergo changes generated by temperature changes. It will be realised by this method of traversing virtual and reality in a computer-programmed way, ie, firstly, by sensing the change of outside temperature through temperature sensors, secondly, receiving multisensor data through Arduino and send the data to the computer through a serial port, and finally, the virtual scene in the device that receives the command gradually changes from a silvery winter into a lush summer scene. This project uses interactive technology to explore the real and virtual connection.The virtual reality interactive installation\" Symbiotic Hands\" can be seen as a bridge between virtual and reality through the hand of the audience that can influence the virtual environment. In today's vigorous development of virtual reality technology, many studies are increasingly focused on the physical experience in a virtual environment. However, few studies and creations present and discuss the impact of reality on virtual environments (Bhagavathula et al. 2018). However, as the technology for gestural manipulation matures", "IdName": "gao2023symbiotic", "Citation": "", "Keywords": ""}, {"Name": "Players are not Ready 101: A Tutorial on Organising Mixed-mode Events in the Metaverse", "Authors": ["Kirill Shatilov", "Ahmad Alhilal", "Tristan Braud", "Lik-Hang Lee", "Pengyuan Zhou", "Pan Hui"], "Sources": "Proceedings of the First Workshop on Metaverse Systems and Applications", "PublishedYears": "2023", "Doi": "", "Abstracts": "While the academic community tries to define and experiment with the metaverse, businesses and institutions seek to build their representation in the metaverse. Many educational institutions build meta-campuses and move online classes into virtual environments beyond simple videoconferencing. This paper describes our experience building a university metaverse, highlighting the technical, human, and organisational challenges we have encountered through two major events. Considering the issue of real-time communication and scalability in the web-based metaverse, we also present an analysis of video streaming in virtual reality (VR) platforms: Meta's Workroom, Spatial, and Mozilla Hubs.", "IdName": "shatilov2023players", "Citation": "", "Keywords": ""}, {"Name": "A human mobility dataset collected via LBSLab", "Authors": ["Yuwei Zhang", "Qingyuan Gong", "Yang Chen", "Yu Xiao", "Xin Wang", "Pan Hui", "Xiaoming Fu"], "Sources": "Data in Brief 46", "PublishedYears": "2023", "Doi": "", "Abstracts": "Location-Based Services (LBS) have been prosperous owing to technological advancements of smart devices. Analyzing location-based user-generated data is a helpful way to understand human mobility patterns, further fueling applications such as recommender systems and urban computing. This dataset documents user activities of location-based services through LBSLab, a smartphone-based system implemented as a mini-program in the WeChat app. The dataset contains activity data of multiple types including logins, profile viewing, weather checking, and check-ins with location information (latitude and longitude), POI and mood indicated, collected from 467 users over a period of 11 days. We also present some temporal and spatial data analysis and believe the reuse of the data will allow researchers to better understand user behaviors of LBS, human mobility, and also temporal and spatial characteristics?\u2026", "IdName": "zhang2023human", "Citation": "", "Keywords": ""}, {"Name": "Detecting malicious accounts in online developer communities using deep learning", "Authors": ["Qingyuan Gong", "Yushan Liu", "Jiayun Zhang", "Yang Chen", "Qi Li", "Yu Xiao", "Xin Wang", "Pan Hui"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Online developer communities like GitHub allow a massive number of developers to collaborate. However, the openness of the communities makes them vulnerable to different types of malicious attacks, since attackers can easily join these communities and interact with legitimate users. In this work, we propose GitSec, a deep learning-based solution for detecting malicious accounts in online developer communities. GitSec distinguishes malicious accounts from legitimate ones based on the account profiles, dynamic activity characteristics, as well as social interactions. First, GitSec introduces two user activity sequences and applies a parallel neural network design with an attention mechanism to process the sequences. Second, GitSec constructs two graphs to represent the interactions between users according to their repository operations. Especially, graph neural networks and structural hole theory are?\u2026", "IdName": "gong2023detecting", "Citation": "", "Keywords": ""}, {"Name": "Envisioning A hyper-learning system in the age of metaverse", "Authors": ["Anqi Wang", "Ze Gao", "Zeyu Wang", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The digital technologies, such as interactive interfaces, augmented reality (AR), and virtual reality (VR), are emerging as the latest examples of an ongoing trend of digitizing learning in the metaverse. Their pervasive impact requires us to rethink the notion of information gathering and learning [Pokhrel and Chhetri 2021]. Although much research has been devoted to AR/VR/metaverse education, there is little research on the pedagogical interactions of pre-learning information in the metaverse. Pre-learning refers to", "IdName": "wang2022envisioning", "Citation": "", "Keywords": ""}, {"Name": "Causal Analysis on the Anchor Store Effect in a Location-based Social Network", "Authors": ["Anish K Vallapuram", "Young D Kwon", "Lik-Hang Lee", "Fengli Xu", "Pan Hui"], "Sources": "2022 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "A particular phenomenon of interest in Retail Eco-nomics is the spillover effect of anchor stores (specific stores with a reputable brand) to non-anchor stores in terms of customer traffic. Prior works in this area rely on small and survey-based datasets that are often confidential or expensive to collect on a large scale. Also, very few works study the underlying causal mechanisms between factors that underpin the spillover effect. In this work, we analyze the causal relationship between anchor stores and customer traffic to non-anchor stores and employ a propensity score matching framework to investigate this effect more efficiently. First of all, to demonstrate the effect, we leverage open and mobile data from London Datastore and Location-Based Social Networks (LBSNs) such as Foursquare. We then perform a large-scale empirical analysis of customer visit patterns from anchor stores to non-anchor stores (e.g., non?\u2026", "IdName": "vallapuram2022causal", "Citation": "", "Keywords": ""}, {"Name": "CityNeuro: Towards Location and Time Prediction for Urban Abnormal Events", "Authors": ["Mingyang Zhang", "Tong Li", "Pan Hui"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2022", "Doi": "", "Abstracts": "Urban abnormal events constitute a significant threat to social order and public safety. It is of vital importance for emergency treatment if the location and time of abnormal events could be predicted before they happen. However, forecasting the occurrence of urban abnormal events is extremely challenging due to various influencing factors. First, the spatiotemporal environment in urban space is associated with complicated and dynamic attributes, which all potentially affect the happening of urban emergency events. Second, historical events also influence the occurrence of future events, and the impacts vary across urban regions and time due to dynamic regional relations. In this paper, we propose a framework called CityNeuro that incorporates both environmental and historical influence for location and time prediction of urban abnormal events. On the one hand, we identify important environmental factors by?\u2026", "IdName": "zhang2022cityneuro", "Citation": "", "Keywords": ""}, {"Name": "Enabling continuous object recognition in mobile augmented reality", "Authors": ["Xiang Su", "Ai Jiang", "Jacky Cao", "Wenxiao Zhang", "Pan Hui", "Juan Ye"], "Sources": "27th International Conference on Intelligent User Interfaces", "PublishedYears": "2022", "Doi": "", "Abstracts": " Mobile Augmented Reality (MAR) applications enable users to interact with physical environments through overlaying digital information on top of camera views. Detecting and classifying complex objects in the real world presents a critical challenge to enable immersive user experiences in MAR applications. Aiming to provide continuous MAR experiences, we address a key challenge of continuous object recognition, which requires accommodating an increasing number of recognition requests on different types of images in MAR systems and possible new types of images in emerging applications. Inspired by the latest advance in continual learning approaches in computer vision, this paper presents a novel MAR system to enhance its scalability with continual learning in realistic scenarios. Our experiments demonstrate that 1) the system enables efficiently recognising objects without requiring retraining from?\u2026", "IdName": "su2022enabling", "Citation": "", "Keywords": ""}, {"Name": "Towards user-centered metrics for trustworthy AI in immersive cyberspace", "Authors": ["Pengyuan Zhou", "Benjamin Finley", "Lik-Hang Lee", "Yong Liao", "Haiyong Xie", "Pan Hui"], "Sources": "arXiv preprint arXiv:2203.03718", "PublishedYears": "2022", "Doi": "", "Abstracts": "AI plays a key role in current cyberspace and future immersive ecosystems that pinpoint user experiences. Thus, the trustworthiness of such AI systems is vital as failures in these systems can cause serious user harm. Although there are related works on exploring trustworthy AI (TAI) metrics in the current cyberspace, ecosystems towards user-centered services, such as the metaverse, are much more complicated in terms of system performance and user experience assessment, thus posing challenges for the applicability of existing approaches. Thus, we give an overlook on fairness, privacy and robustness, across the historical path from existing approaches. Eventually, we propose a research agenda towards systematic yet user-centered TAI in immersive ecosystems.", "IdName": "zhou2022towards", "Citation": "", "Keywords": ""}, {"Name": "DeepPick: a deep learning approach to unveil outstanding users with public attainable features", "Authors": ["Wanda Li", "Zhiwei Xu", "Yi Sun", "Qingyuan Gong", "Yang Chen", "Aaron Yi Ding", "Xin Wang", "Pan Hui"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Outstanding users (OUs) denote the influential, \u201ccore\u201d or \u201cbridge\u201d users in online social networks. How to accurately detect and rank them is an important problem for third-party online service providers and researchers. Conventional efforts, ranging from early graph-based algorithms to recent machine learning-based approaches, typically rely on an entire social network's information. However, for privacy-conscious users or newly-registered users, such information is not easily accessible. To address this issue, we present DeepPick, a novel framework that considers both the generalization and specialization in the detection task of OUs. For generalization, we introduce deep neural networks to capture dynamic features of the users. For specialization, we leverage the traditional descriptive features to make use of public information about users. Extensive experiments based on real-world datasets demonstrate that?\u2026", "IdName": "li2021deeppick", "Citation": "", "Keywords": ""}, {"Name": "5G MEC computation handoff for mobile augmented reality", "Authors": ["Zhou Pengyuan", "Finley Benjamin", "Li Xuebing", "Tarkoma Sasu", "Kangasharju Jussi", "Ammar Mostafa", "Hui Pan"], "Sources": "arXiv preprint", "PublishedYears": "2021", "Doi": "", "Abstracts": "None", "IdName": "pengyuan20215g", "Citation": "", "Keywords": ""}, {"Name": "DADIM: A distance adjustment dynamic influence map model", "Authors": ["Xiaofeng Lu", "Xiaoming Wang", "Pan Hui"], "Sources": "Future Generation Computer Systems 112", "PublishedYears": "2020", "Doi": "", "Abstracts": "Influence map (IM) is often used as a decision supporting technology in game artificial intelligence (AI). However, the traditional influence map does not describe dynamic information. Some improved IM models can describe dynamic information, but not accurately enough. When an object moves, it would produce large influence in its moving direction than other directions. Therefore, the influence produce by the object to a location depends on the relation between the location and the object\u2019s moving direction. This paper proposed a dynamic influence map model based on distance adjustment, DADIM. This model produces different influence values in different direction by adjusting the \u201cdistance\u201d between two locations. This method can encode dynamic information into the influence map easily. Experiments show this model avoids the weakness of dynamic influence map with location prediction. Compared with?\u2026", "IdName": "lu2020dadim", "Citation": "", "Keywords": ""}, {"Name": "Human data model: Improving programmability of health and well-being data for enhanced perception and interaction", "Authors": ["Niko M?kitalo", "Daniel Flores-Martin", "Huber Flores", "Eemil Lagerspetz", "Francois Christophe", "Petri Ihantola", "Masiar Babazadeh", "Pan Hui", "Juan Manuel Murillo", "Sasu Tarkoma", "Tommi Mikkonen"], "Sources": "ACM Transactions on Computing for Healthcare", "PublishedYears": "2020", "Doi": "", "Abstracts": "Today, an increasing number of systems produce, process, and store personal and intimate data. Such data has plenty of potential for entirely new types of software applications, as well as for improving old applications, particularly in the domain of smart healthcare. However, utilizing this data, especially when it is continuously generated by sensors and other devices, with the current approaches is complex\u2014data is often using proprietary formats and storage, and mixing and matching data of different origin is not easy. Furthermore, many of the systems are such that they should stimulate interactions with humans, which further complicates the systems. In this article, we introduce the Human Data Model\u2014a new tool and a programming model for programmers and end users with scripting skills that help combine data from various sources, perform computations, and develop and schedule computer-human?\u2026", "IdName": "makitalo2020human", "Citation": "", "Keywords": ""}, {"Name": "The bits of silence: Redundant traffic in voip", "Authors": ["Mohammad A Hoque", "Petteri Nurmi", "Matti Siekkinen", "Pan Hui", "Sasu Tarkoma"], "Sources": "Proceedings of the 11th ACM Multimedia Systems Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": "Human conversation is characterized by brief pauses and so-called turn-taking behavior between the speakers. In the context of VoIP, this means that there are frequent periods where the microphone captures only background noise - or even silence whenever the microphone is muted. The bits transmitted from such silence periods introduce overhead in terms of data usage, energy consumption, and network infrastructure costs. In this paper, we contribute by shedding light on these costs for VoIP applications. We systematically measure the performance of six popular mobile VoIP applications with controlled human conversation and acoustic setup. Our analysis demonstrates that significant savings can indeed be achieved - with the best performing silence suppression technique being effective on 75% of silent pauses in the conversation in a quiet place. This results in 2-5 times data savings, and 50-90% lower?\u2026", "IdName": "hoque2020bits", "Citation": "", "Keywords": ""}, {"Name": "FovOptix: Human Vision-Compatible Video Encoding and Adaptive Streaming in VR Cloud Gaming", "Authors": ["Ahmad Alhilal", "Ze Wu", "Yuk Hang Tsui", "Pan Hui"], "Sources": "Proceedings of the 15th ACM Multimedia Systems Conference", "PublishedYears": "2024", "Doi": "", "Abstracts": "VR cloud gaming enables users to play high-end VR games on lightweight devices by offloading rendering tasks to cloud servers. Despite video compression, high-definition video streaming requires substantial data transfer rates. Foveated rendering (FR) and video encoding (FVE) leverage the non-uniform perception of the human visual system to reduce computing and bandwidth demand. They enhance visual quality in central gaze regions and reduce it in the periphery. However, bandwidth variation may hinder the provision of smooth VR gaming experiences. We present FovOptix, a system that combines FR with adaptive FVE to deliver video stream at a lower yet adaptive bitrate while not compromising the perceived video quality. FovOptix is based on a game-agnostic open-source to ensure reproducibility and compatibility with various games. We evaluate FovOptix against benchmarks using 5G mobile?\u2026", "IdName": "alhilal2024fovoptix", "Citation": "", "Keywords": ""}, {"Name": "Text2VRScene: Exploring the Framework of Automated Text-driven Generation System for VR Experience", "Authors": ["Zhizhuo Yin", "Yuyang Wang", "Theodoros Papatheodorou", "Pan Hui"], "Sources": "2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the recent development of the Virtual Reality (VR) industry, the increasing number of VR users pushes the demand for the massive production of immersive and expressive VR scenes in related industries. However, creating expressive VR scenes involves the reasonable organization of various digital content to express a coherent and logical theme, which is time-consuming and labor-intensive. In recent years, Large Language Models (LLMs) such as ChatGPT 3.5 and generative models such as stable diffusion have emerged as powerful tools for comprehending natural language and generating digital contents such as text, code, images, and 3D objects. In this paper, we have explored how we can generate VR scenes from text by incorporating LLMs and various generative models into an automated system. To achieve this, we first identify the possible limitations of LLMs for an automated system and propose?\u2026", "IdName": "yin2024text2vrscene", "Citation": "", "Keywords": ""}, {"Name": "Sora OpenAI's Prelude: Social Media Perspectives on Sora OpenAI and the Future of AI Video Generation", "Authors": ["Reza Hadi Mogavi", "Derrick Wang", "Joseph Tu", "Hilda Hadan", "Sabrina A Sgandurra", "Pan Hui", "Lennart E Nacke"], "Sources": "arXiv preprint arXiv:2403.14665", "PublishedYears": "2024", "Doi": "", "Abstracts": "The rapid advancement of Generative AI (Gen-AI) is transforming Human-Computer Interaction (HCI), with significant implications across various sectors. This study investigates the public's perception of Sora OpenAI, a pioneering Gen-AI video generation tool, via social media discussions on Reddit before its release. It centers on two main questions: the envisioned applications and the concerns related to Sora's integration. The analysis forecasts positive shifts in content creation, predicting that Sora will democratize video marketing and innovate game development by making video production more accessible and economical. Conversely, there are concerns about deepfakes and the potential for disinformation, underscoring the need for strategies to address disinformation and bias. This paper contributes to the Gen-AI discourse by fostering discussion on current and future capabilities, enriching the understanding of public expectations, and establishing a temporal benchmark for user anticipation. This research underscores the necessity for informed, ethical approaches to AI development and integration, ensuring that technological advancements align with societal values and user needs.", "IdName": "mogavi2024sora", "Citation": "", "Keywords": ""}, {"Name": "Behave Differently when Clustering: A Semi-asynchronous Federated Learning Approach for IoT", "Authors": ["Boyu Fan", "Xiang Su", "Sasu Tarkoma", "Pan Hui"], "Sources": "ACM Transactions on Sensor Networks", "PublishedYears": "2024", "Doi": "", "Abstracts": "The Internet of Things (IoT) has revolutionized the connectivity of diverse sensing devices, generating an enormous volume of data. However, applying machine learning algorithms to sensing devices presents substantial challenges due to resource constraints and privacy concerns. Federated learning (FL) emerges as a promising solution allowing for training models in a distributed manner while preserving data privacy on client devices. We contribute SAFI, a semi-asynchronous FL approach based on clustering to achieve a novel in-cluster synchronous and out-cluster asynchronous FL training mode. Specifically, we propose a three-tier architecture to enable IoT data processing on edge devices and design a clustering selection module to effectively group heterogeneous edge devices based on their processing capacities. The performance of SAFI has been extensively evaluated through experiments conducted?\u2026", "IdName": "fan2024behave", "Citation": "", "Keywords": ""}, {"Name": "Model-Heterogeneous Federated Learning for Internet of Things: Enabling Technologies and Future Directions", "Authors": ["Boyu Fan", "Siyang Jiang", "Xiang Su", "Pan Hui"], "Sources": "arXiv preprint arXiv:2312.12091", "PublishedYears": "2023", "Doi": "", "Abstracts": "Internet of Things (IoT) interconnects a massive amount of devices, generating heterogeneous data with diverse characteristics. IoT data emerges as a vital asset for data-intensive IoT applications, such as healthcare, smart city and predictive maintenance, harnessing the vast volume of heterogeneous data to its maximum advantage. These applications leverage different Artificial Intelligence (AI) algorithms to discover new insights. While machine learning effectively uncovers implicit patterns through model training, centralizing IoT data for training poses significant privacy and security concerns. Federated Learning (FL) offers an promising solution, allowing IoT devices to conduct local learning without sharing raw data with third parties. Model-heterogeneous FL empowers clients to train models with varying complexities based on their hardware capabilities, aligning with heterogeneity of devices in real-world IoT environments. In this article, we review the state-of-the-art model-heterogeneous FL methods and provide insights into their merits and limitations. Moreover, we showcase their applicability to IoT and identify the open problems and future directions. To the best of our knowledge, this is the first article that focuses on the topic of model-heterogeneous FL for IoT.", "IdName": "fan2023model", "Citation": "", "Keywords": ""}, {"Name": "Echo Chambers within the Russo-Ukrainian War: The Role of Bipartisan Users", "Authors": ["Peixian Zhang", "Ehsan-Ul Haq", "Yiming Zhu", "Pan Hui", "Gareth Tyson"], "Sources": "arXiv preprint arXiv:2311.09934", "PublishedYears": "2023", "Doi": "", "Abstracts": "The ongoing Russia-Ukraine war has been extensively discussed on social media. One commonly observed problem in such discussions is the emergence of echo chambers, where users are rarely exposed to opinions outside their worldview. Prior literature on this topic has assumed that such users hold a single consistent view. However, recent work has revealed that complex topics (such as the war) often trigger bipartisanship among certain people. With this in mind, we study the presence of echo chambers on Twitter related to the Russo-Ukrainian war. We measure their presence and identify an important subset of bipartisan users who vary their opinions during the invasion. We explore the role they play in the communications graph and identify features that distinguish them from remaining users. We conclude by discussing their importance and how they can improve the quality of discourse surrounding the war.", "IdName": "zhang2023echo", "Citation": "", "Keywords": ""}, {"Name": "Toward Trustworthy and Responsible Autonomous Drones in Future Smart Cities", "Authors": ["Abdul-Rasheed Ottun", "Zhigang Yin", "Mohaan Liyanage", "Michell Boerger", "Mehrdad Asadi", "Pan Hui", "Sasu Tarkoma", "Nikolay Tcholtchev", "Petteri Nurmi", "Huber Flores"], "Sources": "Authorea Preprints", "PublishedYears": "2023", "Doi": "", "Abstracts": "Autonomous drones are reaching a level of maturity when they can be deployed in cities to support tasks ranging from medicine or food delivery to environmental monitoring. These operations rely on powerful AI models integrated into the drones. Ensuring these models are robust is essential for operating in cities as any errors in the decisions of the autonomous drones can cause damage to the citizens or the urban infrastructure. We contribute a research vision for trustworthy city-scale deployments of autonomous drones. We highlight current key requirements and challenges that have to be fulfilled for achieving city-scale autonomous drone deployments. In addition, we also analyze the complexity of using XAI methods to monitor drone behavior. We demonstrate this by inducing changes in AI model behavior using data poisoning attacks. Our results demonstrate that XAI methods are sensitive enough to detect the possibility of a data attack, but a combination of multiple XAI methods is better to improve the robustness of the estimation. Our results also suggest that currently, the reaction time to counter an attack in city-scale deployment is large due to the complexity of the XAI analysis.", "IdName": "ottun2023toward", "Citation": "", "Keywords": ""}, {"Name": "A Deep Cybersickness Predictor through Kinematic Data with Encoded Physiological Representation", "Authors": ["Ruichen Li", "Yuyang Wang", "Handi Yin", "Jean-R\u00e9my Chardonnet", "Pan Hui"], "Sources": "2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Users would experience individually different sickness symptoms during or after navigating through an immersive virtual environment, generally known as cybersickness. Previous studies have predicted the severity of cybersickness based on physiological and/or kinematic data. However, compared with kinematic data, physiological data rely heavily on biosensors during the collection, which is inconvenient and limited to a few affordable VR devices. In this work, we proposed a deep neural network to predict cybersickness through kinematic data. We introduced the encoded physiological representation to characterize the individual susceptibility; therefore, the predictor could predict cybersickness only based on a user\u2019s kinematic data without counting on biosensors. Fifty-three participants were recruited to attend the user study to collect multimodal data, including kinematic data (navigation speed, head tracking?\u2026", "IdName": "li2023deep", "Citation": "", "Keywords": ""}, {"Name": "Development of an immersive simulator for improving student chemistry learning efficiency", "Authors": ["Shan Jin", "Yuyang Wang", "Lik-Hang Lee", "Xinyi Luo", "Pan Hui"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Virtual reality (VR) technology has been used for educational purposes in different learning contents during teaching and training. VR could improve users\u2019 learning efficiency and motivation to study abstract concepts. This work designed a VR environment for chemistry education to support computer-mediated hands-on exercises, including Self-propagating high-temperature synthesis (SHS) and Electrode sheet fabrication (ESF). In our evaluation with 39 participants who wore heart beat measurement wearables, we compared the students\u2019 performances in hands-on chemistry tasks, either with or without score-keeping and time-sensitive conditions. Accordingly, we designed questionnaires reflecting sixteen qualitative aspects (e.g., content, perspicuity, and interaction) and perceived user workloads. The experimental results indicate participants\u2019 preferences and attitudes in terms of efficiency and sense of safety?\u2026", "IdName": "jin2023development", "Citation": "", "Keywords": ""}, {"Name": "RLPTO: A reinforcement learning-based performance-time optimized task and resource scheduling mechanism for distributed machine learning", "Authors": ["Xiaofeng Lu", "Chao Liu", "Senhao Zhu", "Yilu Mao", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Transactions on Parallel and Distributed Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "With the wide application of deep learning, the amount of data required to train deep learning models is becoming increasingly larger, resulting in an increased training time and higher requirements for computing resources. To improve the throughput of a distributed learning system, task scheduling and resource scheduling are required. This article proposes to combine ARIMA and GRU models to predict the future task volume. In terms of task scheduling, multi-priority task queues are used to divide tasks into different queues according to their priorities to ensure that high-priority tasks can be completed in advance. In terms of resource scheduling, the reinforcement learning method is adopted to manage limited computing resources. The reward function of reinforcement learning is constructed based on the resources occupied by the task, the training time, the accuracy of the model. When a distributed learning?\u2026", "IdName": "lu2023rlpto", "Citation": "", "Keywords": ""}, {"Name": "An Analysis of Twitter Discourse on the War Between Russia and Ukraine", "Authors": ["Haris Bin Zia", "Ehsan Ul Haq", "Ignacio Castro", "Pan Hui", "Gareth Tyson"], "Sources": "arXiv preprint arXiv:2306.11390", "PublishedYears": "2023", "Doi": "", "Abstracts": "On the 21st of February 2022, Russia recognised the Donetsk People's Republic and the Luhansk People's Republic, three days before launching an invasion of Ukraine. Since then, an active debate has taken place on social media, mixing organic discussions with coordinated information campaigns. The scale of this discourse, alongside the role that information warfare has played in the invasion, make it vital to better understand this ecosystem. We therefore present a study of pro-Ukrainian vs. pro-Russian discourse through the lens of Twitter. We do so from two perspectives: (i) the content that is shared; and (ii) the users who participate in the sharing. We first explore the scale and nature of conversations, including analysis of hashtags, toxicity and media sharing. We then study the users who drive this, highlighting a significant presence of new users and bots.", "IdName": "zia2023analysis", "Citation": "", "Keywords": ""}, {"Name": "Getting Back on Track: Understanding COVID-19 Impact on Urban Mobility and Segregation with Location Service Data", "Authors": ["Lin Chen", "Fengli Xu", "Qianyue Hao", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the International AAAI Conference on Web and Social Media 17?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Understanding the impact of COVID-19 on urban life rhythms is crucial for accelerating the return-to-normal progress and envisioning more resilient and inclusive cities. While previous studies either depended on small-scale surveys or focused on the response to initial lockdowns, this paper uses large-scale location service data to systematically analyze the urban mobility behavior changes across three distinct phases of the pandemic, ie, pre-pandemic, lockdown, and reopen. Our analyses reveal two typical patterns that govern the mobility behavior changes in most urban venues: daily life-centered urban venues go through smaller mobility drops during the lockdown and more rapid recovery after reopening, while work-centered urban venues suffer from more significant mobility drops that are likely to persist even after reopening. Such mobility behavior changes exert deeper impacts on the underlying social fabric, where the level of mobility reduction is positively correlated with the experienced segregation at that urban venue. Therefore, urban venues undergoing more mobility reduction are also more filled with people from homogeneous socio-demographic backgrounds. Moreover, mobility behavior changes display significant heterogeneity across geographical regions, which can be largely explained by the partisan inclination at the state level. Our study shows the vast potential of location service data in deriving a timely and comprehensive understanding of the social dynamic in urban space, which is valuable for informing the gradual transition back to the normal lifestyle in a \u201cpost-pandemic era\u201d.", "IdName": "chen2023getting", "Citation": "", "Keywords": ""}, {"Name": "Towards AI-Architecture Liberty: A Comprehensive Survey on Designing and Collaborating Virtual Architecture by Deep Learning in the Metaverse", "Authors": ["Anqi Wang", "Jiahua Dong", "Lik-Hang Lee", "Jiachuan Shen", "Pan Hui"], "Sources": "arXiv preprint arXiv:2305.00510", "PublishedYears": "2023", "Doi": "", "Abstracts": "3D shape generation techniques leveraging deep learning have garnered significant interest from both the computer vision and architectural design communities, promising to enrich the content of the future metaverse. However, research on virtual architectural design remains limited, particularly regarding human-AI collaboration and deep learning-assisted design. We first illuminate the principles, generation techniques, and current literature of virtual architecture, focusing on challenges such as datasets, multimodality, design intuition, and generative frameworks. In our survey, we reviewed 187 related articles (80.7\\% of articles published between 2018 and 2022) covering architectural research, virtual environments, and technical approaches. This survey investigates the latest approaches to 3D object generation with deep generative models (DGMs) and summarizes four characteristics of deep-learning generation approaches for virtual architecture. According to our analysis of the survey, we expound on four research agendas, including agency, communication, user consideration, and integrating tools, and highlight three important enablers of ubiquitous interaction with immersive systems in deep learning-assisted architectural generation. Our work contributes to fostering understanding between designers and deep learning techniques, broadening access to human-AI collaboration. We advocate for interdisciplinary efforts to address this timely research topic, facilitating content designing and generation in the metaverse.", "IdName": "wang2023towards", "Citation": "", "Keywords": ""}, {"Name": "An immersive simulator for improving chemistry learning efficiency", "Authors": ["Jin Shan", "Yuyang Wang", "Lik-Hang Lee", "Xian Wang", "Zeming Chen", "Boya Dong", "Xinyi Luo", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper designed a virtual simulator for chemistry education and computer-mediated hands-on exercises. We compared the participants' performances in hands-on chemistry tasks with or without score-keeping and timer and used questionnaires to measure their learning performance and perceived cognitive workload. The experimental results indicate participants' preferences and attitudes toward efficiency and safety. Most participants reported that the learning simulator could improve learning efficiency and a sense of safety. Our findings shed light on the quality and learning performance of theory knowledge and operational skills for chemistry education.", "IdName": "shan2023immersive", "Citation": "", "Keywords": ""}, {"Name": "Development and penta-metric evaluation of a virtual interview simulator", "Authors": ["Xinyi Luo", "Yuyang Wang", "Lik-Hang Lee", "Zihan Xing", "Shan Jin", "Boya Dong", "Yuanyi Hu", "Zeming Chen", "Jing Yan", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The virtual reality interview training system (VRITS) can provide a manageable training approach for candidates who tend to be very ner-vous during interviews; yet, the major anxiety stimulating elements remain unknown. By developing the VRITS and analyzing people's anxiety levels with an orthogonal experiment, we investigated five factors. Results indicate that Type Of Interview Questions plays a major role in the interviewee's anxiety. Secondly, Level Of Realism and Preparation both have some degree of influence. Lastly, Interrogator's Attitude and Timed Or Untimed Answers have little to no impact. This work contributes towards cues for designing future VRITS.", "IdName": "luo2023development", "Citation": "", "Keywords": ""}, {"Name": "A Twitter Dataset for Pakistani Political Discourse", "Authors": ["Ehsan-Ul Haq", "Haris Bin Zia", "Reza Hadi Mogavi", "Gareth Tyson", "Yang K Lu", "Tristan Braud", "Pan Hui"], "Sources": "arXiv preprint arXiv:2301.06316", "PublishedYears": "2023", "Doi": "", "Abstracts": "We share the largest dataset for the Pakistani Twittersphere consisting of over 49 million tweets, collected during one of the most politically active periods in the country. We collect the data after the deposition of the government by a No Confidence Vote in April 2022. This large-scale dataset can be used for several downstream tasks such as political bias, bots detection, trolling behavior, (dis)misinformation, and censorship related to Pakistani Twitter users. In addition, this dataset provides a large collection of tweets in Urdu and Roman Urdu that can be used for optimizing language processing tasks.", "IdName": "haq2023twitter", "Citation": "", "Keywords": ""}, {"Name": "Networking and cyber foraging for mobile augmented reality", "Authors": ["Tristan Braud", "Wenxiao Zhang", "Benjamin Finley", "Pan Hui"], "Sources": "Springer Handbook of Augmented Reality", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile augmented reality (MAR) applications are gaining popularity due to the wide adoption of mobile and especially wearable devices such as smartglasses. These devices often strike a compromise between mobility, energy efficiency, and performance. On the other hand, MAR applications rely on computationally intensive computer vision algorithms with extreme latency requirements. Cyber-foraging allows resource-constrained devices to leverage the computing power of nearby machines, and has often been proposed as a solution for increasing the computing capabilities of constrained devices. However, this process introduces new constraints in the application, especially in terms of latency and bandwidth. MAR applications are so demanding that current network infrastructures are barely ready for such traffic. Such resource-hungry applications may rapidly saturate future wireless networks such as 5G. As?\u2026", "IdName": "braud2023networking", "Citation": "", "Keywords": ""}, {"Name": "Exploring Mental Health Communications among Instagram Coaches", "Authors": ["Ehsan-Ul Haq", "Lik-Hang Lee", "Gareth Tyson", "Reza Hadi Mogavi", "Tristan Braud", "Pan Hui"], "Sources": "2022 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "There has been a significant expansion in the use of online social networks (OSNs) to support people experiencing mental health issues. This paper studies the role of Instagram influencers who specialize in coaching people with mental health issues. Using a dataset of 97k posts, we characterize such users' linguistic and behavioural features. We explore how these observations impact audience engagement (as measured by likes). We show that the support provided by these accounts varies based on their self-declared professional identities. For instance, Instagram accounts that declare themselves as Authors offer less support than accounts that label themselves as a Coach. We show that increasing information support in general communication positively affects user engagement. However, the effect of vocabulary on engagement is not consistent across the Instagram account types. Our findings shed light on?\u2026", "IdName": "haq2022exploring", "Citation": "", "Keywords": ""}, {"Name": "Understanding scholar social networks: taking scholat as an example", "Authors": ["Min Gao", "Yang Chen", "Qingyuan Gong", "Xin Wang", "Pan Hui"], "Sources": "CCF Conference on Computer Supported Cooperative Work and Social Computing?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Scholar social networks are composed of scholars and social connections among them. Studying such social networks can help promote academic exchanges and cooperation, and predict future trends in research. In this paper, we analyze SCHOLAT, a representative scholar social network in China, from three perspectives. First, we explore SCH-OLAT\u2019s social graph, and we find this graph has a smaller average shortest-path length and a higher clustering coefficient than other social networks, for example, the collaboration network of Google Scholar and the Flickr social network. Moreover, we leverage the structural hole theory to identify important users on SCHOLAT. By comparing the top-500 structural hole spanners with 500 randomly selected users, we have found that the former have the higher values of several graph-based metrics, and they also connect more communities. Finally, we also undertake user?\u2026", "IdName": "gao2021understanding", "Citation": "", "Keywords": ""}, {"Name": "Evaluating transport protocols on 5g for mobile augmented reality", "Authors": ["Jacky Cao", "Xiang Su", "Benjamin Finley", "Pengyuan Zhou", "Pan Hui"], "Sources": "arXiv preprint arXiv:2006.02859", "PublishedYears": "2020", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) mixes physical environments with user-interactive virtual annotations. Immersive MAR experiences are supported by computation-intensive tasks which rely on offloading mechanisms to ease device workloads. However, this introduces additional network traffic which in turn influences the motion-to-photon latency (a determinant of user-perceived quality of experience). Therefore, a proper transport protocol is crucial to minimise transmission latency and ensure sufficient throughput to support MAR performance. Relatedly, 5G, a potential MAR supporting technology, is widely believed to be smarter, faster, and more efficient than its predecessors. However, the suitability and performance of existing transport protocols in MAR in the 5G context has not been explored. Therefore, we present an evaluation of popular transport protocols, including UDP, TCP, MPEG-TS, RTP, and QUIC, with a MAR system on a real-world 5G testbed. We also compare with their 5G performance with LTE and WiFi. Our evaluation results indicate that TCP has the lowest round-trip-time on 5G, with a median of  ms, while QUIC appears to perform better on LTE. Through an additional test with varying signal quality (specifically, degrading secondary synchronisation signal reference signal received quality), we discover that protocol performance appears to be significantly impacted by signal quality.", "IdName": "cao2020evaluating", "Citation": "", "Keywords": ""}, {"Name": "Modelling global public health strategies in COVID-19 pandemic using deep reinforcement learning", "Authors": ["Kwak Gloria Hyunjung", "Lowell Ling", "Pan Hui"], "Sources": "None", "PublishedYears": "2020", "Doi": "", "Abstracts": "Objectives:This study evaluates the timing and intensity of public health policies in each country and territory in the COVID-19 pandemic, and whether machine learning can help them to find better global health strategies.Methods:: Population and COVID-19 epidemiological data between 21st January 2020 to 7th April 2020 from 183 countries and 78 territories were included with the implemented public health interventions. We used deep reinforcement learning, and the model was trained to try to find the optimal public health strategies with maximizing total reward on controlling spread of COVID-19. The results proposed by the model were analyzed against the actual timing and intensity of lockdown and travel restrictions. Measurements and Main Results: Early implementation of the actual lockdown and travel restriction policies were associated with gradually groups of less severe crisis severity, relative to local index case date in each country or territory, not to 31st December 2019. However, our model suggested to initiate at least minimal intensity of lockdown or travel restriction even before index cases in each country and territory. In addition, the model mostly recommended a combination of lockdown and travel restrictions and higher intensity policies than the implemented policies by government, but did not always encourage rapid full lockdown and full border closures.Conclusion:Compared to actual government implementation, our model mostly recommended earlier and higher intensity of lockdown and travel restrictions. Machine learning may be used as a decision support tool for implementation of public health interventions during?\u2026", "IdName": "hyunjung2020modelling", "Citation": "", "Keywords": ""}, {"Name": "A Study of Partisan News Sharing in the Russian Invasion of Ukraine", "Authors": ["Yiming Zhu", "Ehsan-Ul Haq", "Gareth Tyson", "Lik-Hang Lee", "Yuyang Wang", "Pan Hui"], "Sources": "Proceedings of the International AAAI Conference on Web and Social Media 18?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Since the Russian invasion of Ukraine, a large volume of biased and partisan news has been spread via social media platforms. As this may lead to wider societal issues, we argue that understanding how partisan news sharing impacts users' communication is crucial for better governance of online communities. In this paper, we perform a measurement study of partisan news sharing. We aim to characterize the role of such sharing in influencing users' communications. Our analysis covers an eight-month dataset across six Reddit communities related to the Russian invasion. We first perform an analysis of the temporal evolution of partisan news sharing. We confirm that the invasion stimulates discussion in the observed communities, accompanied by an increased volume of partisan news sharing. Next, we characterize users' response to such sharing. We observe that partisan bias plays a role in narrowing its propagation. More biased media is less likely to be spread across multiple subreddits. However, we find that partisan news sharing attracts more users to engage in the discussion, by generating more comments. We then built a predictive model to identify users likely to spread partisan news. The prediction is challenging though, with 61.57% accuracy on average. Our centrality analysis on the commenting network further indicates that the users who disseminate partisan news possess lower network influence in comparison to those who propagate neutral news.", "IdName": "zhu2024study", "Citation": "", "Keywords": ""}, {"Name": "Similarity-driven and task-driven models for diversity of opinion in crowdsourcing markets", "Authors": ["Chen Jason Zhang", "Yunrui Liu", "Pengcheng Zeng", "Ting Wu", "Lei Chen", "Pan Hui", "Fei Hao"], "Sources": "The VLDB Journal", "PublishedYears": "2024", "Doi": "", "Abstracts": "The recent boom in crowdsourcing has opened up a new avenue for utilizing human intelligence in the realm of data analysis. This innovative approach provides a powerful means for connecting online workers to tasks that cannot effectively be done solely by machines or conducted by professional experts due to cost constraints. Within the field of social science, four elements are required to construct a sound crowd\u2014Diversity of Opinion, Independence, Decentralization and Aggregation. However, while the other three components have already been investigated and implemented in existing crowdsourcing platforms,\u2018Diversity of Opinion\u2019has not been functionally enabled yet. From a computational point of view, constructing a wise crowd necessitates quantitatively modeling and taking diversity into account. There are usually two paradigms in a crowdsourcing marketplace for worker selection: building a crowd to?\u2026", "IdName": "zhang2024similarity", "Citation": "", "Keywords": ""}, {"Name": "Digital Democracy at Crossroads: A Meta-Analysis of Web and AI Influence on Global Elections", "Authors": ["Zheng Wei", "Xian Xu", "Pan Hui"], "Sources": "Companion Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "2024 will be the largest election year in history involving over 50 countries and approximately 4.2 billion people. Since 1996, the Web has been instrumental in political campaigns, enhancing public engagement and creating new communication avenues for elections. Nevertheless, the proliferation of generative AI technologies has made false information dissemination simpler and quicker, posing a substantial threat to election integrity and democratic processes. The 2024 global elections underscore the need to comprehend and tackle the impact of such technologies on democracy. In this paper, we undertake a detailed meta-analysis, scrutinizing 44 papers published in The Web Conference, detailing the influence of the Web on elections. Our research reveals key historical trends on how the Web has impacted elections: first, social media has revolutionized election strategies through direct voter-candidate?\u2026", "IdName": "wei2024digital", "Citation": "", "Keywords": ""}, {"Name": "Social Media Discourses on Interracial Intimacy: Tracking Racism and Sexism through Chinese Geo-located Social Media Data", "Authors": ["Zheng Wei", "Yixuan Xie", "Danyun Xiao", "Simin Zhang", "Pan Hui", "Muzhi Zhou"], "Sources": "Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "We examine the social media discourse surrounding interracial relationships in China, specifically on the popular platform Douyin. By analyzing comments on short video posts, the study focuses on four types of interracial relationships: Black men and Chinese women, Black women and Chinese men, White men and Chinese women, and White women and Chinese men. The study also explores potential regional differences in these discourses, using IP geolocation data made available to the public since April 2022. Our content analysis revealed that the Black men and Chinese women couples attracted the most negative comments and the White women and Chinese men couples received the least negative comments. We also observed substantial regional differences in the discourses towards these interracial relationships. We investigated several regional socioeconomic development indicators and noted that?\u2026", "IdName": "wei2024social", "Citation": "", "Keywords": ""}, {"Name": "History in Making: Political Campaigns in the Era of Artificial Intelligence-Generated Content", "Authors": ["Ehsan-Ul Haq", "Yiming Zhu", "Pan Hui", "Gareth Tyson"], "Sources": "Companion Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Web 2.0 provided impactful tools, based on user-generated content, for political campaigns and opinion engineering. However, in recent months, AI advances and the ease of access to AI-generated content (AIGC) have led to a paradigm shift in political participation by politicians and electorates alike. This paper aims to explore a historical analysis of this shift. We provide anecdotal evidence of new trends, potential impact, and challenges. We discuss the usage of AIGC in political campaigns, and how AIGC is used as a substitute for incarcerated politicians. Such a usage presents novel ways for leaders to reach the public and keep them politically active. However, AIGC also has risks when used for disinformation, such as DeepFake media and caller bots, to undermine and malign the opponents. On the other hand, the evidence shows that governments can nudge AIGC content by censoring Internet services. We?\u2026", "IdName": "haq2024history", "Citation": "", "Keywords": ""}, {"Name": "APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT", "Authors": ["Yiming Zhu", "Zhizhuo Yin", "Gareth Tyson", "Ehsan-Ul Haq", "Lik-Hang Lee", "Pan Hui"], "Sources": "Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent research has highlighted the potential of LLMs, like ChatGPT, for performing label annotation on social computing data. However, it is already well known that performance hinges on the quality of the input prompts. To address this, there has been a flurry of research into prompt tuning --- techniques and guidelines that attempt to improve the quality of prompts. Yet these largely rely on manual effort and prior knowledge of the dataset being annotated. To address this limitation, we propose APT-Pipe, an automated prompt-tuning pipeline. APT-Pipe aims to automatically tune prompts to enhance ChatGPT's text classification performance on any given dataset. We implement APT-Pipe and test it across twelve distinct text classification datasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higher weighted F1-score on nine out of twelve experimented datasets, with an improvement of 7.01% on?\u2026", "IdName": "zhu2024apt", "Citation": "", "Keywords": ""}, {"Name": "CharacterMeet: Supporting Creative Writers' Entire Story Character Construction Processes Through Conversation with LLM-Powered Chatbot Avatars", "Authors": ["Hua Xuan Qin", "Shan Jin", "Ze Gao", "Mingming Fan", "Pan Hui"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Support for story character construction is as essential as characters are for stories. Building upon past research on early character construction stages, we explore how conversation with chatbot avatars embodying characters powered by more recent technologies could support the entire character construction process for creative writing. Through a user study (N=14) with creative writers, we examine thinking and usage patterns of CharacterMeet, a prototype system allowing writers to progressively manifest characters through conversation while customizing context, character appearance, voice, and background image. We discover that CharacterMeet facilitates iterative character construction. Specifically, participants, including those with more linear usual approaches, alternated between writing and personalized exploration through visualization of ideas on CharacterMeet while visuals and audio enhanced?\u2026", "IdName": "qin2024charactermeet", "Citation": "", "Keywords": ""}, {"Name": "OmniColor: A Global Camera Pose Optimization Approach of LiDAR-360Camera Fusion for Colorizing Point Clouds", "Authors": ["Bonan Liu", "Guoyang Zhao", "Jianhao Jiao", "Guang Cai", "Chengyang Li", "Handi Yin", "Yuyang Wang", "Ming Liu", "Pan Hui"], "Sources": "arXiv preprint arXiv:2404.04693", "PublishedYears": "2024", "Doi": "", "Abstracts": "A Colored point cloud, as a simple and efficient 3D representation, has many advantages in various fields, including robotic navigation and scene reconstruction. This representation is now commonly used in 3D reconstruction tasks relying on cameras and LiDARs. However, fusing data from these two types of sensors is poorly performed in many existing frameworks, leading to unsatisfactory mapping results, mainly due to inaccurate camera poses. This paper presents OmniColor, a novel and efficient algorithm to colorize point clouds using an independent 360-degree camera. Given a LiDAR-based point cloud and a sequence of panorama images with initial coarse camera poses, our objective is to jointly optimize the poses of all frames for mapping images onto geometric reconstructions. Our pipeline works in an off-the-shelf manner that does not require any feature extraction or matching process. Instead, we find optimal poses by directly maximizing the photometric consistency of LiDAR maps. In experiments, we show that our method can overcome the severe visual distortion of omnidirectional images and greatly benefit from the wide field of view (FOV) of 360-degree cameras to reconstruct various scenarios with accuracy and stability. The code will be released at https://github.com/liubonan123/OmniColor/.", "IdName": "liu2024omnicolor", "Citation": "", "Keywords": ""}, {"Name": "Perceived User Reachability in Mobile UIs Using Data Analytics and Machine Learning", "Authors": ["Lik-Hang Lee", "Yui-Pan Yau", "Pan Hui"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "One-handed interactions on smartphone interfaces offer a prominent feature of highly mobile inputs. Thus, the design factor of user reachability is essential to realizing the incentive. However, the sole consideration of physical characteristics, such as hand size and thumb length, does not fully reflect the users\u2019 perceived choices of hand poses and the corresponding inertia. We first conducted a 6-week questionnaire-based study of UI rating tasks and collected 62,156 responses reflecting user preferences for 3000 clustered UIs. Our analysis of the responses shows that user perceptions of smartphone UI components are divergent from their physical ability of thumb reaches; e.g. they can reach an icon with a thumb reach, but they prefer alternative hand poses. Accordingly, we propose a machine learning model, i.e. XGBoost (XGB), to predict the user\u2019s choices of hand poses, with a reasonable prediction accuracy of?\u2026", "IdName": "lee2024perceived", "Citation": "", "Keywords": ""}, {"Name": "Jump Cut Effects in Cinematic Virtual Reality: Editing with the 30-degree Rule and 180-degree Rule", "Authors": ["Junjie Zhang", "Lik-Hang Lee", "Yuyang Wang", "Shan Jin", "Dan-Lu Fei", "Pan Hui"], "Sources": "2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2024", "Doi": "", "Abstracts": "Virtual reality (VR) is an immersive medium that offers users a unique opportunity to experience a digital environment realistically. As the demand for VR content continues to grow, the importance of effective VR editing techniques becomes increasingly apparent. This paper is a pioneering work investigating the effects of jump cuts on the viewer\u2019s sense of presence, viewing experience, and edit quality in cinematic VR. Specifically, this work focuses on using the 30-degree and 180-degree rules in VR editing to minimize the adverse effects of jump cuts. We conducted a user study with thirteen participants, who watched nine different VR edits and completed a survey for each edited video. Our results indicate that employing the 30-degree and 180-degree rules in VR editing can significantly improve the sense of presence, viewing experience, and edit quality while mitigating the negative effects of jump cuts. We?\u2026", "IdName": "zhang2024jump", "Citation": "", "Keywords": ""}, {"Name": "AnchorLoc: Large-Scale, Real-Time Visual Localisation Through Anchor Extraction and Detection", "Authors": ["Chun Ho Park", "Ahmad Alhilal", "Tristan Braud", "Pan Hui"], "Sources": "2024 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Pervasive Augmented Reality (AR) requires accurate pose registration of the device in real-time at a neighbourhood-to-city scale. At such a scale, most pose registration techniques suffer from exponential computational and storage costs and a significant data collection burden. This paper introduces AnchorLoc, a framework that relies on visual anchors (stable and highly recognisable visual elements in a scene) to perform fast and accurate pose registration. Anchorloc automatically identifies these anchors from large image sequences to optimise the search space in later image retrieval and pose registration. As such, it significantly improves the computational efficiency of existing hierarchical localisation pipelines without compromising accuracy. We collect a large-scale localisation dataset consisting of image sequences and 3D reconstruction of a university campus. AnchorLoc reduces localisation runtime by 83?\u2026", "IdName": "park2024anchorloc", "Citation": "", "Keywords": ""}, {"Name": "Using a virtual reality interview simulator to explore factors influencing people\u2019s behavior", "Authors": ["Xinyi Luo", "Yuyang Wang", "Lik-Hang Lee", "Zihan Xing", "Shan Jin", "Boya Dong", "Yuanyi Hu", "Zeming Chen", "Jing Yan", "Pan Hui"], "Sources": "Virtual Reality", "PublishedYears": "2024", "Doi": "", "Abstracts": "Virtual reality interview simulator (VRIS) is an effective and valid tool that uses virtual reality technology to train people\u2019s interview skills. Typically, it offers candidates prone to being very nervous during interviews the opportunity to practice interviews in a safe and manageable virtual environment and realistic settings, providing real-time feedback from a virtual interviewer on their performance. It helps interviewees improve their skills, reduce their fears, gain confidence, and minimize the cost and time associated with traditional interview preparation. Yet, the major anxiety-inducing elements remain unknown. During an interview, the anxiety levels, overall experience, and performance of interviewees might be affected by various circumstances. By analyzing electrodermal activity and questionnaire, we investigated the influence of five variables:(I) Realism;(II) Question type;(III) Interviewer attitude;(IV) Timing; and (V?\u2026", "IdName": "luo2024using", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Potential of Large Language Models in Artistic Creation: Collaboration and Reflection on Creative Programming", "Authors": ["Anqi Wang", "Zhizhuo Yin", "Yulu Hu", "Yuanyuan Mao", "Pan Hui"], "Sources": "arXiv preprint arXiv:2402.09750", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recently, the potential of large language models (LLMs) has been widely used in assisting programming. However, current research does not explore the artist potential of LLMs in creative coding within artist and AI collaboration. Our work probes the reflection type of artists in the creation process with such collaboration. We compare two common collaboration approaches: invoking the entire program and multiple subtasks. Our findings exhibit artists' different stimulated reflections in two different methods. Our finding also shows the correlation of reflection type with user performance, user satisfaction, and subjective experience in two collaborations through conducting two methods, including experimental data and qualitative interviews. In this sense, our work reveals the artistic potential of LLM in creative coding. Meanwhile, we provide a critical lens of human-AI collaboration from the artists' perspective and expound design suggestions for future work of AI-assisted creative tasks.", "IdName": "wang2024exploring", "Citation": "", "Keywords": ""}, {"Name": "Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via Transformer-Based 360 Image Outpainting", "Authors": ["Hao Ai", "Zidong Cao", "Haonan Lu", "Chen Chen", "Jian Ma", "Pengyuan Zhou", "Tae-Kyun Kim", "Pan Hui", "Lin Wang"], "Sources": "arXiv preprint arXiv:2401.10564", "PublishedYears": "2024", "Doi": "", "Abstracts": "360 images, with a field-of-view (FoV) of 180x360, provide immersive and realistic environments for emerging virtual reality (VR) applications, such as virtual tourism, where users desire to create diverse panoramic scenes from a narrow FoV photo they take from a viewpoint via portable devices. It thus brings us to a technical challenge: `How to allow the users to freely create diverse and immersive virtual scenes from a narrow FoV image with a specified viewport?' To this end, we propose a transformer-based 360 image outpainting framework called Dream360, which can generate diverse, high-fidelity, and high-resolution panoramas from user-selected viewports, considering the spherical properties of 360 images. Compared with existing methods, e.g., [3], which primarily focus on inputs with rectangular masks and central locations while overlooking the spherical property of 360 images, our Dream360 offers higher outpainting flexibility and fidelity based on the spherical representation. Dream360 comprises two key learning stages: (I) codebook-based panorama outpainting via Spherical-VQGAN (S-VQGAN), and (II) frequency-aware refinement with a novel frequency-aware consistency loss. Specifically, S-VQGAN learns a sphere-specific codebook from spherical harmonic (SH) values, providing a better representation of spherical data distribution for scene modeling. The frequency-aware refinement matches the resolution and further improves the semantic consistency and visual fidelity of the generated results. Our Dream360 achieves significantly lower Frechet Inception Distance (FID) scores and better visual fidelity than existing methods?\u2026", "IdName": "ai2024dream360", "Citation": "", "Keywords": ""}, {"Name": "Long-Term Gamification: A Survey", "Authors": ["Lei Huang", "Chao Deng", "Jennifer Hoffman", "Reza Hadi Mogavi", "Justin Juho Kim", "Pan Hui"], "Sources": "International Conference on Human-Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "In addressing the challenge of sustaining user engagement in gamified systems, this survey explores the long-term effects of gamification strategies. It emerges that success hinges on a nuanced blend of design elements, tailored personalization, evolving challenges, collaborative features, story-driven content, and dynamic updates. These factors are found to foster a deep-rooted sense of ownership, skill development, community belonging, and continuous discovery, all of which are crucial for keeping users engaged over time. This paper contributes by providing an early analysis of longitudinal studies, offering a valuable roadmap for developing enduring gamification experiences within the fields of human-computer interaction and gamification. Our paper advocates for further research examining long-term gamification in a more systematic and thorough manner.", "IdName": "huang2024long", "Citation": "", "Keywords": ""}, {"Name": "Mobile User Traffic Generation via Multi-Scale Hierarchical GAN", "Authors": ["Tong Li", "Shuodi Hui", "Shiyuan Zhang", "Huandong Wang", "Yuheng Zhang", "Pan Hui", "Depeng Jin", "Yong Li"], "Sources": "ACM Transactions on Knowledge Discovery from Data", "PublishedYears": "2024", "Doi": "", "Abstracts": "Mobile user traffic facilitates diverse applications, including network planning and optimization, whereas large-scale mobile user traffic is hardly available due to privacy concerns. One alternative solution is to generate mobile user traffic data for downstream applications. However, existing generation models cannot simulate the multi-scale temporal dynamics in mobile user traffic on individual and aggregate levels. In this work, we propose a multi-scale hierarchical generative adversarial network (MSH-GAN) containing multiple generators and a multi-class discriminator. Specifically, the mobile traffic usage behavior exhibits a mixture of multiple behavior patterns, which are called micro-scale behavior patterns and are modeled by different pattern generators in our model. Moreover, the traffic usage behavior of different users exhibits strong clustering characteristics, with the co-existence of users with similar and?\u2026", "IdName": "li2024mobile", "Citation": "", "Keywords": ""}, {"Name": "Metaverse for Connected and Automated Vehicles and Intelligent Transportation Systems [From the Guest Editors]", "Authors": ["Pengyuan Zhou", "Lik-Hang Lee", "Zhi Liu", "Hang Qiu", "Tristan Braud", "Aaron Yi Ding", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Vehicular Technology Magazine", "PublishedYears": "2023", "Doi": "", "Abstracts": "The metaverse aims to blur the boundary between the physical world and digital content. To achieve this goal, the metaverse relies heavily on extended reality (XR), the Internet of Things, and communication technologies. Concurrently, connected vehicles and intelligent transportation systems (ITSs) are envisioned as the future paradigm of driving and becoming reality thanks to increasingly powerful onboard vehicular processing capacity and advanced vehicle-to-everything networking technologies.", "IdName": "zhou2023metaverse", "Citation": "", "Keywords": ""}, {"Name": "Head-mounted display-based augmented reality for water quality visualisation", "Authors": ["Jacky Cao", "Xiaoli Liu", "Xiang Su", "Jonas Eilertsen H?dahl", "Thomas Berg Fjellestad", "Donjete Haziri", "Andr\u00e9 Hoang-An Vu", "Jari Koskiaho", "Satu Maaria Karjalainen", "Anna-kaisa Ronkanen", "Sasu Tarkoma", "Pan Hui"], "Sources": "Water Science and Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Water covers most of the Earth\u2019s surface and is nowhere near a good ecological or recreational state in many areas of the world. Moreover, only a small fraction of the water is potable. As climate change-induced extreme weather events become ever more prevalent, more and more issues arise, such as worsening water quality problems. Therefore, protecting invaluable and useable drinking water is critical. Environmental agencies must continuously check water sources to determine whether they are in a good or healthy state regarding pollutant levels and ecological status. The currently available tools are better suited for stationary laboratory use, and domain specialists lack suitable tools for on-site visualisation and interactive exploration of environmental data. Meanwhile, data collection for laboratory analysis requires substantial time and significant effort. We, therefore, developed an augmented reality system?\u2026", "IdName": "cao2023head", "Citation": "", "Keywords": ""}, {"Name": "Is the Price Right? The Economic Value of Sharing Sensors", "Authors": ["Ngoc Thi Nguyen", "Maria Zubair", "Agustin Zuniga", "Sasu Tarkoma", "Pan Hui", "Hyowon Lee", "Simon Tangi Perrault", "Mostafa H Ammar", "Huber Flores", "Petteri Nurmi"], "Sources": "IEEE Transactions on Computational Social Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "We study user\u2019s valuations of smartphone sensing resources and the factors mediating them through a systematic auction study with 108 bids from N =18 participants, two resource use conditions [fixed battery (FB) and variable battery (VB)] and three sensors (camera, microphone, and GPS) with differing energy and privacy costs. We use a second-price sealed-bid reverse auction as this allows us to elicit the participants\u2019 truthful perceived value for sharing resources. We show that most users would be willing to share even highly-privacy intrusive sensors if they are sufficiently compensated. At the FB level, participants placed much lower value for sharing GPS (\u20ac13) than camera (\u20ac30) or microphone (\u20ac32.5). The values people place on sharing access to resources generally reflect four considerations: 1) the perceived value of the sensor type; 2) the value of the data captured by the sensor; 3) the impact of sharing?\u2026", "IdName": "nguyen2023price", "Citation": "", "Keywords": ""}, {"Name": "QoE Optimization for VR Streaming: a Continual RL Framework in Digital Twin-empowered MEC", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Tailin Zhou", "Pan Hui", "Danny HK Tsang"], "Sources": "GLOBECOM 2023-2023 IEEE Global Communications Conference", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile edge computing (MEC) resource allocation for remote rendering in virtual reality (VR) content streaming is critical for user experience. However, resource allocation becomes challenging due to the desynchronization between the physical and digital worlds in digital twin-empowered MEC. This paper presents our continual RL framework that facilitates dynamic resource allocation for MEC-enabled VR content streaming. We first design a digital twin-empowered edge computing (DTEC) system and formulate a maximization problem that considers attention-based resolution perception to maximize the quality of experience (QoE). This problem optimizes the allocation of computing and bandwidth resources while adapting the attention-based resolution of the VR content. We then apply continual reinforcement learning (CRL) to enable adaptive attention-based resolution VR streaming in a time-varying?\u2026", "IdName": "yu2023qoe", "Citation": "", "Keywords": ""}, {"Name": "VR PreM+: An Immersive Pre-learning Branching Visualization System for Museum Tours", "Authors": ["Ze Gao", "Xiang Li", "Changkun Liu", "Xian Wang", "Anqi Wang", "Liang Yang", "Yuyang Wang", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the Eleventh International Symposium of Chinese CHI", "PublishedYears": "2023", "Doi": "", "Abstracts": "We present VR PreM+, an innovative VR system designed to enhance web exploration beyond traditional computer screens. Unlike static 2D displays, VR PreM+ leverages 3D environments to create an immersive pre-learning experience. Using keyword-based information retrieval allows users to manage and connect various content sources in a dynamic 3D space, improving communication and data comparison. We conducted preliminary and user studies that demonstrated efficient information retrieval, increased user engagement, and a greater sense of presence. These findings yielded three design guidelines for future VR information systems: display, interaction, and user-centric design. VR PreM+ bridges the gap between traditional web browsing and immersive VR, offering an interactive and comprehensive approach to information acquisition. It holds promise for research, education, and beyond.", "IdName": "gao2023vr", "Citation": "", "Keywords": ""}, {"Name": "Poster Abstract: Multi-User Privacy-Preserving Mechanism for Extended Reality in Healthcare", "Authors": ["Xiang Su", "Luyi Sun", "Pan Hui"], "Sources": "Proceedings of the 21st ACM Conference on Embedded Networked Sensor Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Health monitoring scenarios involve multiple users with conflicting privacy concerns. We envision extended reality facilitating smooth interactions among users while resolving potential conflicts arising from users' conflicting goals, ensuring that sensitive information is not unintentionally revealed. We contribute to an adaptive approach to resolving decision conflicts and content sharing and a scenario-centric access control model with a strategy mediator.", "IdName": "su2023multi", "Citation": "", "Keywords": ""}, {"Name": "Towards Risk-Averse Edge Computing With Deep Reinforcement Learning", "Authors": ["Dianlei Xu", "Xiang Su", "Huandong Wang", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, artificial intelligence paves the way for the development of smart services for people anytime and anywhere, which poses great challenges on accessing computing resources. Multi-access edge computing complements existing cloud computing infrastructure at the edge of the network, where mobile users can offload computationally intensive tasks of smart applications to edge servers that are in proximity to the users themselves. Existing offloading schemes mainly focus on selecting edge servers for each offloading task with the goal of optimizing the overall average latency. However, the solutions with the optimal overall average latency may be not the most suitable for all offloading tasks. There is still a possibility that offloading leads to an extreme case of ultra-high latency, which is not acceptable for latency-sensitive applications. To address this problem, we therefore introduce modern portfolio theory?\u2026", "IdName": "xu2023towards", "Citation": "", "Keywords": ""}, {"Name": "Towards Optimising Transport Protocols on the 5G Edge for Mobile Augmented Reality", "Authors": ["Jacky Cao", "Xiang Su", "Pan Hui"], "Sources": "Proceedings of the 2nd International Workshop on Interactive eXtended?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile augmented reality (MAR) achieves immersive real-time experiences by offloading computation-intensive computer vision tasks. 5G NR (5G) networks and edge computing enable optimised latency and enhanced throughput for MAR offloading. However, efficiently leveraging the 5G edge also requires optimising the data link between MAR devices and server machines. We report preliminary experiments of optimising transport protocols (i.e., UDP and TCP) to understand how we could further modify the data link between MAR clients and servers. Preliminary analysis shows that when using a real-world 5G testbed, our evaluation indicates that for our settings, TCP with default configuration parameters has the lowest round-trip time on 5G, with a median of 15.8\\pm10.3 ms. Then by increasing the protocol buffer sizes to 100 KB and 1000 KB, the packet latency and jitter decrease while throughput increases for?\u2026", "IdName": "cao2023towards", "Citation": "", "Keywords": ""}, {"Name": "Designing Loving-Kindness Meditation in Virtual Reality for Long-Distance Romantic Relationships", "Authors": ["Xian Wang", "Xiaoyu Mo", "Lik-Hang Lee", "Xiaoying Wei", "Xiaofu Jin", "Mingming Fan", "Pan Hui"], "Sources": "Proceedings of the 31st ACM International Conference on Multimedia", "PublishedYears": "2023", "Doi": "", "Abstracts": "Loving-kindness meditation (LKM) is used in clinical psychology for couples' relationship therapy, but physical isolation can make the relationship more strained and inaccessible to LKM. Virtual reality (VR) can provide immersive LKM activities for long-distance couples. However, no suitable commercial VR applications for couples exist to engage in LKM activities of long-distance. This paper organized a series of workshops with couples to build a prototype of a couple-preferred LKM app. Through analysis of participants' design works and semi-structured interviews, we derived design considerations for such VR apps and created a prototype for couples to experience. We conducted a study with couples to understand their experiences of performing LKM using the VR prototype and a traditional video conferencing tool. Results show that LKM session utilizing both tools has a positive effect on the intimate?\u2026", "IdName": "wang2023designing", "Citation": "", "Keywords": ""}, {"Name": "SoK: Distributed Computing in ICN", "Authors": ["Wei Geng", "Yulong Zhang", "Dirk Kutscher", "Abhishek Kumar", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the 10th ACM Conference on Information-Centric Networking", "PublishedYears": "2023", "Doi": "", "Abstracts": "Information-Centric Networking (ICN), with its data-oriented operation and generally more powerful forwarding layer, provides an attractive platform for distributed computing. This paper provides a systematic overview and categorization of different distributed computing approaches in ICN encompassing fundamental design principles, frameworks and orchestration, protocols, enablers, and applications. We discuss current pain points in legacy distributed computing, attractive ICN features, and how different systems use them. This paper also provides a discussion of potential future work for distributed computing in ICN.", "IdName": "geng2023sok", "Citation": "", "Keywords": ""}, {"Name": "Ghost Booking as a New Philanthropy Channel: A Case Study on Ukraine-Russia Conflict", "Authors": ["Fachrina Dewi Puspitasari", "Gareth Tyson", "Ehsan-Ul Haq", "Pan Hui", "Lik-Hang Lee"], "Sources": "Proceedings of the 34th ACM Conference on Hypertext and Social Media", "PublishedYears": "2023", "Doi": "", "Abstracts": "The term ghost booking has recently emerged as a new way to conduct humanitarian acts during the conflict between Russia and Ukraine in 2022. The phenomenon describes the events where netizens donate to Ukrainian citizens through no-show bookings on the Airbnb platform. Impressively, the social fundraising act that used to be organized on donation-based crowdfunding platforms is shifted into a sharing economy platform market and thus gained more visibility. Although the donation purpose is clear, the motivation of donors in selecting a property to book remains concealed. Thus, our study explores peer-to-peer donation behavior on Airbnb, which was originally intended for economic exchanges, and further identifies which platform attributes effectively drive donation behaviors. We collect over 200K guest reviews from 16K Airbnb property listings in Ukraine by employing two collection methods (screen?\u2026", "IdName": "puspitasari2023ghost", "Citation": "", "Keywords": ""}, {"Name": "Toward A Traffic Metaverse With Shared Vehicle Perception", "Authors": ["Ahmad Ahilal", "Tristan Braud", "Lik-Hang Lee", "Hang Chen", "Pan Hui"], "Sources": "IEEE Communications Standards Magazine", "PublishedYears": "2023", "Doi": "", "Abstracts": "The emergence of the Metaverse enables the creation of alternative spaces at the intersection between digital and physical through the replication of physical events and objects within physical-digital twins. In this article, we apply such twins to connected vehicles within a Traffic Metaverse as an intermediate platform for the shared perception of the road environment. The platform builds a real-time digital copy of the road conditions to serve vehicular applications on a city scale through ubiquitous sensing, reliable and low-latency communications, artificial intelligence, and extended reality. This article focuses on collaboratively building virtual 3D maps of road networks that provide road users with a pervasive view of the road conditions to increase situational awareness. Through vehicle-to-everything (V2X) cooperative perception, such a Metaverse platform expands the driver's visibility beyond the vehicle's line of?\u2026", "IdName": "ahilal2023toward", "Citation": "", "Keywords": ""}, {"Name": "Efficient Task Offloading Algorithm for Digital Twin in Edge/Cloud Computing Environment", "Authors": ["Ziru Zhang", "Xuling Zhang", "Guangzhi Zhu", "Yuyang Wang", "Pan Hui"], "Sources": "arXiv preprint arXiv:2307.05888", "PublishedYears": "2023", "Doi": "", "Abstracts": "In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to empower various areas as a bridge between physical objects and the digital world. Through virtualization and simulation techniques, multiple functions can be achieved by leveraging computing resources. In this process, Mobile Cloud Computing (MCC) and Mobile Edge Computing (MEC) have become two of the key factors to achieve real-time feedback. However, current works only considered edge servers or cloud servers in the DT system models. Besides, The models ignore the DT with not only one data resource. In this paper, we propose a new DT system model considering a heterogeneous MEC/MCC environment. Each DT in the model is maintained in one of the servers via multiple data collection devices. The offloading decision-making problem is also considered and a new offloading scheme is proposed based on Distributed Deep Learning (DDL). Simulation results demonstrate that our proposed algorithm can effectively and efficiently decrease the system's average latency and energy consumption. Significant improvement is achieved compared with the baselines under the dynamic environment of DTs.", "IdName": "zhang2023efficient", "Citation": "", "Keywords": ""}, {"Name": "Towards a 3D Evaluation Dataset for User Acceptance of Automated Shuttles", "Authors": ["Ming Yan", "Wei Geng", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The popularity of automatic driving technology has gradually freed users from driving tasks and increased interaction with vehicles and machines. Understanding user acceptance and making them more receptive to new technologies can help businesses and researchers find better ways to design Human-Machine Interactions. The simulation experiment in an immersion environment can evaluate the user's acceptance of the design with low cost and high efficiency. Fur-ther, the evaluation methods of some existing studies are different, which creates obstacles to the reuse and reference of research results between different scholars. However, there are limited simulation data that can be used for such interactive evaluation, such as typical 3D environment data based on Virtual Reality devices. We design dataset, an ongoing 3D test dataset produced by Unity software, to be employed by different studies to evaluate?\u2026", "IdName": "yan2023towards", "Citation": "", "Keywords": ""}, {"Name": "ARCam: A User-Defined Camera for AR Photographic Art Creation", "Authors": ["Xinyi Luo", "Zihao Zhu", "Yuyang Wang", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Photography in augmented reality can be challenging due to the restrictions of pre-defined settings. However, adjustable photography settings and real-time previews are significant for AR photographic creation as creators must adjust multiple camera properties to present unique visual effects. In this work, we designed an AR camera (ARCam) with various adjustable properties to give users a high degree of freedom for photographic art creation in real-time preview.", "IdName": "luo2023arcam", "Citation": "", "Keywords": ""}, {"Name": "Learn to Optimize the Constrained Shortest Paths on Large Dynamic Graphs", "Authors": ["Jiaming Yin", "Weixiong Rao", "Qinpei Zhao", "Chenxi Zhang", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2023", "Doi": "", "Abstracts": "The constrained shortest path (  ) problem has wide applications in travel path planning, mobile video broadcasting and network routing. Existing works do not work well on large dynamic graphs and suffer from either ineffectiveness or low scalability issues. To overcome these issues, in this paper, we propose an efficient and effective solution framework, namely   . The solution framework includes two key components: (1) the techniques to decompose a large    instance into multiple small sub-instances and (2) the developed learning model    to solve small    instances. The evaluation result on real road network graphs indicates that our approach    performs well on large dynamic graphs by rather high quality and reasonable running time, and particularly adapt to significant graph changes even with broken edges. To the best of our knowledge, this is the first learning-based model to well?\u2026", "IdName": "yin2023learn", "Citation": "", "Keywords": ""}, {"Name": "Dataset for predicting cybersickness from a virtual navigation task", "Authors": ["Yuyang Wang", "Ruichen Li", "Jean-R\u00e9my Chardonnet", "Pan Hui"], "Sources": "arXiv preprint arXiv:2303.13527", "PublishedYears": "2023", "Doi": "", "Abstracts": "This work presents a dataset collected to predict cybersickness in virtual reality environments. The data was collected from navigation tasks in a virtual environment designed to induce cybersickness. The dataset consists of many data points collected from diverse participants, including physiological responses (EDA and Heart Rate) and self-reported cybersickness symptoms. The paper will provide a detailed description of the dataset, including the arranged navigation task, the data collection procedures, and the data format. The dataset will serve as a valuable resource for researchers to develop and evaluate predictive models for cybersickness and will facilitate more research in cybersickness mitigation.", "IdName": "wang2023dataset", "Citation": "", "Keywords": ""}, {"Name": "Fairness-Aware Algorithms for Seed Allocation in Social Advertising", "Authors": ["Pengzi Wang", "Yiming Zhu", "Kai Han", "Zhizhuo Yin", "Qing Xiu", "Pan Hui"], "Sources": "2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "As a crucial and widely researched application in social networks, social advertising refers to selecting seed users for several advertisers to propagate their advertisements in the network via a information cascade effect. Prior studies on this topic have presented approximation algorithms merely for maximizing the expected revenue. However, regarding to the fairness issue, no existing works have provided effective solution. Such a issue would cause polarized revenues among different advertisers and the draining of them. In this paper, we investigate the fairness issue in social advertising. That is, how the social network platform owner distributes seeds users fairly to different advertisers. We define the fairness metric according to the maximin share, a concept about fair distribution in computation economics, and develop a novel approximation algorithm. Our approach achieves an approximation factor of   , where  ?\u2026", "IdName": "wang2022fairness", "Citation": "", "Keywords": ""}, {"Name": "Federated split GANs for collaborative training with heterogeneous devices", "Authors": ["Yilei Liang", "Pranvera Korto?i", "Pengyuan Zhou", "Lik-Hang Lee", "Abbas Mehrabi", "Pan Hui", "Sasu Tarkoma", "Jon Crowcroft"], "Sources": "Software Impacts 14", "PublishedYears": "2022", "Doi": "", "Abstracts": "Applications based on machine learning (ML) are greatly facilitated by mobile devices and their enormous volume and variety of data. To better safeguard the privacy of user data, traditional ML techniques have transitioned toward new paradigms like federated learning (FL) and split learning (SL). However, existing frameworks have overlooked device heterogeneity, greatly hindering their applicability in practice. In order to address such limitations, we developed a framework based on both FL and SL to share the training load of the discriminative part of a GAN to different client devices. We make our framework available as open-source software1.", "IdName": "liang2022federated", "Citation": "", "Keywords": ""}, {"Name": "Intelligent Decision Making Based on the Combination of Deep Reinforcement Learning and an Influence Map", "Authors": ["Xiaofeng Lu", "Ao Xue", "Pietro Lio", "Pan Hui"], "Sources": "Applied Sciences", "PublishedYears": "2022", "Doi": "", "Abstracts": "Almost all recent deep reinforcement learning algorithms use four consecutive frames as the state space to retain the dynamic information. If the training state data constitute an image, the state space is used as the input of the neural network for training. As an AI-assisted decision-making technology, a dynamic influence map can describe dynamic information. In this paper, we propose the use of a frame image superimposed with an influence map as the state space to express dynamic information. Herein, we optimize Ape-x as a distributed reinforcement learning algorithm. Sparse reward is an issue that must be solved in refined intelligent decision making. The use of an influence map is proposed to generate the intrinsic reward when there is no external reward. The experiments conducted in this study prove that the combination of a dynamic influence map and deep reinforcement learning is effective. Compared with the traditional method that uses four consecutive frames to represent dynamic information, the score of the proposed method is increased by 11\u201313%, the training speed is increased by 59%, the video memory consumption is reduced by 30%, and the memory consumption is reduced by 50%. The proposed method is compared with the Ape-x algorithm without an influence map, DQN, N-Step DQN, QR-DQN, Dueling DQN, and C51. The experimental results show that the final score of the proposed method is higher than that of the compared baseline methods. In addition, the influence map is used to generate an intrinsic reward to effectively resolve the sparse reward problem.", "IdName": "lu2022intelligent", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical Multi-agent Model for Reinforced Medical Resource Allocation with Imperfect Information", "Authors": ["Qianyue Hao", "Fengli Xu", "Lin Chen", "Pan Hui", "Yong Li"], "Sources": "ACM Transactions on Intelligent Systems and Technology", "PublishedYears": "2022", "Doi": "", "Abstracts": "With the advent of the COVID-19 pandemic, the shortage in medical resources became increasingly more evident. Therefore, efficient strategies for medical resource allocation are urgently needed. However, conventional rule-based methods employed by public health experts have limited capability in dealing with the complex and dynamic pandemic-spreading situation. In addition, model-based optimization methods such as dynamic programming (DP) fail to work since we cannot obtain a precise model in real-world situations most of the time. Model-free reinforcement learning (RL) is a powerful tool for decision-making; however, three key challenges exist in solving this problem via RL: (1) complex situations and countless choices for decision-making in the real world; (2) imperfect information due to the latency of pandemic spreading; and (3) limitations on conducting experiments in the real world since we?\u2026", "IdName": "hao2022hierarchical", "Citation": "", "Keywords": ""}, {"Name": "Generating layout designs from high-level specifications", "Authors": ["Xiao-Yu Wang", "Kang Zhang"], "Sources": "Automation in Construction 119", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper presents a framework for the automatic generation of floor plans based on adjacency relations among rooms. The adjacency can be generated from user-specified design requirements using a graph grammar formalism. We propose a set of grammar rules to generate graphs that represent adjacency relationships. Our solution overcomes the limitation of previous approaches that generate only rectangular floor plans. We define a set of constraints, such as plan size, room orientation and aspect ratio, for specifying the desired floor plans; and present a set of algorithms for placing rectangular or non-rectangular rooms and for generating non-rectangular floor plan boundaries. We demonstrate that our method can generate varied floor plans from user-specified design requirements.", "IdName": "wang2020generating", "Citation": "", "Keywords": ""}, {"Name": "The influence of font scale on semantic expression of word cloud", "Authors": ["Lu Yang", "Jie Li", "Wenhuan Lu", "Yi Chen", "Kang Zhang", "Yan Li"], "Sources": "Journal of Visualization 23", "PublishedYears": "2020", "Doi": "", "Abstracts": " Abstract Word cloud is a common text visualization technique. With the ability of presenting the keywords of a document in a direct way, it has been widely applied in many real-world situations. However, to better represent the main idea of a document, a critical aspect for word cloud design is to set an appropriate font size to facilitate semantic expression. In this paper, we explore the influence of font scale on semantic expression and evaluate font size of word cloud in a more systematic approach. To quantify semantic information of a document, we utilize an LDA ensemble-based method to support interactive selection of topics and obtain the semantics of documents in a scientific way. We conducted two pilot studies to decide important attributes of word clouds for the formal study. Through formal study 1, we find that the scale affects the semantic expression of word cloud, including accuracy, time and confidence in?\u2026", "IdName": "yang2020influence", "Citation": "", "Keywords": ""}, {"Name": "Visual complexity of shapes: a hierarchical perceptual learning model", "Authors": ["Lingchen Dai", "Kang Zhang", "Xianjun Sam Zheng", "Ralph R Martin", "Yina Li", "Jinhui Yu"], "Sources": "The Visual Computer", "PublishedYears": "2022", "Doi": "", "Abstracts": " Understanding how people perceive the visual complexity of shapes has important theoretical as well as practical implications. One school of thought, driven by information theory, focuses on studying the local features that contribute to the perception of visual complexity. Another school, in contrast, emphasizes the impact of global characteristics of shapes on perceived complexity. Inspired by recent discoveries in neuroscience, our model considers both local features of shapes: edge lengths and vertex angles, and global features: concaveness, and is in 92% agreement with human subjective ratings of shape complexity. The model is also consistent with the hierarchical perceptual learning theory, which explains how different layers of neurons in the visual system act together to yield a perception of visual shape complexity. ", "IdName": "dai2022visual", "Citation": "", "Keywords": ""}, {"Name": "Parametric modeling and generation of mandala thangka patterns", "Authors": ["Jiajing Zhang", "Kang Zhang", "Ren Peng", "Jinhui Yu"], "Sources": "Journal of Computer Languages 58", "PublishedYears": "2020", "Doi": "", "Abstracts": "The mandala thangka, as a religious art in Tibetan Buddhism, is an invaluable cultural and artistic heritage. However, drawing a mandala pattern of thangka style is both time- and effort-consuming and requires mastery due to intricate details. Retaining and digitizing this heritage is an unresolved research challenge to date. In this paper, we propose a parametric approach to model and generate mandala thangka patterns to address this issue. Specifically, we construct parameterized models of three stylistic elements used in the interior mandalas of Nyingma school in Tibetan Buddhism according to their geometric features, namely the star, crescent, and lotus flower motifs. Varieties of interior mandala patterns are successfully generated using these parameterized motifs based on the hierarchical structures observed from hand-drawn mandalas. Moreover, we design a user interaction tool which can flexibly generate?\u2026", "IdName": "zhang2020parametric", "Citation": "", "Keywords": ""}, {"Name": "A graph grammar approach to the design and validation of floor plans", "Authors": ["Xiao-Yu Wang", "Yu-Feng Liu", "Kang Zhang"], "Sources": "The Computer Journal", "PublishedYears": "2020", "Doi": "", "Abstracts": " Researchers have proposed many approaches to generate floor plans using shape grammars. None of them, however, testifies the semantic relations among rooms. This paper presents a generic approach for grammar specification, grammar induction, validation, and design generation of house floor plans using their path graphs based on the reserved graph grammar (RGG) formalism. In our approach, the connectivity of a floor plan is analyzed by user-specified graph grammar transformation rules, also known as productions. Floor plans of houses in different styles share common attributes while retaining specific features. By identifying these features, our approach validates floor plans in different styles with user-specified graph productions. A graph grammar induction engine is also introduced to assist designers by automatically inferring graph productions from an input graph set. In addition, the derivation?\u2026", "IdName": "wang2020graph", "Citation": "", "Keywords": ""}, {"Name": "Measuring and evaluating the visual complexity of Chinese ink paintings", "Authors": ["Zhen-Bao Fan", "Yi-Na Li", "Kang Zhang", "Jinhui Yu", "Mao Lin Huang"], "Sources": "The Computer Journal", "PublishedYears": "2022", "Doi": "", "Abstracts": " Painters arrange white space in contrast with chromatic space composed of strokes. This research measures white space, color complexity and stroke density in Chinese ink paintings and examines how these attributes influence the paintings\u2019 perceived complexity. Empirical evidence from 21 well-known modern Chinese artists\u2019 ink paintings shows that white space decreases paintings\u2019 complexity, while chromatic space and stroke density increase complexity. We also reveal that a large rate of white space guides the viewers\u2019 attention on chromatic space and enhances the impacts of color complexity and stroke density on perceived complexity. An eye-tracker measures viewers\u2019 elaboration duration on each painting, which provides consistent evidence to validate our conclusion based on subjective reported visual complexity. Our research provides insights into the rhetorical role of white space in sensory?\u2026", "IdName": "fan2022measuring", "Citation": "", "Keywords": ""}, {"Name": "An end-to-end model for chinese calligraphy generation", "Authors": ["Peichi Zhou", "Zipeng Zhao", "Kang Zhang", "Chen Li", "Changbo Wang"], "Sources": "Multimedia Tools and Applications 80", "PublishedYears": "2021", "Doi": "", "Abstracts": " A Chinese calligraphy copybook usually has a limited number of Chinese characters, far from a whole set of characters needed for typesetting. Therefore, there is a need to develop complete sets of Chinese calligraphy libraries for well-known calligrapher styles. This paper proposes an end-to-end network for character generation based on specific calligraphy styles. Specifically, a style transfer network is designed to transfer the style of characters, and a content supplement network is designed to capture the details of stylish strokes. Our model can generate high-quality calligraphy images without manually annotating data. To verify the generated calligraphy styles, a new dataset is constructed for experimental comparison between our method and two other baseline methods. Moreover, a user study is conducted to evaluate our generated calligraphy from a visual perspective. When the experiment?\u2026", "IdName": "zhou2021end", "Citation": "", "Keywords": ""}, {"Name": "Visual order of Chinese ink paintings", "Authors": ["Zhen-Bao Fan", "Kang Zhang"], "Sources": "Visual Computing for Industry", "PublishedYears": "2020", "Doi": "", "Abstracts": " Visual order is one of the key factors influencing the aesthetic judgment of artworks. This paper reports the results of evaluating the influence of extracted features on visual order in Chinese ink paintings, using a regression model. We use nine contemporary artists\u2019 paintings as examples and extract features related to the visual order of their paintings. A questionnaire survey is conducted to collect people\u2019s rating scores on the visual order. Via regression modeling, our research analyzes the significance of each feature and validates the influences of the features on the visual order.", "IdName": "fan2020visual", "Citation": "", "Keywords": ""}, {"Name": "Ultrahigh energy-dissipation and multifunctional auxetic polymeric foam inspired by balloon art", "Authors": ["Kang Zhang", "Xiyao Zhang", "Qiang Gao", "Meishan Chan", "Shilong Zhang", "Jifan Li", "Wei-Hsin Liao"], "Sources": "Composites Part A: Applied Science and Manufacturing 167", "PublishedYears": "2023", "Doi": "", "Abstracts": "Herein, we report a novel strategy for making ultrahigh energy-dissipation auxetic foam inspired by balloon art. As revealed by finite element analysis of balloon deformation evolution in polymer matrix, spherical balloons will turn to reentrant shape when compressed uniaxially in polymer matrix with large Poisson\u2019s ratio. By utilizing the know-how, auxetic silicone foam (ASF) was successfully developed through a well-designed foaming-compression-curing process. ASF shows ultrahigh energy dissipation capability of \uff5e2000?kJ/m3, which is over 80 times higher than conventional auxetic polyurethane foams. Moreover, ASF has low water absorption and high chemical and temperature resistance, allowing it to be used in harsh circumstances. Additionally, ASF is a thermal-responsive material that can expand at high temperature and return to its initial state when cooling down. Our work provides routes towards?\u2026", "IdName": "zhang2023ultrahigh", "Citation": "", "Keywords": ""}, {"Name": "Interactive influences of color attributes on color perception bias", "Authors": ["Huan Yang", "Yi-Na Li", "Kang Zhang"], "Sources": "The Visual Computer 36", "PublishedYears": "2020", "Doi": "", "Abstracts": " Graphic user interfaces and information visualization use color to represent qualitative or quantitative information. The interaction between adjacent colors leads to perceptual bias, known as simultaneous color contrast, and implicitly distort the understanding of visualized information presentation. To investigate the effect of simultaneous color contrast, we conduct two empirical experiments, in both theoretical and application settings, using a set of random target/proximal combinations of colors in the CIEL*a*b* color space. The perception bias of a target color, induced by its surround, is measured. Linear regression analysis indicates that both a high saturation of the proximal color and a high a*/low b* value of the target color cause a strong simultaneous color contrast (i.e., high perception bias). A moderating effect analysis indicates that a* value/b* value of the target color moderates the influence of the?\u2026", "IdName": "yang2020interactive", "Citation": "", "Keywords": ""}, {"Name": "A comparative study of oil paintings and Chinese ink paintings on composition", "Authors": ["Zhen-Bao Fan", "Yi-Xuan Zhu", "Slobodan Markovi?", "Kang Zhang"], "Sources": "The Visual Computer", "PublishedYears": "2023", "Doi": "", "Abstracts": "In this study, we compare Western oil paintings and Chinese ink paintings on their composition, by extracting and computing 28 composition features of the paintings, including visual balance and relationships between different regions (segments). Among the extracted segments, we compute average distance and rule-based features based on three layout rules, rule of thirds, golden mean and golden triangle. A total of 2253 paintings including 1138 oil paintings and 1115 Chinese ink paintings are collected. By comparing the results of the features on these paintings, our study investigates the difference and similarity between the two types of paintings on composition. Their composition designs are similar in visual balance and their tendency of composing along two diagonal lines, but are fairly different on many other aspects. For example, oil paintings are inclined to place objects on the bottom horizontal dividing?\u2026", "IdName": "fan2023comparative", "Citation": "", "Keywords": ""}, {"Name": "Coordinate graph grammar for the specification of spatial graphs", "Authors": ["Yufeng Liu", "Xiaoqin Zeng", "Kang Zhang", "Yang Zou"], "Sources": "The Computer Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": " As a two-dimensional formal method, graph grammar is widely used in defining various visual programming languages. This paper presents a new graph grammar formalism called coordinate graph grammar (CGG). CGG is extended from the edge-based graph grammar (EGG) by introducing the spatial mechanism into the theoretical framework, which consists of continuous coordinate graph grammar (cCGG) and discrete coordinate graph grammar (dCGG). By combining quantitative and qualitative spatial semantics in one framework, CGG provides strong expressiveness and flexibility for specifying various spatial graphs. This paper focuses on several important issues on the new formalism. First, the theoretical framework of CGG is given. Second, two matching algorithms for cCGG and dCGG are proposed, which use the spatial relationships between nodes to narrow down the search space during parsing?\u2026", "IdName": "liu2021coordinate", "Citation": "", "Keywords": ""}, {"Name": "The computer-based generation of fonts in the style of Kandinsky", "Authors": ["Kang Zhang", "Jinhui Yu"], "Sources": "Leonardo", "PublishedYears": "2021", "Doi": "", "Abstracts": " This article presents a general framework for programmed automatic generation of artistic fonts. By parameterizing various font attributes, such as color and aspect ratio, the authors are able to generate artistically styled fonts in almost unlimited variations to suit any type of design requirement. The authors demonstrate their experiments on generating fonts in an abstract style similar to Kandinsky's, built on a collection of the artist's styled patterns. The approach generates fonts composed of vector strokes and is thus highly scalable, limited only by the computer hardware.", "IdName": "zhang2021computer", "Citation": "", "Keywords": ""}, {"Name": "Introducing Massive Open Metaverse Course (MOMC) and Its Enabling Technology", "Authors": ["Kang Zhang", "Zhijing Shao", "Yun Lu", "Ying Yu", "Wei Sun", "Zeyu Wang"], "Sources": "IEEE Transactions on Learning Technologies", "PublishedYears": "2023", "Doi": "", "Abstracts": "As metaverse becomes one of the most popular buzzwords in technology, there is still a lack of support to integrate true metaverse learning experiences in massive open online courses (MOOCs). This article introduces a new framework of massive open metaverse courses (MOMCs) and its major enabling technologies, which add immersive and 3-D learning experiences lacking in MOOCs. It then describes a detailed case study, the President's First Lecture at the Hong Kong University of Science and Technology (Guangzhou), which we consider the world's first true MOMC environment, enabled by the latest volumetric video and related virtual and augmented reality technologies. We describe in detail how this course is created and discuss the major advantages of MOMC over MOOC as well as its current limitations.", "IdName": "zhang2023introducing", "Citation": "", "Keywords": ""}, {"Name": "Transformation of portraits to Picasso\u2019s cubism style", "Authors": ["Guanyu Lian", "Kang Zhang"], "Sources": "The Visual Computer", "PublishedYears": "2020", "Doi": "", "Abstracts": " This paper presents an approach to the transformation of portrait photographs to Picasso\u2019s cubism style using deep learning and image processing techniques. We obtain the side-view face by rotating the face model constructed from a frontal portrait image 90 and then replace the left half of the portrait by the side-view face. Our approach is applicable to online transformation of selfie photographs and potentially extendable to broader categories of images and artistic styles.", "IdName": "lian2020transformation", "Citation": "", "Keywords": ""}, {"Name": "The Contemporary Art of Image Search: Iterative User Intent Expansion via Vision-Language Model", "Authors": ["Yilin Ye", "Qian Zhu", "Shishi Xiao", "Kang Zhang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2312.01656", "PublishedYears": "2023", "Doi": "", "Abstracts": "Image search is an essential and user-friendly method to explore vast galleries of digital images. However, existing image search methods heavily rely on proximity measurements like tag matching or image similarity, requiring precise user inputs for satisfactory results. To meet the growing demand for a contemporary image search engine that enables accurate comprehension of users' search intentions, we introduce an innovative user intent expansion framework. Our framework leverages visual-language models to parse and compose multi-modal user inputs to provide more accurate and satisfying results. It comprises two-stage processes: 1) a parsing stage that incorporates a language parsing module with large language models to enhance the comprehension of textual inputs, along with a visual parsing module that integrates an interactive segmentation module to swiftly identify detailed visual elements within images; and 2) a logic composition stage that combines multiple user search intents into a unified logic expression for more sophisticated operations in complex searching scenarios. Moreover, the intent expansion framework enables users to perform flexible contextualized interactions with the search results to further specify or adjust their detailed search intents iteratively. We implemented the framework into an image search system for NFT (non-fungible token) search and conducted a user study to evaluate its usability and novel properties. The results indicate that the proposed framework significantly improves users' image search experience. Particularly the parsing and contextualized interactions prove useful in allowing users to?\u2026", "IdName": "ye2023contemporary", "Citation": "", "Keywords": ""}, {"Name": "Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example", "Authors": ["Aven-Le Zhou", "Yu-Ao Wang", "Wei Wu", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2402.06389", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the advancement of neural generative capabilities, the art community has actively embraced GenAI (generative artificial intelligence) for creating painterly content. Large text-to-image models can quickly generate aesthetically pleasing outcomes. However, the process can be non-deterministic and often involves tedious trial-and-error, as users struggle with formulating effective prompts to achieve their desired results. This paper introduces a prompting-free generative approach that empowers users to automatically generate personalized painterly content that incorporates their aesthetic preferences in a customized artistic style. This approach involves utilizing ``semantic injection'' to customize an artist model in a specific artistic style, and further leveraging a genetic algorithm to optimize the prompt generation process through real-time iterative human feedback. By solely relying on the user's aesthetic evaluation and preference for the artist model-generated images, this approach creates the user a personalized model that encompasses their aesthetic preferences and the customized artistic style.", "IdName": "zhou2024human", "Citation": "", "Keywords": ""}, {"Name": "A survey of recent practice of Artificial Life in visual art", "Authors": ["Zi-Wei Wu", "Huamin Qu", "Kang Zhang"], "Sources": "Artificial Life", "PublishedYears": "2024", "Doi": "", "Abstracts": "Nowadays, interdisciplinary fields between Artificial Life, artificial intelligence, computational biology, and synthetic biology are increasingly emerging into public view. It is necessary to reconsider the relations between the material body, identity, the natural world, and the concept of life. Art is known to pave the way to exploring and conveying new possibilities. This survey provides a literature review on recent works of Artificial Life in visual art during the past 40 years, specifically in the computational and software domain. Having proposed a set of criteria and a taxonomy, we briefly analyze representative artworks of different categories. We aim to provide a systematic overview of how artists are understanding nature and creating new life with modern technology.", "IdName": "wu2024survey", "Citation": "", "Keywords": ""}, {"Name": "PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering", "Authors": ["Rong Huang", "Hai-Chuan Lin", "Chuanzhang Chen", "Kang Zhang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2401.17120", "PublishedYears": "2024", "Doi": "", "Abstracts": "Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI) enable automated generation of landscape renderings, the end-to-end methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of GAI models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and second, illustration module converts scene layouts into realistic landscape renderings using a fine-tuned low-rank adaptation diffusion model. PlantoGraphy has undergone a series of performance evaluations and user studies, demonstrating its effectiveness in landscape rendering generation and the high recognition of its interactive functionality.", "IdName": "huang2024plantography", "Citation": "", "Keywords": ""}, {"Name": "Body Cosmos: An Immersive Experience Driven by Real-Time Bio-Data", "Authors": ["Rem RunGu Lin", "Yongen Ke", "Kang Zhang"], "Sources": "2023 IEEE VIS Arts Program (VISAP)", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper presents \u201cBody Cosmos\u201d, an artwork that creates a symbiotic relationship between the human body and a simulated cosmic environment through volumetric rendering and particle system. Drawing from DICOM data to simulate the human body and nebulae, we create an interactive and dynamic virtual environment. The real-time bio-data of users, collected via heart rate sensors and EEG devices, is integrated into the visualization, fostering a personal engagement and unity within this \u2018cosmos.\u2019 Body Cosmos provokes curiosity and expands users\u2019 imagination, and deepens their understanding of life\u2019s macrocosm and microcosm. This exploratory project redefines traditional perceptions of the human body in relation to the universe, creating a unique lens to view selfhood, embodiment, and identity. As we look to the future, the system\u2019s evolution will include incorporation of more bio-data sensors, an?\u2026", "IdName": "lin2023body", "Citation": "", "Keywords": ""}, {"Name": "Shanshui Journey: AI Reproducing the Experience of Chinese \u201cLiterati\u201d Ink Paintings", "Authors": ["Aven Le Zhou", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2023", "Doi": "", "Abstracts": " The authors investigate Chinese \u201cShanshui\u201d (literally meaning mountain and water), a China-origin and East Asian ink paintings of the natural landscape, through an interactive art installation, entitled \u201cShanshui Journey.\u201d By examining Shanshui\u2019s philosophy, multiple-moving perspectives, and creation and appreciation practices, the work emphasizes motion in nature, memories, and interactive appreciation. These concepts are realized in a digitized room, where each participant\u2019s motion is captured as a line \u201csketch\u201d and transformed into an ink painting (i.e., Shanshui) via a custom neural network. Generated paintings are displayed in real-time alongside previous works, collectively termed \u201cShanshui Memories,\u201d mimicking the handscroll interaction. This new Shanshui approach aims to reproduce the Chinese literati art experience, raising awareness of the cultural heritage.", "IdName": "zhou2023shanshui", "Citation": "", "Keywords": ""}, {"Name": "Bitter Data: Bitterness Taste in 100,000 Trouble Data", "Authors": ["Yufan Li", "Yue Huang", "Kang Zhang", "Varvara Guljajeva"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Our participatory art project, Bitter Data, allows the audience to taste the bitterness of 100,000 trouble data via 11 teapots corresponding to 11 years of data. The bitterness and color of each pot reflect the quantity of trouble data in the corresponding year. By mapping bitterness and color to data quantity, we brew tea with varying tastes and tones. Tasting the tea with multi-sensory feelings allows participants to understand the negative emotions behind the data and how young Chinese have faced troubles in the past 11 years.", "IdName": "li2023bitter", "Citation": "", "Keywords": ""}, {"Name": "Naturality: A Natural Reflection of Chinese Calligraphy", "Authors": ["Bingyuan Wang", "Kang Zhang", "Zeyu Wang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We present a machine learning-based interactive video installation powered by CLIP and diffusion models and inspired by the concept of naturality in traditional Chinese calligraphy. The artwork explores contemporary interpretations of this traditional concept through practical methods in Artificial Intelligence Generated Content (AIGC). Technically, the algorithms are based on state-of-the-art perceptual and generative models, incorporating multi-dimensional controls over text-to-image and image-to-image translation; conceptually, this real-time art installation extends the discussion brought by Xu Bing\u2019s pieces Book from the Sky and Square Word Calligraphy. The project explores the possibility of AIGC in bridging human creativity and natural randomness, as well as a shifting creative paradigm enhanced by AI knowledge, perception, and association.", "IdName": "wang2023naturality", "Citation": "", "Keywords": ""}, {"Name": "A comparative study of color between abstract paintings, oil paintings and Chinese ink paintings", "Authors": ["Zhenbao Fan", "Yixuan Zhu", "Christine Yan", "Yufan Li", "Kang Zhang"], "Sources": "Proceedings of the 15th International Symposium on Visual Information?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Color is one of the fundamental elements of paintings. This paper proposes a set of measurements for color usage in a painting, including basic color elements, color harmony templates, and spatial distribution, characterizing both global and local features of color. Applying the measurements to over 3000 abstract paintings, oil paintings and Chinese ink paintings, we are able to observe the roles of color in the three genres of paintings. We report our findings in details on the effectiveness of these measurements, which may serve as tools for classification of paintings. The work is the first of this kind and points to further investigation of color usage in other forms of art and design.", "IdName": "fan2022comparative", "Citation": "", "Keywords": ""}, {"Name": "Verification of the Instantiation and Integration of Security Patterns", "Authors": ["Tu Peng", "Shuliang Wang", "Jing Geng", "Qinsi Wang", "Yun Yang", "Kang Zhang"], "Sources": "Journal of Web Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "As software applications suffer from increasing malicious attacks, security becomes a critically important issue for software development. To avoid security problems and increase efficiency, a large software system design may reuse good security solutions for existing security patterns. While security patterns document expert solutions to common security problems and capture well-examined practices on secure software design, implementing them in a particular context (pattern instantiation) and composing them with other related patterns (pattern integration) are prone to flaws and may break expected security properties. In this paper, we present an approach to verify security patterns instantiation and integration automatically. We offer formal definitions for security pattern instantiation and integration, and establish rules to transform sequence diagrams (representing the behaviors of security patterns) to expressions?\u2026", "IdName": "peng2020verification", "Citation": "", "Keywords": ""}, {"Name": "Cursive Calligraphy in 3d and bio-Ink", "Authors": ["Rem RunGu Lin", "You Zhou", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2024", "Doi": "", "Abstracts": " This paper presents a generative approach to creating dynamic 3D cursive calligraphy by integrating motion and bio-data captured by EEG and EMG sensors with particle systems driven by vector fields. The artwork created through this method metaphorically and visually represents a calligrapher\u2019s energy, inspired by the traditional concept of qi. The authors use the term bio-ink to describe the visualization technique of this digital sculpture, which uses bio-data as parameters to control the flow and dynamism of the particles. Utilizing Unreal Engine 5, the authors create a dynamic 3D artwork that inspires further investigation into the therapeutic benefits of calligraphy, highlights the potential use of biofeedback in skill development, and paves the way for combining traditional arts with artists\u2019 life-data.", "IdName": "lin2024cursive", "Citation": "", "Keywords": ""}, {"Name": "Mixed or Misperceived Reality?", "Authors": ["Aven Le Zhou", "Lei Xi", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2405.02338", "PublishedYears": "2024", "Doi": "", "Abstracts": "\"Surrealism Me\" delves into Vil\\'em Flusser's critique of media as mediators that often distort human perception of reality through an interactive virtual-embodying MR experience. It examines the obfuscating nature of media and reveals the constructed nature of media-projected realities, prompting a reevaluation of media's role and influence on our perception.", "IdName": "steinicke2019misperception", "Citation": "", "Keywords": ""}, {"Name": "Another Body in the World: Flusserian Freedom in Mixed Reality", "Authors": ["Aven Le Zhou", "Lei Xi", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2402.10751", "PublishedYears": "2024", "Doi": "", "Abstracts": "In Flusserian view of media history, humans often misperceive the world projected by media to be the world itself, leading to a loss of freedom. This paper examines Flusserian Freedom in the context of Mixed Reality (MR) and explores how humans can recognize the obscuration of the world within the media (i.e., MR) and understand their relationship. The authors investigate the concept of playing against apparatus and deliberately alienating the perception of the projected world through an artwork titled \"Surrealism Me.\" This artwork enables the user to have another body within MR through interactive and immersive experiences based on the definition of Sense of Embodiment. The purpose of this work is to raise awareness of the domination of media and to approach Flusserian freedom within contemporary technical arrangements.", "IdName": "zhou2024another", "Citation": "", "Keywords": ""}, {"Name": "Shanshui Journey: Using AI to Reproduce the Experience of Chinese Literati Ink Paintings", "Authors": ["Aven Le Zhou", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2024", "Doi": "", "Abstracts": "The authors investigate Chinese shanshui (literally, \u201cmountain  and water\u201d), ink paintings of the natural landscape, through an  interactive art installation entitled Shanshui Journey. By examining  shanshui\u2019s philosophy, multiple moving perspectives, and creation  and appreciation practices, the work emphasizes motion in nature,  memories, and interactive appreciation. These concepts are realized  in a digitized room, where each participant\u2019s motion is captured as a  line \u201csketch\u201d and transformed into an ink painting via a custom neural  network. Generated paintings are displayed in real time alongside  previous works, collectively termed Shanshui Memories, mimicking  handscroll interaction. The authors\u2019 approach to shanshui aims to  reproduce the Chinese literati art experience, and to raise awareness of  this cultural heritage.", "IdName": "le2024shanshui", "Citation": "", "Keywords": ""}, {"Name": "Media Interpretation: Revisiting McLuhans' Laws of Media and Ant Farm", "Authors": ["Rem Rungu Lin", "Kang Zhang"], "Sources": "SIGGRAPH Asia 2023 Art Papers", "PublishedYears": "2023", "Doi": "", "Abstracts": " This paper reexamines the work of Marshall McLuhan and Ant Farm, highlighting their enduring relevance for contemporary mediated urbanism and architecture. By exploring their historical context, connections, and influences, the authors provide insights for architects and artists navigating the complex interplay between media, technology, and the built environment. The analysis bridges the gap between historical context and contemporary practice, focusing on the motivations, possibilities, and limitations of media interpretation as a critical and creative practice. The paper addresses the pressing questions concerning the future design of architectural spaces and urban forms, ultimately fostering innovative approaches that challenge conventional design thinking", "IdName": "lin2023media", "Citation": "", "Keywords": ""}, {"Name": "Painterly Reality: Enhancing Audience Experience with Paintings through Interactive Art", "Authors": ["Aven Le Zhou", "Kang Zhang", "David Yip"], "Sources": "arXiv preprint arXiv:2312.01067", "PublishedYears": "2023", "Doi": "", "Abstracts": "Perceiving paintings entails more than merely engaging the audience's eyes and brains; their perceptions and experiences of a painting can be intricately connected with body movement. This paper proposes an interactive art approach entitled \"Painterly Reality\" that facilitates the perception and interaction with paintings in a three-dimensional manner. Its objective is to promote bodily engagement with the painting (i.e., embedded body embodiment and its movement and interaction) to enhance the audience's experience, while maintaining its essence. Unlike two-dimensional interactions, this approach constructs the Painterly Reality by capturing the audience's body embodiment in real-time and embedding into a three-dimensional painterly world derived from a given painting input. Through their body embodiment, the audience can navigate the painterly world and play with the magical realism (i.e., interactive painterly objects), fostering meaningful experiences via interactions. The Painterly Reality is subsequently projected through an Augmented Reality Mirror as a live painting and displayed in front of the audience. Hence, the audience can gain enhanced experiences through bodily engagement while simultaneously viewing and appreciating the live painting. The paper implements the proposed approach as an interactive artwork, entitled \"Everyday Conjunctive,\" with Fong Tse Ka's painting and installs in a local museum, which successfully enhances audience experience through bodily engagement.", "IdName": "zhou2023painterly", "Citation": "", "Keywords": ""}, {"Name": "Comparing color usage in abstract, oil, and Chinese ink paintings", "Authors": ["YuFan Li", "ZhenBao Fan", "YiXuan Zhu", "Christine Yan", "Kang Zhang"], "Sources": "Journal of Visualization", "PublishedYears": "2023", "Doi": "", "Abstracts": "Color is one of the fundamental elements of paintings. This paper proposes a set of measurements for color usage in a painting, including basic color elements, global and local color harmony, and color statistical properties, characterizing color features from both the spatial domain and frequency domain. We also collect a painting set including 1059 abstract paintings, 1012 oil paintings, and 1003 Chinese ink paintings. Applying the measurements to this painting set, we are able to observe the roles of color in the three genres of paintings. We report our findings in detail on the effectiveness of these measurements. Chinese ink paintings are significantly different from abstract and oil paintings in color usage, while abstract paintings emphasize color more than the two other genres. The measurements may serve as tools for the classification of paintings. The work is the first of this kind and points to further?\u2026", "IdName": "li2023comparing", "Citation": "", "Keywords": ""}, {"Name": "Archiving Body Movements: Collective Generation of Chinese Calligraphy", "Authors": ["Aven Le Zhou", "Jiayi Ye", "Tianchen Liu", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2311.13770", "PublishedYears": "2023", "Doi": "", "Abstracts": "As a communication channel, body movements have been widely explored in behavioral studies and kinesics. Performing and visual arts share the same interests but focus on documenting and representing human body movements, such as for dance notation and visual work creation. This paper investigates body movements in oriental calligraphy and how to apply calligraphy principles to stimulate and archive body movements. Through an artwork (Wushu), the authors experiment with an interactive and generative approach to engage the audience's bodily participation and archive the body movements as a compendium of generated calligraphy. The audience assumes the role of both writers and readers; creating (\"writing\") and appreciating (\"reading\") the generated calligraphy becomes a cyclical process within this infinite \"Book,\" which can motivate further attention and discussions concerning Chinese characters and calligraphy.", "IdName": "zhou2023archiving", "Citation": "", "Keywords": ""}, {"Name": "Kandinsky's Color-Shape Associations in Chinese Context: Do Personality and Affect Matter?", "Authors": ["Zixu Gong", "Kang Zhang", "Rongrong Chen"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Inspired by Kandinsky's original postulation of specific color-shape association preferences in human beings (i.e., blue circle, red square and yellow triangle), extensive literature from diverse cultural backgrounds has re-examined this issue and achieved a consensus on the existence of such preferences, yet there is disagreement on the specific association patterns. In this study, we investigated the association between color and basic geometric shapes among Chinese college students. Correspondence analysis revealed that both circles and triangles are highly associated with yellow. Circles are also associated with red, while squares exhibit a strong association with blue. Additionally, we confirmed Kandinsky's theory that the angular characteristics of shapes affect the choice of warm and cold colors assigned to them. Interestingly, neither personality traits nor affect states affect the color-shape association?\u2026", "IdName": "gong2023kandinsky", "Citation": "", "Keywords": ""}, {"Name": "Urban Symphony: An AI and Data-Driven Approach to Real-Time Animation for Public Digital Art", "Authors": ["Rem RunGu Lin", "Yongen Ke", "Kang Zhang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Projection mapping is a form of urban public art that uses light and video to transform buildings and structures into dynamic canvases. However, producing high-quality projection mapping content with compelling storytelling requires extensive time and resources, as it involves integrating local culture, urban spatial understanding, and animation production. To address this challenge, this paper proposes a method that combines artistic co-creation with AI, audio-visualization, and data-visualization techniques. The authors present a case study: \u201cUrban Symphony,\u201d an immersive public art installation that showcases our method and leverages AI and data-driven storytelling. This method fosters interdisciplinary research collaboration and explores the potential of projection mapping as a bridge between art, technology, and society. The paper describe the motivation, design, and production of the artwork, the outcomes?\u2026", "IdName": "lin2023urban", "Citation": "", "Keywords": ""}, {"Name": "Metaphor Design of Dockless Bike-sharing Based on Spatio-temporal Geographic Data", "Authors": ["Kelin Li", "Hong Yin", "Dong Li", "Kang Zhang", "Changbo Wang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Dockless Bike-sharing systems can be treated as a typical paradigm of the sharing economy. Due to the indiscriminate use and placement of huge bikes, their scheduling rules are complicated, which poses a challenge to the macro-control of the companies To enhance the information dimension of bike Origin-Destination (OD) data, an algorithm based on grid features is proposed to reconstruct travel trajectories of OD data. This paper starts by analyzing and designing metaphors to describe the scheduling rules and trip characteristics of Dockless Bike-Sharing. The evaluation shows that the proposed metaphors are user-friendly to novice users. We argue that metaphors provide an effective way for users to understand abstract ideas in a visual design with a large dataset.", "IdName": "li2023metaphor", "Citation": "", "Keywords": ""}, {"Name": "BiverWordle: Visualizing Stock Market Sentiment with Financial Text Data and Trends", "Authors": ["Lei Xia", "Yi-Ping Gao", "Le Lin", "Yu-Xi Chen", "Kang Zhang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " While financial forums are increasingly significant in financial analysis, current visualization tools do not properly exploit their text data. To address this, we present BiverWordle, a novel tool that reveals the relationship between market sentiment and firm trends. BiverWordle integrates candlestick chart, ThemeRiver, and Wordle with text classification and sentiment analysis techniques to decode market dynamics from textual sources, such as shareholder opinions and firm announcements. With the application of a Voting model to the manually labeled data, we achieved an accuracy of approximately 64%. BiverWordle facilitates the extraction of shareholder insights from sparse comments and provides a visual method for historical stock trend analysis, which we validated with three distinct stock trends. Resources are accessible at https://github.com/Brian-Lei-XIA/BiverWordle. ", "IdName": "xia2023biverwordle", "Citation": "", "Keywords": ""}, {"Name": "Interactive moir\u00e9 patterns Reflecting on the traditional nanjing baiju", "Authors": ["Ye Yang", "Guangxi Chen", "Mengqi Li", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2023", "Doi": "", "Abstracts": " This article presents a human-machine design approach to the artistic and metaphorical representation of the traditional weaving scenes featured on Yunjin brocade as interactive moir\u00e9 patterns accompanied by Nanjing Baiju performance. After extracting the basic elements of the eye-shaped moir\u00e9 patterns, the authors systematically recomposed them to mimic the weaving process. They then wrote an algorithm to generate moir\u00e9 patterns that respond dynamically to the unique sounds weavers make while weaving, symbolizing the gazes and eye contacts among the weavers. This became an interactive sonic installation, Sweating Weaving Room, which represents the rhythmic machine sounds, the Nanjing Baiju, and the hard labor and harmonious work hidden behind the glamorous brocade.", "IdName": "yang2023interactive", "Citation": "", "Keywords": ""}, {"Name": "Learning computer graphics via a student-led open source demonstration project", "Authors": ["Pushpa Kumar", "Kang Zhang"], "Sources": "Journal of Computing Sciences in Colleges", "PublishedYears": "2020", "Doi": "", "Abstracts": "Computer Graphics is a computer science subject involving heavy mathematics and many classic graphics algorithms. Providing students hands-on learning experience via programming projects is essential but insufficient. In this paper, we share our experiences in teaching Computer Graphics by letting students build their own algorithm animation and demonstrations open source software. The open source demonstration software, called CGDemo, includes animation and interactive demonstration of various classic graphics algorithms and 3D mathematic transformations. Students first learn the algorithms by developing demonstration projects in Java, following a consistent demonstration framework, and meanwhile by learning and reusing software components built by other students. The gradually built open source project CGDemo has been helping all the subsequent students to learn complex graphics?\u2026", "IdName": "kumar2020learning", "Citation": "", "Keywords": ""}, {"Name": "Practices and Challenges of Using Think-Aloud Protocols in Industry: An International Survey", "Authors": ["Mingming Fan", "Serina Shi", "Khai N Truong"], "Sources": "Journal of Usability Studies", "PublishedYears": "2020", "Doi": "", "Abstracts": "Think-aloud protocols are one of the classic methods often taught in universities for training UX designers and researchers. Although previous research reported how these protocols were used in industry, the findings were typically based on the practices of a small number of professionals in specific geographic regions or on studies conducted years ago. As UX practices continuously evolve to address new challenges emerging in industry, it is important to understand the challenges faced by current UX practitioners around the world when using think-aloud protocols. Such an understanding is beneficial for UX professionals to reflect on and learn from the UX community\u2019s practices. It is also invaluable for academic researchers and educators to understand the challenges faced by professionals when carrying out the protocols in a wide range of practical contexts and to better explore methods to address these challenges. We conducted an international survey study with UX professionals in various sized companies around the world. We found that think-aloud protocols are widely and almost equally used in controlled lab studies and remote usability testing; concurrent protocols are more popular than retrospective protocols. Most UX practitioners probe participants during test sessions, explicitly request them to verbalize particular types of content, and do not administer practice sessions. The findings also offer insights on practices and challenges in analyzing think-aloud sessions. In sum, UX practitioners often deal with the tension between validity and efficiency in their analysis and demand better fast-paced and reliable analysis methods than?\u2026", "IdName": "fan2020practices", "Citation": "", "Keywords": ""}, {"Name": "Chartseer: Interactive steering exploratory visual analysis with machine intelligence", "Authors": ["Jian Zhao", "Mingming Fan", "Mi Feng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "During exploratory visual analysis (EVA), analysts need to continually determine which subsequent activities to perform, such as which data variables to explore or how to present data variables visually. Due to the vast combinations of data variables and visual encodings that are possible, it is often challenging to make such decisions. Further, while performing local explorations, analysts often fail to attend to the holistic picture that is emerging from their analysis, leading them to improperly steer their EVA. These issues become even more impactful in the real world analysis scenarios where EVA occurs in multiple asynchronous sessions that could be completed by one or more analysts. To address these challenges, this work proposes ChartSeer, a system that uses machine intelligence to enable analysts to visually monitor the current state of an EVA and effectively identify future activities to perform. ChartSeer?\u2026", "IdName": "zhao2020chartseer", "Citation": "", "Keywords": ""}, {"Name": "Accessible or not? an empirical investigation of Android app accessibility", "Authors": ["Sen Chen", "Chunyang Chen", "Lingling Fan", "Mingming Fan", "Xian Zhan", "Yang Liu"], "Sources": "IEEE Transactions on Software Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Mobile apps provide new opportunities to people with disabilities to act independently in the world. Following the law of the US, EU, mobile OS vendors such as Google and Apple have included accessibility features in their mobile systems and provide a set of guidelines and toolsets for ensuring mobile app accessibility. Motivated by this trend, researchers have conducted empirical studies by using the inaccessibility issue rate of each page (i.e., screen level) to represent the characteristics of mobile app accessibility. However, there still lacks an empirical investigation directly focusing on the issues themselves (i.e., issue level) to unveil more fine-grained findings, due to the lack of an effective issue detection method and a relatively comprehensive dataset of issues. To fill in this literature gap, we first propose an automated app page exploration tool, named Xbot, to facilitate app accessibility testing and?\u2026", "IdName": "chen2021accessible", "Citation": "", "Keywords": ""}, {"Name": "Human-ai collaboration for ux evaluation: Effects of explanation and synchronization", "Authors": ["Mingming Fan", "Xianyou Yang", "TszTung Yu", "Q Vera Liao", "Jian Zhao"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool-AI Assistant-with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable?\u2026", "IdName": "fan2022human", "Citation": "", "Keywords": ""}, {"Name": "\u201cI Choose Assistive Devices That Save My Face\u201d A Study on Perceptions of Accessibility and Assistive Technology Use Conducted in China", "Authors": ["Franklin Mingzhe Li", "Di Laura Chen", "Mingming Fan", "Khai N Truong"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " Despite the potential benefits of assistive technologies (ATs) for people with various disabilities, only around 7% of Chinese with disabilities have had an opportunity to use ATs. Even for those who have used ATs, the abandonment rate was high. Although China has the world\u2019s largest population with disabilities, prior research exploring how ATs are used and perceived, and why ATs are abandoned have been conducted primarily in North America and Europe. In this paper, we present an interview study conducted in China with 26 people with various disabilities to understand their practices, challenges, perceptions, and misperceptions of using ATs. From the study, we learned about factors that influence AT adoption practices (e.g., misuse of accessible infrastructure, issues with replicating existing commercial ATs), challenges using ATs in social interactions (e.g., Chinese stigma), and misperceptions about ATs?\u2026", "IdName": "li2021choose", "Citation": "", "Keywords": ""}, {"Name": "Automatic Detection of Usability Problem Encounters in Think-Aloud Sessions", "Authors": ["Mingming Fan", "Yue Li", "Khai N Truong"], "Sources": "ACM Transactions on Interactive Intelligent Systems (TiiS)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Think-aloud protocols are a highly valued usability testing method for identifying usability problems. Despite the value of conducting think-aloud usability test sessions, analyzing think-aloud sessions is often time-consuming and labor-intensive. Consequently, previous research has urged the community to develop techniques to support fast-paced analysis. In this work, we took the first step to design and evaluate machine learning (ML) models to automatically detect usability problem encounters based on users\u2019 verbalization and speech features in think-aloud sessions. Inspired by recent research that shows subtle patterns in users\u2019 verbalizations and speech features tend to occur when they encounter problems, we examined whether these patterns can be utilized to improve the automatic detection of usability problems. We first conducted and recorded think-aloud sessions and then examined the effect of different?\u2026", "IdName": "fan2020automatic", "Citation": "", "Keywords": ""}, {"Name": "Eyelid gestures on mobile devices for people with motor impairments", "Authors": ["Mingming Fan", "Zhen Li", "Franklin Mingzhe Li"], "Sources": "Proceedings of the 22nd International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": " Eye-based interactions for people with motor impairments have often used clunky or specialized equipment (e.g., eye-trackers with non-mobile computers) and primarily focused on gaze and blinks. However, two eyelids can open and close for different duration in different orders to form various eyelid gestures. We take a first step to design, detect, and evaluate a set of eyelid gestures for people with motor impairments on mobile devices. We present an algorithm to detect nine eyelid gestures on smartphones in real-time and evaluate it with twelve able-bodied people and four people with severe motor impairments in two studies. The results of the study with people with motor-impairments show that the algorithm can detect the gestures with .76 and .69 overall accuracy in user-dependent and user-independent evaluations. Moreover, we design and evaluate a gesture mapping scheme allowing for navigating mobile?\u2026", "IdName": "fan2020eyelid", "Citation": "", "Keywords": ""}, {"Name": "Older adults\u2019 think-aloud verbalizations and speech features for identifying user experience problems", "Authors": ["Mingming Fan", "Qiwen Zhao", "Vinita Tibdewal"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Subtle patterns in users\u2019 think-aloud (TA) verbalizations and speech features are shown to be telltale signs of User Experience (UX) problems. However, such patterns were uncovered among young adults. Whether such patterns apply for older adults remains unknown. We conducted TA usability testing with older adults using physical and digital products. We analyzed their verbalizations, extracted speech features, identified UX problems, and uncovered the patterns that indicate UX problems. Our results show that when older adults encounter problems, their verbalizations tend to include observations (remarks), negations, question words and words with negative sentiments; and their voices tend to include high loudness, high pitch and high speech rate. We compare these subtle patterns with those of young adults uncovered in recent studies and discuss the implications of these patterns for the design of Human?\u2026", "IdName": "fan2021older", "Citation": "", "Keywords": ""}, {"Name": "Vmirror: Enhancing the interaction with occluded or distant objects in vr with virtual mirrors", "Authors": ["Nianlong Li", "Zhengquan Zhang", "Can Liu", "Zengyao Yang", "Yinan Fu", "Feng Tian", "Teng Han", "Mingming Fan"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Interacting with out of reach or occluded VR objects can be cumbersome. Although users can change their position and orientation, such as via teleporting, to help observe and select, doing so frequently may cause loss of spatial orientation or motion sickness. We present vMirror, an interactive widget leveraging reflection of mirrors to observe and select distant or occluded objects. We first designed interaction techniques for placing mirrors and interacting with objects through mirrors. We then conducted a formative study to explore a semi-automated mirror placement method with manual adjustments. Next, we conducted a target-selection experiment to measure the effect of the mirror\u2019s orientation on users\u2019 performance. Results showed that vMirror can be as efficient as direct target selection for most mirror orientations. We further compared vMirror with teleport technique in a virtual treasure hunt game and?\u2026", "IdName": "li2021vmirror", "Citation": "", "Keywords": ""}, {"Name": "Communication in immersive social virtual reality: A systematic review of 10 years\u2019 studies", "Authors": ["Xiaoying Wei", "Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the Tenth International Symposium of Chinese CHI", "PublishedYears": "2022", "Doi": "", "Abstracts": "As virtual reality (VR) technologies have improved in the past decade, more research has investigated how they could support more effective communication in various contexts to improve collaboration and social connectedness. However, there was no literature to summarize the uniqueness VR provided and put forward guidance for designing social VR applications for better communication. To understand how VR has been designed and used to facilitate communication in different contexts, we conducted a systematic review of the studies investigating communication in social VR in the past ten years by following the PRISMA guidelines. We highlight current practices and challenges and identify research opportunities to improve the design of social VR to better support communication and make social VR more accessible.", "IdName": "wei2022communication", "Citation": "", "Keywords": ""}, {"Name": "CoUX: collaborative visual analysis of think-aloud usability test videos for digital interfaces", "Authors": ["Ehsan Jahangirzadeh Soure", "Emily Kuang", "Mingming Fan", "Jian Zhao"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Reviewing a think-aloud video is both time-consuming and demanding as it requires UX (user experience) professionals to attend to many behavioral signals of the user in the video. Moreover, challenges arise when multiple UX professionals need to collaborate to reduce bias and errors. We propose a collaborative visual analytics tool, CoUX, to facilitate UX evaluators collectively reviewing think-aloud usability test videos of digital interfaces. CoUX seamlessly supports usability problem identification, annotation, and discussion in an integrated environment. To ease the discovery of usability problems, CoUX visualizes a set of problem-indicators based on acoustic, textual, and visual features extracted from the video and audio of a think-aloud session with machine learning. CoUX further enables collaboration amongst UX evaluators for logging, commenting, and consolidating the discovered problems with a?\u2026", "IdName": "soure2021coux", "Citation": "", "Keywords": ""}, {"Name": "Mouill\u00e9: Exploring wetness illusion on fingertips to enhance immersive experience in vr", "Authors": ["Teng Han", "Sirui Wang", "Sijia Wang", "Xiangmin Fan", "Jie Liu", "Feng Tian", "Mingming Fan"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Providing users with rich sensations is beneficial to enhance their immersion in Virtual Reality (VR) environments. Wetness is one such imperative sensation that affects users' sense of comfort and helps users adjust grip force when interacting with objects. Researchers have recently begun to explore ways to create wetness illusions, primarily on a user's face or body skin. In this work, we extended this line of research by creating wetness illusion on users' fingertips. We first conducted a user study to understand the effect of thermal and tactile feedback on users' perceived wetness sensation. Informed by the findings, we designed and evaluated a prototype---Mouill\u00e9---that provides various levels of wetness illusions on fingertips for both hard and soft items when users squeeze, lift, or scratch it. Study results indicated that users were able to feel wetness with different levels of temperature changes and they were able?\u2026", "IdName": "han2020mouille", "Citation": "", "Keywords": ""}, {"Name": "Synapse: interactive guidance by demonstration with trial-and-error support for older adults to use smartphone apps", "Authors": ["Xiaofu Jin", "Xiaozhu Hu", "Xiaoying Wei", "Mingming Fan"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2022", "Doi": "", "Abstracts": "As smartphones are widely adopted, mobile applications (apps) are emerging to provide critical services such as food delivery and telemedicine. While bring convenience to everyday life, this trend may create barriers for older adults who tend to be less tech-savvy than young people. In-person or screen sharing support is helpful but limited by the help-givers' availability. Video tutorials can be useful but require users to switch contexts between watching the tutorial and performing the corresponding actions in the app, which is cumbersome to do on a mobile phone. Although interactive tutorials have been shown to be promising, none was designed for older adults. Furthermore, the trial-and-error approach has been shown to be beneficial for older adults, but they often lack support to use the approach. Inspired by both interactive tutorials and trial-and-error approach, we designed an app-independent mobile service?\u2026", "IdName": "jin2022synapse", "Citation": "", "Keywords": ""}, {"Name": "Douleur: creating pain sensation with chemical stimulant to enhance user experience in virtual reality", "Authors": ["Chutian Jiang", "Yanjun Chen", "Mingming Fan", "Liuping Wang", "Luyao Shen", "Nianlong Li", "Wei Sun", "Yu Zhang", "Feng Tian", "Teng Han"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2021", "Doi": "", "Abstracts": "The imitation of pain sensation in Virtual Reality is considered valuable for safety education and training but has been seldom studied. This paper presents Douleur, a wearable haptic device that renders intensity-adjustable pain sensations with chemical stimulants. Different from mechanical, thermal, or electric stimulation, chemical-induced pain is more close to burning sensations and long-lasting. Douleur consists of a microfluidic platform that precisely emits capsaicin onto the skin and a microneedling component to help the stimulant penetrate the epidermis layer to activate the trigeminal nerve efficiently. Moreover, it embeds a Peltier module to apply the heating or cooling stimulus to the affected area to adjust the level of pain on the skin. To better understand how people would react to the chemical stimulant, we conducted a first study to quantify the enhancement of the sensation by changing the capsaicin?\u2026", "IdName": "jiang2021douleur", "Citation": "", "Keywords": ""}, {"Name": "\" I am the follower, also the boss\": Exploring Different Levels of Autonomy and Machine Forms of Guiding Robots for the Visually Impaired", "Authors": ["Yan Zhang", "Ziang Li", "Haole Guo", "Luyao Wang", "Qihe Chen", "Wenjie Jiang", "Mingming Fan", "Guyue Zhou", "Jiangtao Gong"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Guiding robots, in the form of canes or cars, have recently been explored to assist blind and low vision (BLV) people. Such robots can provide full or partial autonomy when guiding. However, the pros and cons of different forms and autonomy for guiding robots remain unknown. We sought to fill this gap. We designed autonomy-switchable guiding robotic cane and car. We conducted a controlled lab-study (N=12) and a field study (N=9) on BLV. Results showed that full autonomy received better walking performance and subjective ratings in the controlled study, whereas participants used more partial autonomy in the natural environment as demanding more control. Besides, the car robot has demonstrated abilities to provide a higher sense of safety and navigation efficiency compared with the cane robot. Our findings offered empirical evidence about how the BLV community perceived different machine forms and?\u2026", "IdName": "zhang2023follower", "Citation": "", "Keywords": ""}, {"Name": "\"It Feels Like Being Locked in A Cage\": Understanding Blind or Low Vision Streamers' Perceptions of Content Curation Algorithms", "Authors": ["Ethan Z. Rong", "Mo Morgana Zhou", "Zhicong Lu", "Mingming Fan"], "Sources": "Designing Interactive Systems Conference", "PublishedYears": "2022", "Doi": "", "Abstracts": "Blind or low vision (BLV) people were recently reported to be live streamers on the online platforms that employed content curation algorithms. Recent research uncovered perceived algorithmic biases suppressing the content created by marginalized populations (e.g., people of color, the LGBT+ community, and content creators of lower socioeconomic status). However, little is known about how BLV streamers, as a marginalized population, perceive the effects of the algorithms adopted by live streaming platforms. We interviewed BLV streamers (N=19) of Douyin \u2014 a popular live stream platform in China \u2014 to understand their perceptions of algorithms, perceived challenges, and mitigation strategies. Our findings show the perceived factors contributing to disadvantages under algorithmic evaluation of BLV streamers\u2019 content (e.g., issues with filming and timely interaction with viewers) and perceived algorithmic?\u2026", "IdName": "rong2022feels", "Citation": "", "Keywords": ""}, {"Name": "Bridging the generational gap: exploring how virtual reality supports remote communication between grandparents and grandchildren", "Authors": ["Xiaoying Wei", "Yizheng Gu", "Emily Kuang", "Xian Wang", "Beiyan Cao", "Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "When living apart, grandparents and grandchildren often use audio-visual communication approaches to stay connected. However, these approaches seldom provide sufficient companionship and intimacy due to a lack of co-presence and spatial interaction, which can be fulfilled by immersive virtual reality (VR). To understand how grandparents and grandchildren might leverage VR to facilitate their remote communication and better inform future design, we conducted a user-centered participatory design study with twelve pairs of grandparents and grandchildren. Results show that VR affords casual and equal communication by reducing the generational gap, and promotes conversation by offering shared activities as bridges for connection. Participants preferred resemblant appearances on avatars for conveying well-being but created ideal selves for gaining playfulness. Based on the results, we contribute eight?\u2026", "IdName": "wei2023bridging", "Citation": "", "Keywords": ""}, {"Name": "\"I Don't Want People to Look At Me Differently\": Designing User-Defined Above-the-Neck Gestures for People with Upper Body Motor Impairments", "Authors": ["Xuan Zhao", "Mingming Fan", "Teng Han"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recent research proposed eyelid gestures for people with upper-body motor impairments (UMI) to interact with smartphones without finger touch. However, such eyelid gestures were designed by researchers. It remains unknown what eyelid gestures people with UMI would want and be able to perform. Moreover, other above-the-neck body parts (e.g., mouth, head) could be used to form more gestures. We conducted a user study in which 17 people with UMI designed above-the-neck gestures for 26 common commands on smartphones. We collected a total of 442 user-defined gestures involving the eyes, the mouth, and the head. Participants were more likely to make gestures with their eyes and preferred gestures that were simple, easy-to-remember, and less likely to draw attention from others. We further conducted a survey (N=24) to validate the usability and acceptance of these user-defined gestures. Results?\u2026", "IdName": "zhao2022don", "Citation": "", "Keywords": ""}, {"Name": "\u201cI need to be professional until my new team uses emoji, GIFs, or memes first\u201d: New Collaborators\u2019 Perspectives on Using Non-Textual Communication in Virtual Workspaces", "Authors": ["Esha Shandilya", "Mingming Fan", "Garreth W Tigwell"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": " Virtual workspaces rapidly increased during the COVID-19 pandemic, and for many new collaborators, working remotely was their first introduction to their colleagues. Building rapport is essential for a healthy work environment, and while this can be achieved through non-textual responses within chat-based systems (e.g., emoji, GIF, stickers, memes), those non-textual responses are typically associated with personal relationships and informal settings. We studied the experiences of new collaborators (questionnaire N=49; interview N=14) in using non-textual responses to communicate with unacquainted teams and the effect of non-textual responses on new collaborators\u2019 interpersonal bonds. We found new collaborators selectively and progressively use non-textual responses to establish interpersonal bonds. Moreover, the use of non-textual responses has exposed several limitations when used on various?\u2026", "IdName": "shandilya2022need", "Citation": "", "Keywords": ""}, {"Name": "Understanding older adults\u2019 perceptions and challenges in using AI-enabled everyday technologies", "Authors": ["Esha Shandilya", "Mingming Fan"], "Sources": "Proceedings of the Tenth International Symposium of Chinese CHI", "PublishedYears": "2022", "Doi": "", "Abstracts": "Artificial intelligence (AI)-enabled everyday technologies could help address age-related challenges like physical impairments and cognitive decline. While recent research studied older adults\u2019 experiences with specific AI-enabled products (e.g., conversational agents and assistive robots), it remains unknown how older adults perceive and experience current AI-enabled everyday technologies in general, which could impact their adoption of future AI-enabled products. We conducted a survey study (N=41) and semi-structured interviews (N=15) with older adults to understand their experiences and perceptions of AI. We found that older adults were enthusiastic about learning and using AI-enabled products, but they lacked learning avenues. Additionally, they worried when AI-enabled products outwitted their expectations, intruded on their privacy, or impacted their decision-making skills. Therefore, they held mixed?\u2026", "IdName": "shandilya2022understanding", "Citation": "", "Keywords": ""}, {"Name": "\" Too old to bank digitally?\": A Survey of Banking Practices and Challenges Among Older Adults in China", "Authors": ["Xiaofu Jin", "Emily Kuang", "Mingming Fan"], "Sources": "ACM SIGCHI Conference on Designing Interactive Systems Conference 2021 (DIS?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " The banking industry has been integrating digital technologies globally. However, accepting new technologies is challenging in particular for older adults. We focus on older adults\u2019 banking experiences in China, where digital transactions have been growing rapidly, to provide a perspective on how they adapt to this trend. We conducted an online survey with 155 older adults who are 60 or above (M = 70, SD = 9) from 18 provinces to explore their banking practices and challenges. Our results show that older adults conduct banking transactions frequently. However, few do so using digital platforms despite long wait times in physical banks. The main concerns reported by them are about security and usability. Nonetheless, they hold a positive attitude towards digital platforms (e.g., apps, virtual banks). Interestingly, age and gender have significant effects on particular banking behaviors. We discuss our findings in the?\u2026", "IdName": "jin2021too", "Citation": "", "Keywords": ""}]