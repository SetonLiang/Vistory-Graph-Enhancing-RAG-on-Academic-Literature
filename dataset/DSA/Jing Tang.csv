Year,Sources,Name,Authors,First Author,Chinese/English,Abstract,Venues,doi,Citation,Id,Keywords
2021,Advances in Neural Information Processing Systems (NeurIPS) 34,Learning to Iteratively Solve Routing Problems with Dual-Aspect Collaborative Transformer,"Yining Ma, Jingwen Li, Zhiguang Cao, Wen Song, Le Zhang, Zhenghua Chen, Jing Tang",Yining Ma,English,"Recently, Transformer has become a prevailing deep architecture for solving vehicle routing problems (VRPs). However, it is less effective in learning improvement models for VRP because its positional encoding (PE) method is not suitable in representing VRP solutions. This paper presents a novel Dual-Aspect Collaborative Transformer (DACT) to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. Moreover, the positional features are embedded through a novel cyclic positional encoding (CPE) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions (ie, cyclic sequences). We train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. We apply DACT to solve the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP). Results show that our DACT outperforms existing Transformer based improvement models, and exhibits much better generalization performance across different problem sizes on synthetic and benchmark instances, respectively.",Conference paper,https://proceedings.neurips.cc/paper_files/paper/2021/hash/5c53292c032b6cb8510041c54274e65f-Abstract.html,113,ma2021learning,"Vehicle Routing problems,Dual-Aspect Collaborative Transformer"
2020,2020 ACM International Conference on Multimedia (ACM MM),Campus3D: A Photogrammetry Point Cloud Benchmark for Hierarchical Understanding of Outdoor Scene,"Xinke Li, Chongshou Li, Zekun Tong, Andrew Lim, Junsong Yuan, Yuwei Wu, Jing Tang, Raymond Huang",Xinke Li,English,"Learning on 3D scene-based point cloud has received extensive attention as its promising application in many fields, and well-annotated and multisource datasets can catalyze the development of those data-driven approaches. To facilitate the research of this area, we present a richly-annotated 3D point cloud dataset for multiple outdoor scene understanding tasks and also an effective learning framework for its hierarchical segmentation task. The dataset was generated via the photogrammetric processing on unmanned aerial vehicle (UAV) images of the National University of Singapore (NUS) campus, and has been point-wisely annotated with both hierarchical and instance-based labels. Based on it, we formulate a hierarchical learning problem for 3D point cloud segmentation and propose a measurement evaluating consistency across various hierarchies. To solve this problem, a two-stage method including?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3394171.3413661,45,li2020campus3d,None
2021,Proceedings of the 2021 SIGMOD International Conference on Management of?…,Do the Rich Get Richer? Fairness Analysis for Blockchain Incentives,"Yuming Huang, Jing Tang, Qianhao Cong, Andrew Lim, Jianliang Xu",Yuming Huang,English,"Proof-of-Work (PoW) is the most widely adopted incentive model in current blockchain systems, which unfortunately is energy inefficient. Proof-of-Stake (PoS) is then proposed to tackle the energy issue. The rich-get-richer concern of PoS has been heavily debated in the blockchain community. The debate is centered around the argument that whether rich miners possessing more stakes will obtain higher staking rewards and further increase their potential income in the future. In this paper, we define two types of fairness, i.e., expectational fairness and robust fairness, that are useful for answering this question. In particular, expectational fairness illustrates that the expected income of a miner is proportional to her initial investment, indicating that the expected return on investment is a constant. To better capture the uncertainty of mining outcomes, robust fairness is proposed to characterize whether the return on?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3448016.3457285,39,huang2021rich,"Blockchain, Proof-of-Stake"
2020,The VLDB Journal,Efficient Approximation Algorithms for Adaptive Influence Maximization,"Keke Huang, Jing Tang, Kai Han, Xiaokui Xiao, Wei Chen, Aixin Sun, Xueyan Tang, Andrew Lim",Keke Huang,English," Given a social network G and an integer k, the influence maximization (IM) problem asks for a seed set S of k nodes from G to maximize the expected number of nodes influenced via a propagation model. The majority of the existing algorithms for the IM problem are developed only under the non-adaptive setting, i.e., where all k seed nodes are selected in one batch without observing how they influence other users in real world. In this paper, we study the adaptive IM problem where the k seed nodes are selected in batches of equal size b, such that the i-th batch is identified after the actual influence results of the former  batches are observed. In this paper, we propose the first practical algorithm for the adaptive IM problem that could provide the worst-case approximation guarantee of , where  and  is a user-specified parameter. In particular, we propose a general?…",Article,https://link.springer.com/article/10.1007/s00778-020-00615-8,39,huang2020efficient,"Social networks,Influence maximization,Adaptive influence maximization,Adaptive stochastic optimization,Approximation algorithms"
2020,Proceedings of the VLDB Endowment,Pricing Influential Nodes in Online Social Networks,"Yuqing Zhu, Jing Tang, Xueyan Tang",Yuqing Zhu,English,"Influential nodes with rich connections in online social networks (OSNs) are of great values to initiate marketing campaigns. However, the potential influence spread that can be generated by these influential nodes is hidden behind the structures of OSNs, which are often held by OSN providers and unavailable to advertisers for privacy concerns. A social advertising model known as influencer marketing is to have OSN providers offer and price candidate nodes for advertisers to purchase for seeding marketing campaigns. In this setting, a reasonable price profile for the candidate nodes should effectively reflect the expected influence gain they can bring in a marketing campaign. In this paper, we study the problem of pricing the influential nodes based on their expected influence spread to help advertisers select the initiators of marketing campaigns without the knowledge of OSN structures. We design a function?…",Article,https://dl.acm.org/doi/abs/10.14778/3401960.3401961,21,zhu2020pricing,Online social network
2020,2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS),An Analysis of Blockchain Consistency in Asynchronous Networks: Deriving a Neat Bound,"Jun Zhao, Jing Tang, Zengxiang Li, Huaxiong Wang Wang, Kwok-Yan Lam, Kaiping Xue",Jun Zhao,English,"Formal analyses of blockchain protocols have received much attention recently. Consistency results of Nakamoto's blockchain protocol are often expressed in a quantity c, which denotes the expected number of network delays before some block is mined. With μ (resp., ν) denoting the fraction of computational power controlled by benign miners (resp., the adversary), where μ+ν =1, we prove for the first time that to ensure the consistency property of Nakamoto's blockchain protocol in an asynchronous network, it suffices to have c to be just slightly greater than 2μ/(ln(μ/ν)). Such a result is both neater and stronger than existing ones. In the proof, we formulate novel Markov chains which characterize the numbers of mined blocks in different rounds.",Conference paper,https://ieeexplore.ieee.org/abstract/document/9355787/,19,zhao2020analysis,"Blockchain, consistency, asynchronous networks, Markov chains"
2022,ACM Transactions on Database Systems (TODS),Influence Maximization Revisited: Efficient Sampling with Bound Tightened,"Qintian Guo, Sibo Wang, Zhewei Wei, Wenqing Lin, Jing Tang",Qintian Guo,English,"Given a social network G with n nodes and m edges, a positive integer k, and a cascade model C, the influence maximization (IM) problem asks for k nodes in G such that the expected number of nodes influenced by the k nodes under cascade model C is maximized. The state-of-the-art approximate solutions run in O(k(n+m)log n/ε2) expected time while returning a (1 - 1/e - ε) approximate solution with at least 1 - 1/n probability. A key phase of these IM algorithms is the random reverse reachable (RR) set generation, and this phase significantly affects the efficiency and scalability of the state-of-the-art IM algorithms. In this article, we present a study on this key phase and propose an efficient random RR set generation algorithm under IC model. With the new algorithm, we show that the expected running time of existing IM algorithms under IC model can be improved to O(k ? n log n ?2), when for any node v, the total?…",Article,https://dl.acm.org/doi/abs/10.1145/3533817,18,guo2022influence,"Influence maximization, sampling"
2021,Proceedings of the ACM on Measurement and Analysis of Computing Systems 5 (1?…,Revisiting Modified Greedy Algorithm for Monotone Submodular Maximization with a Knapsack Constraint,"Jing Tang, Xueyan Tang, Andrew Lim, Kai Han, Chongshou Li, Junsong Yuan",Jing Tang,English,"Monotone submodular maximization with a knapsack constraint is NP-hard. Various approximation algorithms have been devised to address this optimization problem. In this paper, we revisit the widely known modified greedy algorithm. First, we show that this algorithm can achieve an approximation factor of 0.405, which significantly improves the known factors of 0.357 given by Wolsey and (1-1/e)/2\approx 0.316 given by Khuller et al. More importantly, our analysis closes a gap in Khuller et al.'s proof for the extensively mentioned approximation factor of (1-1/\sqrte )\approx 0.393 in the literature to clarify a long-standing misconception on this issue. Second, we enhance the modified greedy algorithm to derive a data-dependent upper bound on the optimum. We empirically demonstrate the tightness of our upper bound with a real-world application. The bound enables us to obtain a data-dependent ratio typically?…",Article,https://dl.acm.org/doi/abs/10.1145/3447386,18,tang2021revisiting,"Submodular maximization, Greedy algorithm, Approximation guarantee"
2020,2020 IEEE 36th International Conference on Data Engineering (ICDE),Efficient Approximation Algorithms for Adaptive Target Profit Maximization,"Keke Huang, Jing Tang, Xiaokui Xiao, Aixin Sun, Andrew Lim",Keke Huang,English,"Given a social network G, the profit maximization (PM) problem asks for a set of seed nodes to maximize the profit, i.e., revenue of influence spread less the cost of seed selection. The target profit maximization (TPM) problem, which generalizes the PM problem, aims to select a subset of seed nodes from a target user set T to maximize the profit. Existing algorithms for PM mostly consider the nonadaptive setting, where all seed nodes are selected in one batch without any knowledge on how they may influence other users. In this paper, we study TPM in adaptive setting, where the seed users are selected through multiple batches, such that the selection of a batch exploits the knowledge of actual influence in the previous batches. To acquire an overall understanding, we study the adaptive TPM problem under both the oracle model and the noise model, and propose ADG and AddATP algorithms to address them with?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/9101853/,18,huang2020efficient,"target profit maximization, social networks, approximation algorithms"
2021,International Conference on Machine Learning,Optimal Streaming Algorithms for Multi-Armed Bandits,"Tianyuan Jin, Keke Huang, Jing Tang, Xiaokui Xiao",Tianyuan Jin,English,"This paper studies two variants of the best arm identification (BAI) problem under the streaming model, where we have a stream of n arms with reward distributions supported on [0, 1] with unknown means. The arms in the stream are arriving one by one, and the algorithm cannot access an arm unless it is stored in a limited size memory. We first study the streaming\epslion-topk-arms identification problem, which asks for k arms whose reward means are lower than that of the k-th best arm by at most\epsilon with probability at least 1-\delta. For general\epsilon\in (0, 1), the existing solution for this problem assumes k= 1 and achieves the optimal sample complexity O (\frac {n}{\epsilon^ 2}\log\frac {1}{\delta}) using O (\log^*(n)) memory and a single pass of the stream. We propose an algorithm that works for any k and achieves the optimal sample complexity O (\frac {n}{\epsilon^ 2}\log\frac {k}{\delta}) using a single-arm memory and a single pass of the stream. Second, we study the streaming BAI problem, where the objective is to identify the arm with the maximum reward mean with at least 1-\delta probability, using a single-arm memory and as few passes of the input stream as possible. We present a single-arm-memory algorithm that achieves a near instance-dependent optimal sample complexity within O (\log\Delta_2^{-1}) passes, where\Delta_2 is the gap between the mean of the best arm and that of the second best arm.",Conference paper,http://proceedings.mlr.press/v139/jin21a.html,15,jin2021optimal,best arm identification
2021,International Conference on Machine Learning,Almost Optimal Anytime Algorithm for Batched Multi-Armed Bandits,"Tianyuan Jin, Jing Tang, Pan Xu, Keke Huang, Xiaokui Xiao, Quanquan Gu",Tianyuan Jin,English,"In batched multi-armed bandit problems, the learner can adaptively pull arms and adjust strategy in batches. In many real applications, not only the regret but also the batch complexity need to be optimized. Existing batched bandit algorithms usually assume that the time horizon T is known in advance. However, many applications involve an unpredictable stopping time. In this paper, we study the anytime batched multi-armed bandit problem. We propose an anytime algorithm that achieves the asymptotically optimal regret for exponential families of reward distributions with $ O (\log\log T\ilog^{\alpha}(T)) $\footnote {Notation\ilog^{\alpha}(T) is the result of iteratively applying the logarithm function on T for\alpha times, eg,\ilog^{3}(T)=\log\log\log T.} batches, where . Moreover, we prove that for any constant c> 0, no algorithm can achieve the asymptotically optimal regret within c\log\log T batches.",Conference paper,http://proceedings.mlr.press/v139/jin21c.html,14,jin2021almost,multi-armed bandit
2021,International Conference on Machine Learning,Randomized Algorithms for Submodular Function Maximization with a -System Constraint,"Shuang Cui, Kai Han, Tianshuai Zhu, Jing Tang, Benwei Wu, He Huang",Shuang Cui,English,"Submodular optimization has numerous applications such as crowdsourcing and viral marketing. In this paper, we study the problem of non-negative submodular function maximization subject to a -system constraint, which generalizes many other important constraints in submodular optimization such as cardinality constraint, matroid constraint, and -extendible system constraint. The existing approaches for this problem are all based on deterministic algorithmic frameworks, and the best approximation ratio achieved by these algorithms (for a general submodular function) is . We propose a randomized algorithm with an improved approximation ratio of , while achieving nearly-linear time complexity significantly lower than that of the state-of-the-art algorithm. We also show that our algorithm can be further generalized to address a stochastic case where the elements can be adaptively selected, and propose an approximation ratio of  for the adaptive optimization case. The empirical performance of our algorithms is extensively evaluated in several applications related to data mining and social computing, and the experimental results demonstrate the superiorities of our algorithms in terms of both utility and efficiency.",Conference paper,https://proceedings.mlr.press/v139/cui21b.html,12,cui2021randomized,"Submodular maximization, k-system constraint,"
2023,Proceedings of the ACM Web Conference (WWW),Node-wise Diffusion for Scalable Graph Learning,"Keke Huang, Jing Tang, Juncheng Liu, Renchi Yang, Xiaokui Xiao",Keke Huang,English," Graph Neural Networks (GNNs) have shown superior performance for semi-supervised learning of numerous web applications, such as classification on web services and pages, analysis of online social networks, and recommendation in e-commerce. The state of the art derives representations for all nodes in graphs following the same diffusion (message passing) model without discriminating their uniqueness. However, (i) labeled nodes involved in model training usually account for a small portion of graphs in the semi-supervised setting, and (ii) different nodes locate at different graph local contexts and it inevitably degrades the representation qualities if treating them undistinguishedly in diffusion.  To address the above issues, we develop NDM, a universal node-wise diffusion model, to capture the unique characteristics of each node in diffusion, by which NDM is able to yield high-quality node representations?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3543507.3583408,11,huang2023node,"Graph Neural Networks, scalability , semi-supervised classification"
2023,IEEE Transactions on Knowledge and Data Engineering,2-hop+ Sampling: Efficient and Effective Influence Estimation,"Yuqing Zhu, Jing Tang, Xueyan Tang, Sibo Wang, Andrew Lim",Yuqing Zhu,English,"With rapidly growing sizes of online social networks, computational challenges arise in analyzing the diffusion process over networks. Sampling methods are commonly used to study the cascade effect and estimate users’ influence. In this paper, we propose a brand-new sampling method, called 2-hop+ sampling for quickly and accurately estimating the cascade size generated by a set of seed users under the independent cascade model. Our method generates only samples with at least one 2-hop live path from the source to reduce the number of samples. We further enhance the sampling efficiency of our method by a    technique. Moreover, we improve the generalized stopping rule algorithm to obtain an   -estimate of the mean of random variables with fewer samples needed. Extensive experiments with real-world datasets show that our techniques can significantly improve the estimation efficiency?…",Article,https://ieeexplore.ieee.org/abstract/document/9470928/,9,zhu20212,"Online social networks, influence estimation, sampling"
2021,Proceedings of the 2021 SIGMOD International Conference on Management of?…,Efficient and Effective Algorithms for Revenue Maximization in Social Advertising,"Kai Han, Benwei Wu, Jing Tang, Shuang Cui, Cigdem Aslay, Laks VS Lakshmanan",Kai Han,English,"We consider the revenue maximization problem in social advertising, where a social network platform owner needs to select seed users for a group of advertisers, each with a payment budget, such that the total expected revenue that the owner gains from the advertisers by propagating their ads in the network is maximized. Previous studies on this problem show that it is intractable and present approximation algorithms. We revisit this problem from a fresh perspective and develop novel efficient approximation algorithms, both under the setting where an exact influence oracle is assumed and under one where this assumption is relaxed. Our approximation ratios significantly improve upon the previous ones. Furthermore, we empirically show, using extensive experiments on four datasets, that our algorithms considerably outperform the existing methods on both the solution quality and computation efficiency.",Conference paper,https://dl.acm.org/doi/abs/10.1145/3448016.3459243,9,han2021efficient,"Social networks,Social advertising"
2023,arXiv preprint arXiv:2310.02954,Dq-lore: Dual queries with low rank approximation re-ranking for in-context learning,"Jing Xiong, Zixuan Li, Chuanyang Zheng, Zhijiang Guo, Yichun Yin, Enze Xie, Zhicheng Yang, Qingxing Cao, Haiming Wang, Xiongwei Han, Jing Tang, Chengming Li, Xiaodan Liang",Jing Xiong,English,"Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning. A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning. In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning. Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge. Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge. Through extensive experiments, we demonstrate that DQ-LoRe significantly outperforms prior state-of-the-art methods in the automatic selection of exemplars for GPT-4, enhancing performance from 92.5% to 94.2%. Our comprehensive analysis further reveals that DQ-LoRe consistently outperforms retrieval-based approaches in terms of both performance and adaptability, especially in scenarios characterized by distribution shifts. DQ-LoRe pushes the boundaries of in-context learning and opens up new avenues for addressing complex reasoning challenges. We will release the code soon.",Article,https://arxiv.org/abs/2310.02954,8,xiong2023dq,"Large Language Models,Dual Queries and Low-rank approximation Re-ranking"
2022,2022 IEEE 38th International Conference on Data Engineering (ICDE),Distributed Influence Maximization for Large-Scale Online Social Networks,"Jing Tang, Yuqing Zhu, Xueyan Tang, Kai Han",Jing Tang,English,"Thanks to billions of users in online social networks (OSNs), viral marketing becomes one of the most effective promotion channels for various new products or campaigns. Influence maximization is a classic problem in viral marketing, which has been extensively studied in the past two decades. Existing algorithms for influence maximization, however, mostly focus on single machine processing. To address the influence maximization problem on a massive scale, we design distributed algorithms via a cluster of machines, which can effectively speed up the computation while maintaining the state-of-the-art (1 -1/e-c)-approximation guarantee. Our distributed algorithms consist of two building blocks: (i) distributed reverse influence sampling, and (ii) element-distributed maximum coverage. We carry out extensive experiments on real datasets with millions of nodes and billions of edges to demonstrate the scalability of?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/9835215/,4,tang2022distributed,"Influence maximization, Distributed algorithms, Online social networks"
2023,Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and?…,Efficient Approximation Algorithms for Spanning Centrality,"Shiqi Zhang, Renchi Yang, Jing Tang, Xiaokui Xiao, Bo Tang",Shiqi Zhang,English,"Given a graph \mathcalG , the spanning centrality (SC) of an edge e measures the importance of e for \mathcalG to be connected. In practice, SC has seen extensive applications in computational biology, electrical networks, and combinatorial optimization. However, it is highly challenging to compute the SC of all edges (AESC) on large graphs. Existing techniques fail to deal with such graphs, as they either suffer from expensive matrix operations or require sampling numerous long random walks. To circumvent these issues, this paper proposes TGT and its enhanced version TGT+, two algorithms for AESC computation that offers rigorous theoretical approximation guarantees. In particular, TGT remedies the deficiencies of previous solutions by conducting deterministic graph traversals with carefully-crafted truncated lengths. TGT+ further advances TGT in terms of both empirical efficiency and asymptotic?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3580305.3599323,3,zhang2023efficient,"spanning centrality, graph traversal, random walk, eigenvector"
2023,arXiv preprint arXiv:2305.04225,LSGNN: Towards General Graph Neural Network in Node Classification by Local Similarity,"Yuhan Chen, Yihong Luo, Jing Tang, Liang Yang, Siya Qiu, Chuan Wang, Xiaochun Cao",Yuhan Chen,English,"Heterophily has been considered as an issue that hurts the performance of Graph Neural Networks (GNNs). To address this issue, some existing work uses a graph-level weighted fusion of the information of multi-hop neighbors to include more nodes with homophily. However, the heterophily might differ among nodes, which requires to consider the local topology. Motivated by it, we propose to use the local similarity (LocalSim) to learn node-level weighted fusion, which can also serve as a plug-and-play module. For better fusion, we propose a novel and efficient Initial Residual Difference Connection (IRDC) to extract more informative multi-hop information. Moreover, we provide theoretical analysis on the effectiveness of LocalSim representing node homophily on synthetic graphs. Extensive evaluations over real benchmark datasets show that our proposed method, namely Local Similarity Graph Neural Network (LSGNN), can offer comparable or superior state-of-the-art performance on both homophilic and heterophilic graphs. Meanwhile, the plug-and-play model can significantly boost the performance of existing GNNs. Our code is provided at https://github.com/draym28/LSGNN.",Article,https://arxiv.org/abs/2305.04225,3,chen2023lsgnn,"Graph Neural Networks,local similarity"
2023,Proceedings of the ACM Web Conference (WWW),Randomized Pricing with Deferred Acceptance for Revenue Maximization with Submodular Objectives,"He Huang, Kai Han, Shuang Cui, Jing Tang",He Huang,English," A lot of applications in web economics need to maximize the revenue under a budget for payments and also guarantee the truthfulness of users, so Budget-Feasible Mechanism (BFM) Design has aroused great interests during last decade. Most of the existing BFMs concentrate on maximizing a monotone submodular function subject to a knapsack constraint, which is insufficient for many applications with complex objectives or constraints. Observing this, the recent studies (e.g., [4, 5, 11]) have considered non-monotone submodular objectives or more complex constraints such as a k-system constraint. In this study, we follow this line of research and propose truthful BFMs with improved performance bounds for non-monotone submodular objectives with or without a k-system constraint. Our BFMs leverage the idea of providing random prices to users while deferring the decision on the final winning set, and are also?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3543507.3583477,3,huang2023randomized,"mechanism design, Submodular maximization, approximation"
2023,Proceedings of the 37th AAAI Conference on Artificial Intelligence,Practical Parallel Algorithms for Submodular Maximization subject to a Knapsack Constraint with Nearly Optimal Adaptivity,"Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, Zhiyu Li",Shuang Cui,English,"Submodular maximization has wide applications in machine learning and data mining, where massive datasets have brought the great need for designing efficient and parallelizable algorithms. One measure of the parallelizability of a submodular maximization algorithm is its adaptivity complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an (8+ epsilon)-approximation under O (log n) adaptive complexity, which is optimal up to a factor of O (loglog n). Moreover, under slightly larger adaptivity, we also propose approximation algorithms with nearly optimal query complexity of O (n), while achieving better approximation ratios. We show that our algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.",Conference paper,https://ojs.aaai.org/index.php/AAAI/article/view/25885,3,cui2023practical,"Submodular maximization,knapsack constraint"
2022,Proceedings of the ACM on Measurement and Analysis of Computing Systems 6 (3?…,Streaming Algorithms for Constrained Submodular Maximization,"Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, Zhiyu Li",Shuang Cui,English,"It is of great importance to design streaming algorithms for submodular maximization, as many applications (e.g., crowdsourcing) have large volume of data satisfying the well-known ''diminishing returns'' property, which cannot be handled by offline algorithms requiring full access to the whole dataset. However, streaming submodular maximization has been less studied than the offline algorithms due to the hardness brought by more stringent requirements on memory consumption. In this paper, we consider the fundamental problem of Submodular Maximization under k-System and d-Knapsack constraints (SMSK), which has only been successfully addressed by offline algorithms in previous studies, and we propose the first streaming algorithm for it with provable performance bounds. Our approach adopts a novel algorithmic framework dubbed MultiplexGreedy, making it also perform well under a single k-system?…",Article,https://dl.acm.org/doi/abs/10.1145/3570615,3,cui2022streaming,"machine learning, big data, optimization"
2022,Proceedings of the VLDB Endowment,Analysis of Influence Contribution in Social Advertising,"Yuqing Zhu, Jing Tang, Xueyan Tang, Lei Chen",Yuqing Zhu,English,"Online Social Network (OSN) providers usually conduct advertising campaigns by inserting social ads into promoted posts. Whenever a user engages in a promoted ad, she may further propagate the promoted ad to her followers recursively and the propagation process is known as the word-of-mouth effect. In order to spread the promotion cascade widely and efficiently, the OSN provider often tends to select the influencers, who normally have large audiences over the social network, to initiate the advertising campaign. This marketing model, also termed as influencer marketing, has been gaining increasing traction and investment and is rapidly becoming one of the most widely-used channels in digital marketing. In this paper, we formulate the problem for the OSN provider to derive the influence contributions of influencers given the campaign result, considering the viral propagation of the ads, namely influence?…",Article,https://dl.acm.org/doi/abs/10.14778/3489496.3489514,3,zhu2021analysis,"Online Social Network, influence contribution allocation"
2023,Proceedings of the 2023 SIGMOD International Conference on Management of Data,Efficient Estimation of Pairwise Effective Resistance,"Renchi Yang, Jing Tang",Renchi Yang,English,"Given an undirected graph G, the effective resistance r(s,t) measures the dissimilarity of node pair s,t in G, which finds numerous applications in real-world problems, such as recommender systems, combinatorial optimization, molecular chemistry, and electric power networks. Existing techniques towards pairwise effective resistance estimation either trade approximation guarantees for practical efficiency, or vice versa. In particular, the state-of-the-art solution is based on a multitude of Monte Carlo random walks, rendering it rather inefficient in practice, especially on large graphs. Motivated by this, this paper first presents an improved Monte Carlo approach, AMC, which reduces both the length and amount of random walks required without degrading the theoretical accuracy guarantee, through careful theoretical analysis and an adaptive sampling scheme. Further, we develop a greedy approach, GEER, which?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3588696,2,yang2023efficient,"Effective Resistance, Random Walk, Matrix Multiplication"
2022,2022 IEEE 38th International Conference on Data Engineering (ICDE),Cost-Effective Algorithms for Average-Case Interactive Graph Search,"Qianhao Cong, Jing Tang, Yuming Huang, Lei Chen, Yeow Meng Chee",Qianhao Cong,English,"Interactive graph search (IGS) uses human intelligence to locate the target node in hierarchy, which can be applied for image classification, product categorization and searching a database. Specifically, IGS aims to categorize an object from a given category hierarchy via several rounds of interactive queries. In each round of query, the search algorithm picks a category and receives a boolean answer on whether the object is under the chosen category. The main efficiency goal asks for the minimum number of queries to identify the correct hierarchical category for the object. In this paper, we study the average-case interactive graph search (AIGS) problem that aims to minimize the expected number of queries when the objects follow a probability distribution. We propose a greedy search policy that splits the candidate categories as evenly as possible with respect to the probability weights, which offers an approximation?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/9835483/,2,cong2022cost,"Interactive graph search,average-case interactive graph search"
2022,Advances in Neural Information Processing Systems,"Chromatic Correlation Clustering, Revisited","Qing Xiu, Kai Han, Jing Tang, Shuang Cui, He Huang",Qing Xiu,English,"Chromatic Correlation Clustering (CCC)(introduced by Bonchi et al.[6]) is a natural generalization of the celebrated Correlation Clustering (CC) problem, introduced by Bonchi et al.[6]. It models objects with categorical pairwise relationships by an edge-colored graph, and has many applications in data mining, social networks and bioinformatics. We show that there exists a -approximation to the CCC problem based on a Linear Programming (LP) approach, thus improving the best-known approximation ratio of 3 achieved by Klodt et al.[21]. We also present an efficient heuristic algorithm for CCC leveraging a greedy clustering strategy, and conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.",Conference paper,https://proceedings.neurips.cc/paper_files/paper/2022/hash/a781ff9cfb267277937db1818284739f-Abstract-Conference.html,2,xiu2022chromatic,Chromatic Correlation Clustering
2021,arXiv preprint arXiv:2112.00499,Structure-Aware Label Smoothing for Graph Neural Networks,"Yiwei Wang, Yujun Cai, Yuxuan Liang, Wei Wang, Henghui Ding, Muhao Chen, Jing Tang, Bryan Hooi",Yiwei Wang,English,"Representing a label distribution as a one-hot vector is a common practice in training node classification models. However, the one-hot representation may not adequately reflect the semantic characteristics of a node in different classes, as some nodes may be semantically close to their neighbors in other classes. It would cause over-confidence since the models are encouraged to assign full probabilities when classifying every node. While training models with label smoothing can ease this problem to some degree, it still fails to capture the nodes' semantic characteristics implied by the graph structures. In this work, we propose a novel SALS (\textit{Structure-Aware Label Smoothing}) method as an enhancement component to popular node classification models. SALS leverages the graph structures to capture the semantic correlations between the connected nodes and generate the structure-aware label distribution to replace the original one-hot label vectors, thus improving the node classification performance without inference costs. Extensive experiments on seven node classification benchmark datasets reveal the effectiveness of our SALS on improving both transductive and inductive node classification. Empirical results show that SALS is superior to the label smoothing method and enhances the node classification models to outperform the baseline methods.",Article,https://arxiv.org/abs/2112.00499,2,wang2021structure,"Graph Neural Network,Structure-Aware Label Smoothing"
2023,Proceedings of the 27th Conference on Computational Natural Language?…,How Fragile is Relation Extraction under Entity Replacements?,"Yiwei Wang, Bryan Hooi, Fei Wang, Yujun Cai, Yuxuan Liang, Wenxuan Zhou, Jing Tang, Manjuan Duan, Muhao Chen",Yiwei Wang,English,"Relation extraction (RE) aims to extract the relations between entity names from the textual context. In principle, textual context determines the ground-truth relation and the RE models should be able to correctly identify the relations reflected by the textual context. However, existing work has found that the RE models memorize the entity name patterns to make RE predictions while ignoring the textual context. This motivates us to raise the question: are RE models robust to the entity replacements? In this work, we operate the random and type-constrained entity replacements over the RE instances in TACRED and evaluate the state-of-the-art RE models under the entity replacements. We observe the 30%-50% F1 score drops on the state-of-the-art RE models under entity replacements. These results suggest that we need more efforts to develop effective RE models robust to entity replacements. We release the source code at https://github. com/wangywUST/RobustRE.",Conference paper,https://aclanthology.org/2023.conll-1.27/,1,wang2023fragile,Relation extraction
2023,arXiv preprint arXiv:2310.14129,Optimal Batched Best Arm Identification,"Tianyuan Jin, Yu Yang, Jing Tang, Xiaokui Xiao, Pan Xu",Tianyuan Jin,English,"We study the batched best arm identification (BBAI) problem, where the learner's goal is to identify the best arm while switching the policy as less as possible. In particular, we aim to find the best arm with probability  for some small constant  while minimizing both the sample complexity (total number of arm pulls) and the batch complexity (total number of batches). We propose the three-batch best arm identification (Tri-BBAI) algorithm, which is the first batched algorithm that achieves the optimal sample complexity in the asymptotic setting (i.e., ) and runs only in at most  batches. Based on Tri-BBAI, we further propose the almost optimal batched best arm identification (Opt-BBAI) algorithm, which is the first algorithm that achieves the near-optimal sample and batch complexity in the non-asymptotic setting (i.e.,  is arbitrarily fixed), while enjoying the same batch and sample complexity as Tri-BBAI when  tends to zero. Moreover, in the non-asymptotic setting, the complexity of previous batch algorithms is usually conditioned on the event that the best arm is returned (with a probability of at least ), which is potentially unbounded in cases where a sub-optimal arm is returned. In contrast, the complexity of Opt-BBAI does not rely on such an event. This is achieved through a novel procedure that we design for checking whether the best arm is eliminated, which is of independent interest.",Article,https://arxiv.org/abs/2310.14129,1,jin2023optimal,batched best arm identification
2023,Proceedings of the ACM Web Conference (WWW),Constrained Subset Selection from Data Streams for Profit Maximization,"Shuang Cui, Kai Han, Jing Tang, He Huang",Shuang Cui,English," The problem of constrained subset selection from a large data stream for profit maximization has many applications in web data mining and machine learning, such as social advertising, team formation and recommendation systems. Such a problem can be formulated as maximizing a regularized submodular function under certain constraints. In this paper, we consider a generalized k-system constraint, which captures various requirements in real-world applications. For this problem, we propose the first streaming algorithm with provable performance bounds, leveraging a novel multitudinous distorted filter framework. The empirical performance of our algorithm is extensively evaluated in several applications including web data mining and recommendation systems, and the experimental results demonstrate the superiorities of our algorithm in terms of both effectiveness and efficiency.",Conference paper,https://dl.acm.org/doi/abs/10.1145/3543507.3583490,1,cui2023constrained,"web data mining, machine learning, streaming algorithm, data summarization, submodular maximization"
2024,arXiv preprint arXiv:2406.01940,Process-Driven Autoformalization in Lean 4,"Jianqiao Lu, Zhengying Liu, Yingjia Wan, Yinya Huang, Haiming Wang, Zhicheng Yang, Jing Tang, Zhijiang Guo",Jianqiao Lu,English,"Autoformalization, the conversion of natural language mathematics into formal languages, offers significant potential for advancing mathematical reasoning. However, existing efforts are limited to formal languages with substantial online corpora and struggle to keep pace with rapidly evolving languages like Lean 4. To bridge this gap, we propose a new benchmark \textbf{Form}alization for \textbf{L}ean~\textbf{4} (\textbf{\name}) designed to evaluate the autoformalization capabilities of large language models (LLMs). This benchmark encompasses a comprehensive assessment of questions, answers, formal statements, and proofs. Additionally, we introduce a \textbf{P}rocess-\textbf{S}upervised \textbf{V}erifier (\textbf{PSV}) model that leverages the precise feedback from Lean 4 compilers to enhance autoformalization. Our experiments demonstrate that the PSV method improves autoformalization, enabling higher accuracy using less filtered training data. Furthermore, when fine-tuned with data containing detailed process information, PSV can leverage the data more effectively, leading to more significant improvements in autoformalization for Lean 4. Our dataset and code are available at \url{https://github.com/rookie-joe/PDA}.",Article,https://arxiv.org/abs/2406.01940,0,lu2024process,"Process-Supervised Verifier,Lean 4"
2024,arXiv preprint arXiv:2405.14414,Proving Theorems Recursively,"Haiming Wang, Huajian Xin, Zhengying Liu, Wenda Li, Yinya Huang, Jianqiao Lu, Zhicheng Yang, Jing Tang, Jian Yin, Zhenguo Li, Xiaodan Liang",Haiming Wang,English,"Recent advances in automated theorem proving leverages language models to explore expanded search spaces by step-by-step proof generation. However, such approaches are usually based on short-sighted heuristics (e.g., log probability or value function scores) that potentially lead to suboptimal or even distracting subgoals, preventing us from finding longer proofs. To address this challenge, we propose POETRY (PrOvE Theorems RecursivelY), which proves theorems in a recursive, level-by-level manner in the Isabelle theorem prover. Unlike previous step-by-step methods, POETRY searches for a verifiable sketch of the proof at each level and focuses on solving the current level's theorem or conjecture. Detailed proofs of intermediate conjectures within the sketch are temporarily replaced by a placeholder tactic called sorry, deferring their proofs to subsequent levels. This approach allows the theorem to be tackled incrementally by outlining the overall theorem at the first level and then solving the intermediate conjectures at deeper levels. Experiments are conducted on the miniF2F and PISA datasets and significant performance gains are observed in our POETRY approach over state-of-the-art methods. POETRY on miniF2F achieves an average proving success rate improvement of 5.1%. Moreover, we observe a substantial increase in the maximum proof length found by POETRY, from 10 to 26.",Article,https://arxiv.org/abs/2405.14414,0,wang2024proving,None
2024,Proceedings of the ACM on Web Conference 2024,Link Recommendation to Augment Influence Diffusion with Provable Guarantees,"Xiaolong Chen, Yifan Song, Jing Tang",Xiaolong Chen,English,"Link recommendation systems in online social networks (OSNs), such as Facebook's ``People You May Know'', Twitter's ``Who to Follow'', and Instagram's ``Suggested Accounts'', facilitate the formation of new connections among users. This paper addresses the challenge of link recommendation for the purpose of social influence maximization. In particular, given a graph  and the seed set , our objective is to select  edges that connect seed nodes and ordinary nodes to optimize the influence dissemination of the seed set. This problem, referred to as influence maximization with augmentation (IMA), has been proven to be NP-hard. In this paper, we propose an algorithm, namely \textsf{AIS}, consisting of an efficient estimator for augmented influence estimation and an accelerated sampling approach. \textsf{AIS} provides a -approximate solution with a high probability of , and runs in  time assuming that the influence of any singleton node is smaller than that of the seed set. To the best of our knowledge, this is the first algorithm that can be implemented on large graphs containing millions of nodes while preserving strong theoretical guarantees. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.",Conference paper,https://arxiv.org/abs/2402.19189,0,chen2024link,"Social networks, Influence maximization"
2024,arXiv preprint arXiv:2403.12931,You Only Sample Once: Taming One-Step Text-To-Image Synthesis by Self-Cooperative Diffusion GANs,"Yihong Luo, Xiaolong Chen, Jing Tang",Yihong Luo,English,"We introduce YOSO, a novel generative model designed for rapid, scalable, and high-fidelity one-step image synthesis. This is achieved by integrating the diffusion process with GANs. Specifically, we smooth the distribution by the denoising generator itself, performing self-cooperative learning. We show that our method can serve as a one-step generation model training from scratch with competitive performance. Moreover, we show that our method can be extended to finetune pre-trained text-to-image diffusion for high-quality one-step text-to-image synthesis even with LoRA fine-tuning. In particular, we provide the first diffusion transformer that can generate images in one step trained on 512 resolution, with the capability of adapting to 1024 resolution without explicit training. Our code is provided at https://github.com/Luo-Yihong/YOSO.",Article,https://arxiv.org/abs/2403.12931,0,luo2024you,"Diffusion model, generative adversarial network"
2023,arXiv preprint arXiv:2311.13538,Speak Like a Native: Prompting Large Language Models in a Native Style,"Zhicheng Yang, Yiwei Wang, Yinya Huang, Jing Xiong, Xiaodan Liang, Jing Tang",Zhicheng Yang,English,"Existing work has found that the prompt engineering heavily influences the performance of large language models (LLMs). Chain-of-thought (CoT), as a popular prompt engineering technique, prompted LLMs using in-context examples with reasoning steps. In current studies, the few-shot examples of CoT are generally handcrafted by humans. However, how the text style of in-context examples influence the outputs of LLMs still remains under-explored. This paper presents a novel and effective approach, named \textbf{AlignCoT}, to improve the reasoning capability of LLMs by aligning the in-context examples with the native style of LLMs. ``Native'' refers to the inherent characteristic style of LLMs which can be probed by original zero-shot scenarios. AlignCoT is orthogonal to other prompt engineering methods, making it easy to combine with state-of-the-art techniques to further improve the LLMs' performance. We conduct extensive and comprehensive experiments on several benchmarks. The empirical results demonstrate that our AlignCoTsignificantly improves performance over the carefully handcrafted in-context examples. For instance, with GPT-3.5-turbo, we observed a +2.5\% improvement on GSM8K. Furthermore, our AlignCoT consistently improve the performance when combined with other state-of-the-art prompt engineering methods. The source code and dataset will be available at \href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.",Article,https://arxiv.org/abs/2311.13538,0,yang2023speak,"Large Language Models,In-context learning"
2023,arXiv preprint arXiv:2308.10656,Practical Parallel Algorithms for Non-Monotone Submodular Maximization,"Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, Aakas Zhiyuli, Hanxiao Li",Shuang Cui,English,"Submodular maximization has found extensive applications in various domains within the field of artificial intelligence, including but not limited to machine learning, computer vision, and natural language processing. With the increasing size of datasets in these domains, there is a pressing need to develop efficient and parallelizable algorithms for submodular maximization. One measure of the parallelizability of a submodular maximization algorithm is its adaptive complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an -approximation under  adaptive complexity, which is \textit{optimal} up to a factor of . Moreover, we also propose the first algorithm with both provable approximation ratio and sublinear adaptive complexity for the problem of non-monotone submodular maximization subject to a -system constraint. As a by-product, we show that our two algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.",Article,https://arxiv.org/abs/2308.10656,0,cui2023practical,Submodular maximization
2023,arXiv preprint arXiv:2305.13551,EntRED: Benchmarking Relation Extraction with Fewer Shortcuts,"Yiwei Wang, Bryan Hooi, Fei Wang, Yujun Cai, Yuxuan Liang, Wenxuan Zhou, Jing Tang, Manjuan Duan, Muhao Chen",Yiwei Wang,English,"Entity names play an effective role in relation extraction (RE) and often influence model performance. As a result, the entity names in the benchmarks' test sets significantly influence the evaluation of RE models. In this work, we find that the standard RE benchmarks' datasets have a large portion of incorrect entity annotations, low entity name diversity, and are prone to have shortcuts from entity names to ground-truth relations. These issues make the standard benchmarks far from reflecting the real-world scenarios. Hence, in this work, we present EntRED, a challenging RE benchmark with reduced shortcuts and higher diversity of entities. To build EntRED, we propose an end-to-end entity replacement pipeline based on causal inference (CI): ERIC. ERIC performs type-constrained replacements on entities to reduce the shortcuts from entity bias to ground-truth relations. ERIC applies CI in two aspects: 1) targeting the instances that need entity replacements, and 2) determining the candidate entities for replacements. We apply ERIC on TACRED to produce EntRED. Our EntRED evaluates whether the RE model can correctly extract the relations from the text instead of relying on entity bias. Empirical results reveal that even the strong RE model has a significant performance drop on EntRED, which memorizes entity name patterns instead of reasoning from the textual context. We release ERIC's source code and the EntRED benchmark at https://github.com/wangywUST/ENTRED.",Article,https://arxiv.org/abs/2305.13551,0,wang2023entred,Relation extraction
2022,The VLDB Journal,Optimal price profile for influential nodes in online social networks,"Yuqing Zhu, Jing Tang, Xueyan Tang",Yuqing Zhu,English,"Influential nodes with rich connections in online social networks (OSNs) are of great values to initiate marketing campaigns. However, the potential influence spread that can be generated by these influential nodes is hidden behind the structures of OSNs, which are often held by OSN providers and unavailable to advertisers for privacy concerns. A social advertising model known as influencer marketing is to have OSN providers offer and price candidate nodes for advertisers to purchase for seeding marketing campaigns. In this setting, a reasonable price profile for the candidate nodes should effectively reflect the expected influence gain they can bring in a marketing campaign. In this paper, we study the problem of pricing the influential nodes based on their expected influence spread to help advertisers select the initiators of marketing campaigns without the knowledge of OSN structures. We design a function?…",Article,https://link.springer.com/article/10.1007/s00778-021-00727-9,0,zhu2022optimal,"Pricing,Optimization,Influence spread,Online social network"
2022,Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and?…,Noisy Interactive Graph Search,"Qianhao Cong, Jing Tang, Kai Han, Yuming Huang, Lei Chen, Yeow Meng Chee",Qianhao Cong,English,"The interactive graph search (IGS) problem aims to locate an initially unknown target node leveraging human intelligence. In IGS, we can gradually find the target node by sequentially asking humans some reachability queries like ""is the target node reachable from a given node x?"". However, human workers may make mistakes when answering these queries. Motivated by this concern, in this paper, we study a noisy version of the IGS problem. Our objective in this problem is to minimize the query complexity while ensuring accuracy. We propose a method to select the query node such that we can push the search process as much as possible and an online method to infer which node is the target after collecting a new answer. By rigorous theoretical analysis, we show that the query complexity of our approach is near-optimal up to a constant factor. The extensive experiments on two real datasets also demonstrate?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3534678.3539267,0,cong2022noisy,"Crowd sourcing, Interactive Graph Search, Algorithms"
2021,arXiv preprint arXiv:2106.07116,The Power of Randomization: Efficient and Effective Algorithms for Constrained Submodular Maximization,"Kai Han, Shuang Cui, Tianshuai Zhu, Jing Tang, Benwei Wu, He Huang",Kai Han,English,"Submodular optimization has numerous applications such as crowdsourcing and viral marketing. In this paper, we study the fundamental problem of non-negative submodular function maximization subject to a -system constraint, which generalizes many other important constraints in submodular optimization such as cardinality constraint, matroid constraint, and -extendible system constraint. The existing approaches for this problem achieve the best-known approximation ratio of  (for a general submodular function) based on deterministic algorithmic frameworks. We propose several randomized algorithms that improve upon the state-of-the-art algorithms in terms of approximation ratio and time complexity, both under the non-adaptive setting and the adaptive setting. The empirical performance of our algorithms is extensively evaluated in several applications related to data mining and social computing, and the experimental results demonstrate the superiorities of our algorithms in terms of both utility and efficiency.",Article,https://arxiv.org/abs/2106.07116,0,han2021power,Submodular maximization
