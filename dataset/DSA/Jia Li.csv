Year,Sources,Name,Authors,First Author,Chinese/English,Abstract,Venues,doi,Citation,Id,Keywords
2022,ICML,Rethinking Graph Neural Networks for Anomaly Detection,"Jianheng Tang, Jiajin Li, Ziqi Gao, Jia Li",Jianheng Tang,English,"Graph Neural Networks (GNNs) are widely applied for graph anomaly detection. As one of the key components for GNN design is to select a tailored spectral filter, we take the first step towards analyzing anomalies via the lens of the graph spectrum. Our crucial observation is the existence of anomalies will lead to the ‘right-shift’phenomenon, that is, the spectral energy distribution concentrates less on low frequencies and more on high frequencies. This fact motivates us to propose the Beta Wavelet Graph Neural Network (BWGNN). Indeed, BWGNN has spectral and spatial localized band-pass filters to better handle the ‘right-shift’phenomenon in anomalies. We demonstrate the effectiveness of BWGNN on four large-scale anomaly detection datasets. Our code and data are released at https://github. com/squareRoot3/Rethinking-Anomaly-Detection.",Article,https://proceedings.mlr.press/v162/tang22b.html,133,tang2022rethinking,"graph neural networks,anomaly detection"
2020,Proceedings of The Web Conference 2020,Adversarial attack on community detection by hiding individuals,"Jia Li, Honglei Zhang, Zhichao Han, Yu Rong, Hong Cheng, Junzhou Huang",Jia Li,English,"It has been demonstrated that adversarial graphs, i.e., graphs with imperceptible perturbations added, can cause deep graph models to fail on node/graph classification tasks. In this paper, we extend adversarial graphs to the problem of community detection which is much more difficult. We focus on black-box attack and aim to hide targeted individuals from the detection of deep graph community detection models, which has many applications in real-world scenarios, for example, protecting personal privacy in social networks and understanding camouflage patterns in transaction networks. We propose an iterative learning framework that takes turns to update two modules: one working as the constrained graph generator and the other as the surrogate community detection model. We also find that the adversarial graphs generated by our method can be transferred to other learning based community detection models. ",Conference paper,https://dl.acm.org/doi/abs/10.1145/3366423.3380171,87,li2020adversarial,"adversarial attack, community detection, graph generation"
2023,KDD 2023,All in One: Multi-Task Prompting for Graph Neural Networks,"Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, Jihong Guan",Xiangguo Sun,English,"Recently, ""pre-training and fine-tuning'' has been adopted as a standard workflow for many graph tasks since it can take general graph knowledge to relieve the lack of graph annotations from each application. However, graph tasks with node level, edge level, and graph level are far diversified, making the pre-training pretext often incompatible with these multiple tasks. This gap may even cause a ""negative transfer'' to the specific application, leading to poor results. Inspired by the prompt learning in natural language processing (NLP), which has presented significant effectiveness in leveraging prior knowledge for various NLP tasks, we study the prompting topic for graphs with the motivation of filling the gap between pre-trained models and various graph tasks. In this paper, we propose a novel multi-task prompting method for graph models. Specifically, we first unify the format of graph prompts and language?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3580305.3599256,60,sun2023all,"pretraining, prompt tuning, graph neural networks"
2023,Nature Communications,Hierarchical graph learning for protein–protein interaction,"Ziqi Gao, Chenran Jiang, Jiawen Zhang, Xiaosen Jiang, Lanqing Li, Peilin Zhao, Huanming Yang, Yong Huang, Jia Li",Ziqi Gao,English,"Protein-Protein Interactions (PPIs) are fundamental means of functions and signalings in biological systems. The massive growth in demand and cost associated with experimental PPI studies calls for computational tools for automated prediction and understanding of PPIs. Despite recent progress, in silico methods remain inadequate in modeling the natural PPI hierarchy. Here we present a double-viewed hierarchical graph learning model, HIGH-PPI, to predict PPIs and extrapolate the molecular details involved. In this model, we create a hierarchical graph, in which a node in the PPI network (top outside-of-protein view) is a protein graph (bottom inside-of-protein view). In the bottom view, a group of chemically relevant descriptors, instead of the protein sequences, are used to better capture the structure-function relationship of the protein. HIGH-PPI examines both outside-of-protein and inside-of-protein of the?…",Article,https://www.nature.com/articles/s41467-023-36736-1,57,gao2023hierarchical,"graph algorithms, large language models, instruction tuning"
2020,NeurIPS 33,Dirichlet graph variational autoencoder,"Jia Li, Jianwei Yu, Jiajin Li, Honglei Zhang, Kangfei Zhao, Yu Rong, Hong Cheng, Junzhou Huang",Jia Li,English,"Graph Neural Networks (GNN) and Variational Autoencoders (VAEs) have been widely used in modeling and generating graphs with latent factors. However there is no clear explanation of what these latent factors are and why they perform well. In this work, we present Dirichlet Graph Variational Autoencoder (DGVAE) with graph cluster memberships as latent factors. Our study connects VAEs based graph generation and balanced graph cut, and provides a new way to understand and improve the internal mechanism of VAEs based graph generation. Specifically, we first interpret the reconstruction term of DGVAE as balanced graph cut in a principled way. Furthermore, motivated by the low pass characteristics in balanced graph cut, we propose a new variant of GNN named Heatts to encode the input graph into cluster memberships. Heatts utilizes the Taylor series for fast computation of Heat kernels and has better low pass characteristics than Graph Convolutional Networks (GCN). Through experiments on graph generation and graph clustering, we demonstrate the effectiveness of our proposed framework.",Article,https://proceedings.neurips.cc/paper_files/paper/2020/hash/38a77aa456fc813af07bb428f2363c8d-Abstract.html,45,li2020dirichlet,"variational autoencoders, topic models, Dirichlet distribution, reparameterization, generative models"
2023,EMNLP Findings,Large Language Models Meet Harry Potter: A Bilingual Dataset for Aligning Dialogue Agents with Characters,"Nuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan Li, Ziyang Chen, Longyue Wang, Jia Li",Nuo Chen,English,"In recent years, Dialogue-style Large Language Models (LLMs) such as ChatGPT and GPT4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character. We benchmark LLMs on HPD using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter.",Article,https://arxiv.org/abs/2211.06869,15,chen2022large,"Imbalanced Learning, Long-tailed Learning, AI for Drug Discovery, Deep Learning Benchmark"
2023,IJCAI 2024,A survey of graph meets large language model: Progress and future directions,"Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, Jeffrey Xu Yu",Yuhan Li,English,"Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are summarized and will be consistently updated at: https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.",Conference paper,https://arxiv.org/abs/2311.12399,19,li2023survey,"large language models, graph neural networks"
2021,NeurIPS 34,Deconvolutional Networks on Graph Data,"Jia Li, Jiajin Li, Yang Liu, Jianwei Yu, Yueting Li, Hong Cheng",Jia Li,English,"In this paper, we consider an inverse problem in graph learning domain--"" given the graph representations smoothed by Graph Convolutional Network (GCN), how can we reconstruct the input graph signal?"" We propose Graph Deconvolutional Network (GDN) and motivate the design of GDN via a combination of inverse filters in spectral domain and de-noising layers in wavelet domain, as the inverse operation results in a high frequency amplifier and may amplify the noise. We demonstrate the effectiveness of the proposed method on several tasks including graph feature imputation and graph structure generation.",Article,https://proceedings.neurips.cc/paper/2021/hash/afa299a4d1d8c52e75dd8a24c3ce534f-Abstract.html,23,li2021deconvolutional,"graph convolutional networks,graph deconvolutional networks"
2023,IEEE Transactions on Knowledge and Data Engineering,Self-supervised hypergraph representation learning for sociological analysis,"Xiangguo Sun, Hong Cheng, Bo Liu, Jia Li, Hongyang Chen, Guandong Xu, Hongzhi Yin",Xiangguo Sun,English,"Modern sociology has profoundly uncovered many convincing social criteria for behavioral analysis. Unfortunately, many of them are too subjective to be measured and very challenging to be presented in online social networks (OSNs) for the large data volume and complicated environments to be explored. On the other hand, data mining techniques can better find data patterns but many of them leave behind unnatural understanding to humans. Although there are some works trying to integrate social observations for specific tasks, they are still hard to be applied to more general cases. In this paper, we propose a fundamental methodology to support the further fusion of data mining techniques and sociological behavioral criteria. Our highlights are three-fold: First, we propose an effective hypergraph awareness and a fast line graph construction framework. The hypergraph can more profoundly indicate the?…",Article,https://ieeexplore.ieee.org/abstract/document/10040228/,25,sun2023self,"hypergraph, social conformity, social influence, self-supervised learning"
2022,IEEE Transactions on Pattern Analysis and Machine Intelligence,Semi-supervised hierarchical graph classification,"Jia Li, Yongfeng Huang, Heng Chang, Yu Rong",Jia Li,English,"Node classification and graph classification are two graph learning problems that predict the class label of a node and the class label of a graph respectively. A node of a graph usually represents a real-world entity, e.g., a user in a social network, or a document in a document citation network. In this work, we consider a more challenging but practically useful setting, in which a node itself is a graph instance. This leads to a hierarchical graph perspective which arises in many domains such as social network, biological network and document collection. We study the node classification problem in the hierarchical graph where a “node” is a graph instance. As labels are usually limited, we design a novel semi-supervised solution named SEAL-CI. SEAL-CI adopts an iterative framework that takes turns to update two modules, one working at the graph instance level and the other at the hierarchical graph level. To enforce?…",Article,https://ieeexplore.ieee.org/abstract/document/9875050/,19,li2022semi,"graph representation, graph mutual information, hierarchical graph, semi-supervised learning"
2023,arXiv preprint arXiv:2311.16534,Graph prompt learning: A comprehensive survey and beyond,"Xiangguo Sun, Jiawen Zhang, Xixi Wu, Hong Cheng, Yun Xiong, Jia Li",Xiangguo Sun,English,"Artificial General Intelligence (AGI) has revolutionized numerous fields, yet its integration with graph data, a cornerstone in our interconnected world, remains nascent. This paper presents a pioneering survey on the emerging domain of graph prompts in AGI, addressing key challenges and opportunities in harnessing graph data for AGI applications. Despite substantial advancements in AGI across natural language processing and computer vision, the application to graph data is relatively underexplored. This survey critically evaluates the current landscape of AGI in handling graph data, highlighting the distinct challenges in cross-modality, cross-domain, and cross-task applications specific to graphs. Our work is the first to propose a unified framework for understanding graph prompt learning, offering clarity on prompt tokens, token structures, and insertion patterns in the graph domain. We delve into the intrinsic properties of graph prompts, exploring their flexibility, expressiveness, and interplay with existing graph models. A comprehensive taxonomy categorizes over 100 works in this field, aligning them with pre-training tasks across node-level, edge-level, and graph-level objectives. Additionally, we present, ProG, a Python library, and an accompanying website, to support and advance research in graph prompting. The survey culminates in a discussion of current challenges and future directions, offering a roadmap for research in graph prompting within AGI. Through this comprehensive analysis, we aim to catalyze further exploration and practical applications of AGI in graph data, underlining its potential to reshape AGI fields and beyond. ProG?…",Conference paper,https://arxiv.org/abs/2311.16534,19,sun2023graph,"graph prompt, graph pre-training, graph learning, artificial general intelligence"
2023,NeurIPS 2023,GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection,"Jianheng Tang, Fengrui Hua, Ziqi Gao, Peilin Zhao, Jia Li",Jianheng Tang,English,"With a long history of traditional Graph Anomaly Detection (GAD) algorithms and recently popular Graph Neural Networks (GNNs), it is still not clear (1) how they perform under a standard comprehensive setting,(2) whether GNNs can outperform traditional algorithms such as tree ensembles, and (3) how about their efficiency on large-scale graphs. In response, we introduce GADBench---a benchmark tool dedicated to supervised anomalous node detection in static graphs. GADBench facilitates a detailed comparison across 29 distinct models on ten real-world GAD datasets, encompassing thousands to millions (~ 6M) nodes. Our main finding is that tree ensembles with simple neighborhood aggregation can outperform the latest GNNs tailored for the GAD task. We shed light on the current progress of GAD, setting a robust groundwork for subsequent investigations in this domain. GADBench is open-sourced at https://github. com/squareRoot3/GADBench.",Article,https://proceedings.neurips.cc/paper_files/paper/2023/hash/5eaafd67434a4cfb1cf829722c65f184-Abstract-Datasets_and_Benchmarks.html,17,tang2024gadbench,"graph neural networks,graph anomaly detection"
2023,arXiv preprint arXiv:2310.20246,Breaking language barriers in multilingual mathematical reasoning: Insights and observations,"Nuo Chen, Zinan Zheng, Ning Wu, Linjun Shou, Ming Gong, Yangqiu Song, Dongmei Zhang, Jia Li",Nuo Chen,English,"Existing research predominantly focuses on developing powerful language learning models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights from extensive experiments: (1) When extending the rejection sampling strategy to the multilingual context, it proves effective for model performances, albeit limited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT) across multiple languages not only significantly enhances model performance multilingually but also elevates their monolingual performance. This indicates that crafting multilingual corpora can be regarded as a vital strategy for enhancing model performance in a specific language, especially in mathematical reasoning tasks. For instance, MathOctopus-7B improves its counterparts that trained on English from 42.2% to 50.8% on GSM8K testset.",Article,https://arxiv.org/abs/2310.20246,14,chen2023breaking,"large language models,Multilingual Math Reasoning"
2023,ICLR 2023,A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein in Graph Data,"Jiajin Li, Jianheng Tang, Lemin Kong, Huikang Liu, Jia Li, Anthony Man-Cho So, Jose Blanchet",Jiajin Li,English,"In this work, we present the Bregman Alternating Projected Gradient (BAPG) method, a single-loop algorithm that offers an approximate solution to the Gromov-Wasserstein (GW) distance. We introduce a novel relaxation technique that balances accuracy and computational efficiency, albeit with some compromises in the feasibility of the coupling map. Our analysis is based on the observation that the GW problem satisfies the Luo-Tseng error bound condition, which relates to estimating the distance of a point to the critical point set of the GW problem based on the optimality residual. This observation allows us to provide an approximation bound for the distance between the fixed-point set of BAPG and the critical point set of GW. Moreover, under a mild technical assumption, we can show that BAPG converges to its fixed point set. The effectiveness of BAPG has been validated through comprehensive numerical experiments in graph alignment and partition tasks, where it outperforms existing methods in terms of both solution quality and wall-clock time.",Article,https://arxiv.org/abs/2303.06595,12,li2023convergent,"Time Series, Co-training, Contrastive Learning, Noisy Data"
2023,AAAI 2023,Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning,"Jiashun Cheng, Man Li, Jia Li, Fugee Tsung",Jiashun Cheng,English,"Graph self-supervised learning (SSL) has been vastly employed to learn representations from unlabeled graphs. Existing methods can be roughly divided into predictive learning and contrastive learning, where the latter one attracts more research attention with better empirical performance. We argue that, however, predictive models weaponed with powerful decoder could achieve comparable or even better representation power than contrastive models. In this work, we propose a Wiener Graph Deconvolutional Network (WGDN), an augmentation-adaptive decoder empowered by graph wiener filter to perform information reconstruction. Theoretical analysis proves the superior reconstruction ability of graph wiener filter. Extensive experimental results on various datasets demonstrate the effectiveness of our approach.",Article,https://ojs.aaai.org/index.php/AAAI/article/view/25870,12,cheng2023wiener,"graph deconvolutional networks,Self-Supervised Learning"
2022,AAAI 2023,Handling Missing Data via Max-Entropy Regularized Graph Autoencoder,"Ziqi Gao, Yifan Niu, Jiashun Cheng, Jianheng Tang, Tingyang Xu, Peilin Zhao, Lanqing Li, Fugee Tsung, Jia Li",Ziqi Gao,English,"Graph neural networks (GNNs) are popular weapons for modeling relational data. Existing GNNs are not specified for attribute-incomplete graphs, making missing attribute imputation a burning issue. Until recently, many works notice that GNNs are coupled with spectral concentration, which means the spectrum obtained by GNNs concentrates on a local part in spectral domain, eg, low-frequency due to oversmoothing issue. As a consequence, GNNs may be seriously flawed for reconstructing graph attributes as graph spectral concentration tends to cause a low imputation precision. In this work, we present a regularized graph autoencoder for graph attribute imputation, named MEGAE, which aims at mitigating spectral concentration problem by maximizing the graph spectral entropy. Notably, we first present the method for estimating graph spectral entropy without the eigen-decomposition of Laplacian matrix and provide the theoretical upper error bound. A maximum entropy regularization then acts in the latent space, which directly increases the graph spectral entropy. Extensive experiments show that MEGAE outperforms all the other state-of-the-art imputation methods on a variety of benchmark datasets.",Article,https://ojs.aaai.org/index.php/AAAI/article/view/25928,11,gao2023handling,"Graph AutoEncoder,graph neural networks"
2023,ACL 2023,Alleviating Over-smoothing for Unsupervised Sentence Representation,"Nuo Chen, Linjun Shou, Ming Gong, Jian Pei, Bowen Cao, Jianhui Chang, Daxin Jiang, Jia Li",Nuo Chen,English,"Currently, learning better unsupervised sentence representations is the pursuit of many natural language processing communities. Lots of approaches based on pre-trained language models (PLMs) and contrastive learning have achieved promising results on this task. Experimentally, we observe that the over-smoothing problem reduces the capacity of these powerful PLMs, leading to sub-optimal sentence representations. In this paper, we present a Simple method named Self-Contrastive Learning (SSCL) to alleviate this issue, which samples negatives from PLMs intermediate layers, improving the quality of the sentence representation. Our proposed method is quite simple and can be easily extended to various state-of-the-art models for performance boosting, which can be seen as a plug-and-play contrastive framework for learning unsupervised sentence representation. Extensive results prove that SSCL brings the superior performance improvements of different strong baselines (e.g., BERT and SimCSE) on Semantic Textual Similarity and Transfer datasets. Our codes are available at https://github.com/nuochenpku/SSCL.",Article,https://arxiv.org/abs/2305.06154,9,chen2023alleviating,"sentence representation,pre-trained language models"
2023,ICDE 2023,Robust attributed graph alignment via joint structure learning and optimal transport,"Jianheng Tang, Weiqi Zhang, Jiajin Li, Kangfei Zhao, Fugee Tsung, Jia Li",Jianheng Tang,English,"Graph alignment, which aims at identifying corresponding entities across multiple networks, has been widely applied in various domains. As the graphs to be aligned are usually constructed from different sources, the inconsistency issues of structures and features between two graphs are ubiquitous in real-world applications. Most existing methods follow the ""embed-then-cross-compare"" paradigm which computes node embeddings in each graph and then processes node correspondences based on cross-graph embedding comparison. However, we find these methods are unstable and sub-optimal when structure or feature inconsistency appears. To this end, we propose SLOTAlign, an unsupervised graph alignment framework that jointly performs Structure Learning and Optimal Transport Alignment. We convert graph alignment to an optimal transport problem between two intra-graph matrices without the?…",Article,https://ieeexplore.ieee.org/abstract/document/10184815/,11,tang2023robust,"Graph alignment, Unsupervised learning, Structure learning, Optimal transport"
2023,WWW 2023,Knowledge Graph Completion with Counterfactual Augmentation,"Heng Chang, Jie Cai, Jia Li",Heng Chang,English," Graph Neural Networks (GNNs) have demonstrated great success in Knowledge Graph Completion (KGC) by modeling how entities and relations interact in recent years. However, most of them are designed to learn from the observed graph structure, which appears to have imbalanced relation distribution during the training stage. Motivated by the causal relationship among the entities on a knowledge graph, we explore this defect through a counterfactual question: “would the relation still exist if the neighborhood of entities became different from observation?”. With a carefully designed instantiation of a causal model on the knowledge graph, we generate the counterfactual relations to answer the question by regarding the representations of entity pair given relation as context, structural information of relation-aware neighborhood as treatment, and validity of the composed triplet as the outcome. Furthermore, we?…",Article,https://dl.acm.org/doi/abs/10.1145/3543507.3583401,9,chang2023knowledge,"causal inference, knowledge graph completion, graph augmentation, graph neural networks"
2021,US Patent US 2019/0355147 A1,"Method and apparatus for determining object posture in image, device, and storage medium",Jia Li,Jia Li,English,"This application discloses a method and an apparatus for determining a posture of a target object in an image, a device, and a non-transitory storage medium. In the method, a training model parameter of a convolutional neural network of the target object is obtained from a server. A real-time image of the target object is obtained. At least one first image block from the real-time image is identified. The at least one first image block is a local image of the real-time image. According to the training model parameter, a label image block matching the at least one first image block is determined. The label image block is a local image of a standard image of the target object. Furthermore, the posture of the target object is determined, by processing circuitry of a terminal device, according to the at least one first image block and the determined label image block.",Conference paper,https://patents.google.com/patent/US11107232B2/en,9,li2021method,None
2021,Proceedings of the Web Conference 2021,Mask-gvae: Blind denoising graphs via partition,"Jia Li, Mengzhou Liu, Honglei Zhang, Pengyun Wang, Yong Wen, Lujia Pan, Hong Cheng",Jia Li,English," We present Mask-GVAE, a variational generative model for blind denoising large discrete graphs, in which ”blind denoising” means we don’t require any supervision from clean graphs. We focus on recovering graph structures via deleting irrelevant edges and adding missing edges, which has many applications in real-world scenarios, for example, enhancing the quality of connections in a co-authorship network. Mask-GVAE makes use of the robustness in low eigenvectors of graph Laplacian against random noise and decomposes the input graph into several stable clusters. It then harnesses the huge computations by decoding probabilistic smoothed subgraphs in a variational manner. On a wide variety of benchmarks, Mask-GVAE outperforms competing approaches by a significant margin on PSNR and WL similarity. ",Conference paper,https://dl.acm.org/doi/abs/10.1145/3442381.3449899,9,li2021mask,"graph denoising, graph clustering, graph autoencoder"
2020,arXiv preprint arXiv:2012.11898,Graph autoencoders with deconvolutional networks,"Jia Li, Tomas Yu, Da-Cheng Juan, Arjun Gopalan, Hong Cheng, Andrew Tomkins",Jia Li,English,"Recent studies have indicated that Graph Convolutional Networks (GCNs) act as a \emph{low pass} filter in spectral domain and encode smoothed node representations. In this paper, we consider their opposite, namely Graph Deconvolutional Networks (GDNs) that reconstruct graph signals from smoothed node representations. We motivate the design of Graph Deconvolutional Networks via a combination of inverse filters in spectral domain and de-noising layers in wavelet domain, as the inverse operation results in a \emph{high pass} filter and may amplify the noise. Based on the proposed GDN, we further propose a graph autoencoder framework that first encodes smoothed graph representations with GCN and then decodes accurate graph signals with GDN. We demonstrate the effectiveness of the proposed method on several tasks including unsupervised graph-level representation , social recommendation and graph generation",Article,https://arxiv.org/abs/2012.11898,9,li2020graph,"graph convolutional networks,graph deconvolutional networks"
2023,ACL 2023 Findings,A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph Entity Alignment,"Jianheng Tang, Kangfei Zhao, Jia Li",Jianheng Tang,English,"Entity alignment is the task of identifying corresponding entities across different knowledge graphs (KGs). Although recent embedding-based entity alignment methods have shown significant advancements, they still struggle to fully utilize KG structural information. In this paper, we introduce FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework. To address the computational challenges associated with optimizing FGW, we devise a three-stage progressive optimization algorithm. It starts with a basic semantic embedding matching, proceeds to approximate cross-KG structural and relational similarity matching based on iterative updates of high-confidence entity links, and ultimately culminates in a global structural comparison between KGs. We perform extensive experiments on four entity alignment datasets covering 14 distinct KGs across five languages. Without any supervision or hyper-parameter tuning, FGWEA surpasses 21 competitive baselines, including cutting-edge supervised entity alignment methods. Our code is available at https://github.com/squareRoot3/FusedGW-Entity-Alignment.",Article,https://arxiv.org/abs/2305.06574,9,tang2023fused,"Fused Gromov-Wasserstein,knowledge graph"
2023,CIKM,A Co-training Approach for Noisy Time Series Learning,"Weiqi Zhang, Jianfeng Zhang, Jia Li, Fugee Tsung",Weiqi Zhang,English,"In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to?…",Article,https://dl.acm.org/doi/abs/10.1145/3583780.3614759,7,zhang2023co,"Bregman Alternating Projected Gradient,Gromov-Wasserstein"
2023,KDD 2023,Warpformer: A Multi-scale Modeling Approach for Irregular Clinical Time Series,"Jiawen Zhang, Shun Zheng, Wei Cao, Jiang Bian, Jia Li",Jiawen Zhang,English,"Irregularly sampled multivariate time series are ubiquitous in various fields, particularly in healthcare, and exhibit two key characteristics: intra-series irregularity and inter-series discrepancy. Intra-series irregularity refers to the fact that time-series signals are often recorded at irregular intervals, while inter-series discrepancy refers to the significant variability in sampling rates among diverse series. However, recent advances in irregular time series have primarily focused on addressing intra-series irregularity, overlooking the issue of inter-series discrepancy. To bridge this gap, we present Warpformer, a novel approach that fully considers these two characteristics. In a nutshell, Warpformer has several crucial designs, including a specific input representation that explicitly characterizes both intra-series irregularity and inter-series discrepancy, a warping module that adaptively unifies irregular time series in a given?…",Article,https://dl.acm.org/doi/abs/10.1145/3580305.3599543,7,zhang2023warpformer,"clinical time series, irregularly sampled time series, multi-scale representation"
2023,EMNLP Findings,Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension,"Nuo Chen, Hongguang Li, Yinan Bao, Junqing He, Xinshi Lin, Qi Yang, Jianfeng Liu, Ruyi Gan, Jiaxing Zhang, Baoyuan Wang, Jia Li",Nuo Chen,English,"The conversational machine reading comprehension (CMRC) task aims to answer questions in conversations, which has been a hot research topic in recent years because of its wide applications. However, existing CMRC benchmarks in which each conversation is assigned a static passage are inconsistent with real scenarios. Thus, model's comprehension ability towards real scenarios are hard to evaluate reasonably. To this end, we propose the first Chinese CMRC benchmark Orca and further provide zero-shot/few-shot settings to evaluate model's generalization ability towards diverse domains. We collect 831 hot-topic driven conversations with 4,742 turns in total. Each turn of a conversation is assigned with a response-related passage, aiming to evaluate model's comprehension ability more reasonably. The topics of conversations are collected from social media platform and cover 33 domains, trying to be consistent with real scenarios. Importantly, answers in Orca are all well-annotated natural responses rather than the specific spans or short phrase in previous datasets. Besides, we implement three strong baselines to tackle the challenge in Orca. The results indicate the great challenge of our CMRC benchmark. Our datatset and checkpoints are available at https://github.com/nuochenpku/Orca.",Article,https://arxiv.org/abs/2302.13619,6,chen2023orca,Chinese machine reading comprehension
2023,The Twelfth International Conference on Learning Representations,Improving generalization in equivariant graph neural networks with physical inductive biases,"Yang Liu, Jiashun Cheng, Haihong Zhao, Tingyang Xu, Peilin Zhao, Fugee Tsung, Jia Li, Yu Rong",Yang Liu,English,"Graph Neural Networks (GNNs) with equivariant properties have emerged as powerful tools for modeling complex dynamics of multi-object physical systems. However, their generalization ability is limited by the inadequate consideration of physical inductive biases: (1) Existing studies overlook the continuity of transitions among system states, opting to employ several discrete transformation layers to learn the direct mapping between two adjacent states; (2) Most models only account for first-order velocity information, despite the fact that many physical systems are governed by second-order motion laws. To incorporate these inductive biases, we propose the Second-order Equivariant Graph Neural Ordinary Differential Equation (SEGNO). Specifically, we show how the second-order continuity can be incorporated into GNNs while maintaining the equivariant property. Furthermore, we offer theoretical insights into SEGNO, highlighting that it can learn a unique trajectory between adjacent states, which is crucial for model generalization. Additionally, we prove that the discrepancy between this learned trajectory of SEGNO and the true trajectory is bounded. Extensive experiments on complex dynamical systems including molecular dynamics and motion capture demonstrate that our model yields a significant improvement over the state-of-the-art baselines.",Conference paper,https://openreview.net/forum?id=3oTPsORaDH,4,liu2024improving,equivariant graph neural networks
2023,WSDM 2024,GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction,"Amit Roy, Juan Shu, Jia Li, Carl Yang, Olivier Elshocht, Jeroen Smeets, Pan Li",Amit Roy,English,"Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes within graphs, finding applications in network security, fraud detection, social media spam detection, and various other domains. A common method for GAD is Graph Auto-Encoders (GAEs), which encode graph data into node representations and identify anomalies by assessing the reconstruction quality of the graphs based on these representations. However, existing GAE models are primarily optimized for direct link reconstruction, resulting in nodes connected in the graph being clustered in the latent space. As a result, they excel at detecting cluster-type structural anomalies but struggle with more complex structural anomalies that do not conform to clusters. To address this limitation, we propose a novel solution called GAD-NR, a new variant of GAE that incorporates neighborhood reconstruction for graph anomaly detection. GAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the local structure, self-attributes, and neighbor attributes, based on the corresponding node representation. By comparing the neighborhood reconstruction loss between anomalous nodes and normal nodes, GAD-NR can effectively detect any anomalies. Extensive experimentation conducted on six real-world datasets validates the effectiveness of GAD-NR, showcasing significant improvements (by up to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR is openly available. Importantly, the comparative analysis reveals that the existing methods perform well only in detecting one or two types of anomalies out of the three types studied. In?…",Article,https://arxiv.org/abs/2306.01951,5,roy2024gad,"Anomaly Detection, graph neural networks, Auto-Encoder"
2022,AAAI 2023,Human Mobility Modeling During the COVID-19 Pandemic via Deep Graph Diffusion Infomax,"Yang Liu, Yu Rong, Zhuoning Guo, Nuo Chen, Tingyang Xu, Fugee Tsung, Jia Li",Yang Liu,English,"Non-Pharmaceutical Interventions (NPIs), such as social gathering restrictions, have shown effectiveness to slow the transmission of COVID-19 by reducing the contact of people. To support policy-makers, multiple studies have first modelled human mobility via macro indicators (eg, average daily travel distance) and then study the effectiveness of NPIs. In this work, we focus on mobility modelling and, from a micro perspective, aim to predict locations that will be visited by COVID-19 cases. Since NPIs generally cause economic and societal loss, such a prediction benefits governments when they design and evaluate them. However, in real-world situations, strict privacy data protection regulations result in severe data sparsity problems (ie, limited case and location information). To address these challenges and jointly model variables including a geometric graph, a set of diffusions and a set of locations, we propose a model named Deep Graph Diffusion Infomax (DGDI). We show the maximization of DGDI can be bounded by two tractable components: a univariate Mutual Information (MI) between geometric graph and diffusion representation, and a univariate MI between diffusion representation and location representation. To facilitate the research of COVID-19 prediction, we present two benchmarks that contain geometric graphs and location histories of COVID-19 cases. Extensive experiments on the two benchmarks show that DGDI significantly outperforms other competing methods.",Article,https://ojs.aaai.org/index.php/AAAI/article/view/26678,5,liu2023human,"Non-Pharmaceutical Interventions,Deep Graph Diffusion Infomax"
2022,arXiv preprint arXiv:2209.07921,Imdrug: A benchmark for deep imbalanced learning in ai-aided drug discovery,"Lanqing Li, Liang Zeng, Ziqi Gao, Shen Yuan, Yatao Bian, Bingzhe Wu, Hengtong Zhang, Yang Yu, Chan Lu, Zhipeng Zhou, Hongteng Xu, Jia Li, Peilin Zhao, Pheng-Ann Heng",Lanqing Li,English,"The last decade has witnessed a prosperous development of computational methods and dataset curation for AI-aided drug discovery (AIDD). However, real-world pharmaceutical datasets often exhibit highly imbalanced distribution, which is overlooked by the current literature but may severely compromise the fairness and generalization of machine learning applications. Motivated by this observation, we introduce ImDrug, a comprehensive benchmark with an open-source Python library which consists of 4 imbalance settings, 11 AI-ready datasets, 54 learning tasks and 16 baseline algorithms tailored for imbalanced learning. It provides an accessible and customizable testbed for problems and solutions spanning a broad spectrum of the drug discovery pipeline such as molecular modeling, drug-target interaction and retrosynthesis. We conduct extensive empirical studies with novel evaluation metrics, to demonstrate that the existing algorithms fall short of solving medicinal and pharmaceutical challenges in the data imbalance scenario. We believe that ImDrug opens up avenues for future research and development, on real-world challenges at the intersection of AIDD and deep imbalanced learning.",Article,https://arxiv.org/abs/2209.07921,5,li2022imdrug,"Imbalanced Learning, Long-tailed Learning, AI for Drug Discovery, Deep Learning Benchmark"
2020,US Patent 10,"Method, device and system for sharing cross-platform account resources","Hongfei Zhou, Jia Li",Hongfei Zhou,English,"A method for sharing a cross-platform account resource is described. An authentication request carrying a user name, a password, and an ID of an APP resource server is transmitted to an account management server, based on a register account on the account management server; an authentication ticket corresponding to the APP resource server is received from the account managements server, and the authentication ticket is stored, in which the authentication ticket carries a user ID, an authorization key and a refresh key; a resource request is transmitted to the APP resource server, based on the user ID and the authorization key in the authentication ticket; an APP resource is received from the APP resource server, after the APP resource server requests the account management server to verify the authentication ticket by using the user ID and the authorization key.",Conference paper,https://patents.google.com/patent/US10586027B2/en,5,zhou2020method,"causal inference, knowledge graph completion, graph augmentation, graph neural networks"
2024,arXiv preprint arXiv:2402.18813,Protein Multimer Structure Prediction via Prompt Learning,"Ziqi Gao, Xiangguo Sun, Zijing Liu, Yu Li, Hong Cheng, Jia Li",Ziqi Gao,English,"Understanding the 3D structures of protein multimers is crucial, as they play a vital role in regulating various cellular processes. It has been empirically confirmed that the multimer structure prediction~(MSP) can be well handled in a step-wise assembly fashion using provided dimer structures and predicted protein-protein interactions~(PPIs). However, due to the biological gap in the formation of dimers and larger multimers, directly applying PPI prediction techniques can often cause a \textit{poor generalization} to the MSP task. To address this challenge, we aim to extend the PPI knowledge to multimers of different scales~(i.e., chain numbers). Specifically, we propose \textbf{\textsc{PromptMSP}}, a pre-training and \textbf{Prompt} tuning framework for \textbf{M}ultimer \textbf{S}tructure \textbf{P}rediction. First, we tailor the source and target tasks for effective PPI knowledge learning and efficient inference, respectively. We design PPI-inspired prompt learning to narrow the gaps of two task formats and generalize the PPI knowledge to multimers of different scales. We provide a meta-learning strategy to learn a reliable initialization of the prompt model, enabling our prompting framework to effectively adapt to limited data for large-scale multimers. Empirically, we achieve both significant accuracy (RMSD and TM-Score) and efficiency improvements compared to advanced MSP models. The code, data and checkpoints are released at \url{https://github.com/zqgao22/PromptMSP}.",Article,https://arxiv.org/abs/2402.18813,5,gao2024protein,"protein-protein interactions,prompt learning"
2024,arXiv preprint arXiv:2402.09834,All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining,"Haihong Zhao, Aochuan Chen, Xiangguo Sun, Hong Cheng, Jia Li",Haihong Zhao,English,"Large Language Models (LLMs) have revolutionized the fields of computer vision (CV) and natural language processing (NLP). One of the most notable advancements of LLMs is that a single model is trained on vast and diverse datasets spanning multiple domains -- a paradigm we term `All in One'. This methodology empowers LLMs with super generalization capabilities, facilitating an encompassing comprehension of varied data distributions. Leveraging these capabilities, a single LLM demonstrates remarkable versatility across a variety of domains -- a paradigm we term `One for All'. However, applying this idea to the graph field remains a formidable challenge, with cross-domain pretraining often resulting in negative transfer. This issue is particularly important in few-shot learning scenarios, where the paucity of training data necessitates the incorporation of external knowledge sources. In response to this challenge, we propose a novel approach called Graph COordinators for PrEtraining (GCOPE), that harnesses the underlying commonalities across diverse graph datasets to enhance few-shot learning. Our novel methodology involves a unification framework that amalgamates disparate graph datasets during the pretraining phase to distill and transfer meaningful knowledge to target tasks. Extensive experiments across multiple graph datasets demonstrate the superior efficacy of our approach. By successfully leveraging the synergistic potential of multiple graph datasets for pretraining, our work stands as a pioneering contribution to the realm of graph foundational model.",Article,https://arxiv.org/abs/2402.09834,6,zhao2024all,"pretraining, prompt tuning, graph neural networks"
2022,US Patent 11,"Data response method, terminal device, and server","LIU Feifei, Yong Yang, Meng Chen, JIA Yiwen, Fei You, WEN Binmin, Jia Li, ZONG Xuan, HAN Wuyu, YU Chuansheng, Wei Tian, CHEN Yuanbin, Yaohua Zhang",LIU Feifei,English,"Embodiments of the present disclosure disclose a data response method, a terminal device, and a server. The method in the embodiments of the present disclosure includes: sending encrypted information to a terminal device; receiving a first honeypot character, the encrypted information, and user data from the terminal device; decrypting the encrypted information, to obtain a second honeypot character comprised in the encrypted information; determining whether the first honeypot character sent by the terminal device is the same as the second honeypot character decrypted from the encrypted information; and responding to the user data in response to the first honeypot character being the same as the second honeypot character.",Conference paper,https://patents.google.com/patent/US11431684B2/en,1,feifei2022data,None
2023,NeurIPS 2023,Deep Insights into Noisy Pseudo Labeling on Graph Data,"Botao Wang, Jia Li, Yang Liu, Jiashun Cheng, Yu Rong, Wenjia Wang, Fugee Tsung",Botao Wang,English,"Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view consistency. Finally, extensive experiments demonstrate that the proposed strategy improves graph learning process and outperforms other PL strategies on link prediction and node classification tasks.",Article,https://proceedings.neurips.cc/paper_files/paper/2023/hash/f0318ba897cee71ce200e408dea6062e-Abstract-Conference.html,3,botao2023deep,pseudo labeling
2023,arXiv preprint arXiv:2302.09302,Bridge the gap between language models and tabular understanding,"Nuo Chen, Linjun Shou, Ming Gong, Jian Pei, Chenyu You, Jianhui Chang, Daxin Jiang, Jia Li",Nuo Chen,English,"Table pretrain-then-finetune paradigm has been proposed and employed at a rapid pace after the success of pre-training in the natural language domain. Despite the promising findings in tabular pre-trained language models (TPLMs), there is an input gap between pre-training and fine-tuning phases. For instance, TPLMs jointly pre-trained with table and text input could be effective for tasks also with table-text joint input like table question answering, but it may fail for tasks with only tables or text as input such as table retrieval. To this end, we propose UTP, an approach that dynamically supports three types of multi-modal inputs: table-text, table, and text. Specifically, UTP is pre-trained with two strategies: (1) We first utilize a universal mask language modeling objective on each kind of input, enforcing the model to adapt various inputs. (2) We then present Cross-Modal Contrastive Regularization (CMCR), which utilizes contrastive learning to encourage the consistency between table-text cross-modality representations via unsupervised instance-wise training signals during pre-training. By these means, the resulting model not only bridges the input gap between pre-training and fine-tuning but also advances in the alignment of table and text. Extensive results show UTP achieves superior results on uni-modal input tasks (e.g., table retrieval) and cross-modal input tasks (e.g., table question answering).",Article,https://arxiv.org/abs/2302.09302,3,chen2023bridge,"pre-trained language models,tabular understanding"
2024,arXiv preprint arXiv:2402.11975,Compress to Impress: Unleashing the Potential of Compressive Memory in Real-World Long-Term Conversations,"Nuo Chen, Hongguang Li, Juhua Huang, Baoyuan Wang, Jia Li",Nuo Chen,English,"Existing retrieval-based methods have made significant strides in maintaining long-term conversations. However, these approaches face challenges in memory database management and accurate memory retrieval, hindering their efficacy in dynamic, real-world interactions. This study introduces a novel framework, COmpressive Memory-Enhanced Dialogue sYstems (COMEDY), which eschews traditional retrieval modules and memory databases. Instead, COMEDY adopts a ''One-for-All'' approach, utilizing a single language model to manage memory generation, compression, and response generation. Central to this framework is the concept of compressive memory, which intergrates session-specific summaries, user-bot dynamics, and past events into a concise memory format. To support COMEDY, we curated a large-scale Chinese instruction-tuning dataset, Dolphin, derived from real user-chatbot interactions. Comparative evaluations demonstrate COMEDY's superiority over traditional retrieval-based methods in producing more nuanced and human-like conversational experiences. Our codes are available at https://github.com/nuochenpku/COMEDY.",Article,https://arxiv.org/abs/2402.11975,2,chen2024compress,"retrieval-based,long-term conversations"
2023,Findings of the Association for Computational Linguistics: ACL 2023,Structural Contrastive Pretraining for Cross-Lingual Comprehension,"Nuo Chen, Linjun Shou, Tengtao Song, Ming Gong, Jian Pei, Jianhui Chang, Daxin Jiang, Jia Li",Nuo Chen,English,"To present, multilingual language models trained using various pre-training tasks like mask language modeling (MLM) have yielded encouraging results on a wide range of downstream tasks. Despite the promising performances, structural knowledge in cross-lingual corpus is less explored in current works, leading to the semantic misalignment. In this paper, we propose a new pre-training task named Structural Contrast Pretraining (SCP) to align the structural words in a parallel sentence, enhancing the models’ ability to comprehend cross-lingual representations. Concretely, each structural word in source and target languages is regarded as a positive pair in SCP. Since contrastive learning compares positive and negative pairs, an increase in the frequency of negative pairings could enhance the performance of the resulting model. Therefore, we further propose Cross-lingual Momentum Contrast (CL-MoCo) to increase the number of negative pairs by maintaining a large size of the queue. CL-MoCo extends the original Moco approach into cross-lingual training and jointly optimizes the source-to-target language and target-to-source language representations, resulting in a more suitable encoder for cross-lingual transfer. We conduct extensive experiments to validate the proposed approach on three cross-lingual tasks across five datasets such as MLQA, WikiAnn, etc, and results prove the effectiveness of our method.",Conference paper,https://aclanthology.org/2023.findings-acl.128/,2,chen2023structural,Structural Contrast Pretraining
2024,arXiv preprint arXiv:2405.02358,A Survey of Time Series Foundation Models: Generalizing Time Series Representation with Large Language Mode,"Jiexia Ye, Weiqi Zhang, Ke Yi, Yongzi Yu, Ziyue Li, Jia Li, Fugee Tsung",Jiexia Ye,English,"Time series data are ubiquitous across various domains, making time series analysis critically important. Traditional time series models are task-specific, featuring singular functionality and limited generalization capacity. Recently, large language foundation models have unveiled their remarkable capabilities for cross-task transferability, zero-shot/few-shot learning, and decision-making explainability. This success has sparked interest in the exploration of foundation models to solve multiple time series challenges simultaneously. There are two main research lines, namely \textbf{pre-training foundation models from scratch for time series} and \textbf{adapting large language foundation models for time series}. They both contribute to the development of a unified model that is highly generalizable, versatile, and comprehensible for time series analysis. This survey offers a 3E analytical framework for comprehensive examination of related research. Specifically, we examine existing works from three dimensions, namely \textbf{Effectiveness}, \textbf{Efficiency} and \textbf{Explainability}. In each dimension, we focus on discussing how related works devise tailored solution by considering unique challenges in the realm of time series.Furthermore, we provide a domain taxonomy to help followers keep up with the domain-specific advancements. In addition, we introduce extensive resources to facilitate the field's development, including datasets, open-source, time series libraries. A GitHub repository is also maintained for resource updates (https://github.com/start2020/Awesome-TimeSeries-LLM-FM).",Article,https://arxiv.org/abs/2405.02358,1,ye2024survey,"time series,large language models"
2024,arXiv preprint arXiv:2405.02299,Deep Reinforcement Learning for Modelling Protein Complexes,"Tao Feng, Ziqi Gao, Jiaxuan You, Chenyi Zi, Yan Zhou, Chen Zhang, Jia Li",Tao Feng,English,"AlphaFold can be used for both single-chain and multi-chain protein structure prediction, while the latter becomes extremely challenging as the number of chains increases. In this work, by taking each chain as a node and assembly actions as edges, we show that an acyclic undirected connected graph can be used to predict the structure of multi-chain protein complexes (a.k.a., protein complex modelling, PCM). However, there are still two challenges: 1) The huge combinatorial optimization space of  ( is the number of chains) for the PCM problem can easily lead to high computational cost. 2) The scales of protein complexes exhibit distribution shift due to variance in chain numbers, which calls for the generalization in modelling complexes of various scales. To address these challenges, we propose GAPN, a Generative Adversarial Policy Network powered by domain-specific rewards and adversarial loss through policy gradient for automatic PCM prediction. Specifically, GAPN learns to efficiently search through the immense assembly space and optimize the direct docking reward through policy gradient. Importantly, we design an adversarial reward function to enhance the receptive field of our model. In this way, GAPN will simultaneously focus on a specific batch of complexes and the global assembly rules learned from complexes with varied chain numbers. Empirically, we have achieved both significant accuracy (measured by RMSD and TM-Score) and efficiency improvements compared to leading PCM softwares. GAPN outperforms the state-of-the-art method (MoLPC) with up to 27% improvement in TM-Score, with a speed-up of 600?…",Article,https://arxiv.org/abs/2405.02299,1,feng2024deep,"Generative Adversarial Policy Network,reinforcement learning"
2024,arXiv preprint arXiv:2402.16029,GraphWiz: An Instruction-Following Language Model for Graph Problems,"Nuo Chen, Yuhan Li, Jianheng Tang, Jia Li",Nuo Chen,English,"Large language models (LLMs) have achieved impressive success across several fields, but their proficiency in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel and comprehensive instruction-tuning dataset designed to equip language models with the ability to tackle a broad spectrum of graph problems using explicit reasoning paths. Utilizing GraphInstruct, we build GraphWiz, an open-source language model capable of resolving various graph problem types while generating clear reasoning processes. To enhance the model's capability and reliability, we incorporate the Direct Preference Optimization (DPO) framework into the graph problem-solving context. The enhanced model, GraphWiz-DPO, achieves an average accuracy of 65% across nine tasks with different complexity levels, surpassing GPT-4 which has an average accuracy of 43.8%. Moreover, our research delves into the delicate balance between training data volume and model performance, highlighting the potential for overfitting with increased data. We also explore the transferability of the model's reasoning ability across different graph tasks, indicating the model's adaptability and practical application potential. Our investigation offers a new blueprint and valuable insights for developing LLMs specialized in graph reasoning and problem-solving.",Article,https://arxiv.org/abs/2402.16029,1,chen2024graphwiz,"graph algorithms, large language models, instruction tuning"
2023,arXiv preprint arXiv:2401.05384,From good to great: Improving math reasoning with tool-augmented interleaf prompting,"Nuo Chen, Hongguang Li, Baoyuan Wang, Jia Li",Nuo Chen,English,"This paper investigates the performance of Large Language Models (LLMs) and Tool-augmented LLMs in tackling complex mathematical reasoning tasks. We introduce IMP-TIP: Improving Math Reasoning with Tool-augmented Interleaf Prompting, a framework that combines the strengths of both LLMs and Tool-augmented LLMs. IMP-TIP follows the ``From Good to Great"" concept, collecting multiple potential solutions from both LLMs and their Tool-Augmented counterparts for the same math problem, and then selecting or re-generating the most accurate answer after cross-checking these solutions via tool-augmented interleaf prompting. The framework incorporates two key aspects: self-prompt and tool-augmented interleaf prompting (TIP). The former allows LLMs to autonomously refine and improve an initial prompt related to tool usage, while the latter enables LLMs to derive the final answer by dynamically analyzing the problem, cross-checking potential solutions, and revising previous reasoning hints in an interleaved manner. Experimental analysis shows that IMP-TIP achieves enhanced mathematical capabilities and outperforms traditional LLMs and tool-augmented LLMs in accuracy and reasoning diversity on math reasoning tasks. For instance, IMP-TIP can improve Tool-augmented ChatGPT on GSM8K-Hard from 56.0% to 65.2%.",Article,https://arxiv.org/abs/2401.05384,1,chen2023good,"large language models,tool augmented interleaf prompting"
2023,arXiv preprint arXiv:2312.04333,Beyond Surface: Probing LLaMA Across Scales and Layers,"Nuo Chen, Ning Wu, Shining Liang, Ming Gong, Linjun Shou, Dongmei Zhang, Jia Li",Nuo Chen,English,"This paper presents an in-depth analysis of Large Language Models (LLMs), focusing on LLaMA, a prominent open-source foundational model in natural language processing. Instead of assessing LLaMA through its generative output, we design multiple-choice tasks to probe its intrinsic understanding in high-order tasks such as reasoning and computation. We examine the model horizontally, comparing different sizes, and vertically, assessing different layers. We unveil several key and uncommon findings based on the designed probing tasks: (1) Horizontally, enlarging model sizes almost could not automatically impart additional knowledge or computational prowess. Instead, it can enhance reasoning abilities, especially in math problem solving, and helps reduce hallucinations, but only beyond certain size thresholds; (2) In vertical analysis, the lower layers of LLaMA lack substantial arithmetic and factual knowledge, showcasing logical thinking, multilingual and recognitive abilities, with top layers housing most computational power and real-world knowledge.",Article,https://arxiv.org/abs/2312.04333,1,chen2023beyond,"large language models,LLaMA"
2023,arXiv preprint arXiv:2304.04474,Missing Data Imputation with Graph Laplacian Pyramid Network,"Weiqi Zhang, Guanlve Li, Jianheng Tang, Jia Li, Fugee Tsung",Weiqi Zhang,English,"Data imputation is a prevalent and important task due to the ubiquitousness of missing data. Many efforts try to first draft a completed data and second refine to derive the imputation results, or ""draft-then-refine"" for short. In this work, we analyze this widespread practice from the perspective of Dirichlet energy. We find that a rudimentary ""draft"" imputation will decrease the Dirichlet energy, thus an energy-maintenance ""refine"" step is in need to recover the overall energy. Since existing ""refine"" methods such as Graph Convolutional Network (GCN) tend to cause further energy decline, in this work, we propose a novel framework called Graph Laplacian Pyramid Network (GLPN) to preserve Dirichlet energy and improve imputation performance. GLPN consists of a U-shaped autoencoder and residual networks to capture global and local detailed information respectively. By extensive experiments on several real-world datasets, GLPN shows superior performance over state-of-the-art methods under three different missing mechanisms. Our source code is available at https://github.com/liguanlue/GLPN.",Article,https://arxiv.org/abs/2304.04474,1,zhang2023missing,"Missing Data, Dirichlet Energy, Graph Deep Learning"
2023,EMNLP Findings,Natural Response Generation for Chinese Reading Comprehension,"Nuo Chen, Hongguang Li, Yinan Bao, Baoyuan Wang, Jia Li",Nuo Chen,English,"Machine reading comprehension (MRC) is an important area of conversation agents and draws a lot of attention. However, there is a notable limitation to current MRC benchmarks: The labeled answers are mostly either spans extracted from the target corpus or the choices of the given candidates, ignoring the natural aspect of high-quality responses. As a result, MRC models trained on these datasets can not generate human-like responses in real QA scenarios. To this end, we construct a new dataset called Penguin to promote the research of MRC, providing a training and test bed for natural response generation to real scenarios. Concretely, Penguin consists of 200k training data with high-quality fluent, and well-informed responses. Penguin is the first benchmark towards natural response generation in Chinese MRC on a relatively large scale. To address the challenges in Penguin, we develop two strong baselines: end-to-end and two-stage frameworks. Following that, we further design Prompt-BART: fine-tuning the pre-trained generative language models with a mixture of prefix prompts in Penguin. Extensive experiments validated the effectiveness of this design.",Article,https://arxiv.org/abs/2302.08817,1,chen2023natural,machine reading comprehension
2024,arXiv preprint arXiv:2406.05346,ProG: A Graph Prompt Learning Benchmark,"Chenyi Zi, Haihong Zhao, Xiangguo Sun, Yiqing Lin, Hong Cheng, Jia Li",Chenyi Zi,English,"Artificial general intelligence on graphs has shown significant advancements across various applications, yet the traditional 'Pre-train & Fine-tune' paradigm faces inefficiencies and negative transfer issues, particularly in complex and few-shot settings. Graph prompt learning emerges as a promising alternative, leveraging lightweight prompts to manipulate data and fill the task gap by reformulating downstream tasks to the pretext. However, several critical challenges still remain: how to unify diverse graph prompt models, how to evaluate the quality of graph prompts, and to improve their usability for practical comparisons and selection. In response to these challenges, we introduce the first comprehensive benchmark for graph prompt learning. Our benchmark integrates SIX pre-training methods and FIVE state-of-the-art graph prompt techniques, evaluated across FIFTEEN diverse datasets to assess performance, flexibility, and efficiency. We also present 'ProG', an easy-to-use open-source library that streamlines the execution of various graph prompt models, facilitating objective evaluations. Additionally, we propose a unified framework that categorizes existing graph prompt methods into two main approaches: prompts as graphs and prompts as tokens. This framework enhances the applicability and comparison of graph prompt techniques. The code is available at: https://github.com/sheldonresearch/ProG.",Article,https://arxiv.org/abs/2406.05346,0,zi2024prog,"graph prompt learning,fine-tuning"
2024,arXiv e-prints,DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation,"Weiqi Zhang, Jiexia Ye, Ziyue Li, Jia Li, Fugee Tsung",Weiqi Zhang,English,"The recent rapid development of language models (LMs) has attracted attention in the field of time series, including multimodal time series modeling. However, we note that current time series multimodal methods are biased, often assigning a primary role to one modality while the other assumes a secondary role. They overlook the mutual benefits and complementary of different modalities. For example, in seizure diagnosis, relying solely on textual clinical reports makes it difficult to pinpoint the area and type of the disease, while electroencephalograms (EEGs) alone cannot provide an accurate diagnosis without considering the symptoms. In this study, based on the complementary information mining of time series multimodal data, we propose DualTime, a Dual-adapter multimodal language model for Time series representation implementing temporal-primary and textual-primary modeling simultaneously. By injecting lightweight adaption tokens, the LM pipeline shared by dual adapters encourages embedding alignment and achieves efficient fine-tuning. Empirically, our method outperforms state-of-the-art models in both supervised and unsupervised settings, highlighting the complementary benefits of different modalities. In addition, we conduct few-shot label transfer experiments, which further verifies the transferability and expressiveness of our proposed DualTime.",Article,https://arxiv.org/pdf/2406.06620,0,zhang2024dualtime,"dual-adapter,multimodal language model"
2024,arXiv preprint arXiv:2405.20202,One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments,"Ke Yi, Yuhui Xu, Heng Chang, Chen Tang, Yuan Meng, Tong Zhang, Jia Li",Ke Yi,English,"Large Language Models (LLMs) have advanced rapidly but face significant memory demands. While quantization has shown promise for LLMs, current methods typically require lengthy training to alleviate the performance degradation from quantization loss. However, deploying LLMs across diverse scenarios with different resource constraints, e.g., servers and personal computers, requires repeated training per application, which amplifies the lengthy training problem. Given that, it is advantageous to train a once-for-all (OFA) supernet capable of yielding diverse optimal subnets for downstream applications through one-shot training. Nonetheless, the scale of current language models impedes efficiency and amplifies interference from weight sharing between subnets. We make an initial attempt to extend the once-for-all framework to large language models. Specifically, we decouple shared weights to eliminate the interference and incorporate Low-Rank adapters for training efficiency. Furthermore, we observe the imbalance allocation of training resources from the traditional uniform sampling. A non-parametric scheduler is introduced to adjust the sampling rate for each quantization configuration, achieving a more balanced allocation among subnets with varying demands. We validate the approach on LLaMA2 families, and downstream evaluation confirms our ability to maintain high performance while significantly reducing deployment time faced with multiple scenarios.",Article,https://arxiv.org/abs/2405.20202,0,yi2024one,"large language models,once-for-all,LLaMA"
2024,Proceedings of the ACM on Web Conference 2024,Weakly Supervised Anomaly Detection via Knowledge-Data Alignment,"Haihong Zhao, Chenyi Zi, Yang Liu, Chen Zhang, Yan Zhou, Jia Li",Haihong Zhao,English,"Anomaly detection (AD) plays a pivotal role in numerous web-based applications, including malware detection, anti-money laundering, device failure detection, and network fault analysis. Most methods, which rely on unsupervised learning, are hard to reach satisfactory detection accuracy due to the lack of labels. Weakly Supervised Anomaly Detection (WSAD) has been introduced with a limited number of labeled anomaly samples to enhance model performance. Nevertheless, it is still challenging for models, trained on an inadequate amount of labeled data, to generalize to unseen anomalies. In this paper, we introduce a novel framework Knowledge-Data Alignment (KDAlign) to integrate rule knowledge, typically summarized by human experts, to supplement the limited labeled data. Specifically, we transpose these rules into the knowledge space and subsequently recast the incorporation of knowledge as the alignment of knowledge and data. To facilitate this alignment, we employ the Optimal Transport (OT) technique. We then incorporate the OT distance as an additional loss term to the original objective function of WSAD methodologies. Comprehensive experimental results on five real-world datasets demonstrate that our proposed KDAlign framework markedly surpasses its state-of-the-art counterparts, achieving superior performance across various anomaly types.",Conference paper,https://arxiv.org/abs/2402.03785,0,zhao2024weakly,"Weakly Supervised Anomaly Detection,anomaly detection"
2024,arXiv preprint arXiv:2405.03003,Parameter-Efficient Fine-Tuning with Discrete Fourier Transform,"Ziqi Gao, Qichao Wang, Aochuan Chen, Zijing Liu, Bingzhe Wu, Liang Chen, Jia Li",Ziqi Gao,English,"Low-rank adaptation~(LoRA) has recently gained much interest in fine-tuning foundation models. It effectively reduces the number of trainable parameters by incorporating low-rank matrices  and  to represent the weight change, i.e., . Despite LoRA's progress, it faces storage challenges when handling extensive customization adaptations or larger base models. In this work, we aim to further compress trainable parameters by enjoying the powerful expressiveness of the Fourier transform. Specifically, we introduce FourierFT, which treats  as a matrix in the spatial domain and learns only a small fraction of its spectral coefficients. With the trained spectral coefficients, we implement the inverse discrete Fourier transform to recover . Empirically, our FourierFT method shows comparable or better performance with fewer parameters than LoRA on various tasks, including natural language understanding, natural language generation, instruction tuning, and image classification. For example, when performing instruction tuning on the LLaMA2-7B model, FourierFT surpasses LoRA with only 0.064M trainable parameters, compared to LoRA's 33.5M. Our code is released at \url{https://github.com/Chaos96/fourierft}.",Article,https://arxiv.org/abs/2405.03003,0,gao2024parameter,"low-rank adaptation,fine-tuning, LLaMA"
2024,arXiv preprint arXiv:2402.11235,ZeroG: Investigating Cross-dataset Zero-shot Transferability in Graphs,"Yuhan Li, Peisong Wang, Zhixun Li, Jeffrey Xu Yu, Jia Li",Yuhan Li,English,"With the development of foundation models such as large language models, zero-shot transfer learning has become increasingly significant. This is highlighted by the generative capabilities of NLP models like GPT-4, and the retrieval-based approaches of CV models like CLIP, both of which effectively bridge the gap between seen and unseen data. In the realm of graph learning, the continuous emergence of new graphs and the challenges of human labeling also amplify the necessity for zero-shot transfer learning, driving the exploration of approaches that can generalize across diverse graph data without necessitating dataset-specific and label-specific fine-tuning. In this study, we extend such paradigms to zero-shot transferability in graphs by introducing ZeroG, a new framework tailored to enable cross-dataset generalization. Addressing the inherent challenges such as feature misalignment, mismatched label spaces, and negative transfer, we leverage a language model to encode both node attributes and class semantics, ensuring consistent feature dimensions across datasets. We also propose a prompt-based subgraph sampling module that enriches the semantic information and structure information of extracted subgraphs using prompting nodes and neighborhood aggregation, respectively. We further adopt a lightweight fine-tuning strategy that reduces the risk of overfitting and maintains the zero-shot learning efficacy of the language model. The results underscore the effectiveness of our model in achieving significant cross-dataset zero-shot transferability, opening pathways for the development of graph foundation models. Especially?…",Article,https://arxiv.org/abs/2402.11235,0,li2024zerog,"Graph alignment, Unsupervised learning, Structure learning, Optimal transport"
2024,arXiv preprint arXiv:2401.02290,Path-based Explanation for Knowledge Graph Completion,"Heng Chang, Jiangnan Ye, Alejo Lopez Avila, Jinhua Du, Jia Li",Heng Chang,English,"Graph Neural Networks (GNNs) have achieved great success in Knowledge Graph Completion (KGC) by modelling how entities and relations interact in recent years. However, the explanation of the predicted facts has not caught the necessary attention. Proper explanations for the results of GNN-based KGC models increase model transparency and help researchers develop more reliable models. Existing practices for explaining KGC tasks rely on instance/subgraph-based approaches, while in some scenarios, paths can provide more user-friendly and interpretable explanations. Nonetheless, the methods for generating path-based explanations for KGs have not been well-explored. To address this gap, we propose Power-Link, the first path-based KGC explainer that explores GNN-based models. We design a novel simplified graph-powering technique, which enables the generation of path-based explanations with a fully parallelisable and memory-efficient training scheme. We further introduce three new metrics for quantitative evaluation of the explanations, together with a qualitative human evaluation. Extensive experiments demonstrate that Power-Link outperforms the SOTA baselines in interpretability, efficiency, and scalability.",Article,https://arxiv.org/abs/2401.02290,0,chang2024path,"Graph Neural Networks, Knowledge Graph Completion, Model Transparency, Model Explanation"
2023,None,Hierarchical Graph Latent Diffusion Model for Molecule Generation,"Tian Bian, Yifan Niu, Heng Chang, Divin Yan, Tingyang Xu, Yu Rong, Jia Li, Hong Cheng",Tian Bian,English,"Recently, generative models based on the diffusion process have emerged as a promising direction for automating the design of molecules. However, directly adding continuous Gaussian noise to discrete graphs leads to the problem of the final noisy data not conforming to the standard Gaussian distribution. Current graph diffusion models either corrupt discrete data through a transition matrix or relax the discrete data to continuous space for the diffusion process. These approaches not only require significant computation resources due to the inclusion of the bond type matrix but also cannot easily perform scalable conditional generation, such as adding cross-attention layers, due to the lack of embedding representations. In this paper, we first introduce the Graph Latent Diffusion Model (GLDM), a novel variant of latent diffusion models that overcomes the mismatch problem of continuous diffusion space and discrete data space. Meanwhile, the latent diffusion framework avoids the issues of computational resource consumption and lack of embeddings for conditional generation faced by current graph diffusion models. However, it only utilizes graph-level embeddings for molecule generation, losing node-level and structural information. Therefore, we further ex- tend the GLDM to the Hierarchical Graph Latent Diffusion Model (HGLDM). By including node embeddings and subgraph embeddings that contain structural in- formation, our model significantly reduces computation time compared to the cur- rent graph diffusion models. We evaluate our model on three benchmarks through unconditional generation and conditional generation tasks, which?…",Conference paper,https://openreview.net/forum?id=RSincg5RBe,0,bianhierarchical,"Hierarchical Graph Latent Diffusion, Molecule Generation"
2023,None,Trading-off Multiple Properties for Molecular Optimization,"Yifan Niu, Ziqi Gao, Tingyang Xu, Yatao Bian, Yu Rong, Jia Li",Yifan Niu,English,"Molecular optimization, a critical research area in drug discovery, aims to enhance the properties or performance of molecules through systematic modifications of their chemical structures. Recently, existing Multi-Objective Molecular Optimization (MOMO) methods are extended from Single-Objective Molecular Optimization (SOMO) approaches by employing techniques such as Linear Scalarization, Evolutionary Algorithms, and Multi-Objective Bayesian Optimization. In Multi-Objective Optimization, the ideal goal is to find Pareto optimal solutions over different preferences, which indicate the importance of different objectives. However, these straightforward extensions often struggle with trading off multiple properties due to the conflicting or correlated nature of certain properties.  More specifically, current MOMO methods derived from SOMO are still challenged in finding preference-conditioned Pareto solutions and exhibit low efficiency in Pareto search. To address the aforementioned problems, we propose the \textbf{P}reference-\textbf{C}onditioned \textbf{I}nversion (PCI) framework,  efficiently ``inverting'' a pre-trained surrogate oracle under the guidance of a non-dominated gradient, to generate candidate Pareto optimal molecules over preference-conditioned distributions. Additionally, we provide theoretical guarantees for PCI's capability in converging to preference-conditioned solutions. This unique characteristic enables PCI to search the full Pareto front approximately, thereby assisting in the discovery of diverse molecules with varying ratios of properties. Comprehensive experimental evaluations show that our model significantly?…",Conference paper,https://openreview.net/forum?id=7ezBaMwOqY,0,niutrading,"Molecular Optimization,Preference-Conditioned Inversion"
2023,arXiv preprint arXiv:2310.07446,ProbTS: A Unified Toolkit to Probe Deep Time-series Forecasting,"Jiawen Zhang, Xumeng Wen, Shun Zheng, Jia Li, Jiang Bian",Jiawen Zhang,English,"Time-series forecasting serves as a linchpin in a myriad of applications, spanning various domains. With the growth of deep learning, this arena has bifurcated into two salient branches: one focuses on crafting specific neural architectures tailored for time series, and the other harnesses advanced deep generative models for probabilistic forecasting. While both branches have made significant progress, their differences across data scenarios, methodological focuses, and decoding schemes pose profound, yet unexplored, research questions. To bridge this knowledge chasm, we introduce ProbTS, a pioneering toolkit developed to synergize and compare these two distinct branches. Endowed with a unified data module, a modularized model module, and a comprehensive evaluator module, ProbTS allows us to revisit and benchmark leading methods from both branches. The scrutiny with ProbTS highlights their distinct characteristics, relative strengths and weaknesses, and areas that need further exploration. Our analyses point to new avenues for research, aiming for more effective time-series forecasting.",Article,https://arxiv.org/abs/2310.07446,0,zhang2023probts,time-series forecasting
2023,ICDE 2023,Decision Support System for Chronic Diseases Based on Drug-Drug Interactions,"Tian Bian, Yuli Jiang, Jia Li, Tingyang Xu, Yu Rong, Yi Su, Timothy Kwok, Helen Meng, Hong Cheng",Tian Bian,English,"Many patients with chronic diseases resort to multiple medications to relieve various symptoms, which raises concerns about the safety of multiple medication use, as severe drug-drug antagonism can lead to serious adverse effects or even death. This paper presents a Decision Support System, called DSSDDI, based on drug-drug interactions to support doctors prescribing decisions. DSSDDI contains three modules, Drug-Drug Interaction (DDI) module, Medical Decision (MD) module and Medical Support (MS) module. The DDI module learns safer and more effective drug representations from the drug-drug interactions. To capture the potential causal relationship between DDI and medication use, the MD module considers the representations of patients and drugs as context, DDI and patients’ similarity as treatment, and medication use as outcome to construct counterfactual links for the representation learning?…",Article,https://ieeexplore.ieee.org/abstract/document/10184846/,0,bian2023decision,"Decision Support System, Drug-Drug Interactions, Causal Inference"
2022,US Patent 11,"Network communication method and system, device, and storage medium","Zhihao Shang, Jia Li, Huanxin Liu, Hongfei Zhou",Zhihao Shang,English,"This application discloses a network communication method applied to a network communication system including a first network device in a first private network, a second network device in a second private network and a gateway device coupling the first private network to the second private network. The first network device receives a first data packet transmitted from a terminal to a target blockchain node, and acquires an actual network address of the target blockchain node; and generates a second data packet according to the first data packet and the actual network address, and transmits the second data packet to a virtual network address of the second network device in the second private network, so that the operation overheads generated when the gateway device generates virtual network addresses for blockchain nodes can be reduced, thereby saving a storage space of the gateway device.",Conference paper,https://patents.google.com/patent/US11271892B2/en,11,shang2022network,"graph denoising, graph clustering, graph autoencoder"
