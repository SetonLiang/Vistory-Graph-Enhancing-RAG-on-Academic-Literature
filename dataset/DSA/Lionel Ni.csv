Year,Sources,Name,Authors,First Author,Chinese/English,Abstract,Venues,doi,Citation,Id,Keywords
2020,ACM computing surveys (csur),Generalizing from a few examples: A survey on few-shot learning,"Yaqing Wang, Quanming Yao, James T Kwok, Lionel M Ni",Yaqing Wang,English,"Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3386252,2950,wang2020generalizing,"Few-shot learning, one-shot learning, low-shot learning, small sample learning, meta-learning, prior knowledge"
2022,arXiv preprint arXiv:2203.03605,Dino: Detr with improved denoising anchor boxes for end-to-end object detection,"Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun Zhu, Lionel M Ni, Heung-Yeung Shum",Hao Zhang,English,"We present DINO (\textbf{D}ETR with \textbf{I}mproved de\textbf{N}oising anch\textbf{O}r boxes), a state-of-the-art end-to-end object detector. % in this paper. DINO improves over previous DETR-like models in performance and efficiency by using a contrastive way for denoising training, a mixed query selection method for anchor initialization, and a look forward twice scheme for box prediction. DINO achieves AP in  epochs and AP in  epochs on COCO with a ResNet-50 backbone and multi-scale features, yielding a significant improvement of \textbf{AP} and \textbf{AP}, respectively, compared to DN-DETR, the previous best DETR-like model. DINO scales well in both model size and data size. Without bells and whistles, after pre-training on the Objects365 dataset with a SwinL backbone, DINO obtains the best results on both COCO \texttt{val2017} (\textbf{AP}) and \texttt{test-dev} (\textbf{AP}). Compared to other models on the leaderboard, DINO significantly reduces its model size and pre-training data size while achieving better results. Our code will be available at \url{https://github.com/IDEACVR/DINO}.",Article,https://arxiv.org/abs/2203.03605,932,zhang2022dino,"Object Detection, Detection Transformer, End-to-End Detector"
2022,Proceedings of the IEEE/CVF conference on computer vision and pattern?…,Dn-detr: Accelerate detr training by introducing query denoising,"Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel M Ni, Lei Zhang",Feng Li,English,"We present in this paper a novel denoising training method to speedup DETR (DEtection TRansformer) training and offer a deepened understanding of the slow convergence issue of DETR-like methods. We show that the slow convergence results from the instability of bipartite graph matching which causes inconsistent optimization goals in early training stages. To address this issue, except for the Hungarian loss, our method additionally feeds ground-truth bounding boxes with noises into Transformer decoder and trains the model to reconstruct the original boxes, which effectively reduces the bipartite graph matching difficulty and leads to a faster convergence. Our method is universal and can be easily plugged into any DETR-like methods by adding dozens of lines of code to achieve a remarkable improvement. As a result, our DN-DETR results in a remarkable improvement (+ 1.9 AP) under the same setting and achieves the best result (AP 43.4 and 48.6 with 12 and 50 epochs of training respectively) among DETR-like methods with ResNet-50 backbone. Our code will be released after the blind review.",Conference paper,http://openaccess.thecvf.com/content/CVPR2022/html/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.html,488,li2022dn,"denoising,Detection Transformer"
2023,Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?…,Mask dino: Towards a unified transformer-based framework for object detection and segmentation,"Feng Li, Hao Zhang, Huaizhe Xu, Shilong Liu, Lei Zhang, Lionel M Ni, Heung-Yeung Shum",Feng Li,English,"In this paper we present Mask DINO, a unified object detection and segmentation framework. Mask DINO extends DINO (DETR with Improved Denoising Anchor Boxes) by adding a mask prediction branch which supports all image segmentation tasks (instance, panoptic, and semantic). It makes use of the query embeddings from DINO to dot-product a high-resolution pixel embedding map to predict a set of binary masks. Some key components in DINO are extended for segmentation through a shared architecture and training process. Mask DINO is simple, efficient, scalable, and benefits from joint large-scale detection and segmentation datasets. Our experiments show that Mask DINO significantly outperforms all existing specialized segmentation methods, both on a ResNet-50 backbone and a pre-trained model with SwinL backbone. Notably, Mask DINO establishes the best results to date on instance segmentation (54.5 AP on COCO), panoptic segmentation (59.4 PQ on COCO), and semantic segmentation (60.8 mIoU on ADE20K) among models under one billion parameters. We will release the code after the blind review.",Conference paper,http://openaccess.thecvf.com/content/CVPR2023/html/Li_Mask_DINO_Towards_a_Unified_Transformer-Based_Framework_for_Object_Detection_CVPR_2023_paper.html,244,li2023mask,"object detection and segmentation,Detection Transformer"
2020,Information Sciences 523,Knowledge modeling via contextualized representations for LSTM-based personalized exercise recommendation,"Yujia Huo, Derek F Wong, Lionel M Ni, Lidia S Chao, Jing Zhang",Yujia Huo,English,"Intelligent education systems have enabled personalized learning (PL). In PL, students are presented with educational contents that are consistent with their personal knowledge states (KS), and the critical task is accurately estimating these states through data. Knowledge tracing (KT) infers KS (latent) through historical student interactions (observed) with the knowledge components (KCs). A wide variety of KT techniques have been developed, from Bayesian Knowledge Tracing (BKT) to Deep Knowledge Tracing (DKT). However, in most of these methods, the KCs are represented as stand-alone entities, and the effect of representing KCs using contexts such as learning-related factors has been under-investigated. Also, KT needs to generate personalized results to facilitate tasks such as exercise recommendation. In this paper, we propose two approaches that use a contextualized representation of KCs, one with?…",Article,https://www.sciencedirect.com/science/article/pii/S002002552030195X,81,huo2020knowledge,"Personalized learning , Knowledge tracing LSTM, Context representation, Exercise recommendation"
2020,IEEE Internet of Things Journal,FraudTrip: Taxi fraudulent trip detection from corresponding trajectories,"Ye Ding, Wenyi Zhang, Xibo Zhou, Qing Liao, Qiong Luo, Lionel M Ni",Ye Ding,English,"A passenger is overcharged by the taxi driver is one common type of fraudulent trip, and it brings negative impacts to modern cities. Most existing fraudulent trip detection works rely on the assumption that the trip is correctly recorded by the taximeter. However, there are many taxi drivers in China carrying passengers without activating the taximeter, especially when the taxi driver is trying to overcharge the passengers. Hence, existing detection methods cannot be directly applied to such real-world scenario. In this article, we propose a system, called “FraudTrip,” which detects “unmetered” taxi trips based on a novel fraud detection algorithm and a heuristic maximum fraudulent trajectory construction algorithm. Based on the experiments on both synthetic and real-world trajectory data sets, FraudTrip can effectively and efficiently detect fraudulent trips without the help of taximeters.",Article,https://ieeexplore.ieee.org/abstract/document/9177063/,64,ding2020fraudtrip,"anomaly detection, taxi fraud detection, trajectory"
2023,Proceedings of the IEEE/CVF conference on computer vision and pattern?…,Lite detr: An interleaved multi-scale encoder for efficient detr,"Feng Li, Ailing Zeng, Shilong Liu, Hao Zhang, Hongyang Li, Lei Zhang, Lionel M Ni",Feng Li,English,"Recent DEtection TRansformer-based (DETR) models have obtained remarkable performance. Its success cannot be achieved without the re-introduction of multi-scale feature fusion in the encoder. However, the excessively increased tokens in multi-scale features, especially for about 75% of low-level features, are quite computationally inefficient, which hinders real applications of DETR models. In this paper, we present Lite DETR, a simple yet efficient end-to-end object detection framework that can effectively reduce the GFLOPs of the detection head by 60% while keeping 99% of the original performance. Specifically, we design an efficient encoder block to update high-level features (corresponding to small-resolution feature maps) and low-level features (corresponding to large-resolution feature maps) in an interleaved way. In addition, to better fuse cross-scale features, we develop a key-aware deformable attention to predict more reliable attention weights. Comprehensive experiments validate the effectiveness and efficiency of the proposed Lite DETR, and the efficient encoder strategy can generalize well across existing DETR-based models. The code will be released after the blind review.",Conference paper,http://openaccess.thecvf.com/content/CVPR2023/html/Li_Lite_DETR_An_Interleaved_Multi-Scale_Encoder_for_Efficient_DETR_CVPR_2023_paper.html,44,li2023lite,"Detection Transformer,end-to-end object detection"
2022,arXiv preprint arXiv:2203.01922,"Vision-language intelligence: Tasks, representation learning, and large models","Feng Li, Hao Zhang, Yi-Fan Zhang, Shilong Liu, Jian Guo, Lionel M Ni, PengChuan Zhang, Lei Zhang",Feng Li,English,"This paper presents a comprehensive survey of vision-language (VL) intelligence from the perspective of time. This survey is inspired by the remarkable progress in both computer vision and natural language processing, and recent trends shifting from single modality processing to multiple modality comprehension. We summarize the development in this field into three time periods, namely task-specific methods, vision-language pre-training (VLP) methods, and larger models empowered by large-scale weakly-labeled data. We first take some common VL tasks as examples to introduce the development of task-specific methods. Then we focus on VLP methods and comprehensively review key components of the model structures and training methods. After that, we show how recent work utilizes large-scale raw image-text data to learn language-aligned visual representations that generalize better on zero or few shot learning tasks. Finally, we discuss some potential future trends towards modality cooperation, unified representation, and knowledge incorporation. We believe that this review will be of help for researchers and practitioners of AI and ML, especially those interested in computer vision and natural language processing.",Article,https://arxiv.org/abs/2203.01922,34,li2022vision,"vision-language intelligence, representation learning, computer vision"
2023,Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?…,Mp-former: Mask-piloted transformer for image segmentation,"Hao Zhang, Feng Li, Huaizhe Xu, Shijia Huang, Shilong Liu, Lionel M Ni, Lei Zhang",Hao Zhang,English,"We present a mask-piloted Transformer which improves masked-attention in Mask2Former for image segmentation. The improvement is based on our observation that Mask2Former suffers from inconsistent mask predictions between consecutive decoder layers, which leads to inconsistent optimization goals and low utilization of decoder queries. To address this problem, we propose a mask-piloted training approach, which additionally feeds noised ground-truth masks in masked-attention and trains the model to reconstruct the original ones. Compared with the predicted masks used in mask-attention, the ground-truth masks serve as a pilot and effectively alleviate the negative impact of inaccurate mask predictions in Mask2Former. Based on this technique, our MP-Former achieves a remarkable performance improvement on all three image segmentation tasks (instance, panoptic, and semantic), yielding+ 2.3 AP and+ 1.6 mIoU on the Cityscapes instance and semantic segmentation tasks with a ResNet-50 backbone. Our method also significantly speeds up the training, outperforming Mask2Former with half of the number of training epochs on ADE20K with both a ResNet-50 and a Swin-L backbones. Moreover, our method only introduces little computation during training and no extra computation during inference. Our code will be released at https://github. com/IDEA-Research/MP-Former.",Conference paper,http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_MP-Former_Mask-Piloted_Transformer_for_Image_Segmentation_CVPR_2023_paper.html,32,zhang2023mp,"mask-piloted Transformer, image segmentation, Resnet"
2020,Knowledge-Based Systems 207,HeTROPY: Explainable learning diagnostics via heterogeneous maximum-entropy and multi-spatial knowledge representation,"Yujia Huo, Derek F Wong, Lionel M Ni, Lidia S Chao, Jing Zhang",Yujia Huo,English,"Autonomous learning diagnostics, where the students’ strengths and weaknesses are disclosed from their observed performance data, is a challenging task in e-learning systems. Current student knowledge models can alleviate some of the problems in learning (i.e. predicting student performance) but they neglect learning diagnostics, which is based on causal reasoning. To this end, we propose a novel heterogeneous attention interpreter with a maximum entropy regularizer on top of a student knowledge model to achieve explainable learning diagnostics. Our model segregates the impact of the homogeneous knowledge points, while promoting the heterogeneous relatives by maximizing their chance to contribute to the prediction. We also propose a multi-spatial knowledge representation that is readily generalizable to other data-driven educational tasks. Extensive experiments on real-world datasets reveal that?…",Article,https://www.sciencedirect.com/science/article/pii/S095070512030527X,14,huo2020hetropy,"Causal reasoning,Knowledge representation,Learning diagnostics,Relation prediction"
2023,arXiv preprint arXiv:2302.13002 3,DA-BEV: Depth aware BEV transformer for 3D object detection,"Hao Zhang, Hongyang Li, Xingyu Liao, Feng Li, Shilong Liu, Lionel M Ni, Lei Zhang",Hao Zhang,English,None,Article,https://scholar.google.com/scholar?cluster=15866523284122625081&hl=en&oi=scholarr,8,zhang2023bev,"Transformer,Object Detection"
2020,IEEE Transactions on Image Processing 29,Generalized convolutional sparse coding with unknown noise,"Yaqing Wang, James T Kwok, Lionel M Ni",Yaqing Wang,English,"Convolutional sparse coding (CSC) can learn representative shift-invariant patterns from data. However, existing CSC methods assume the Gaussian noise, which can be restrictive in some challenging applications. In this paper, we propose a generalized CSC model capable of handling complicated unknown noise. The noise is modeled by the Gaussian mixture model, which can approximate any continuous probability density function. The Expectation-Maximization algorithm is used to solve the resultant learning problem. For efficient optimization, the crux is to speed up the convolution in the frequency domain while keeping the other computations involving the weight matrix in the spatial domain. We design an efficient solver for the weighted CSC problem in the M-step. The dictionary and codes are updated simultaneously by an efficient nonconvex accelerated proximal gradient algorithm. The resultant?…",Article,https://ieeexplore.ieee.org/abstract/document/9049336/,8,wang2020generalized,"convolutional sparse coding, noise modeling, Gaussian mixture model"
2023,arXiv preprint arXiv:2308.00016,Alpha-gpt: Human-ai interactive alpha mining for quantitative investment,"Saizhuo Wang, Hang Yuan, Leon Zhou, Lionel M Ni, Heung-Yeung Shum, Jian Guo",Saizhuo Wang,English,"One of the most important tasks in quantitative investment research is mining new alphas (effective trading signals or factors). Traditional alpha mining methods, either hand-crafted factor synthesizing or algorithmic factor mining (e.g., search with genetic programming), have inherent limitations, especially in implementing the ideas of quants. In this work, we propose a new alpha mining paradigm by introducing human-AI interaction, and a novel prompt engineering algorithmic framework to implement this paradigm by leveraging the power of large language models. Moreover, we develop Alpha-GPT, a new interactive alpha mining system framework that provides a heuristic way to ``understand'' the ideas of quant researchers and outputs creative, insightful, and effective alphas. We demonstrate the effectiveness and advantage of Alpha-GPT via a number of alpha mining experiments.",Article,https://arxiv.org/abs/2308.00016,6,wang2023alpha,"large language models,quantitative investment"
2023,Journal of Computer Science and Technology,"Ubiquitous WiFi and Acoustic Sensing: Principles, Technologies, and Applications","Jia-Ling Huang, Yun-Shu Wang, Yong-Pan Zou, Kai-Shun Wu, Lionel Ming-shuan Ni",Jia-Ling Huang,English,"With the increasing pervasiveness of mobile devices such as smartphones, smart TVs, and wearables, smart sensing, transforming the physical world into digital information based on various sensing medias, has drawn researchers’ great attention. Among different sensing medias, WiFi and acoustic signals stand out due to their ubiquity and zero hardware cost. Based on different basic principles, researchers have proposed different technologies for sensing applications with WiFi and acoustic signals covering human activity recognition, motion tracking, indoor localization, health monitoring, and the like. To enable readers to get a comprehensive understanding of ubiquitous wireless sensing, we conduct a survey of existing work to introduce their underlying principles, proposed technologies, and practical applications. Besides we also discuss some open issues of this research area. Our survey reals that as a?…",Article,https://link.springer.com/article/10.1007/s11390-023-3073-5,5,huang2023ubiquitous,"WiFi sensing, acoustic sensing, human-computer interaction, human activity recognition"
2022,arXiv preprint arXiv:2301.04020,"Quant 4.0: Engineering Quantitative Investment with Automated, Explainable and Knowledge-driven Artificial Intelligence","Jian Guo, Saizhuo Wang, Lionel M Ni, Heung-Yeung Shum",Jian Guo,English,"Quantitative investment (``quant'') is an interdisciplinary field combining financial engineering, computer science, mathematics, statistics, etc. Quant has become one of the mainstream investment methodologies over the past decades, and has experienced three generations: Quant 1.0, trading by mathematical modeling to discover mis-priced assets in markets; Quant 2.0, shifting quant research pipeline from small ``strategy workshops'' to large ``alpha factories''; Quant 3.0, applying deep learning techniques to discover complex nonlinear pricing rules. Despite its advantage in prediction, deep learning relies on extremely large data volume and labor-intensive tuning of ``black-box'' neural network models. To address these limitations, in this paper, we introduce Quant 4.0 and provide an engineering perspective for next-generation quant. Quant 4.0 has three key differentiating components. First, automated AI changes quant pipeline from traditional hand-craft modeling to the state-of-the-art automated modeling, practicing the philosophy of ``algorithm produces algorithm, model builds model, and eventually AI creates AI''. Second, explainable AI develops new techniques to better understand and interpret investment decisions made by machine learning black-boxes, and explains complicated and hidden risk exposures. Third, knowledge-driven AI is a supplement to data-driven AI such as deep learning and it incorporates prior knowledge into modeling to improve investment decision, in particular for quantitative value investing. Moreover, we discuss how to build a system that practices the Quant 4.0 concept. Finally, we propose ten challenging?…",Article,https://arxiv.org/abs/2301.04020,5,guo2022quant,"Quantitative investment,Knowledge-driven AI"
2021,Knowledge-Based Systems 229,Learning cognitive embedding using signed knowledge interaction graph,"Yujia Huo, Derek F Wong, Lionel M Ni, Lidia S Chao, Jing Zhang, Xin Zuo",Yujia Huo,English,"Measuring learner cognition based on their problem-solving performance is a joint discipline of cognitive psychology and machine learning. In the case of learner problem-solving, the interaction between learner and knowledge forms a typical type of signed interaction graph. Interaction graphs are a widely used and effective solution to model the relationships between interacting entities. However, most of previous interaction graph methods are inclined to the observed interactions as positive links but they often fail to consider unobserved and negative links, which leads to an insufficiency in capturing the complete cognition/mis-cognition proximity information. To address this limitation, we propose a knowledge graph representation learning method that is based on signed knowledge interaction network (SKIN). We explicitly model the correct/incorrect cognitive performance as the positively+/negatively? signed?…",Article,https://www.sciencedirect.com/science/article/pii/S095070512100589X,4,huo2021learning,"Signed interaction graph,Representation learning,Knowledge representation"
2023,arXiv preprint arXiv:2302.09347,Closed-loop transcription via convolutional sparse coding,"Xili Dai, Ke Chen, Shengbang Tong, Jingyuan Zhang, Xingjian Gao, Mingyang Li, Druv Pai, Yuexiang Zhai, XIaojun Yuan, Heung-Yeung Shum, Lionel M Ni, Yi Ma",Xili Dai,English,"Autoencoding has achieved great empirical success as a framework for learning generative models for natural images. Autoencoders often use generic deep networks as the encoder or decoder, which are difficult to interpret, and the learned representations lack clear structure. In this work, we make the explicit assumption that the image distribution is generated from a multi-stage sparse deconvolution. The corresponding inverse map, which we use as an encoder, is a multi-stage convolution sparse coding (CSC), with each stage obtained from unrolling an optimization algorithm for solving the corresponding (convexified) sparse coding program. To avoid computational difficulties in minimizing distributional distance between the real and generated images, we utilize the recent closed-loop transcription (CTRL) framework that optimizes the rate reduction of the learned sparse representations. Conceptually, our method has high-level connections to score-matching methods such as diffusion models. Empirically, our framework demonstrates competitive performance on large-scale datasets, such as ImageNet-1K, compared to existing autoencoding and generative methods under fair conditions. Even with simpler networks and fewer computational resources, our method demonstrates high visual quality in regenerated images. More surprisingly, the learned autoencoder performs well on unseen datasets. Our method enjoys several side benefits, including more structured and interpretable representations, more stable convergence, and scalability to large datasets. Our method is arguably the first to demonstrate that a concatenation of multiple?…",Article,https://arxiv.org/abs/2302.09347,3,dai2023closed,"convolution sparse coding, closed-loop transcription"
2023,Journal of Computer Science and Technology,HXPY: A high-performance data processing package for financial time-series data,"Jiadong Guo, Jingshu Peng, Hang Yuan, Lionel Ming-shuan Ni",Jiadong Guo,English,"A tremendous amount of data has been generated by global financial markets everyday, and such time-series data needs to be analyzed in real time to explore its potential value. In recent years, we have witnessed the successful adoption of machine learning models on financial data, where the importance of accuracy and timeliness demands highly effective computing frameworks. However, traditional financial time-series data processing frameworks have shown performance degradation and adaptation issues, such as the outlier handling with stock suspension in Pandas and TA-Lib. In this paper, we propose HXPY, a high-performance data processing package with a C++/Python interface for financial time-series data. HXPY supports miscellaneous acceleration techniques such as the streaming algorithm, the vectorization instruction set, and memory optimization, together with various functions such as time?…",Article,https://link.springer.com/article/10.1007/s11390-023-2879-5,3,guo2023hxpy,"dataframe, time-series data, SIMD (single instruction multiple data), CUDA (Compute Unified Device Architecture)"
2021,Neurocomputing 444,iMatching: An interactive map-matching system,"Ye Ding, Xibo Zhou, Qing Liao, Haoyu Tan, Qiong Luo, Lionel M Ni",Ye Ding,English,"Map-matching is a process that aligns location points on a digital map and it is an essential step in location-based services. However, regular map-matching methods cannot archive very high accuracy due to the errors in raw location data and the complexity of road networks. Hence, the final resort for map matching is often through manual annotation, which is human labour intensive. Therefore, we propose iMatching, an interactive system for map-matching which greatly reduces annotation cost and achieves a high accuracy through an active learning approach. Specifically, we model the mapping of a sequence of location points to a road network as a hidden Markov model and automatically generate an initial result. Then, we select error-prone points on the trajectory and guide the annotator to review, and possibly correct, the results. Our evaluation on both real-world and synthetic data demonstrates that?…",Article,https://www.sciencedirect.com/science/article/pii/S0925231221001272,3,ding2021imatching,"Map-matching,Active learning,Trajectory analysis,Urban computing"
2022,INFORMS Journal on Computing,Unsupervised Learning for Human Mobility Behaviors,"Siyuan Liu, Shaojie Tang, Jiangchuan Zheng, Lionel M Ni",Siyuan Liu,English,"Learning human mobility behaviors from location-sensing data are crucial to mobility data mining because of its potential to address a range of analytical purposes in mobile context reasoning, including exploration, inference, and prediction. However, existing approaches suffer from two practical problems: temporal and spatial sparsity. To address these shortcomings, we present two unsupervised learning methods to model the mobility behaviors of multiple users (i.e., a population), considering efficiency and accuracy. These methods intelligently overcome the sparsity in individual data by seeking temporal commonality among users’ heterogeneous location behaviors. The advantages of our models are highlighted through experiments on several real-world mobility data sets, which also show how our methods can realize the three analytical purposes in a unified manner.",Article,https://pubsonline.informs.org/doi/abs/10.1287/ijoc.2021.1098,0,liu2022unsupervised,"human mobility behavior, unsupervised learning, mobile sensing,sparsity"
