Year,Sources,Name,Authors,First Author,Chinese/English,Abstract,Venues,doi,Citation,Id,Keywords
2021,ACM CHI Conference on Human Factors in Computing Systems,DistanciAR: Authoring Site-Specific Augmented Reality Experiences for Remote Environments,"Zeyu Wang, Cuong Nguyen, Paul Asente, Julie Dorsey",Zeyu Wang,English,"Most augmented reality (AR) authoring tools only support the author¡¯s current environment, but designers often need to create site-specific experiences for a different environment. We propose DistanciAR, a novel tablet-based workflow for remote AR authoring. Our baseline solution involves three steps. A remote environment is captured by a camera with LiDAR; then, the author creates an AR experience from a different location using AR interactions; finally, a remote viewer consumes the AR content on site. A formative study revealed understanding and navigating the remote space as key challenges with this solution. We improved the authoring interface by adding two novel modes: Dollhouse, which renders a bird¡¯s-eye view, and Peek, which creates photorealistic composite images using captured images. A second study compared this improved system with the baseline, and participants reported that the new?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3411764.3445552,42,wang2021distanciar,"augmented reality, remote authoring, spatial design, 3D scanning "
2021,ACM Transactions on Graphics,Tracing Versus Freehand for Evaluating Computer-Generated Drawings,"Zeyu Wang, Sherry Qiu, Nicole Feng, Holly Rushmeier, Leonard McMillan, Julie Dorsey",Zeyu Wang,English,"Non-photorealistic rendering (NPR) and image processing algorithms are widely assumed as a proxy for drawing. However, this assumption is not well assessed due to the difficulty in collecting and registering freehand drawings. Alternatively, tracings are easier to collect and register, but there is no quantitative evaluation of tracing as a proxy for freehand drawing. In this paper, we compare tracing, freehand drawing, and computer-generated drawing approximation (CGDA) to understand their similarities and differences. We collected a dataset of 1,498 tracings and freehand drawings by 110 participants for 100 image prompts. Our drawings are registered to the prompts and include vector-based timestamped strokes collected via stylus input. Comparing tracing and freehand drawing, we found a high degree of similarity in stroke placement and types of strokes used over time. We show that tracing can serve as a?¡­",Article,https://dl.acm.org/doi/abs/10.1145/3450626.3459819,21,wang2021tracing,"sketch dataset, drawing process, stroke analysis"
2021,ACM Transactions on Applied Perception,The Role of Subsurface Scattering in Glossiness Perception,"Davit Gigilashvili, Weiqi Shi, Zeyu Wang, Marius Pedersen, Jon Yngve Hardeberg, Holly Rushmeier",Davit Gigilashvili,English,"This study investigates the potential impact of subsurface light transport on gloss perception for the purposes of broadening our understanding of visual appearance in computer graphics applications. Gloss is an important attribute for characterizing material appearance. We hypothesize that subsurface scattering of light impacts the glossiness perception. However, gloss has been traditionally studied as a surface-related quality and the findings in the state-of-the-art are usually based on fully opaque materials, although the visual cues of glossiness can be impacted by light transmission as well. To address this gap and to test our hypothesis, we conducted psychophysical experiments and found that subjects are able to tell the difference in terms of gloss between stimuli that differ in subsurface light transport but have identical surface qualities and object shape. This gives us a clear indication that subsurface light?¡­",Article,https://dl.acm.org/doi/abs/10.1145/3458438,21,gigilashvili2021role,"Material appearance, gloss perception, translucency perception, subsurface light transport, MTurk"
2024,IEEE/CVF Conference on Computer Vision and Pattern Recognition,SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting,"Zhijing Shao, Zhaolong Wang, Zhuang Li, Duotun Wang, Xiangru Lin, Yu Zhang, Mingming Fan, Zeyu Wang",Zhijing Shao,English,We present SplattingAvatar a hybrid 3D representation of photorealistic human avatars with Gaussian Splatting embedded on a triangle mesh which renders over 300 FPS on a modern GPU and 30 FPS on a mobile device. We disentangle the motion and appearance of a virtual human with explicit mesh geometry and implicit appearance modeling with Gaussian Splatting. The Gaussians are defined by barycentric coordinates and displacement on a triangle mesh as Phong surfaces. We extend lifted optimization to simultaneously optimize the parameters of the Gaussians while walking on the triangle mesh. SplattingAvatar is a hybrid representation of virtual humans where the mesh represents low-frequency motion and surface deformation while the Gaussians take over the high-frequency geometry and detailed appearance. Unlike existing deformation methods that rely on an MLP-based linear blend skinning (LBS) field for motion we control the rotation and translation of the Gaussians directly by mesh which empowers its compatibility with various animation techniques eg skeletal animation blend shapes and mesh editing. Trainable from monocular videos for both full-body and head avatars SplattingAvatar shows state-of-the-art rendering quality across multiple datasets.,Conference paper,https://openaccess.thecvf.com/content/CVPR2024/html/Shao_SplattingAvatar_Realistic_Real-Time_Human_Avatars_with_Mesh-Embedded_Gaussian_Splatting_CVPR_2024_paper.html,10,shao2024splattingavatar,"human avatar,Gaussian Splatting,FPS,GPU,mesh"
2021,Eurographics Symposium on Rendering,A Low-Dimensional Perceptual Space for Intuitive BRDF Editing,"Weiqi Shi, Zeyu Wang, Cyril Soler, Holly Rushmeier",Weiqi Shi,English,"Understanding and characterizing material appearance based on human perception is challenging because of the highdimensionality and nonlinearity of reflectance data. We refer to the process of identifying specific characteristics of material appearance within the same category as material estimation, in contrast to material categorization which focuses on identifying inter-category differences [FNG15]. In this paper, we present a method to simulate the material estimation process based on human perception. We create a continuous perceptual space for measured tabulated data based on its underlying low-dimensional manifold. Unlike many previous works that only address individual perceptual attributes (such as gloss), we focus on extracting all possible dimensions that can explain the perceived differences between appearances. Additionally, we propose a new material editing interface that combines image navigation and sliders to visualize each perceptual dimension and facilitate the editing of tabulated BRDFs. We conduct a user study to evaluate the efficacy of the perceptual space and the interface in terms of appearance matching.",Conference paper,https://inria.hal.science/hal-03364272/,9,shi2021low,"material estimation,human perception"
2023,ACM CHI Conference on Human Factors in Computing Systems,PointShopAR: Supporting Environmental Design Prototyping Using Point Cloud in Augmented Reality,"Zeyu Wang, Cuong Nguyen, Paul Asente, Julie Dorsey",Zeyu Wang,English," We present PointShopAR, a novel tablet-based system for AR environmental design using point clouds as the underlying representation. It integrates point cloud capture and editing in a single AR workflow to help users quickly prototype design ideas in their spatial context. We hypothesize that point clouds are well suited for prototyping, as they can be captured more rapidly than textured meshes and then edited immediately in situ on the capturing device. We based the design of PointShopAR on the practical needs of six architects in a formative study. Our system supports a variety of point cloud editing operations in AR, including selection, transformation, hole filling, drawing, morphing, and animation. We evaluate PointShopAR through a remote study on usability and an in-person study on environmental design support. Participants were able to iterate design rapidly, showing the merits of an integrated capture?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3544548.3580776,8,wang2023pointshopar,"AR design, point cloud, capture and editing"
2023,IEEE Transactions on Learning Technologies,Introducing Massive Open Metaverse Course and Its Enabling Technology,"Kang Zhang, Zhijing Shao, Yun Lu, Ying Yu, Wei Sun, Zeyu Wang",Kang Zhang,English,"As metaverse becomes one of the most popular buzzwords in technology, there is still a lack of support to integrate true metaverse learning experiences in massive open online courses (MOOCs). This article introduces a new framework of massive open metaverse courses (MOMCs) and its major enabling technologies, which add immersive and 3-D learning experiences lacking in MOOCs. It then describes a detailed case study, the President's First Lecture at the Hong Kong University of Science and Technology (Guangzhou), which we consider the world's first true MOMC environment, enabled by the latest volumetric video and related virtual and augmented reality technologies. We describe in detail how this course is created and discuss the major advantages of MOMC over MOOC as well as its current limitations.",Article,https://ieeexplore.ieee.org/abstract/document/10164142/,4,zhang2023introducing,"Immersive learning, massive open metaverse courses (MOMC), massive open online courses (MOOC), metaverse, virtual and augmented reality, volumetric video"
2021,Eurographics Workshop on Graphics and Cultural Heritage,Reconstructing Dura-Europos From Sparse Photo Collections Using Deep Contour Extraction,"Yifen Shen, Zeyu Wang, Qinying Sun, Anne Chen, Holly Rushmeier",Yifen Shen,English,"In this short paper we present work in progress on creating tools to facilitate 3D reconstruction of cultural heritage. We propose three new types of tools to make reconstruction easier¨Cfirst we fetch linked open data to help organize source materials, next we extract key contours from photographs to speed up reconstruction, and finally we generate video tours of positioned photos and sketches. We also introduce a new, expanded 3D software system to support these tasks. The system is developed based on previous work on 3D sketching in the context of cultural heritage documentation, in particular CHER-ish. We demonstrate the potential of these tools by describing results obtained from the Dura-Europos data set.",Conference paper,https://diglib.eg.org/bitstream/handle/10.2312/gch20211408/075-078.pdf,3,shen2021reconstructing,"3D reconstruction,deep contour extraction, photo collection,culture heritage"
2023,International Symposium on Visual Information Communication and Interaction?¡­,From Expanded Cinema to Extended Reality: How AI Can Expand and Extend Cinematic Experiences,"Junrong Song, Bingyuan Wang, Zeyu Wang, David Kei-man Yip",Junrong Song,English," This paper explores the concept of expanded cinema and its relationship to extended reality (XR), focusing on the potential of artificial intelligence (AI) to expand and extend expressive possibilities. Expanded cinema refers to experimental film and multimedia art forms that challenge the conventions of traditional cinema by creating immersive and interactive experiences for audiences. XR, on the other hand, blurs the line between physical and virtual reality, offering immersive storytelling experiences. Both expanded cinema and XR aim to push the boundaries of traditional norms and create immersive experiences through the integration of technology, interactivity, and cross-sensory elements. The paper emphasizes the role of AI in optimizing 3D scene creation for XR and enhancing the overall experience through a case study. It also presents several AI-based techniques, such as generative models and AI?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3615522.3615556,2,song2023expanded,"Extended reality, expanded cinema, artificial intelligence"
2022,ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its?¡­,Envisioning A Hyper-Learning System in the Age of Metaverse,"Anqi Wang, Gao Ze, Zeyu Wang, Tristan Braud, Pan Hui",Anqi Wang,English,"The digital technologies, such as interactive interfaces, augmented reality (AR), and virtual reality (VR), are emerging as the latest examples of an ongoing trend of digitizing learning in the metaverse. Their pervasive impact requires us to rethink the notion of information gathering and learning [Pokhrel and Chhetri 2021]. Although much research has been devoted to AR/VR/metaverse education, there is little research on the pedagogical interactions of pre-learning information in the metaverse. Pre-learning refers to",Conference paper,https://dl.acm.org/doi/abs/10.1145/3574131.3574427,2,wang2022envisioning,None
