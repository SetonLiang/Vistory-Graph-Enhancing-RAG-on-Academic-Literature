Year,Sources,Name,Authors,First Author,Chinese/English,Abstract,Venues,doi,Citation,Id,Keywords
2020,Proceedings of the 26th ACM SIGKDD international conference on knowledge?¡­,Robust spammer detection by nash reinforcement learning,"Yingtong Dou, Guixiang Ma, Philip S Yu, Sihong Xie",Yingtong Dou,English,"Online reviews provide product evaluations for customers to make decisions. Unfortunately, the evaluations can be manipulated using fake reviews (""spams"") by professional spammers, who have learned increasingly insidious and powerful spamming strategies by adapting to the deployed detectors. Spamming strategies are hard to capture, as they can be varying quickly along time, different across spammers and target products, and more critically, remained unknown in most cases. Furthermore, most existing detectors focus on detection accuracy, which is not well-aligned with the goal of maintaining the trustworthiness of product evaluations. To address the challenges, we formulate a minimax game where the spammers and spam detectors compete with each other on their practical goals that are not solely based on detection accuracy. Nash equilibria of the game lead to stable detectors that are agnostic to any?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3394486.3403135,55,dou2020robust,"Spam Detection, Reinforcement Learning, Adversarial Learning"
2023,IEEE Transactions on Knowledge and Data Engineering,Inconsistent Matters: A Knowledge-guided Dual-consistency Network for Multi-modal Rumor Detection,"and Philip S. Yu Mengzhu Sun, Xi Zhang, Jianqiang Ma, Sihong Xie, Yazheng Liu",and Philip S. Yu Mengzhu Sun,English,"Rumor spreaders are increasingly utilizing multimedia content to attract the attention and trust of news consumers. Though quite a few rumor detection models have exploited the multi-modal data, they seldom consider the inconsistent semantics between images and texts, and rarely spot the inconsistency among the post contents and background knowledge. In addition, they commonly assume the completeness of multiple modalities and thus are incapable of handling handle missing modalities in real-life scenarios. Motivated by the intuition that rumors in social media are more likely to have inconsistent semantics, a novel  Knowledge-guided Dual-consistency Network  is proposed to detect rumors with multimedia contents. It uses two consistency detection subnetworks to capture the inconsistency at the cross-modal level and the content-knowledge level simultaneously. It also enables robust multi-modal?¡­",Article,https://ieeexplore.ieee.org/abstract/document/10123962/,40,sun2023inconsistent,"Multi-modal learning, rumor detection, social media analysis"
2021,21st IEEE International Conference on Data Mining (ICDM 2021),Truth discovery in sequence labels from crowds,"Nasim Sabetpour, Adithya Kulkarni, Sihong Xie, Qi Li",Nasim Sabetpour,English,"Annotation quality and quantity positively affect the learning performance of sequence labeling, a vital task in Natural Language Processing. Hiring domain experts to annotate a corpus is very costly in terms of money and time. Crowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been deployed to assist in this purpose. However, the annotations collected this way are prone to human errors due to the lack of expertise of the crowd workers. Existing literature in annotation aggregation assumes that annotations are independent and thus faces challenges when handling the sequential label aggregation tasks with complex dependencies. To conquer the challenges, we propose an optimization-based method that infers the ground truth labels using annotations provided by workers for sequential labeling tasks. The proposed Aggregation method for Sequential Labels from Crowds (AggSLC) jointly?¡­",Conference paper,https://ieeexplore.ieee.org/abstract/document/9679072/,19,sabetpour2021truth,"Data aggregation, sequence labeling, crowd-sourcing, optimization"
2021,30th ACM International Conference on Information and Knowledge Management?¡­,Certification and Trade-off of Multiple Fairness Criteria in Graph-based Spam Detection,"Kai Burkholder, Kenny Kwock, Yuesheng Xu, Liu Jiaxin, Chao Chen, Sihong Xie",Kai Burkholder,English,"Spamming reviews are prevalent in review systems to manipulate seller reputation and mislead customers. patterns to achieve state-of-the-art detection accuracy. The detection can influence a large number of real-world entities and it is ethical to treat different groups of entities as equally as possible. However, due to skewed distributions of the graphs, GNN can fail to meet diverse fairness criteria designed for different parties. We formulate linear systems of the input features and the adjacency matrix of the review graphs for the certification of multiple fairness criteria. When the criteria are competing, we relax the certification and design a multi-objective optimization (MOO) algorithm to explore multiple efficient trade-offs, so that no objective can be improved without harming another objective. We prove that the algorithm converges to a Pareto efficient solution using duality and the implicit function theorem. Since?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3459637.3482325,10,burkholder2021certification,"Fairness, multiple objective optimization, graphs"
2021,21st IEEE International Conference on Data Mining (ICDM 2021),Multi-objective Explanations of GNN Predictions,"Yifei Liu, Chao Chen, Yazheng Liu, Xi Zhang, Sihong Xie",Yifei Liu,English,"Graph Neural Network (GNN) has achieved state-of-the-art performance in various high-stake prediction tasks, but multiple layers of aggregations on graphs with irregular structures make GNN a less interpretable model. Prior methods use simpler subgraphs to simulate the full model, or counterfactuals to identify the causes of a prediction. The two families of approaches aim at two distinct objectives, ¡°simulatability¡± and ¡°counterfactual relevance¡±, but it is not clear how the objectives can jointly influence the human understanding of an explanation. We design a user-study to investigate such joint effects, and use the findings to design a multi-objective optimization (MOO) algorithm to find Pareto optimal explanations that are well-balanced in simulatability and counterfactual. Since the target model can be of any GNN variants and may not be accessible due to privacy concerns, we design a search algorithm using zero?¡­",Conference paper,https://ieeexplore.ieee.org/abstract/document/9679172/,9,liu2021multi,"Privacy,Sensitivity,Decision making,Predictive models,Pareto optimization,Prediction algorithms,Robustness"
2021,27th ACM SIGKDD international conference on knowledge discovery and data?¡­,Energy-Efficient Models for High-Dimensional Spike Train Classification using Sparse Spiking Neural Network,"Hang Yin, John Lee, Xiangnan Kong, Thomas Hartvigsen, Sihong Xie",Hang Yin,English,"Spike train classification is an important problem in many areas such as healthcare and mobile sensing, where each spike train is a high-dimensional time series of binary values. Conventional research on spike train classification mainly focus on developing Spiking Neural Networks (SNNs) under resource-sufficient settings (e.g., on GPU servers). The neurons of the SNNs are usually densely connected in each layer. However, in many real-world applications, we often need to deploy the SNN models on resource-constrained platforms (e.g., mobile devices) to analyze high-dimensional spike train data. The high resource requirement of the densely-connected SNNs can make them hard to deploy on mobile devices. In this paper, we study the problem of energy-efficient SNNs with sparsely-connected neurons. We propose an SNN model with sparse spatio-temporal coding. Our solution is based on the re?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3447548.3467252,8,yin2021energy,"spiking neural networks, supervised learning, spatio-temporal coding, sparsity, hard-concrete distribution"
2023,International Joint Conference on Neural Networks (IJCNN),Interpretable and Effective Reinforcement Learning for Attacking against Graph-based Rumor Detection,"Yuefei Lyu, Xiaoyu Yang, Jiaxin Liu, Sihong Xie, Philip S. Yu, Xi Zhang",Yuefei Lyu,English,"Social networks are frequently polluted by rumors, which can be detected by advanced models such as graph neural networks. However, the models are vulnerable to attacks, and discovering and understanding the vulnerabilities is critical to robust rumor detection. To discover subtle vulnerabilities, we design a attacking algorithm based on reinforcement learning to camouflage rumors against black-box detectors. We address exponentially large state spaces, high-order graph dependencies, and ranking dependencies, which are unique to the problem setting but fundamentally challenging for the state-of-the-art end-to-end approaches. We design domain-specific features that have causal effect on the reward, so that even a linear policy can arrive at powerful attacks with additional interpretability. To speed up policy optimization, we devise: (i) a credit assignment method that proportionally decomposes delayed?¡­",Conference paper,https://ieeexplore.ieee.org/abstract/document/10191290/,6,lyu2023interpretable,"graph adversarial attack, reinforcement learning, graph convolutional network, rumor detection"
2021,21st IEEE International Conference on Data Mining (ICDM 2021),Self-learn to Explain Siamese Networks Robustly,"Chao Chen, Yifan Shen, Guixiang Ma, Xiangnan Kong, Srinivas Rangarajan, Xi Zhang, Sihong Xie",Chao Chen,English,"Learning to compare two objects are essential in applications, especially when labeled data are scarce and imbalanced. As these applications can involve humans and make high-stake decisions, it is critical to explain the learned models. We aim to study post-hoc explanations of Siamese networks (SN) widely used in learning to compare. We characterize the instability of gradient-based explanations due to the additional compared object in SN, in contrast to architectures with a single input instance. We optimize for global invariance based on unlabeled data using self-learning to promote the stability of local explanations for individual input. The invariance leads to constrained optimization problems that can be solved using gradient descent-ascent (GDA), or KL-divergence regularized unconstrained optimization solved by SGD. We provide convergence proofs when the objective functions are nonconvex due to?¡­",Conference paper,https://ieeexplore.ieee.org/abstract/document/9679164/,5,chen2021self,"siamese networks,self-learning,gradient descent-ascent(GDA),SGD"
2020,29TH ACM International Conference on Information and Knowledge Management,Shapley Values and Meta-Explanations for Probabilistic Graphical Model Inference,"Yifei Liu, Chao Chen, Yazheng Liu, Xi Zhang, Sihong Xie",Yifei Liu,English,"Probabilistic graphical models, such as Markov random fields (MRF), exploit dependencies among random variables to model a rich family of joint probability distributions. Inference algorithms, such as belief propagation (BP), can effectively compute the marginal posteriors for decision making. Nonetheless, inferences involve sophisticated probability calculations and are difficult for humans to interpret. Among all existing explanation methods for MRFs, no method is designed for fair attributions of an inference outcome to elements on the MRF where the inference takes place. Shapley values provide rigorous attributions but so far have not been studied on MRFs. We thus define Shapley values for MRFs to capture both probabilistic and topological contributions of the variables on MRFs. We theoretically characterize the new definition regarding independence, equal contribution, additivity, and submodularity. As?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3340531.3411881,5,liu2020shapley,"Graphical models, explainability"
2023,URL https://par. nsf. gov/biblio/10466683,Reaction-diffusion graph ordinary differential equation networks: Traffic-law-informed speed prediction under mismatched data,"Yue Sun, Chao Chen, Yuesheng Xu, Sihong Xie, Rick S Blum, Parv Venkitasubramaniam",Yue Sun,English,"Accurate traffic speed prediction is critical to many applications, from routing and urban planning to infrastructure management. With sufficient training data where all spatio-temporal patterns are wellrepresented, machine learning models such as Spatial-Temporal Graph Convolutional Networks (STGCN), can make reasonably accurate predictions. However, existing methods fail when the training data distribution (eg, traffic patterns on regular days) is different from test distribution (eg, traffic patterns on special days). We address this challenge by proposing a traffic-law-informed network called Reaction-Diffusion Graph Ordinary Differential Equation (RDGODE) network, which incorporates a physical model of traffic speed evolution based on a reliable and interpretable reactiondiffusion equation that allows the RDGODE to adapt to unseen traffic patterns. We show that with mismatched training data, RDGODE is more robust than the state-of-the-art machine learning methods in the following cases.(1) When the test dataset exhibits spatio-temporal patterns not represented in the training dataset, the performance of RDGODE is more consistent and reliable.(2) When the test dataset has missing data, RDGODE can maintain its accuracy by intrinsically imputing the missing values.",Article,http://urban-computing.com/urbcomp2023/file/UrbComp2023_paper_6.pdf,4,sun2023reaction,"Traffic speed prediction, graph neural networks, spatial-temporal time series prediction"
2023,Uncertainty in Artificial Intelligence,Optimal budget allocation for crowdsourcing labels for graphs,"Adithya Kulkarni, Mohna Chakraborty, Sihong Xie, Qi Li",Adithya Kulkarni,English,"Crowdsourcing is an effective and efficient paradigm for obtaining labels for unlabeled corpus employing crowd workers. This work considers the budget allocation problem for a generalized setting on a graph of instances to be labeled where edges encode instance dependencies. Specifically, given a graph and a labeling budget, we propose an optimal policy to allocate the budget among the instances to maximize the overall labeling accuracy. We formulate the problem as a Bayesian Markov Decision Process (MDP), where we define our task as an optimization problem that maximizes the overall label accuracy under budget constraints. Then, we propose a novel stage-wise reward function that considers the effect of worker labels on the whole graph at each timestamp. This reward function is utilized to find an optimal policy for the optimization problem. Theoretically, we show that our proposed policies are consistent when the budget is infinite. We conduct extensive experiments on five real-world graph datasets and demonstrate the effectiveness of the proposed policies to achieve a higher label accuracy under budget constraints.",Conference paper,https://proceedings.mlr.press/v216/kulkarni23a.html,4,kulkarni2023optimal,"crowdsourcing,budget allocation,Bayesian Markov Decision Process(MDP)"
2022,2022 IEEE International Conference on Big Data (Big Data),Trade less Accuracy for Fairness and Trade-off Explanation for GNN,"Yazheng Liu, Xi Zhang, Sihong Xie",Yazheng Liu,English,"Graphs are widely found in social network analysis and e-commerce, where Graph Neural Networks (GNNs) are the state-of the-art model. GNNs can be biased due to sensitive attributes and network topology. With existing work that learns a fair node representation or adjacency matrix, achieving a strong guarantee of group fairness while preserving prediction accuracy is still challenging, with the fairness-accuracy trade-off remaining obscure to human decision-makers. We first define and analyze a novel upper bound of group fairness to optimize the adjacency matrix for fairness without significantly h arming prediction accuracy. To understand the nuance of fairness-accuracy tradeoff, we further propose macroscopic and microscopic explanation methods to reveal the trade-offs and the space that one can exploit. The macroscopic explanation method is based on stratified sampling and linear programming to?¡­",Conference paper,https://ieeexplore.ieee.org/abstract/document/10020318/,3,liu2022trade,"Training,Upper bound,Network topology,Social networking (online),Microscopy,Big Data,Linear programming,Graph Neural Networks"
2023,arXiv preprint arXiv:2310.14479,DetectGPT-SC: Improving Detection of Text Generated by Large Language Models through Self-Consistency with Masked Predictions,"Rongsheng Wang, Qi Li, Sihong Xie",Rongsheng Wang,English,"General large language models (LLMs) such as ChatGPT have shown remarkable success, but it has also raised concerns among people about the misuse of AI-generated texts. Therefore, an important question is how to detect whether the texts are generated by ChatGPT or by humans. Existing detectors are built on the assumption that there is a distribution gap between human-generated and AI-generated texts. These gaps are typically identified using statistical information or classifiers. In contrast to prior research methods, we find that large language models such as ChatGPT exhibit strong self-consistency in text generation and continuation. Self-consistency capitalizes on the intuition that AI-generated texts can still be reasoned with by large language models using the same logical reasoning when portions of the texts are masked, which differs from human-generated texts. Using this observation, we subsequently proposed a new method for AI-generated texts detection based on self-consistency with masked predictions to determine whether a text is generated by LLMs. This method, which we call DetectGPT-SC. We conducted a series of experiments to evaluate the performance of DetectGPT-SC. In these experiments, we employed various mask scheme, zero-shot, and simple prompt for completing masked texts and self-consistency predictions. The results indicate that DetectGPT-SC outperforms the current state-of-the-art across different tasks.",Article,https://arxiv.org/abs/2310.14479,2,wang2023detectgpt,"large language models,text generation,detection,ChatGPT"
2023,2023 International Conference on Learning Representations (ICLR 2023),A Differential Geometric View and Explainability of GNN on Evolving Graphs,"Yazheng Liu, Xi Zhang, Sihong Xie",Yazheng Liu,English,"Graphs are ubiquitous in social networks and biochemistry, where Graph Neural Networks (GNN) are the state-of-the-art models for prediction. Graphs can be evolving and it is vital to formally model and understand how a trained GNN responds to graph evolution. We propose a smooth parameterization of the GNN predicted distributions using axiomatic attribution, where the distributions are on a low-dimensional manifold within a high-dimensional embedding space. We exploit the differential geometric viewpoint to model distributional evolution as smooth curves on the manifold. We reparameterize families of curves on the manifold and design a convex optimization problem to find a unique curve that concisely approximates the distributional evolution for human interpretation. Extensive experiments on node classification, link prediction, and graph classification tasks with evolving graphs demonstrate the better sparsity, faithfulness, and intuitiveness of the proposed method over the state-of-the-art methods.",Conference paper,https://arxiv.org/abs/2403.06425,2,liu2024differential,"Graph Neural Networks,state-of-the-art, differential geometric viewpoint,graphs"
2022,arXiv preprint arXiv:2204.11164,Subgroup Fairness in Graph-based Spam Detection,"Jiaxin Liu, Yuefei Lyu, Xi Zhang, Sihong Xie",Jiaxin Liu,English,,Article,https://scholar.google.com/scholar?cluster=16546753534511044937&hl=en&oi=scholarr,2,liu2022subgroup,"Graph Neural Networks,state-of-the-art, graphs,subgroups"
2021,arXiv preprint arXiv:2111.10037,Explaining GNN over evolving graphs using information flow,"Yazheng Liu, Xi Zhang, Sihong Xie",Yazheng Liu,English,"Graphs are ubiquitous in many applications, such as social networks, knowledge graphs, smart grids, etc.. Graph neural networks (GNN) are the current state-of-the-art for these applications, and yet remain obscure to humans. Explaining the GNN predictions can add transparency. However, as many graphs are not static but continuously evolving, explaining changes in predictions between two graph snapshots is different but equally important. Prior methods only explain static predictions or generate coarse or irrelevant explanations for dynamic predictions. We define the problem of explaining evolving GNN predictions and propose an axiomatic attribution method to uniquely decompose the change in a prediction to paths on computation graphs. The attribution to many paths involving high-degree nodes is still not interpretable, while simply selecting the top important paths can be suboptimal in approximating the change. We formulate a novel convex optimization problem to optimally select the paths that explain the prediction evolution. Theoretically, we prove that the existing method based on Layer-Relevance-Propagation (LRP) is a special case of the proposed algorithm when an empty graph is compared with. Empirically, on seven graph datasets, with a novel metric designed for evaluating explanations of prediction change, we demonstrate the superiority of the proposed approach over existing methods, including LRP, DeepLIFT, and other path selection methods.",Article,https://arxiv.org/abs/2111.10037,2,liu2021explaining,"Graph Neural Networks,graphs,GNN predictions,LayerRelevance-Propagation (LRP)"
2020,Proceedings of the 29th ACM International Conference on Information?¡­,Active search using meta-bandits,"Shengli Zhu, Jakob Coles, Sihong Xie",Shengli Zhu,English,"There are many applications where positive instances are rare but important to identify. For example, in NLP, positive sentences for a given relation are rare in a large corpus. Positive data are more informative for learning in these applications, but before one labels a certain amount of data, it is unknown where to find the rare positives. Since random sampling can lead to significant waste in labeling effort, previous 'active search' methods use a single bandit model to learn about the data distribution (exploration) while sampling from the regions potentially containing more positives (exploitation). Many bandit models are possible and a sub-optimal model reduces labeling efficiency, but the optimal model is unknown before any data are labeled. We propose Meta-AS (Meta Active Search) that uses a meta-bandit to evaluate a set of base bandits and aims to label positive examples efficiently, comparing to the optimal?¡­",Conference paper,https://dl.acm.org/doi/abs/10.1145/3340531.3417409,2,zhu2020active,crowdsourcing; active search; bandit
2023,arXiv preprint arXiv:2307.04024,Robust Ranking Explanations,"Chao Chen, Chenghua Guo, Guixiang Ma, Ming Zeng, Xi Zhang, Sihong Xie",Chao Chen,English,"Robust explanations of machine learning models are critical to establish human trust in the models. Due to limited cognition capability, most humans can only interpret the top few salient features. It is critical to make top salient features robust to adversarial attacks, especially those against the more vulnerable gradient-based explanations. Existing defense measures robustness using -norms, which have weaker protection power. We define explanation thickness for measuring salient features ranking stability, and derive tractable surrogate bounds of the thickness to design the \textit{R2ET} algorithm to efficiently maximize the thickness and anchor top salient features. Theoretically, we prove a connection between R2ET and adversarial training. Experiments with a wide spectrum of network architectures and data modalities, including brain networks, demonstrate that R2ET attains higher explanation robustness under stealthy attacks while retaining accuracy.",Article,https://arxiv.org/abs/2307.04024,1,chen2023robust,"Robust explanation,machine learning,salient features,ranking,R2ET"
2022,2022 IEEE/ACM International Conference on Big Data Computing,Efficient first-order predictor-corrector multiple objective optimization for fair misinformation detection,"Eric Enouen, Katja Mathesius, Sean Wang, Arielle Carr, Sihong Xie",Eric Enouen,English,"Multiple-objective optimization (MOO) aims to simultaneously optimize multiple conflicting objectives and has found important applications in machine learning, such as minimizing classification loss and discrepancy in treating different populations for fairness. At optimality, further optimizing one objective will necessarily harm at least another objective, and decision-makers need to comprehensively explore multiple optima (called Pareto front) to pinpoint one final solution. We address the efficiency of finding the Pareto front. First, finding the front from scratch using stochastic multi-gradient descent (SMGD) is expensive with large neural networks and datasets. We propose to explore the Pareto front as a manifold from a few initial optima, based on a predictor-corrector method. Second, for each exploration step, the predictor solves a large-scale linear system that scales quadratically in the number of model parameters and requires one backpropagation to evaluate a second-order Hessian-vector product per iteration of the solver. We propose a Gauss-Newton approximation that only scales linearly, and that requires only first-order inner-product per iteration. This also allows for a choice between the MINRES and conjugate gradient methods when approximately solving the linear system. The innovations make predictor-corrector possible for large networks. Experiments on multi-objective (fairness and accuracy) misinformation detection tasks show that 1) the predictor-corrector method can find Pareto fronts better than or similar to SMGD with less time; and 2) the proposed first-order method does not harm the quality of the Pareto front identified by?¡­",Conference paper,https://arxiv.org/abs/2209.07245,1,enouen2022efficient,"multiple objective optimization,machine learning, Pareto front, stochastic multi-gradient descent(SMGD)"
2024,Frontiers in Mechanical Engineering 10,On the Generalization Discrepancy of Spatiotemporal Dynamics-informed Graph Convolutional Networks,"Yue Sun, Chao Chen, Yuesheng Xu, Sihong Xie, Rick S. Blum, Parv Venkitasubramaniam",Yue Sun,English,"Graph neural networks (GNNs) have gained significant attention in diverse domains, ranging from urban planning to pandemic management. Ensuring both accuracy and robustness in GNNs remains a challenge due to insufficient quality data that contains sufficient features. With sufficient training data where all spatiotemporal patterns are well-represented, existing GNN models can make reasonably accurate predictions. However, existing methods fail when the training data are drawn from different circumstances (e.g., traffic patterns on regular days) than test data (e.g., traffic patterns after a natural disaster). Such challenges are usually classified under domain generalization. In this work, we show that one way to address this challenge in the context of spatiotemporal prediction is by incorporating domain differential equations into graph convolutional networks (GCNs). We theoretically derive conditions where GCNs incorporating such domain differential equations are robust to mismatched training and testing data compared to baseline domain agnostic models. To support our theory, we propose two domain-differential-equation-informed networks: Reaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates differential equations for traffic speed evolution, and the Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which incorporates a disease propagation model. Both RDGCN and SIRGCN are based on reliable and interpretable domain differential equations that allow the models to generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN are more robust with mismatched?¡­",Article,https://www.frontiersin.org/articles/10.3389/fmech.2024.1397131/full,0,sun2024generalization,"ODE-based computation model, graph convolutional networks, out-of-distribution generalization, spatiotemporal prediction, reaction-diffusion equation, time series"
2024,arXiv preprint arXiv:2404.18279,Out-of-distribution Detection in Medical Image Analysis: A survey,"Zesheng Hong, Yubiao Yue, Yubin Chen, Huanjie Lin, Yuanmei Luo, Mini Han Wang, Weidong Wang, Jialong Xu, Xiaoqi Yang, Zhenzhang Li, Sihong Xie",Zesheng Hong,English,"Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years. Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data. However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks. Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system. In this survey, we systematically review the recent advances in OOD detection in medical image analysis. We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors. Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy. Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration.",Article,https://arxiv.org/abs/2404.18279,0,hong2024out,"trustworthy AI, medical image analysis, out-of-distribution detection"
2024,arXiv preprint arXiv:2404.14642,Uncertainty Quantification on Graph Learning: A Survey,"Chao Chen, Chenghua Guo, Rui Xu, Xiangwen Liao, Xi Zhang, Sihong Xie, Hui Xiong, Philip Yu",Chao Chen,English,"Graphical models, including Graph Neural Networks (GNNs) and Probabilistic Graphical Models (PGMs), have demonstrated their exceptional capabilities across numerous fields. These models necessitate effective uncertainty quantification to ensure reliable decision-making amid the challenges posed by model training discrepancies and unpredictable testing scenarios. This survey examines recent works that address uncertainty quantification within the model architectures, training, and inference of GNNs and PGMs. We aim to provide an overview of the current landscape of uncertainty in graphical models by organizing the recent methods into uncertainty representation and handling. By summarizing state-of-the-art methods, this survey seeks to deepen the understanding of uncertainty quantification in graphical models, thereby increasing their effectiveness and safety in critical applications.",Article,https://arxiv.org/abs/2404.14642,0,chen2024uncertainty,"uncertainty quantification,GNNs,PGMs,state-of-the-art"
2024,arXiv preprint arXiv:2404.01217,Incorporating Domain Differential Equations into Graph Convolutional Networks to Lower Generalization Discrepancy,"Yue Sun, Chao Chen, Yuesheng Xu, Sihong Xie, Rick S Blum, Parv Venkitasubramaniam",Yue Sun,English,"Ensuring both accuracy and robustness in time series prediction is critical to many applications, ranging from urban planning to pandemic management. With sufficient training data where all spatiotemporal patterns are well-represented, existing deep-learning models can make reasonably accurate predictions. However, existing methods fail when the training data are drawn from different circumstances (e.g., traffic patterns on regular days) compared to test data (e.g., traffic patterns after a natural disaster). Such challenges are usually classified under domain generalization. In this work, we show that one way to address this challenge in the context of spatiotemporal prediction is by incorporating domain differential equations into Graph Convolutional Networks (GCNs). We theoretically derive conditions where GCNs incorporating such domain differential equations are robust to mismatched training and testing data compared to baseline domain agnostic models. To support our theory, we propose two domain-differential-equation-informed networks called Reaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates differential equations for traffic speed evolution, and Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which incorporates a disease propagation model. Both RDGCN and SIRGCN are based on reliable and interpretable domain differential equations that allow the models to generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN are more robust with mismatched testing data than the state-of-the-art deep learning methods.",Article,https://arxiv.org/abs/2404.01217,0,sun2024incorporating,"time series,Graph Convolutional Networks, differential equation"
2024,arXiv preprint arXiv:2403.15025,Robust Conformal Prediction under Distribution Shift via Physics-Informed Structural Causal Model,"Rui Xu, Yue Sun, Chao Chen, Parv Venkitasubramaniam, Sihong Xie",Rui Xu,English,"Uncertainty is critical to reliable decision-making with machine learning. Conformal prediction (CP) handles uncertainty by predicting a set on a test input, hoping the set to cover the true label with at least  confidence. This coverage can be guaranteed on test data even if the marginal distributions  differ between calibration and test datasets. However, as it is common in practice, when the conditional distribution  is different on calibration and test data, the coverage is not guaranteed and it is essential to measure and minimize the coverage loss under distributional shift at \textit{all} possible confidence levels. To address these issues, we upper bound the coverage difference at all levels using the cumulative density functions of calibration and test conformal scores and Wasserstein distance. Inspired by the invariance of physics across data distributions, we propose a physics-informed structural causal model (PI-SCM) to reduce the upper bound. We validated that PI-SCM can improve coverage robustness along confidence level and test domain on a traffic speed prediction task and an epidemic spread task with multiple real-world datasets.",Article,https://arxiv.org/abs/2403.15025,0,xu2024robust,"machine learning, conformal prediction,uncertainty,distribution shift"
2023,2023 International Conference on Machine Learning and Applications (ICMLA?¡­,Implementing Recycling Methods for Linear Systems in Python with an Application to Multiple Objective Optimization,"Ainara Garcia, Sihong Xie, Arielle Carr",Ainara Garcia,English,"Sequences of linear systems arise in the predictor-corrector method when computing the Pareto front for multi-objective optimization. Rather than discarding information generated when solving one system, it may be advantageous to recycle information for subsequent systems. To accomplish this, we seek to reduce the overall cost of computation when solving linear systems using common recycling methods. In this work, we assessed the performance of recycling minimum residual (RMIN-RES) method along with a map between coefficient matrices. For these methods to be fully integrated into the software used in Enouen et al. (2022), there must be working version of each in both Python and PyTorch. Herein, we discuss the challenges we encountered and solutions undertaken (and some ongoing) when computing efficient Python implementations of these recycling strategies. The goal of this project was to?¡­",Conference paper,https://ieeexplore.ieee.org/abstract/document/10459759/,0,garcia2023implementing,"MINRES, Sparse Approximate Maps, Python, PyTorch, Multiobjective Optimization, Recycling"
