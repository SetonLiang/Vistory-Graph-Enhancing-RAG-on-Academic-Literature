Year,Sources,Name,Authors,First Author,Chinese/English,Abstract,Venues,doi,Citation,Id,Keywords
2021,IEEE transactions on visualization and computer graphics,A survey on ML4VIS: Applying machine learning advances to data visualization,"Qianwen Wang, Zhutian Chen, Yong Wang, Huamin Qu",Qianwen Wang,English,"Inspired by the great success of machine learning (ML), researchers have applied ML techniques to visualizations to achieve a better design, development, and evaluation of visualizations. This branch of studies, known as ML4VIS, is gaining increasing research attention in recent years. To successfully adapt ML techniques for visualizations, a structured understanding of the integration of ML4VIS is needed. In this article, we systematically survey 88 ML4VIS studies, aiming to answer two motivating questions:  “what visualization processes can be assisted by ML?”  and  “how ML techniques can be used to solve visualization problems? ” This survey reveals seven main processes where the employment of ML techniques can benefit visualizations:  Data Processing4VIS, Data-VIS Mapping, Insight Communication, Style Imitation, VIS Interaction, VIS Reading, and User Profiling . The seven processes are related to?…",Article,https://ieeexplore.ieee.org/abstract/document/9523770/,76,wang2021survey," ML4VIS, machine learning, data visualization, survey"
2021,IEEE Transactions on Visualization and Computer Graphics,Ai4vis: Survey on artificial intelligence approaches for data visualization,"Aoyu Wu, Yun Wang, Xinhuan Shu, Dominik Moritz, Weiwei Cui, Haidong Zhang, Dongmei Zhang, Huamin Qu",Aoyu Wu,English,"Visualizations themselves have become a data format. Akin to other data formats such as text and images, visualizations are increasingly created, stored, shared, and (re-)used with artificial intelligence (AI) techniques. In this survey, we probe the underlying vision of formalizing visualizations as an emerging data format and review the recent advance in applying AI techniques to visualization data (AI4VIS). We define visualization data as the digital representations of visualizations in computers and focus on data visualization (e.g., charts and infographics). We build our survey upon a corpus spanning ten different fields in computer science with an eye toward identifying important common interests. Our resulting taxonomy is organized around WHAT is visualization data and its representation, WHY and HOW to apply AI to visualization data. We highlight a set of common tasks that researchers apply to the?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/9495259/,97,wu2021ai4vis," Survey, data visualization, artificial intelligence, data format, machine learning"
2020,IEEE Transactions on Visualization and Computer Graphics,Dece: Decision explorer with counterfactual explanations for machine learning models,"Furui Cheng, Yao Ming, Huamin Qu",Furui Cheng,English,"With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable-a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports?…",Article,https://ieeexplore.ieee.org/abstract/document/9229232/,92,cheng2020dece," Tabular Data, Explainable Machine Learning, Counterfactual Explanation, Decision Making"
2021,IEEE Transactions on Visualization and Computer Graphics,KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation,"Haotian Li, Yong Wang, Songheng Zhang, Yangqiu Song, Huamin Qu",Haotian Li,English,"Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data?…",Article,https://ieeexplore.ieee.org/abstract/document/9552844/,87,li2021kg4vis,"Data visualization, Visualization recommendation, Knowledge graph"
2020,IEEE transactions on visualization and computer graphics,EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos,"Haipeng Zeng, Xinhuan Shu, Yanbang Wang, Yong Wang, Liguo Zhang, Ting-Chuen Pong, Huamin Qu",Haipeng Zeng,English,"Analyzing students’ emotions from classroom videos can help both teachers and parents quickly know the engagement of students in class. The availability of high-definition cameras creates opportunities to record class scenes. However, watching videos is time-consuming, and it is challenging to gain a quick overview of the emotion distribution and find abnormal emotions. In this article, we propose  EmotionCues , a visual analytics system to easily analyze classroom videos from the perspective of emotion summary and detailed analysis, which integrates emotion recognition algorithms with visualizations. It consists of three coordinated views: a summary view depicting the overall emotions and their dynamic evolution, a character view presenting the detailed emotion status of an individual, and a video view enhancing the video analysis with further details. Considering the possible inaccuracy of emotion?…",Article,https://ieeexplore.ieee.org/abstract/document/8948010/,80,zeng2020emotioncues,"Emotion, classroom videos, visual summarization, visual analytics"
2021,IEEE Transactions on Visualization and Computer Graphics,M2lens: Visualizing and explaining multimodal models for sentiment analysis,"Xingbo Wang, Jianben He, Zhihua Jin, Muqiao Yang, Yong Wang, Huamin Qu",Xingbo Wang,English,"Multimodal sentiment analysis aims to recognize people's attitudes from multiple communication channels such as verbal content (i.e., text), voice, and facial expressions. It has become a vibrant and important research topic in natural language processing. Much research focuses on modeling the complex intra- and inter-modal interactions between different communication channels. However, current multimodal models with strong performance are often deep-learning-based techniques and work like black boxes. It is not clear how models utilize multimodal information for sentiment predictions. Despite recent advances in techniques for enhancing the explainability of machine learning models, they often target unimodal scenarios (e.g., images, sentences), and little research has been done on explaining multimodal models. In this paper, we present an interactive visual analytics system, M2 Lens, to visualize and?…",Article,https://ieeexplore.ieee.org/abstract/document/9552921/,72,wang2021m2lens,"Visualization, Storytelling, Interview,  Lab  Study, Data Video, Guideline"
2021,Proceedings of the 2021 CHI conference on human factors in computing systems?…,A visual analytics approach to facilitate the proctoring of online exams,"Haotian Li, Min Xu, Yong Wang, Huan Wei, Huamin Qu",Haotian Li,English," Online exams have become widely used to evaluate students’ performance in mastering knowledge in recent years, especially during the pandemic of COVID-19. However, it is challenging to conduct proctoring for online exams due to the lack of face-to-face interaction. Also, prior research has shown that online exams are more vulnerable to various cheating behaviors, which can damage their credibility. This paper presents a novel visual analytics approach to facilitate the proctoring of online exams by analyzing the exam video records and mouse movement data of each student. Specifically, we detect and visualize suspected head and mouse movements of students in three levels of detail, which provides course instructors and teachers with convenient, efficient and reliable proctoring for online exams. Our extensive evaluations, including usage scenarios, a carefully-designed user study and expert interviews?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3411764.3445294,68,li2021visual,"Online proctoring, visual analytics, mouse movement, head pose estimation "
2020,Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?…,Augmenting static visualizations with paparvis designer,"Zhutian Chen, Wai Tong, Qianwen Wang, Benjamin Bach, Huamin Qu",Zhutian Chen,English,"This paper presents an authoring environment for augmenting static visualizations with virtual content in augmented reality.Augmenting static visualizations can leverage the best of both physical and digital worlds, but its creation currently involves different tools and devices, without any means to explicitly design and debug both static and virtual content simultaneously. To address these issues, we design an environment that seamlessly integrates all steps of a design and deployment workflow through its main features: i) an extension to Vega, ii) a preview, and iii) debug hints that facilitate valid combinations of static and augmented content. We inform our design through a design space with four ways to augment static visualizations. We demonstrate the expressiveness of our tool through examples, including books, posters, projections, wall-sized visualizations. A user study shows high user satisfaction of our?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3313831.3376436,56,chen2020augmenting,"Visualization in Augmented Reality, Augmented Static Visualization, Data Visualization Authoring"
2021,IEEE Transactions on Visualization and Computer Graphics,Augmenting sports videos with viscommentator,"Zhutian Chen, Shuainan Ye, Xiangtong Chu, Haijun Xia, Hui Zhang, Huamin Qu, Yingcai Wu",Zhutian Chen,English,"Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level  (what the constituents are)  and clip-level  (how those constituents are organized) . We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis?…",Article,https://ieeexplore.ieee.org/abstract/document/9552848/,54,chen2021augmenting,"Augmented Sports Videos, Video-based Visualization, Sports visualization, Intelligent Design Tool, Storytelling"
2020,IEEE Transactions on Visualization and Computer Graphics,What makes a data-GIF understandable?,"Xinhuan Shu, Aoyu Wu, Junxiu Tang, Benjamin Bach, Yingcai Wu, Huamin Qu",Xinhuan Shu,English,"GIFs are enjoying increasing popularity on social media as a format for data-driven storytelling with visualization; simple visual messages are embedded in short animations that usually last less than 15 seconds and are played in automatic repetition. In this paper, we ask the question, “What makes a data-GIF understandable?” While other storytelling formats such as data videos, infographics, or data comics are relatively well studied, we have little knowledge about the design factors and principles for “data-GIFs”. To close this gap, we provide results from semi-structured interviews and an online study with a total of 118 participants investigating the impact of design decisions on the understandability of data-GIFs. The study and our consequent analysis are informed by a systematic review and structured design space of 108 data-GIFs that we found online. Our results show the impact of design dimensions from our?…",Article,https://ieeexplore.ieee.org/abstract/document/9222309/,51,shu2020makes,"Data-GIFs, Data-driven Storytelling, Evaluation"
2020,Sustainable Cities and Society 54,PRAISE-HK: A personalized real-time air quality informatics system for citizen participation in exposure and health risk management,"Wenwei Che, H Christopher Frey, Jimmy CH Fung, Zhi Ning, Huamin Qu, Hong Kam Lo, Lei Chen, Tze-Wai Wong, Michelle KM Wong, Ophelia CW Lee, David Carruthers, Freeman Cheung, Jimmy WM Chan, David W Yeung, Yik Him Fung, Xuguo Zhang, Jenny Stocker, Christina Hood, Tilman Leo Hohenberger, King Wai Leung, Phillip YK Louie, Alison TY Li, Li Sun, Peng Wei, Zhiyuan Li, Yumiao Zhang, Meilan Wang, Qiaomu Shen, Wei Huang, Enoch Lee, Ashraf Patwary, Xiayu Lei, Steven Cheng, Md Shakhaoat Hossain, Kimberly Tasha Jiayi Tang, XiangQian Lao, Rae Leung, Denise Chan, Ying Li, Zibing Yuan, Alexis KH Lau",Wenwei Che,English,"Exposure to air pollutants causes a range of adverse health effects. These harmful effects occur whenever and wherever people come into direct contact with air pollution. Therefore, individual actions that reduce the frequency, duration, and severity of personal contact with air pollution can reduce health risks. We developed a system that empowers the public with personalized information on air quality and exposure health risk. This system, the Personalised Real-Time Air Quality Informatics System for Exposure – Hong Kong (PRAISE-HK, http://praise.ust.hk/), is embodied in an interactive mobile application. PRAISE-HK is based on real-time data on emissions, high resolution urban morphology, meteorology, physical and chemical processes affecting pollutant transport and transformations, extensive measurements of air pollution concentrations in typical locations such as homes, schools, offices, and?…",Article,https://www.sciencedirect.com/science/article/pii/S2210670719335279,50,che2020praise,"Air pollution,Personalized exposure,Individual health sensitivity,Citizen engagement"
2020,IEEE Transactions on Visualization and Computer Graphics,Visual analysis of discrimination in machine learning,"Qianwen Wang, Zhenhua Xu, Zhutian Chen, Yong Wang, Shixia Liu, Huamin Qu",Qianwen Wang,English,"The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in?…",Article,https://ieeexplore.ieee.org/abstract/document/9222272/,48,wang2020visual,"Machine Learning, Discrimination, Data Visualization"
2021,IEEE Transactions on Visualization and Computer Graphics,MultiVision: Designing analytical dashboards with deep learning based recommendation,"Aoyu Wu, Yun Wang, Mengyu Zhou, Xinyi He, Haidong Zhang, Huamin Qu, Dongmei Zhang",Aoyu Wu,English,"We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model?…",Article,https://ieeexplore.ieee.org/abstract/document/9552449/,47,wu2021multivision,"Visualization Recommendation, Deep Learning, Multiple-View, Dashboard, Mixed-Initiative, Visualization Provenance"
2021,IEEE Transactions on Visualization and Computer Graphics,A design space for applying the freytag's pyramid structure to data stories,"Leni Yang, Xian Xu, XingYu Lan, Ziyan Liu, Shunan Guo, Yang Shi, Huamin Qu, Nan Cao",Leni Yang,English,"Data stories integrate compelling visual content to communicate data insights in the form of narratives. The narrative structure of a data story serves as the backbone that determines its expressiveness, and it can largely influence how audiences perceive the insights. Freytag's Pyramid is a classic narrative structure that has been widely used in film and literature. While there are continuous recommendations and discussions about applying Freytag's Pyramid to data stories, little systematic and practical guidance is available on how to use Freytag's Pyramid for creating structured data stories. To bridge this gap, we examined how existing practices apply Freytag's Pyramid by analyzing stories extracted from 103 data videos. Based on our findings, we proposed a design space of narrative patterns, data flows, and visual communications to provide practical guidance on achieving narrative intents, organizing data facts?…",Article,https://ieeexplore.ieee.org/abstract/document/9552203/,45,yang2021design," Freytag's Pyramid, Narrative Structure, Narrative Visualization, Data Storytelling, Data Video"
2020,IEEE Transactions on Visualization and Computer Graphics,Mobilevisfixer: Tailoring web visualizations for mobile phones leveraging an explainable reinforcement learning framework,"Aoyu Wu, Wai Tong, Tim Dwyer, Bongshin Lee, Petra Isenberg, Huamin Qu",Aoyu Wu,English,"We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view?…",Article,https://ieeexplore.ieee.org/abstract/document/9229072/,45,wu2020mobilevisfixer,"Mobile visualization, Responsive visualization, Machine learning for visualizations, Reinforcement learning"
2021,IEEE Transactions on Visualization and Computer Graphics,Infocolorizer: Interactive recommendation of color palettes for infographics,"Lin-Ping Yuan, Ziqi Zhou, Jian Zhao, Yiqiu Guo, Fan Du, Huamin Qu",Lin-Ping Yuan,English,"When designing infographics, general users usually struggle with getting desired color palettes using existing infographic authoring tools, which sometimes sacrifice customizability, require design expertise, or neglect the influence of elements’ spatial arrangement. We propose a data-driven method that provides flexibility by considering users’ preferences, lowers the expertise barrier via automation, and tailors suggested palettes to the spatial layout of elements. We build a recommendation engine by utilizing deep learning techniques to characterize good color design practices from data, and further develop InfoColorizer, a tool that allows users to obtain color palettes for their infographics in an interactive and dynamic manner. To validate our method, we conducted a comprehensive four-part evaluation, including case studies, a controlled user study, a survey study, and an interview study. The results indicate that?…",Article,https://ieeexplore.ieee.org/abstract/document/9444798/,44,yuan2021infocolorizer,"Color palettes design, infographics, visualization recommendation, machine learning"
2021,Energy and Buildings 253,Development of a back-propagation neural network and adaptive grey wolf optimizer algorithm for thermal comfort and energy consumption prediction and optimization,"Lu Li, Yunfei Fu, Jimmy CH Fung, Huamin Qu, Alexis KH Lau",Lu Li,English,"Heating ventilation and air conditioning (HVAC) systems provide a comfortable indoor thermal environment, but in the process of attaining appropriate indoor thermal comfort levels, they usually entail high energy consumptions. It is therefore imperative to balance thermal comfort value with energy consumption. However, such research currently faces two problems: one, it is difficult to obtain accurate parameters pertaining to the indoor environment of buildings, particularly near heat source areas; two, it is the diametrical nature of having to simultaneously maintain thermal comfort and keep energy consumption low. Therefore, this study aims to propose a rapid thermal comfort level prediction and optimization algorithm, as well as a method to minimize the energy consumption using only a computational fluid dynamic (CFD) database that is compact in size. Firstly, CFD is used to implement the database that stores?…",Article,https://www.sciencedirect.com/science/article/pii/S0378778821007234,40,li2021development,"Back-propagation neural network,Adaptive grey wolf optimizer algorithm,Thermal comfort level,Energy-saving,HVAC system"
2022,Building and Environment 207,A coupled computational fluid dynamics and back-propagation neural network-based particle swarm optimizer algorithm for predicting and optimizing indoor air quality,"Lu Li, Yumiao Zhang, Jimmy CH Fung, Huamin Qu, Alexis KH Lau",Lu Li,English,"In the modern era, people spend approximately 90% of their time in indoor settings, such as offices and residential buildings. As prolonged exposure to indoor environments can significantly impact health outcomes, it is important to ensure that good indoor air quality (IAQ) is achieved. The main obstacles to achieving effective control of IAQ are twofold. First, it is very difficult to monitor the values of IAQ parameters, especially within a person's breathing zone. Second, current heating ventilation and air conditioning systems are unable to rapidly predict and optimize IAQ. This study aims to obtain accurate indoor environmental parameters for rapidly predicting and optimizing IAQ. To achieve this, a computational fluid dynamics (CFD)-based back propagation neural network (BPNN) combined with a particle swarm optimizer (PSO) algorithm is proposed. Notably, the BPNN-PSO algorithm can rapidly predict and?…",Article,https://www.sciencedirect.com/science/article/pii/S0360132321009264,39,li2022coupled,"Computational fluid dynamics, Back-propagation neural network, Particle swarm optimization,Indoor air quality"
2021,IEEE Transactions on Visualization and Computer Graphics,Vbridge: Connecting the dots between features and data to explain healthcare models,"Furui Cheng, Dongyu Liu, Fan Du, Yanna Lin, Alexandra Zytek, Haomin Li, Huamin Qu, Kalyan Veeramachaneni",Furui Cheng,English,"Machine learning (ML) is increasingly applied to Electronic Health Records (EHRs) to solve clinical prediction tasks. Although many ML models perform promisingly, issues with model transparency and interpretability limit their adoption in clinical practice. Directly using existing explainable ML techniques in clinical settings can be challenging. Through literature surveys and collaborations with six clinicians with an average of 17 years of clinical experience, we identified three key challenges, including clinicians' unfamiliarity with ML features, lack of contextual information, and the need for cohort-level evidence. Following an iterative design process, we further designed and developed VBridge, a visual analytics tool that seamlessly incorporates ML explanations into clinicians' decision-making workflow. The system includes a novel hierarchical display of contribution-based feature explanations and enriched?…",Article,https://ieeexplore.ieee.org/abstract/document/9555810/,36,cheng2021vbridge,"Explainable Artificial Intelligence, Healthcare, Visual Analytics, Decision Making"
2020,IEEE transactions on visualization and computer graphics,Topology density map for urban data visualization and analysis,"Zezheng Feng, Haotian Li, Wei Zeng, Shuang-Hua Yang, Huamin Qu",Zezheng Feng,English,"Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density?…",Article,https://ieeexplore.ieee.org/abstract/document/9222248/,36,feng2020topology,"Density map, network topology, urban data"
2020,Proceedings of the tenth international conference on learning analytics?…,Predicting student performance in interactive online question pools using mouse interaction features,"Huan Wei, Haotian Li, Meng Xia, Yong Wang, Huamin Qu",Huan Wei,English,"Modeling student learning and further predicting the performance is a well-established task in online learning and is crucial to personalized education by recommending different learning resources to different students based on their needs. Interactive online question pools (e.g., educational game platforms), an important component of online education, have become increasingly popular in recent years. However, most existing work on student performance prediction targets at online learning platforms with a well-structured curriculum, predefined question order and accurate knowledge tags provided by domain experts. It remains unclear how to conduct student performance prediction in interactive online question pools without such well-organized question orders or knowledge tags by experts. In this paper, we propose a novel approach to boost student performance prediction in interactive online question pools?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3375462.3375521,36,wei2020predicting,"Student performance prediction, question pool, mouse movement trajectory, heterogeneous information network."
2022,IEEE Transactions on Visualization and Computer Graphics,Gnnlens: A visual analytics approach for prediction error diagnosis of graph neural networks,"Zhihua Jin, Yong Wang, Qianwen Wang, Yao Ming, Tengfei Ma, Huamin Qu",Zhihua Jin,English,"Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph data and have achieved significant progress in graph analysis tasks (e.g., node classification) in recent years. However, similar to other deep neural networks like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), GNNs behave like a black box with their details hidden from model developers and users. It is therefore difficult to diagnose possible errors of GNNs. Despite many visual analytics studies being done on CNNs and RNNs, little research has addressed the challenges for GNNs. This paper fills the research gap with an interactive visual analysis tool,  GNNLens , to assist model developers and users in understanding and analyzing GNNs. Specifically, Parallel Sets View and Projection View enable users to quickly identify and validate error patterns in the set of wrong predictions; Graph View and?…",Article,https://ieeexplore.ieee.org/abstract/document/9705076/,34,jin2022gnnlens,"Graph Neural Networks, Error Diagnosis, Visualization"
2020,2020 IEEE Pacific visualization symposium (PacificVis),Visual interpretation of recurrent neural network on multi-dimensional time-series forecast,"Qiaomu Shen, Yanhong Wu, Yuzhe Jiang, Wei Zeng, KH Alexis, Anna Vianova, Huamin Qu",Qiaomu Shen,English,"Recent attempts at utilizing visual analytics to interpret Recurrent Neural Networks (RNNs) mainly focus on natural language processing (NLP) tasks that take symbolic sequences as input. However, many real-world problems like environment pollution forecasting apply RNNs on sequences of multi-dimensional data where each dimension represents an individual feature with semantic meaning such as PM 2.5  and SO 2 . RNN interpretation on multi-dimensional sequences is challenging as users need to analyze what features are important at different time steps to better understand model behavior and gain trust in prediction. This requires effective and scalable visualization methods to reveal the complex many-to-many relations between hidden units and features. In this work, we propose a visual analytics system to interpret RNNs on multi-dimensional time-series forecasts. Specifically, to provide an overview to?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/9086238/,34,shen2020visual,"interpretable machine learning, recurrent neural networks, multi-dimensional time series, air pollutant forecast"
2020,Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?…,Voicecoach: Interactive evidence-based training for voice modulation skills in public speaking,"Xingbo Wang, Haipeng Zeng, Yong Wang, Aoyu Wu, Zhida Sun, Xiaojuan Ma, Huamin Qu",Xingbo Wang,English,"The modulation of voice properties, such as pitch, volume, and speed, is crucial for delivering a successful public speech. However, it is challenging to master different voice modulation skills. Though many guidelines are available, they are often not practical enough to be applied in different public speaking situations, especially for novice speakers. We present VoiceCoach, an interactive evidence-based approach to facilitate the effective training of voice modulation skills. Specifically, we have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically recommends good voice modulation examples from the dataset based on the similarity of both sentence structures and voice modulation skills. Immediate and quantitative visual feedback is provided to guide further improvement. The expert interviews?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3313831.3376726,30,wang2020voicecoach,"Visual Analytics, Tax Network, Tax Evasion Detection, Anomaly detection, Multidimensional data"
2022,Computer Graphics Forum,Misinformed by visualization: What do we learn from misinformative visualizations?,"Leo Yu‐Ho Lo, Ayush Gupta, Kento Shigyo, Aoyu Wu, Enrico Bertini, Huamin Qu",Leo Yu‐Ho Lo,English," Data visualization is powerful in persuading an audience. However, when it is done poorly or maliciously, a visualization may become misleading or even deceiving. Visualizations give further strength to the dissemination of misinformation on the Internet. The visualization research community has long been aware of visualizations that misinform the audience, mostly associated with the terms “lie” and “deceptive.” Still, these discussions have focused only on a handful of cases. To better understand the landscape of misleading visualizations, we open‐coded over one thousand real‐world visualizations that have been reported as misleading. From these examples, we discovered 74 types of issues and formed a taxonomy of misleading elements in visualizations. We found four directions that the research community can follow to widen the discussion on misleading visualizations: (1) informal fallacies in?…",Article,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14559,28,lo2022misinformed,"Datasets, Visual Analytics, Visualization Specification, Visualization Design"
2022,IEEE Transactions on Visualization and Computer Graphics,Dashbot: Insight-driven dashboard generation based on deep reinforcement learning,"Dazhen Deng, Aoyu Wu, Huamin Qu, Yingcai Wu",Dazhen Deng,English,"Analytical dashboards are popular in business intelligence to facilitate insight discovery with multiple charts. However, creating an effective dashboard is highly demanding, which requires users to have adequate data analysis background and be familiar with professional tools, such as Power BI. To create a dashboard, users have to configure charts by selecting data columns and exploring different chart combinations to optimize the communication of insights, which is trial-and-error. Recent research has started to use deep learning methods for dashboard generation to lower the burden of visualization creation. However, such efforts are greatly hindered by the lack of large-scale and high-quality datasets of dashboards. In this work, we propose using deep reinforcement learning to generate analytical dashboards that can use well-established visualization knowledge and the estimation capacity of reinforcement?…",Article,https://ieeexplore.ieee.org/abstract/document/9906971/,27,deng2022dashbot,"Reinforcement Learning, Visualization Recommendation, Multiple-View Visualization"
2021,IEEE Transactions on Visualization and Computer Graphics,Interactive visual exploration of longitudinal historical career mobility data,"Yifang Wang, Hongye Liang, Xinhuan Shu, Jiachen Wang, Ke Xu, Zikun Deng, Cameron Campbell, Bijia Chen, Yingcai Wu, Huamin Qu",Yifang Wang,English,"The increased availability of quantitative historical datasets has provided new research opportunities for multiple disciplines in social science. In this article, we work closely with the constructors of a new dataset, CGED-Q (China Government Employee Database-Qing), that records the career trajectories of over 340,000 government officials in the Qing bureaucracy in China from 1760 to 1912. We use these data to study career mobility from a historical perspective and understand social mobility and inequality. However, existing statistical approaches are inadequate for analyzing career mobility in this historical dataset with its fine-grained attributes and long time span, since they are mostly hypothesis-driven and require substantial effort. We propose  CareerLens , an interactive visual analytics system for assisting experts in exploring, understanding, and reasoning from historical career data. With  CareerLens?…",Article,https://ieeexplore.ieee.org/abstract/document/9382844/,27,wang2021interactive,"Digital humanities, quantitative history, career mobility, visual analytics"
2020,Proceedings of the 29th ACM International Conference on Information?…,Peer-inspired student performance prediction in interactive online question pools with graph neural network,"Haotian Li, Huan Wei, Yong Wang, Yangqiu Song, Huamin Qu",Haotian Li,English,"Student performance prediction is critical to online education. It can benefit many downstream tasks on online learning platforms, such as estimating dropout rates, facilitating strategic intervention, and enabling adaptive online learning. Interactive online question pools provide students with interesting interactive questions to practice their knowledge in online education. However, little research has been done on student performance prediction in interactive online question pools. Existing work on student performance prediction targets at online learning platforms with predefined course curriculum and accurate knowledge labels like MOOC platforms, but they are not able to fully model knowledge evolution of students in interactive online question pools. In this paper, we propose a novel approach using Graph Neural Networks (GNNs) to achieve better student performance prediction in interactive online question?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3340531.3412733,26,li2020peer,"Student performance prediction, graph neural networks, online question pools"
2020,Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?…,Dfseer: A visual analytics approach to facilitate model selection for demand forecasting,"Dong Sun, Zezheng Feng, Yuanzhe Chen, Yong Wang, Jia Zeng, Mingxuan Yuan, Ting-Chuen Pong, Huamin Qu",Dong Sun,English,"Selecting an appropriate model to forecast product demand is critical to the manufacturing industry. However, due to the data complexity, market uncertainty and users' demanding requirements for the model, it is challenging for demand analysts to select a proper model. Although existing model selection methods can reduce the manual burden to some extent, they often fail to present model performance details on individual products and reveal the potential risk of the selected model. This paper presents DFSeer, an interactive visualization system to conduct reliable model selection for demand forecasting based on the products with similar historical demand. It supports model comparison and selection with different levels of details. Besides, it shows the difference in model performance on similar products to reveal the risk of model selection and increase users' confidence in choosing a forecasting model. Two case?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3313831.3376866,26,sun2020dfseer,"Interactive visualization, model selection, product demand forecasting, time series"
2021,Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?…,Learning to automate chart layout configurations using crowdsourced paired comparison,"Aoyu Wu, Liwenhan Xie, Bongshin Lee, Yun Wang, Weiwei Cui, Huamin Qu",Aoyu Wu,English," We contribute a method to automate parameter configurations for chart layouts by learning from human preferences. Existing charting tools usually determine the layout parameters using predefined heuristics, producing sub-optimal layouts. People can repeatedly adjust multiple parameters (e.g., chart size, gap) to achieve visually appealing layouts. However, this trial-and-error process is unsystematic and time-consuming, without a guarantee of improvement. To address this issue, we develop Layout Quality Quantifier (LQ2), a machine learning model that learns to score chart layouts from paired crowdsourcing data. Combined with optimization techniques, LQ2 recommends layout parameters that improve the charts’ layout quality. We apply LQ2 on bar charts and conduct user studies to evaluate its effectiveness by examining the quality of layouts it produces. Results show that LQ2 can generate more visually?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3411764.3445179,24,wu2021learning,"Machine Learning, Visualization, Crowdsourced, Visual Design,Image Quality Assessment"
2021,arXiv preprint arXiv:2102.01330 2,Survey on artificial intelligence approaches for visualization data,"Aoyu Wu, Yun Wang, Xinhuan Shu, Dominik Moritz, Weiwei Cui, Haidong Zhang, Dongmei Zhang, Huamin Qu",Aoyu Wu,English,"Visualizations themselves have become a data format. Akin to other data formats such as text and images, visualizations are increasingly created, stored, shared, and (re-)used with artificial intelligence (AI) techniques. In this survey, we probe the underlying vision of formalizing visualizations as an emerging data format and review the recent advance in applying AI techniques to visualization data. We define visualization data as the digital representations of visualizations in computers and focus on visualizations in information visualization and visual analytic. We build our survey upon a corpus spanning ten different fields in computer science with an eye toward identifying important common interests. Our resulting taxonomy is organized around WHAT is visualization data and its representation, WHY and HOW to apply AI to visualization data. We highlight a set of common tasks that researchers apply to the visualization data and present a detailed discussion of AI approaches developed to accomplish those tasks. Drawing upon our literature review, we discuss several important research questions surrounding the management and exploitation of visualization data, as well as the role of AI in support of those processes. We make the list of surveyed papers and related material available online at ai4vis.github.io.",Article,https://scholar.google.com/scholar?cluster=11090909227810155274&hl=en&oi=scholarr,24,wu2021survey,Survey; Data Visualization; Artificial Intelligence; Data Format; Machine Learning
2020,IEEE Transactions on Visualization and Computer Graphics,TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups,"Yating Lin, Kamkwai Wong, Yong Wang, Rong Zhang, Bo Dong, Huamin Qu, Qinghua Zheng",Yating Lin,English,"Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related?…",Article,https://ieeexplore.ieee.org/abstract/document/9222068/,24,lin2020taxthemis,"Visual Analytics, Tax Network, Tax Evasion Detection, Anomaly detection, Multidimensional data"
2020,Proceedings of the seventh ACM conference on Learning@ Scale,"Using information visualization to promote students' reflection on"" gaming the system"" in online learning","Meng Xia, Yuya Asano, Joseph Jay Williams, Huamin Qu, Xiaojuan Ma",Meng Xia,English,"""Gaming the system"" is the phenomenon where students attempt to perform well by systematically exploiting properties of the learning system, rather than learning the material. Frequent gaming tends to cause bad learning outcomes. Though existing studies tackle the problem by redesigning the system workflow to change students' behaviors automatically, gaming students discover new ways to game. We instead propose a novel way, reflective nudge, to reflectively influence students' attitudes by conveying reasons not to game via information visualizations. Particularly, we identify three common gaming contexts and involve students and instructors in co-designing three context-specific persuasive visualizations. We deploy our information visualizations in a real online learning platform. Through embedded surveys and in-person interviews, we find some evidence that the designs can promote students' reflection?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3386527.3405924,24,xia2020using,"Survey, Data Visualization, Artificial Intelligence, Data Format, Machine Learning"
2023,IEEE Transactions on Visualization and Computer Graphics,Xnli: Explaining and diagnosing nli-based visual data analysis,"Yingchaojie Feng, Xingbo Wang, Bo Pan, Kam Kwai Wong, Yi Ren, Shi Liu, Zihan Yan, Yuxin Ma, Huamin Qu, Wei Chen",Yingchaojie Feng,English,"Natural language interfaces (NLIs) enable users to flexibly specify analytical intentions in data visualization. However, diagnosing the visualization results without understanding the underlying generation process is challenging. Our research explores how to provide explanations for NLIs to help users locate the problems and further revise the queries. We present XNLI, an explainable NLI system for visual data analysis. The system introduces a Provenance Generator to reveal the detailed process of visual transformations, a suite of interactive widgets to support error adjustments, and a Hint Generator to provide query revision hints based on the analysis of user queries and interactions. Two usage scenarios of XNLI and a user study verify the effectiveness and usability of the system. Results suggest that XNLI can significantly enhance task accuracy without interrupting the NLI-based analysis process.",Article,https://ieeexplore.ieee.org/abstract/document/10026499/,23,feng2023xnli,"Natural language interface, visual data analysis,explainability"
2022,Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?…,Structure-aware visualization retrieval,"Haotian Li, Yong Wang, Aoyu Wu, Huan Wei, Huamin Qu",Haotian Li,English," With the wide usage of data visualizations, a huge number of Scalable Vector Graphic?(SVG)-based visualizations have been created and shared online. Accordingly, there has been an increasing interest in exploring how to retrieve perceptually similar visualizations from a large corpus, since it can benefit various downstream applications such as visualization recommendation. Existing methods mainly focus on the visual appearance of visualizations by regarding them as bitmap images. However, the structural information intrinsically existing in SVG-based visualizations is ignored. Such structural information can delineate the spatial and hierarchical relationship among visual elements, and characterize visualizations thoroughly from a new perspective. This paper presents a structure-aware method to advance the performance of visualization retrieval by collectively considering both the visual and structural?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3491102.3502048,23,li2022structure,"Data Visualization, Visualization Retrieval, Visualization Similarity,Representation Learning, Visualization Embedding"
2021,IEEE Transactions on Visualization and Computer Graphics,Explaining with examples: Lessons learned from crowdsourced introductory description of information visualizations,"Leni Yang, Cindy Xiong, Jason K Wong, Aoyu Wu, Huamin Qu",Leni Yang,English,"Data visualizations have been increasingly used in oral presentations to communicate data patterns to the general public. Clear verbal introductions of visualizations to explain how to interpret the visually encoded information are essential to convey the takeaways and avoid misunderstandings. We contribute a series of studies to investigate how to effectively introduce visualizations to the audience with varying degrees of visualization literacy. We begin with understanding how people are introducing visualizations. We crowdsource 110 introductions of visualizations and categorize them based on their content and structures. From these crowdsourced introductions, we identify different introduction strategies and generate a set of introductions for evaluation. We conduct experiments to systematically compare the effectiveness of different introduction strategies across four visualizations with 1,080 participants. We?…",Article,https://ieeexplore.ieee.org/abstract/document/9615008/,21,yang2021explaining,"Narrative visualization, oral presentation, introduction"
2022,IEEE Transactions on Visualization and Computer Graphics,Cohortva: A visual analytic system for interactive exploration of cohorts based on historical data,"Wei Zhang, Jason K Wong, Xumeng Wang, Youcheng Gong, Rongchen Zhu, Kai Liu, Zihan Yan, Siwei Tan, Huamin Qu, Siming Chen, Wei Chen",Wei Zhang,English,"In history research, cohort analysis seeks to identify social structures and figure mobilities by studying the group-based behavior of historical figures. Prior works mainly employ automatic data mining approaches, lacking effective visual explanation. In this paper, we present CohortVA, an interactive visual analytic approach that enables historians to incorporate expertise and insight into the iterative exploration process. The kernel of CohortVA is a novel identification model that generates candidate cohorts and constructs cohort features by means of pre-built knowledge graphs constructed from large-scale history databases. We propose a set of coordinated views to illustrate identified cohorts and features coupled with historical events and figure profiles. Two case studies and interviews with historians demonstrate that CohortVA can greatly enhance the capabilities of cohort identifications, figure authentications, and?…",Article,https://ieeexplore.ieee.org/abstract/document/9912359/,20,zhang2022cohortva,"Historical cohort analysis, machine learning, interpretability, visual analytic"
2021,IEEE Transactions on Visualization and Computer Graphics,Deep colormap extraction from visualizations,"Lin-Ping Yuan, Wei Zeng, Siwei Fu, Zhiliang Zeng, Haotian Li, Chi-Wing Fu, Huamin Qu",Lin-Ping Yuan,English,"This article presents a new approach based on deep learning to automatically extract colormaps from visualizations. After summarizing colors in an input visualization image as a Lab color histogram, we pass the histogram to a pre-trained deep neural network, which learns to predict the colormap that produces the visualization. To train the network, we create a new dataset of   64K visualizations that cover a wide variety of data distributions, chart types, and colormaps. The network adopts an atrous spatial pyramid pooling module to capture color features at multiple scales in the input color histograms. We then classify the predicted colormap as discrete or continuous, and refine the predicted colormap based on its color histogram. Quantitative comparisons to existing methods show the superior performance of our approach on both synthetic and real-world visualizations. We further demonstrate the utility of our?…",Article,https://ieeexplore.ieee.org/abstract/document/9395231/,20,yuan2021deep," Color extraction, information visualization, deep learning, color histogram"
2021,Journal of Visualization 24,Dancingwords: exploring animated word clouds to tell stories,"Xinhuan Shu, Jiang Wu, Xinke Wu, Hongye Liang, Weiwei Cui, Yingcai Wu, Huamin Qu",Xinhuan Shu,English," Abstract By encoding semantic relations into relative positions, word clouds have shown the capability to deliver richer messages than purely visualizing word frequencies. Existing studies mainly focus on layout algorithms that cluster related words, preserve temporal coherence, and optimize spatial shapes. However, they cannot fully convey multiple relations among words and their evolvement through relative positions and static representations. In this paper, we explore animated word clouds that take advantage of storytelling strategies to present interactions between words and show the dynamic process of content changes, thus communicating the underlying stories. We initially create several exemplars of animated word clouds with designers through a structured iterative design process. These exemplars lead to a preliminary design space that distills essential narrative elements with design?…",Article,https://link.springer.com/article/10.1007/s12650-020-00689-0,20,shu2021dancingwords,"Storytelling,Animation,Text visualization,Interaction"
2020,IEEE Transactions on Visualization and Computer Graphics,Qlens: Visual analytics of multi-step problem-solving behaviors for improving question design,"Meng Xia, Reshika Palaniyappan Velumani, Yong Wang, Huamin Qu, Xiaojuan Ma",Meng Xia,English,"With the rapid development of online education in recent years, there has been an increasing number of learning platforms that provide students with multi-step questions to cultivate their problem-solving skills. To guarantee the high quality of such learning materials, question designers need to inspect how students' problem-solving processes unfold step by step to infer whether students' problem-solving logic matches their design intent. They also need to compare the behaviors of different groups (e.g., students from different grades) to distribute questions to students with the right level of knowledge. The availability of fine-grained interaction data, such as mouse movement trajectories from the online platforms, provides the opportunity to analyze problem-solving behaviors. However, it is still challenging to interpret, summarize, and compare the high dimensional problem-solving sequence data. In this paper, we?…",Article,https://ieeexplore.ieee.org/abstract/document/9222360/,20,xia2020qlens,"Learning Behavior Analysis, Visual Analytics, Time Series Data"
2021,IEEE Transactions on Visualization and Computer Graphics,Seek for success: A visualization approach for understanding the dynamics of academic careers,"Yifang Wang, Tai-Quan Peng, Huihua Lu, Haoren Wang, Xiao Xie, Huamin Qu, Yingcai Wu",Yifang Wang,English,"How to achieve academic career success has been a long-standing research question in social science research. With the growing availability of large-scale well-documented academic profiles and career trajectories, scholarly interest in career success has been reinvigorated, which has emerged to be an active research domain called the Science of Science (i.e., SciSci). In this study, we adopt an innovative dynamic perspective to examine how individual and social factors will influence career success over time. We propose  ACSeeker , an interactive visual analytics approach to explore the potential factors of success and how the influence of multiple factors changes at different stages of academic careers. We first applied a Multi-factor Impact Analysis framework to estimate the effect of different factors on academic career success over time. We then developed a visual analytics system to understand the dynamic?…",Article,https://ieeexplore.ieee.org/abstract/document/9552870/,19,wang2021seek,"Career Analysis, Academic Profiles, Science of Science, Publication Data, Citation Data, Sequence Analysis"
2022,IEEE Transactions on Visualization and Computer Graphics,In defence of visual analytics systems: Replies to critics,"Aoyu Wu, Dazhen Deng, Furui Cheng, Yingcai Wu, Shixia Liu, Huamin Qu",Aoyu Wu,English,"The last decade has witnessed many visual analytics (VA) systems that make successful applications to wide-ranging domains like urban analytics and explainable AI. However, their research rigor and contributions have been extensively challenged within the visualization community. We come in defence of VA systems by contributing two interview studies for gathering critics and responses to those criticisms. First, we interview 24 researchers to collect criticisms the review comments on their VA work. Through an iterative coding and refinement process, the interview feedback is summarized into a list of 36 common criticisms. Second, we interview 17 researchers to validate our list and collect their responses, thereby discussing implications for defending and improving the scientific values and rigor of VA systems. We highlight that the presented knowledge is deep, extensive, but also imperfect, provocative, and?…",Article,https://ieeexplore.ieee.org/abstract/document/9906559/,17,wu2022defence,"Visual Analytics, Theory, Qualitative Study, Design Study, Application, Theoretical and Empirical Research"
2023,arXiv preprint arXiv:2304.08366,Why is ai not a panacea for data workers? an interview study on human-ai collaboration in data storytelling,"Haotian Li, Yun Wang, Q Vera Liao, Huamin Qu",Haotian Li,English,"Data storytelling plays an important role in data workers' daily jobs since it boosts team collaboration and public communication. However, to make an appealing data story, data workers spend tremendous efforts on various tasks, including outlining and styling the story. Recently, a growing research trend has been exploring how to assist data storytelling with advanced artificial intelligence (AI). However, existing studies may focus on individual tasks in the workflow of data storytelling and do not reveal a complete picture of humans' preference for collaborating with AI. To better understand real-world needs, we interviewed eighteen data workers from both industry and academia to learn where and how they would like to collaborate with AI. Surprisingly, though the participants showed excitement about collaborating with AI, many of them also expressed reluctance and pointed out nuanced reasons. Based on their responses, we first characterize stages and tasks in the practical data storytelling workflows and the desired roles of AI. Then the preferred collaboration patterns in different tasks are identified. Next, we summarize the interviewees' reasons why and why not they would like to collaborate with AI. Finally, we provide suggestions for human-AI collaborative data storytelling to hopefully shed light on future related research.",Article,https://arxiv.org/abs/2304.08366,15,li2023ai,"Data storytelling, human-AI collaboration, interview study"
2023,IEEE Transactions on Visualization and Computer Graphics,DMiner: Dashboard design mining and recommendation,"Yanna Lin, Haotian Li, Aoyu Wu, Yong Wang, Huamin Qu",Yanna Lin,English,"Dashboards, which comprise multiple views on a single display, help analyze and communicate multiple perspectives of data simultaneously. However, creating effective and elegant dashboards is challenging since it requires careful and logical arrangement and coordination of multiple visualizations. To solve the problem, we propose a data-driven approach for mining design rules from dashboards and automating dashboard organization. Specifically, we focus on two prominent aspects of the organization:  arrangement , which describes the position, size, and layout of each view in the display space; and  coordination , which indicates the interaction between pairwise views. We build a new dataset containing 854 dashboards crawled online, and develop feature engineering methods for describing the single views and view-wise relationships in terms of data, encoding, layout, and interactions. Further, we?…",Article,https://ieeexplore.ieee.org/abstract/document/10057994/,15,lin2023dashboard,"Dashboards, design mining, multiple-view visualization, visualization recommendation"
2022,Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?…,From ‘wow’to ‘why’: Guidelines for creating the opening of a data video with cinematic styles,"Xian Xu, Leni Yang, David Yip, Mingming Fan, Zheng Wei, Huamin Qu",Xian Xu,English," Data videos are an increasingly popular storytelling form. The opening of a data video critically influences its success as the opening either attracts the audience to continue watching or bores them to abandon watching. However, little is known about how to create an attractive opening. We draw inspiration from the openings of famous films to facilitate designing data video openings. First, by analyzing over 200 films from several sources, we derived six primary cinematic opening styles adaptable to data videos. Then, we consulted eight experts from the film industry to formulate 28 guidelines. To validate the usability and effectiveness of the guidelines, we asked participants to create data video openings with and without the guidelines, which were then evaluated by experts and the general public. Results showed that the openings designed with the guidelines were perceived to be more attractive, and the?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3491102.3501896,15,xu2022wow,"Visualization, Storytelling, Interview, Lab Study, Data Video, Guideline"
2021,arXiv preprint arXiv:2109.03137,Numgpt: Improving numeracy ability of generative pre-trained models,"Zhihua Jin, Xin Jiang, Xingbo Wang, Qun Liu, Yong Wang, Xiaozhe Ren, Huamin Qu",Zhihua Jin,English,"Existing generative pre-trained language models (e.g., GPT) focus on modeling the language structure and semantics of general texts. However, those models do not consider the numerical properties of numbers and cannot perform robustly on numerical reasoning tasks (e.g., math word problems and measurement estimation). In this paper, we propose NumGPT, a generative pre-trained model that explicitly models the numerical properties of numbers in texts. Specifically, it leverages a prototype-based numeral embedding to encode the mantissa of the number and an individual embedding to encode the exponent of the number. A numeral-aware loss function is designed to integrate numerals into the pre-training objective of NumGPT. We conduct extensive experiments on four different datasets to evaluate the numeracy ability of NumGPT. The experiment results show that NumGPT outperforms baseline models (e.g., GPT and GPT with DICE) on a range of numerical reasoning tasks such as measurement estimation, number comparison, math word problems, and magnitude classification. Ablation studies are also conducted to evaluate the impact of pre-training and model hyperparameters on the performance.",Article,https://arxiv.org/abs/2109.03137,15,jin2021numgpt,None
2023,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?…,Notable: On-the-fly assistant for data storytelling in computational notebooks,"Haotian Li, Lu Ying, Haidong Zhang, Yingcai Wu, Huamin Qu, Yun Wang",Haotian Li,English," Computational notebooks are widely used for data analysis. Their interleaved displays of code and execution results (e.g., visualizations) are welcomed since they enable iterative analysis and preserve the exploration process. However, the communication of data findings remains challenging in computational notebooks. Users have to carefully identify useful findings from useless ones, document them with texts and visual embellishments, and then organize them in different tools. Such workflow greatly increases their workload, according to our interviews with practitioners. To address the challenge, we designed Notable to offer on-the-fly assistance for data storytelling in computational notebooks. It provides intelligent support to minimize the work of documenting and organizing data findings and diminishes the cost of switching between data exploration and storytelling. To evaluate Notable, we conducted a user?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3544548.3580965,14,li2023notable,"data visualization, data storytelling, computational notebooks"
2022,Proceedings of the ACM on Human-Computer Interaction,Persua: A visual interactive system to enhance the persuasiveness of arguments in online discussion,"Meng Xia, Qian Zhu, Xingbo Wang, Fei Nie, Huamin Qu, Xiaojuan Ma",Meng Xia,English,"Persuading people to change their opinions is a common practice in online discussion forums on topics ranging from political campaigns to relationship consultation. Enhancing people's ability to write persuasive arguments could not only practice their critical thinking and reasoning but also contribute to the effectiveness and civility in online communication. It is, however, not an easy task in online discussion settings where written words are the primary communication channel. In this paper, we derived four design goals for a tool that helps users improve the persuasiveness of arguments in online discussions through a survey with 123 online forum users and interviews with five debating experts. To satisfy these design goals, we analyzed and built a labeled dataset of fine-grained persuasive strategies (i.e., logos, pathos, ethos, and evidence) in 164 arguments with high ratings on persuasiveness from?…",Article,https://dl.acm.org/doi/abs/10.1145/3555210,14,xia2022persua," persuasive strategies, example-based learning, argumentation learning,educational applications"
2023,Proceedings of the 36th Annual ACM Symposium on User Interface Software and?…,Storyfier: Exploring Vocabulary Learning Support with Text Generation Models,"Zhenhui Peng, Xingbo Wang, Qiushi Han, Junkai Zhu, Xiaojuan Ma, Huamin Qu",Zhenhui Peng,English," Vocabulary learning support tools have widely exploited existing materials, e.g., stories or video clips, as contexts to help users memorize each target word. However, these tools could not provide a coherent context for any target words of learners’ interests, and they seldom help practice word usage. In this paper, we work with teachers and students to iteratively develop Storyfier, which leverages text generation models to enable learners to read a generated story that covers any target words, conduct a story cloze test, and use these words to write a new story with adaptive AI assistance. Our within-subjects study (N=28) shows that learners generally favor the generated stories for connecting target words and writing assistance for easing their learning workload. However, in the read-cloze-write learning sessions, participants using Storyfier perform worse in recalling and using target words than learning with a?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3586183.3606786,13,peng2023storyfier,"Visual analytics, Digital humanities, Painting analysis, Traditional Chinese painting"
2023,2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR),Towards an understanding of distributed asymmetric collaborative visualization on problem-solving,"Wai Tong, Meng Xia, Kam Kwai Wong, Doug A Bowman, Ting-Chuen Pong, Huamin Qu, Yalong Yang",Wai Tong,English,"This paper provided empirical knowledge of the user experience for using collaborative visualization in a distributed asymmetrical setting through controlled user studies. With the ability to access various computing devices, such as Virtual Reality (VR) head-mounted displays, scenarios emerge when collaborators have to or prefer to use different computing environments in different places. However, we still lack an understanding of using VR in an asymmetric setting for collaborative visualization. To get an initial understanding and better inform the designs for asymmetric systems, we first conducted a formative study with 12 pairs of participants. All participants collaborated in asymmetric (PC-VR) and symmetric settings (PC-PC and VR-VR). We then improved our asymmetric design based on the key findings and observations from the first study. Another ten pairs of participants collaborated with enhanced PC-VR?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/10108427/,13,tong2023towards,Human-centered computing—Visualization—Visualization techniques; Human-centered computing—Collaborative and social computing—Empirical studies in collaborative and social computing
2023,IEEE Transactions on Visualization and Computer Graphics,Anchorage: Visual analysis of satisfaction in customer service videos via anchor events,"Kam Kwai Wong, Xingbo Wang, Yong Wang, Jianben He, Rong Zhang, Huamin Qu",Kam Kwai Wong,English,"Delivering customer services through video communications has brought new opportunities to analyze customer satisfaction for quality management. However, due to the lack of reliable self-reported responses, service providers are troubled by the inadequate estimation of customer services and the tedious investigation into multimodal video recordings. We introduce  Anchorage , a visual analytics system to evaluate customer satisfaction by summarizing multimodal behavioral features in customer service videos and revealing abnormal operations in the service process. We leverage the semantically meaningful operations to introduce structured event understanding into videos which help service providers quickly navigate to events of their interest.  Anchorage  supports a comprehensive evaluation of customer satisfaction from the service and operation levels and efficient analysis of customer behavioral?…",Article,https://ieeexplore.ieee.org/abstract/document/10045801/,13,wong2023anchorage,"Customer satisfaction, video data, video visualization, visual analytics"
2022,IEEE Transactions on Visualization and Computer Graphics,Exploring interactions with printed data visualizations in augmented reality,"Wai Tong, Zhutian Chen, Meng Xia, Leo Yu-Ho Lo, Linping Yuan, Benjamin Bach, Huamin Qu",Wai Tong,English,"This paper presents a design space of interaction techniques to engage with visualizations that are printed on paper and augmented through Augmented Reality. Paper sheets are widely used to deploy visualizations and provide a rich set of tangible affordances for interactions, such as touch, folding, tilting, or stacking. At the same time, augmented reality can dynamically update visualization content to provide  commands  such as pan, zoom, filter, or detail on demand. This paper is the first to provide a structured approach to mapping possible actions with the paper to interaction commands. This design space and the findings of a controlled user study have implications for future designs of augmented reality systems involving paper sheets and visualizations. Through workshops (  ) and ideation, we identified 81 interactions that we classify in three dimensions: 1)  commands  that can be supported by an?…",Article,https://ieeexplore.ieee.org/abstract/document/9904446/,12,tong2022exploring,"Interaction design, augmented reality, paper interaction, tangible user interface, printed data visualization"
2022,arXiv preprint arXiv:2201.04868,Interactive data analysis with next-step natural language query recommendation,"Xingbo Wang, Furui Cheng, Yong Wang, Ke Xu, Jiang Long, Hong Lu, Huamin Qu",Xingbo Wang,English,"Natural language interfaces (NLIs) provide users with a convenient way to interactively analyze data through natural language queries. Nevertheless, interactive data analysis is a demanding process, especially for novice data analysts. When exploring large and complex SQL databases from different domains, data analysts do not necessarily have sufficient knowledge about different data tables and application domains. It makes them unable to systematically elicit a series of topically-related and meaningful queries for insight discovery in target domains. We develop a NLI with a step-wise query recommendation module to assist users in choosing appropriate next-step exploration actions. The system adopts a data-driven approach to suggest semantically relevant and context-aware queries for application domains of users' interest based on their query logs. Also, the system helps users organize query histories and results into a dashboard to communicate the discovered data insights. With a comparative user study, we show that our system can facilitate a more effective and systematic data analysis process than a baseline without the recommendation module.",Article,https://arxiv.org/abs/2201.04868,12,wang2022interactive," Color palettes design, infographics, visualization recommendation, machine learning"
2021,IEEE Transactions on Visualization and Computer Graphics,DeHumor: Visual analytics for decomposing humor,"Xingbo Wang, Yao Ming, Tongshuang Wu, Haipeng Zeng, Yong Wang, Huamin Qu",Xingbo Wang,English,"Despite being a critical communication skill, grasping humor is challenging—a successful use of humor requires a mixture of both engaging content build-up and an appropriate vocal delivery (e.g., pause). Prior studies on computational humor emphasize the textual and audio features immediately next to the punchline, yet overlooking longer-term context setup. Moreover, the theories are usually too abstract for understanding each concrete humor snippet. To fill in the gap, we develop  DeHumor , a visual analytical system for analyzing humorous behaviors in public speaking. To intuitively reveal the building blocks of each concrete example,  DeHumor  decomposes each humorous video into multimodal features and provides inline annotations of them on the video script. In particular, to better capture the build-ups, we introduce content repetition as a complement to features introduced in theories of computational?…",Article,https://ieeexplore.ieee.org/abstract/document/9488285/,12,wang2021dehumor," Humor, context, multimodal features, visualization"
2020,2020 IEEE Visualization Conference (VIS),Tradao: A visual analytics system for trading algorithm optimization,"Ka Wing Tsang, Haotian Li, Fuk Ming Lam, Yifan Mu, Yong Wang, Huamin Qu",Ka Wing Tsang,English,"With the wide applications of algorithmic trading, it has become critical for traders to build a winning trading algorithm to beat the market. However, due to the lack of efficient tools, traders mainly rely on their memory to manually compare the algorithm instances of a trading algorithm and further select the best trading algorithm instance for the real trading deployment. We work closely with industry practitioners to discover and consolidate user requirements and develop an interactive visual analytics system for trading algorithm optimization. Structured expert interviews are conducted to evaluate TradAO and a representative case study is documented for illustrating the system effectiveness. To the best of our knowledge, previous financial data visual analyses have mainly aimed to assist investment managers in investment portfolio analysis but have neglected the need of traders in developing trading algorithms for?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/9331281/,12,tsang2020tradao,"Data Visualization, Visualization Retrieval, Visualization Similarity, Representation Learning, Visualization Embedding"
2022,IEEE Transactions on Visualization and Computer Graphics,Dpviscreator: Incorporating pattern constraints to privacy-preserving visualizations via differential privacy,"Jiehui Zhou, Xumeng Wang, Jason K Wong, Huanliang Wang, Zhongwei Wang, Xiaoyu Yang, Xiaoran Yan, Haozhe Feng, Huamin Qu, Haochao Ying, Wei Chen",Jiehui Zhou,English,"Data privacy is an essential issue in publishing data visualizations. However, it is challenging to represent multiple data patterns in privacy-preserving visualizations. The prior approaches target specific chart types or perform an anonymization model uniformly without considering the importance of data patterns in visualizations. In this paper, we propose a visual analytics approach that facilitates data custodians to generate multiple private charts while maintaining user-preferred patterns. To this end, we introduce pattern constraints to model users' preferences over data patterns in the dataset and incorporate them into the proposed Bayesian network-based Differential Privacy (DP) model  PriVis . A prototype system,  DPVisCreator , is developed to assist data custodians in implementing our approach. The effectiveness of our approach is demonstrated with quantitative evaluation of pattern utility under the different?…",Article,https://ieeexplore.ieee.org/abstract/document/9904449/,11,zhou2022dpviscreator," Privacy-preserving visualization, visual analytics, differential privacy, tabular data"
2020,Computer Graphics Forum,SeqDynamics: Visual Analytics for Evaluating Online Problem‐solving Dynamics,"Meng Xia, Min Xu, Chuan‐en Lin, Ta Ying Cheng, Huamin Qu, Xiaojuan Ma",Meng Xia,English," Problem‐solving dynamics refers to the process of solving a series of problems over time, from which a student's cognitive skills and non‐cognitive traits and behaviors can be inferred. For example, we can derive a student's learning curve (an indicator of cognitive skill) from the changes in the difficulty level of problems solved, or derive a student's self‐regulation patterns (an example of non‐cognitive traits and behaviors) based on the problem‐solving frequency over time. Few studies provide an integrated overview of both aspects by unfolding the problem‐solving process. In this paper, we present a visual analytics system named SeqDynamics that evaluates students ‘problem‐solving dynamics from both cognitive and non‐cognitive perspectives. The system visualizes the chronological sequence of learners’ problem‐solving behavior through a set of novel visual designs and coordinated contextual views?…",Article,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13998,11,xia2020seqdynamics,"Visual analytics, E-learning"
2022,IEEE Transactions on Visualization and Computer Graphics,Gesturelens: Visual analysis of gestures in presentation videos,"Haipeng Zeng, Xingbo Wang, Yong Wang, Aoyu Wu, Ting-Chuen Pong, Huamin Qu",Haipeng Zeng,English,"Appropriate gestures can enhance message delivery and audience engagement in both daily communication and public presentations. In this article, we contribute a visual analytic approach that assists professional public speaking coaches in improving their practice of gesture training through analyzing presentation videos. Manually checking and exploring gesture usage in the presentation videos is often tedious and time-consuming. There lacks an efficient method to help users conduct gesture exploration, which is challenging due to the intrinsically temporal evolution of gestures and their complex correlation to speech content. In this article, we propose  GestureLens , a visual analytics system to facilitate gesture-based and content-based exploration of gesture usage in presentation videos. Specifically, the exploration view enables users to obtain a quick overview of the spatial and temporal distributions of?…",Article,https://ieeexplore.ieee.org/abstract/document/9761750/,10,zeng2022gesturelens," Gesture, hand movements, presentation video analysis, visual analysis"
2020,2020 IEEE Visualization Conference (VIS),Improving engagement of animated visualization with visual foreshadowing,"Wenchao Li, Yun Wang, Haidong Zhang, Huamin Qu",Wenchao Li,English,"Animated visualization is becoming increasingly popular as a compelling way to illustrate changes in time series data. However, maintaining the viewer's focus throughout the entire animation is difficult because of its time-consuming nature. Viewers are likely to become bored and distracted during the ever-changing animated visualization. Informed by the role of foreshadowing that builds the expectation in film and literature, we introduce visual foreshadowing to improve the engagement of animated visualizations. In specific, we propose designs of visual foreshadowing that engage the audience while watching the animation. To demonstrate our approach, we built a proof-of-concept animated visualization authoring tool that incorporates visual foreshadowing techniques with various styles. Our user study indicates the effectiveness of our foreshadowing techniques on improving engagement for animated?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/9331276/,10,li2020improving,"Human-centered computing Visualization Visualization design and evaluation methods, Computing methodologies Computer graphics Animation"
2023,IEEE Transactions on Visualization and Computer Graphics,Inksight: Leveraging sketch interaction for documenting chart findings in computational notebooks,"Yanna Lin, Haotian Li, Leni Yang, Aoyu Wu, Huamin Qu",Yanna Lin,English,"Computational notebooks have become increasingly popular for exploratory data analysis due to their ability to support data exploration and explanation within a single document. Effective documentation for explaining chart findings during the exploration process is essential as it helps recall and share data analysis. However, documenting chart findings remains a challenge due to its time-consuming and tedious nature. While existing automatic methods alleviate some of the burden on users, they often fail to cater to users' specific interests. In response to these limitations, we present InkSight, a mixed-initiative computational notebook plugin that generates finding documentation based on the user's intent. InkSight allows users to express their intent in specific data subsets through sketching atop visualizations intuitively. To facilitate this, we designed two types of sketches, i.e., open-path and closed-path sketch?…",Article,https://ieeexplore.ieee.org/abstract/document/10296056/,9,lin2023inksight,"Computational Notebook, Sketch-based Interaction, Documentation, Visualization, Exploratory Data Analysis"
2023,IEEE Transactions on Visualization and Computer Graphics,ShortcutLens: A visual analytics approach for exploring shortcuts in natural language understanding dataset,"Zhihua Jin, Xingbo Wang, Furui Cheng, Chunhui Sun, Qun Liu, Huamin Qu",Zhihua Jin,English,"Benchmark datasets play an important role in evaluating Natural Language Understanding (NLU) models. However, shortcuts—unwanted biases in the benchmark datasets—can damage the effectiveness of benchmark datasets in revealing models' real capabilities. Since shortcuts vary in coverage, productivity, and semantic meaning, it is challenging for NLU experts to systematically understand and avoid them when creating benchmark datasets. In this paper, we develop a visual analytics system,  ShortcutLens , to help NLU experts explore shortcuts in NLU benchmark datasets. The system allows users to conduct multi-level exploration of shortcuts. Specifically, Statistics View helps users grasp the statistics such as coverage and productivity of shortcuts in the benchmark dataset. Template View employs hierarchical and interpretable templates to summarize different types of shortcuts. Instance View allows users?…",Article,https://ieeexplore.ieee.org/abstract/document/10015807/,9,jin2023shortcutlens,"Natural language understanding, shortcut, visual analytics"
2022,IEEE transactions on visualization and computer graphics,Polyphony: An interactive transfer learning framework for single-cell data analysis,"Furui Cheng, Mark S Keller, Huamin Qu, Nils Gehlenborg, Qianwen Wang",Furui Cheng,English,"Reference-based cell-type annotation can significantly reduce time and effort in single-cell analysis by transferring labels from a previously-annotated dataset to a new dataset. However, label transfer by end-to-end computational methods is challenging due to the entanglement of technical ( e.g. , from different sequencing batches or techniques) and biological ( e.g. , from different cellular microenvironments) variations, only the first of which must be removed. To address this issue, we propose  Polyphony , an interactive transfer learning (ITL) framework, to complement biologists' knowledge with advanced computational methods.  Polyphony  is motivated and guided by domain experts' needs for a controllable, interactive, and algorithm-assisted annotation process, identified through interviews with seven biologists. We introduce anchors,  i.e. , analogous cell populations across datasets, as a paradigm to explain the?…",Article,https://ieeexplore.ieee.org/abstract/document/9903604/,9,cheng2022polyphony,"Interactive Machine Learning, Transfer Learning, Single-cell Data Analysis, Human-AI Interaction"
2021,Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?…,Causal perception in question-answering systems,"Po-Ming Law, Leo Yu-Ho Lo, Alex Endert, John Stasko, Huamin Qu",Po-Ming Law,English,"Root cause analysis is a common data analysis task. While question-answering systems enable people to easily articulate a why question (e.g., why students in Massachusetts have high ACT Math scores on average) and obtain an answer, these systems often produce questionable causal claims. To investigate how such claims might mislead users, we conducted two crowdsourced experiments to study the impact of showing different information on user perceptions of a question-answering system. We found that in a system that occasionally provided unreasonable responses, showing a scatterplot increased the plausibility of unreasonable causal claims. Also, simply warning participants that correlation is not causation seemed to lead participants to accept reasonable causal claims more cautiously. We observed a strong tendency among participants to associate correlation with causation. Yet, the warning?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3411764.3445444,9,law2021causal,"correlation and causation, question answering"
2023,arXiv preprint arXiv:2309.15723,Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration,"Haotian Li, Yun Wang, Huamin Qu",Haotian Li,English,"Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.",Article,https://arxiv.org/abs/2309.15723,8,li2023we,"Data storytelling, human-AI collaboration"
2023,IEEE Transactions on Visualization and Computer Graphics,Creating emordle: Animating word cloud for emotion expression,"Liwenhan Xie, Xinhuan Shu, Jeon Cheol Su, Yun Wang, Siming Chen, Huamin Qu",Liwenhan Xie,English,"We propose emordle, a conceptual design that animates wordles (compact word clouds) to deliver their emotional context to audiences. To inform the design, we first reviewed online examples of animated texts and animated wordles, and summarized strategies for injecting emotion into the animations. We introduced a composite approach that extends an existing animation scheme for one word to multiple words in a wordle with two global factors: the randomness of text animation (entropy) and the animation speed (speed). To create an emordle, general users can choose one predefined animated scheme that matches the intended emotion class and fine-tune the emotion intensity with the two parameters. We designed proof-of-concept emordle examples for four basic emotion classes, namely happiness, sadness, anger, and fear. We conducted two controlled crowdsourcing studies to evaluate our approach. The?…",Article,https://ieeexplore.ieee.org/abstract/document/10153659/,8,xie2023creating,"Wordle, animation, affective visualization, authoring, casual visualization"
2022,Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?…,Computableviz: Mathematical operators as a formalism for visualisation processing and analysis,"Aoyu Wu, Wai Tong, Haotian Li, Dominik Moritz, Yong Wang, Huamin Qu",Aoyu Wu,English," Data visualizations are created and shared on the web at an unprecedented speed, raising new needs and questions for processing and analyzing visualizations after they have been generated and digitized. However, existing formalisms focus on operating on a single visualization instead of multiple visualizations, making it challenging to perform analysis tasks such as sorting and clustering visualizations. Through a systematic analysis of previous work, we abstract visualization-related tasks into mathematical operators such as union and propose a design space of visualization operations. We realize the design by developing ComputableViz, a library that supports operations on multiple visualization specifications. To demonstrate its usefulness and extensibility, we present multiple usage scenarios concerning processing and analyzing visualization, such as generating visualization embeddings and?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3491102.3517618,8,wu2022computableviz,"Visualization, Visualization Library, Data Model"
2022,27th International Conference on Intelligent User Interfaces,AQX: Explaining air quality forecast for verifying domain knowledge using feature importance visualization,"Reshika Palaniyappan Velumani, Meng Xia, Jun Han, Chaoli Wang, ALEXIS K LAU, Huamin Qu",Reshika Palaniyappan Velumani,English," Air pollution forecast has become critical because of its direct impact on human health and its increased production caused by rapid industrialization. Machine learning (ML) solutions are being drastically explored in this domain because they can potentially produce highly accurate results with access to historical data. However, experts in the environmental area are skeptical about adopting ML solutions in real-world applications and policy making due to their black-box nature. In contrast, despite having low accuracy sometimes, the existing traditional simulation model (e.g., CMAQ) are widely used and follows well-defined and transparent equations. Therefore, presenting the knowledge learned by the ML model can make it transparent as well as comprehensible. In addition, validating the ML model’s learning with the existing domain knowledge might aid in addressing their skepticism, building appropriate trust?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3490099.3511150,8,palaniyappan2022aqx,"Machine Learning, Explainable AI, Air pollution, Visual Analytics, Spatio-Temporal Data, Validation"
2021,Computer Graphics Forum,iQUANT: interactive quantitative investment using sparse regression factors,"Xuanwu Yue, Qiao Gu, Deyun Wang, Huamin Qu, Yong Wang",Xuanwu Yue,English," The model‐based investing using financial factors is evolving as a principal method for quantitative investment. The main challenge lies in the selection of effective factors towards excess market returns. Existing approaches, either hand‐picking factors or applying feature selection algorithms, do not orchestrate both human knowledge and computational power. This paper presents iQUANT, an interactive quantitative investment system that assists equity traders to quickly spot promising financial factors from initial recommendations suggested by algorithmic models, and conduct a joint refinement of factors and stocks for investment portfolio composition. We work closely with professional traders to assemble empirical characteristics of “good” factors and propose effective visualization designs to illustrate the collective performance of financial factors, stock portfolios, and their interactions. We evaluate iQUANT?…",Article,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14299,8,yue2021iquant,"Computational Notebook, Sketch-based Interaction, Documentation, Visualization, Exploratory Data Analysis"
2020,IEEE Transactions on Visualization and Computer Graphics,HypoML: Visual analysis for hypothesis-based evaluation of machine learning models,"Qianwen Wang, William Alexander, Jack Pegg, Huamin Qu, Min Chen",Qianwen Wang,English,"In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a “concept” or “feature” may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have?…",Article,https://ieeexplore.ieee.org/abstract/document/9222284/,8,wang2020hypoml," Visual analytics, model-developmental visualization, machine learning, neural network, hypothesis test, HypoML"
2020,arXiv preprint arXiv:2004.06435,Rankbooster: Visual analysis of ranking predictions,"Abishek Puri, Bon Kyung Ku, Yong Wang, Huamin Qu",Abishek Puri,English,"Ranking is a natural and ubiquitous way to facilitate decision-making in various applications. However, different rankings are often used for the same set of entities, with each ranking method placing emphasis on different factors. These factors can also be multi-dimensional in nature, compounding the problem. This complexity can make it challenging for an entity which is being ranked to understand what they can do to improve their rankings, and to analyze the effect of changes in various factors to their overall rank. In this paper, we present RankBooster, a novel visual analytics system to help users conveniently investigate ranking predictions. We take university rankings as an example and focus on helping universities to better explore their rankings, where they can compare themselves to their rivals in key areas as well as overall. Novel visualizations are proposed to enable efficient analysis of rankings, including a Scenario Analysis View to show a high-level summary of different ranking scenarios, a Relationship View to visualize the influence of each attribute on different indicators and a Rival View to compare the ranking of a university and those of its rivals. A case study demonstrates the usefulness and effectiveness of RankBooster in facilitating the visual analysis of ranking predictions and helping users better understand their current situation.",Article,https://arxiv.org/abs/2004.06435,8,puri2020rankbooster,"Visual analytics, Information visualization"
2024,IEEE Transactions on Visualization and Computer Graphics,Reviving static charts into live charts,"Lu Ying, Yun Wang, Haotian Li, Shuguang Dou, Haidong Zhang, Xinyang Jiang, Huamin Qu, Yingcai Wu",Lu Ying,English,"Data charts are prevalent across various fields due to their efficacy in conveying complex data relationships. However, static charts may sometimes struggle to engage readers and efficiently present intricate information, potentially resulting in limited understanding. We introduce “Live Charts,” a new format of presentation that decomposes complex information within a chart and explains the information pieces sequentially through rich animations and accompanying audio narration. We propose an automated approach to revive static charts into Live Charts. Our method integrates GNN-based techniques to analyze the chart components and extract data from charts. Then we adopt large natural language models to generate appropriate animated visuals along with a voice-over to produce Live Charts from static ones. We conducted a thorough evaluation of our approach, which involved the model performance, use?…",Article,https://ieeexplore.ieee.org/abstract/document/10530507/,7,ying2024reviving,"Charts, storytelling, machine learning, automatic visualization"
2023,Proceedings of the 2023 CHI conference on human factors in computing systems?…,Geocamera: Telling stories in geographic visualizations with camera movements,"Wenchao Li, Zhan Wang, Yun Wang, Di Weng, Liwenhan Xie, Siming Chen, Haidong Zhang, Huamin Qu",Wenchao Li,English,"In geographic data videos, camera movements are frequently used and combined to present information from multiple perspectives. However, creating and editing camera movements requires significant time and professional skills. This work aims to lower the barrier of crafting diverse camera movements for geographic data videos. First, we analyze a corpus of 66 geographic data videos and derive a design space of camera movements with a dimension for geospatial targets and one for narrative purposes. Based on the design space, we propose a set of adaptive camera shots and further develop an interactive tool called GeoCamera. This interactive tool allows users to flexibly design camera movements for geographic visualizations. We verify the expressiveness of our tool through case studies and evaluate its usability with a user study. The participants find that the tool facilitates the design of camera movements. ",Conference paper,https://dl.acm.org/doi/abs/10.1145/3544548.3581470,7,li2023geocamera,"Visual storytelling, data video, geographic visualization, authoring tools"
2022,IEEE Transactions on Visualization and Computer Graphics,Rankfirst: Visual analysis for factor investment by ranking stock timeseries,"Huijie Guo, Meijun Liu, Bowen Yang, Ye Sun, Huamin Qu, Lei Shi",Huijie Guo,English,"In the era of quantitative investment, factor-based investing models are widely adopted in the construction of stock portfolios. These models explain the performance of individual stocks by a set of financial factors, e.g., market beta and company size. In industry, open investment platforms allow the online building of factor-based models, yet set a high bar on the engineering expertise of end-users. State-of-the-art visualization systems integrate the whole factor investing pipeline, but do not directly address domain users' core requests on ranking factors and stocks for portfolio construction. The current model lacks explainability, which downgrades its credibility with stock investors. To fill the gap in modeling, ranking, and visualizing stock time series for factor investment, we designed and implemented a visual analytics system, namely RankFIRST. The system offers built-in support for an established factor collection and?…",Article,https://ieeexplore.ieee.org/abstract/document/9904441/,7,guo2022rankfirst,"Stock market, Factor investing, Visual analysis"
2022,Computers & Graphics 105,Saliency-aware color harmony models for outdoor signboard,"Yanna Lin, Wei Zeng, Yu Ye, Huamin Qu",Yanna Lin,English,"This paper introduces a geometric approach for assessing color harmony of a signboard, and color coherence of a signboard with the environment. We propose to incorporate visual saliency as an inherent color characteristic residing in the image space, to better cope with the attention mechanism when people view a scene. In doing so, our color harmony models consider saliency-weighted color differences and area balance in CIELab color space. We collect 5.2?K valid subjective ratings on 375 diverse signboards in the real world, and translate them into quantitative measures for model construction. Experimental results show that our models improve the overall performance, especially for modeling color coherence between a signboard and the environment. The study also reveals that color combinations with similar chroma but distinctive lightness lead to harmonic signboards, while simple color patches in?…",Article,https://www.sciencedirect.com/science/article/pii/S0097849322000644,7,lin2022saliency,"Color harmony,Visual saliency,Outdoor signboard,Design recommendation"
2022,Proceedings of the Ninth ACM Conference on Learning@ Scale,Blocklens: visual analytics of student coding behaviors in block-based programming environments,"Sean Tsung, Huan Wei, Haotian Li, Yong Wang, Meng Xia, Huamin Qu",Sean Tsung,English,"Block-based programming environments have been widely used to introduce K-12 students to coding. To guide students effectively, instructors and platform owners often need to understand behaviors like how students solve certain questions or where they get stuck and why. However, it is challenging for them to effectively analyze students' coding data. To this end, we propose BlockLens, a novel visual analytics system to assist instructors and platform owners in analyzing students' block-based coding behaviors, mistakes, and problem-solving patterns. BlockLens enables the grouping of students by question progress and performance, identification of common problem-solving strategies and pitfalls, and presentation of insights at multiple granularity levels, from a high-level overview of all students to a detailed analysis of one student's behavior and performance. A usage scenario using real-world data?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3491140.3528298,7,tsung2022blocklens,"Visual analytics, block-based programming, learning analytics"
2024,IEEE Transactions on Visualization and Computer Graphics,Scrolltimes: Tracing the provenance of paintings as a window into history,"Wei Zhang, Wong Kam-Kwai, Yitian Chen, Ailing Jia, Luwei Wang, Jian-Wei Zhang, Lechao Cheng, Huamin Qu, Wei Chen",Wei Zhang,English,"The study of cultural artifact provenance, tracing ownership and preservation, holds significant importance in archaeology and art history. Modern technology has advanced this field, yet challenges persist, including recognizing evidence from diverse sources, integrating sociocultural context, and enhancing interactive automation for comprehensive provenance analysis. In collaboration with art historians, we examined the handscroll, a traditional Chinese painting form that provides a rich source of historical data and a unique opportunity to explore history through cultural artifacts. We present a three-tiered methodology encompassing artifact, contextual, and provenance levels, designed to create a “Biography” for handscroll. Our approach incorporates the application of image processing techniques and language models to extract, validate, and augment elements within handscroll using various cultural heritage?…",Article,https://ieeexplore.ieee.org/abstract/document/10500502/,6,zhang2024scrolltimes,"Visual analytics, Digital humanities, Painting analysis, Traditional Chinese painting"
2022,Expert Systems,A survey of visual analytics in urban area,"Zezheng Feng, Huamin Qu, Shuang‐Hua Yang, Yulong Ding, Jie Song",Zezheng Feng,English," Nowadays, the population has been overgrowing due to urbanization, yielding many severe problems in the urban area, including traffic congestion, unbalanced distribution of urban hotspots, air pollution and so on. Due to the uncertainty of the urban environment, it always needs to integrate experts' domain knowledge into solving these issues. In recent years, the visual analytics method has been widely used to assist domain experts in solving urban problems with its intuitiveness, interactivity and interpretability. In this survey, we first introduce the background of urban computing, present the motivation of visual analytics in the urban area and point out the characteristics of visual analytics methods. Second, we introduce the most frequently used urban data, analyse the main properties and provide an overview on how to use these data. Thereafter, we propose our taxonomy for visual analytics in the urban area?…",Article,https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13065,6,feng2022survey,"data mining, urban data, visual analytics, visualization"
2021,arXiv preprint arXiv:2103.12910,Aqeyes: visual analytics for anomaly detection and examination of air quality data,"Dongyu Liu, Kalyan Veeramachaneni, Alexander Geiger, Victor OK Li, Huamin Qu",Dongyu Liu,English,"Anomaly detection plays a key role in air quality analysis by enhancing situational awareness and alerting users to potential hazards. However, existing anomaly detection approaches for air quality analysis have their own limitations regarding parameter selection (e.g., need for extensive domain knowledge), computational expense, general applicability (e.g., require labeled data), interpretability, and the efficiency of analysis. Furthermore, the poor quality of collected air quality data (inconsistently formatted and sometimes missing) also increases the difficulty of analysis substantially. In this paper, we systematically formulate design requirements for a system that can solve these limitations and then propose AQEyes, an integrated visual analytics system for efficiently monitoring, detecting, and examining anomalies in air quality data. In particular, we propose a unified end-to-end tunable machine learning pipeline that includes several data pre-processors and featurizers to deal with data quality issues. The pipeline integrates an efficient unsupervised anomaly detection method that works without the use of labeled data and overcomes the limitations of existing approaches. Further, we develop an interactive visualization system to visualize the outputs from the pipeline. The system incorporates a set of novel visualization and interaction designs, allowing analysts to visually examine air quality dynamics and anomalous events in multiple scales and from multiple facets. We demonstrate the performance of this pipeline through a quantitative evaluation and show the effectiveness of the visualization system using qualitative case studies on real-world?…",Article,https://arxiv.org/abs/2103.12910,6,liu2021aqeyes,"anomaly detection, air quality, multiple time-series, visualization"
2024,International Journal of Human–Computer Interaction,PoeticAR: Reviving traditional poetry of the heritage site of jichang garden via augmented reality,"Jin Tian, Yifan Cao, Lingyi Feng, Dongting Fu, Linping Yuan, Huamin Qu, Yang Wang, Mingming Fan",Jin Tian,English,"As a famed Chinese classical garden, the Jichang Garden was a constant inspiration to many poets in its hundreds of years’ history, who composed a rich body of poems—a valuable intangible cultural heritage. While tourists tend to pay attention to tangible natural scenery and historical architectures, they often neglect intangible cultural heritage—poems. We interviewed 23 tourists and found that augmented reality (AR) was viable for tourists to enjoy the physical scenery and the poetry simultaneously. We developed an initial prototype of PoeticAR, which presents poems based on physical scenery to enhance tourists’ cultural and aesthetic experience. We further revised the prototype based on the ideas generated from a workshop with 18 tourists. We conducted a between-subject user study with 30 tourists to compare PoeticAR with Video. Results showed that PoeticAR significantly motivated tourists’ interest in?…",Article,https://www.tandfonline.com/doi/abs/10.1080/10447318.2023.2176806,5,tian2024poeticar,None
2023,IEEE Transactions on Visualization and Computer Graphics,CommonsenseVIS: Visualizing and Understanding Commonsense Reasoning Capabilities of Natural Language Models,"Xingbo Wang, Renfei Huang, Zhihua Jin, Tianqing Fang, Huamin Qu",Xingbo Wang,English,"Recently, large pretrained language models have achieved compelling performance on commonsense benchmarks. Nevertheless, it is unclear what commonsense knowledge the models learn and whether they solely exploit spurious patterns. Feature attributions are popular explainability techniques that identify important input concepts for model outputs. However, commonsense knowledge tends to be implicit and rarely explicitly presented in inputs. These methods cannot infer models' implicit reasoning over mentioned concepts. We present  CommonsenseVIS , a visual explanatory system that utilizes external commonsense knowledge bases to contextualize model behavior for commonsense question-answering. Specifically, we extract relevant commonsense knowledge in inputs as references to align model behavior with human knowledge. Our system features multi-level visualization and interactive model?…",Article,https://ieeexplore.ieee.org/abstract/document/10297594/,5,wang2023commonsensevis,"Commonsense reasoning, visual analytics, XAI, natural language processing"
2023,IEEE Transactions on Visualization and Computer Graphics,VideoPro: A Visual Analytics Approach for Interactive Video Programming,"Jianben He, Xingbo Wang, Kam Kwai Wong, Xijie Huang, Changjian Chen, Zixin Chen, Fengjie Wang, Min Zhu, Huamin Qu",Jianben He,English,"Constructing supervised machine learning models for real-world video analysis require substantial labeled data, which is costly to acquire due to scarce domain expertise and laborious manual inspection. While data programming shows promise in generating labeled data at scale with user-defined labeling functions, the high dimensional and complex temporal information in videos poses additional challenges for effectively composing and evaluating labeling functions. In this paper, we propose  VideoPro , a visual analytics approach to support flexible and scalable video data programming for model steering with reduced human effort. We first extract human-understandable events from videos using computer vision techniques and treat them as atomic components of labeling functions. We further propose a two-stage template mining algorithm that characterizes the sequential patterns of these events to serve as?…",Article,https://ieeexplore.ieee.org/abstract/document/10292616/,5,he2023videopro,"Interactive machine learning, data programming, video exploration and analysis"
2023,2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?…,Cinematography in the Metaverse: Exploring the Lighting Education on a Soundstage,"Xian Xu, Wai Tong, Zheng Wei, Meng Xia, Lik-Hang Lee, Huamin Qu",Xian Xu,English,"Lighting education is a foundational component of cinematography education. However, there is still a lack of knowledge on the design of a VR system for teaching cinematography. In this work, we present our VR soundstage system for instructors and learners to emulate cinematography lighting in virtual scenarios and then evaluate it from five aspects in the user study. Qualitative and quantitative feedback in our user study shows promising results. We further discuss the benefits of the approach and opportunities for future research.",Conference paper,https://ieeexplore.ieee.org/abstract/document/10108863/,4,xu2023cinematography,"Human-centered computing,Human computer interaction (HCI),Interaction paradigms,Virtual reality"
2022,Proceedings of the 24th International ACM SIGACCESS Conference on Computers?…,Designing a game for pre-screening students with specific learning disabilities in Chinese,"Ka Yan Fung, Kuen Fung Sin, Zikai Alex Wen, Lik-Hang Lee, Shenghui Song, Huamin Qu",Ka Yan Fung,English," Most students with specific learning disabilities (SLDs) have difficulties in reading and writing. The SLDs pre-screening is crucial because the golden period for therapy is before six years old. However, many students in Hong Kong receive SLDs assessments after the golden period. Also, the SLDs pre-screening is challenging, especially in a language with the logographic script but without prominent sound-script correspondence (e.g., Chinese, Japanese). To make pre-screening SLDs in Chinese more effective and efficient, we designed a new comprehensive pre-screening game for SLDs in Chinese (i.e., dyslexia, dysgraphia, and dyspraxia). Notably, we designed a Chinese morphological awareness puzzle that challenges students to recognize different words made up with the first character that is identical and the second character that is different, such as樹枝 (literally means tree branch),樹幹 (literally means?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3517428.3550384,4,fung2022designing,None
2020,US Patent 10,Method and system for analyzing user activities related to a video,"Huamin Qu, Conglei Shi, Siwei Fu, Qing Chen",Huamin Qu,English,The present teaching relates to analyzing user activities related to a video. The video is provided to a plurality of users. The plurality of users is monitored to detect one or more types of user activities performed in time with respect to different portions of the video. One or more visual representations of the monitored one or more types of user activities are generated. The one or more visual representations capture a level of attention paid by the plurality of users to the different portions of the video at any time instance. Interests of at least some of the plurality of users are determined with respect to the different portions of the video based on the one or more visual representations.,Conference paper,https://patents.google.com/patent/US10616626B2/en,4,qu2020method,"Multimodal models, sentiment analysis, explainable machine learning"
2023,2023 IEEE 16th Pacific Visualization Symposium (PacificVis),Understanding 3D Data Videos: From Screens to Virtual Reality,"Leni Yang, Aoyu Wu, Wai Tong, Xian Xu, Zheng Wei, Huamin Qu",Leni Yang,English,"Data storytelling explores how to communicate data insights to the general public engagingly and effectively. It combines the power of data visualizations and storytelling techniques and is popular in various media such as newspapers, interactive websites, and videos. Recently, virtual reality has brought new opportunities to enhance data storytelling with an incomparable sense of immersion. However, there exists a limited understanding of data stories in virtual reality (VR) as they are still in the early stage. In this paper, we investigated the idea of VR data videos by drawing inspiration from popular 3D data videos and studying how to transfer them from screens to VR. We systematically analyzed 100 highly-watched 3D data videos from Youtube and Tiktok channels to derive their design space. We then conducted a user study with 12 participants to explore the effects of four design factors on user experience?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/10148393/,3,yang2023understanding,Human-centered computing—Visualization—Empirical studies
2022,arXiv preprint arXiv:2211.02567,Kb4va: A knowledge base of visualization designs for visual analytics,"Dazhen Deng, Aoyu Wu, Haotian Li, Ji Lan, Yong Wang, Huamin Qu, Yingcai Wu",Dazhen Deng,English,"Visual analytics (VA) systems have been widely used to facilitate decision-making and analytical reasoning in various application domains. VA involves visual designs, interaction designs, and data mining, which is a systematic and complex paradigm. In this work, we focus on the design of effective visualizations for complex data and analytical tasks, which is a critical step in designing a VA system. This step is challenging because it requires extensive knowledge about domain problems and visualization to design effective encodings. Existing visualization designs published in top venues are valuable resources to inspire designs for problems with similar data structures and tasks. However, those designs are hard to understand, parse, and retrieve due to the lack of specifications. To address this problem, we build KB4VA, a knowledge base of visualization designs in VA systems with comprehensive labels about their analytical tasks and visual encodings. Our labeling scheme is inspired by a workshop study with 12 VA researchers to learn user requirements in understanding and retrieving professional visualization designs in VA systems. The theme extends Vega-Lite specifications for describing advanced and composited visualization designs in a declarative manner, thus facilitating human understanding and automatic indexing. To demonstrate the usefulness of our knowledge base, we present a user study about design inspirations for VA tasks. In summary, our work opens new perspectives for enhancing the accessibility and reusability of professional visualization designs.",Article,https://arxiv.org/abs/2211.02567,3,deng2022kb4va,"Query Recommendation, SQL Databases, Interactive Data Analysis, Natural Language Interface"
2021,arXiv preprint arXiv:2106.14313,AniVis: Generating Animated Transitions Between Statistical Charts with a Tree Model,"Wenchao Li, Yun Wang, He Huang, Weiwei Cui, Haidong Zhang, Huamin Qu, Dongmei Zhang",Wenchao Li,English,"Animated transitions help viewers understand changes between related visualizations. To clearly present the underlying relations between statistical charts, animation authors need to have a high level of expertise and a considerable amount of time to describe the relations with reasonable animation stages. We present AniVis, an automated approach for generating animated transitions to demonstrate the changes between two statistical charts. AniVis models each statistical chart into a tree-based structure. Given an input chart pair, the differences of data and visual properties of the chart pair are formalized as tree edit operations. The edit operations can be mapped to atomic transition units. Through this approach, the animated transition between two charts can be expressed as a set of transition units. Then, we conduct a formative study to understand people's preferences for animation sequences. Based on the study, we propose a set of principles and a sequence composition algorithm to compose the transition units into a meaningful animation sequence. Finally, we synthesize these units together to deliver a smooth and intuitive animated transition between charts. To test our approach, we present a prototype system and its generated results to illustrate the usage of our framework. We perform a comparative study to assess the transition sequence derived from the tree model. We further collect qualitative feedback to evaluate the effectiveness and usefulness of our method.",Article,https://arxiv.org/abs/2106.14313,3,li2021anivis,"Animated transition, automated design, chart animation, tree struc- ture, staging"
2020,arXiv preprint arXiv:2001.02731,SirenLess: Reveal the intention behind news,"Xumeng Chen, Leo Yu-Ho Lo, Huamin Qu",Xumeng Chen,English,"News articles tend to be increasingly misleading nowadays, preventing readers from making subjective judgments towards certain events. While some machine learning approaches have been proposed to detect misleading news, most of them are black boxes that provide limited help for humans in decision making. In this paper, we present SirenLess, a visual analytical system for misleading news detection by linguistic features. The system features article explorer, a novel interactive tool that integrates news metadata and linguistic features to reveal semantic structures of news articles and facilitate textual analysis. We use SirenLess to analyze 18 news articles from different sources and summarize some helpful patterns for misleading news detection. A user study with journalism professionals and university students is conducted to confirm the usefulness and effectiveness of our system.",Article,https://arxiv.org/abs/2001.02731,3,chen2020sirenless,None
2024,arXiv preprint arXiv:2402.08978,Prismatic: Interactive Multi-View Cluster Analysis of Concept Stocks,"Wong Kam-Kwai, Yan Luo, Xuanwu Yue, Wei Chen, Huamin Qu",Wong Kam-Kwai,English,"Financial cluster analysis allows investors to discover investment alternatives and avoid undertaking excessive risks. However, this analytical task faces substantial challenges arising from many pairwise comparisons, the dynamic correlations across time spans, and the ambiguity in deriving implications from business relational knowledge. We propose Prismatic, a visual analytics system that integrates quantitative analysis of historical performance and qualitative analysis of business relational knowledge to cluster correlated businesses interactively. Prismatic features three clustering processes: dynamic cluster generation, knowledge-based cluster exploration, and correlation-based cluster validation. Utilizing a multi-view clustering approach, it enriches data-driven clusters with knowledge-driven similarity, providing a nuanced understanding of business correlations. Through well-coordinated visual views, Prismatic facilitates a comprehensive interpretation of intertwined quantitative and qualitative features, demonstrating its usefulness and effectiveness via case studies on formulating concept stocks and extensive interviews with domain experts.",Article,https://arxiv.org/abs/2402.08978,2,kam2024prismatic,"Financial data, Interactive clustering, Multi-view clustering, Multi-layer network"
2023,Proceedings of the 36th Annual ACM Symposium on User Interface Software and?…,Wakey-Wakey: Animate Text by Mimicking Characters in a GIF,"Liwenhan Xie, Zhaoyu Zhou, Kerun Yu, Yun Wang, Huamin Qu, Siming Chen",Liwenhan Xie,English,"With appealing visual effects, kinetic typography (animated text) has prevailed in movies, advertisements, and social media. However, it remains challenging and time-consuming to craft its animation scheme. We propose an automatic framework to transfer the animation scheme of a rigid body on a given meme GIF to text in vector format. First, the trajectories of key points on the GIF anchor are extracted and mapped to the text’s control points based on local affine transformation. Then the temporal positions of the control points are optimized to maintain the text topology. We also develop an authoring tool that allows intuitive human control in the generation process. A questionnaire study provides evidence that the output results are aesthetically pleasing and well preserve the animation patterns in the original GIF, where participants were impressed by a similar emotional semantics of the original GIF. In addition, we?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3586183.3606813,2,xie2023wakey,"Kinetic typography, Animation, Motion transfer"
2023,IEEE Transactions on Visualization and Computer Graphics,Why Change My Design: Explaining Poorly Constructed Visualization Designs with Explorable Explanations,"Leo Yu-Ho Lo, Yifan Cao, Leni Yang, Huamin Qu",Leo Yu-Ho Lo,English,"Although visualization tools are widely available and accessible, not everyone knows the best practices and guidelines for creating accurate and honest visual representations of data. Numerous books and articles have been written to expose the misleading potential of poorly constructed charts and teach people how to avoid being deceived by them or making their own mistakes. These readings use various rhetorical devices to explain the concepts to their readers. In our analysis of a collection of books, online materials, and a design workshop, we identified six common explanation methods. To assess the effectiveness of these methods, we conducted two crowdsourced studies (each with   ) to evaluate their ability to teach and persuade people to make design changes. In addition to these existing methods, we brought in the idea of Explorable Explanations, which allows readers to experiment with?…",Article,https://ieeexplore.ieee.org/abstract/document/10299537/,2,lo2023change,"Human-centered computing,Visualization,Visualization techniques, Human-centered computing,Collaborative and social computing,Empirical studies in collaborative and social computing"
2023,IEEE Transactions on Visualization and Computer Graphics,Adavis: Adaptive and explainable visualization recommendation for tabular data,"Songheng Zhang, Yong Wang, Haotian Li, Huamin Qu",Songheng Zhang,English,"Automated visualization recommendation facilitates the rapid creation of effective visualizations, which is especially beneficial for users with limited time and limited knowledge of data visualization. There is an increasing trend in leveraging machine learning (ML) techniques to achieve an end-to-end visualization recommendation. However, existing ML-based approaches implicitly assume that there is only one appropriate visualization for a specific dataset, which is often not true for real applications. Also, they often work like a black box, and are difficult for users to understand the reasons for recommending specific visualizations. To fill the research gap, we propose AdaVis, an adaptive and explainable approach to recommend one or multiple appropriate visualizations for a tabular dataset. It leverages a box embedding-based knowledge graph to well model the possible one-to-many mapping relations among?…",Article,https://ieeexplore.ieee.org/abstract/document/10254497/,2,zhang2023adavis,"Visualization Recommendation, Logical Reasoning, Data Visualization, Knowledge Graph"
2023,Proceedings of the 6th ACM SIGCAS/SIGCHI Conference on Computing and?…,FoodWise: Food Waste Reduction and Behavior Change on Campus with Data Visualization and Gamification,"Yue Yu, Sophia Yi, Xi Nan, Leo Yu-Ho Lo, Kento Shigyo, Liwenhan Xie, Jeffry Wicaksana, Kwang-Ting Cheng, Huamin Qu",Yue Yu,English," Food waste presents a substantial challenge with significant environmental and economic ramifications, and its severity on campus environments is of particular concern. In response to this, we introduce FoodWise, a dual-component system tailored to inspire and incentivize campus communities to reduce food waste. The system consists of a data storytelling dashboard that graphically displays food waste information from university canteens, coupled with a mobile web application that encourages users to log their food waste reduction actions and rewards active participants for their efforts.  Deployed during a two-week food-saving campaign at The Hong Kong University of Science and Technology (HKUST) in March 2023, FoodWise engaged over 200 participants from the university community, resulting in the logging of over 800 daily food-saving actions. Feedback collected post-campaign underscores the?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3588001.3609364,2,yu2023foodwise,"food waste reduction, sustainability, human-centered computing, persuasive technology, self-tracking"
2023,Visual Informatics,Tax-Scheduler: An interactive visualization system for staff shifting and scheduling at tax authorities,"Linping Yuan, Boyu Li, Siqi Li, Kam Kwai Wong, Rong Zhang, Huamin Qu",Linping Yuan,English,"Given a large number of applications and complex processing procedures, how to efficiently shift and schedule tax officers to provide good services to taxpayers is now receiving more attention from tax authorities. The availability of historical application data makes it possible for tax managers to shift and schedule staff with data support, but it is unclear how to properly leverage the historical data. To investigate the problem, this study adopts a user-centered design approach. We first collect user requirements by conducting interviews with tax managers and characterize their requirements of shifting and scheduling into time series prediction and resource scheduling problems. Then, we propose Tax-Scheduler, an interactive visualization system with a time-series prediction algorithm and genetic algorithm to support staff shifting and scheduling in the tax scenarios. To evaluate the effectiveness of the system and?…",Article,https://www.sciencedirect.com/science/article/pii/S2468502X23000050,2,yuan2023tax,"Staff scheduling,Tax service,Genetic algorithm,Time series prediction"
2023,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?…,Networknarratives: Data tours for visual network exploration and analysis,"Wenchao Li, Sarah Sch?ttler, James Scott-Brown, Yun Wang, Siming Chen, Huamin Qu, Benjamin Bach",Wenchao Li,English," This paper introduces semi-automatic data tours to aid the exploration of complex networks. Exploring networks requires significant effort and expertise and can be time-consuming and challenging. Distinct from guidance and recommender systems for visual analytics, we provide a set of goal-oriented tours for network overview, ego-network analysis, community exploration, and other tasks. Based on interviews with five network analysts, we developed a user interface (NetworkNarratives) and 10 example tours. The interface allows analysts to navigate an interactive slideshow featuring facts about the network using visualizations and textual annotations. On each slide, an analyst can freely explore the network and specify nodes, links, or subgraphs as seed elements for follow-up tours. Two studies, comprising eight expert and 14 novice analysts, show that data tours reduce exploration effort, support learning about?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3544548.3581452,2,li2023networknarratives,"Guided exploration, network visualization"
2022,US Patent 11,ProtoSteer:Steering deep sequence model with prototypes,"Panpan Xu, Liu Ren, MING Yao, Furui Cheng, Huamin Qu",Panpan Xu,English,Int. Cl. G06F 3/04847(2022.01) G06N 3/08(2006.01) G06F 370482(2013.01)(52) US CI. CPC G06F 3/04847 (2013.01); G06F 3/0482 (2013.01); GOON 3/08 (2013.01),Conference paper,https://patents.google.com/patent/US11513673B2/en,2,xu2022steering,"Sequence Data, Explainable Artificial Intelligence (XAI), Recurrent Neural Networks (RNNs), Prototype Learning"
2022,2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?…,Let Every Seat Be Perfect! A Case Study on Combining BIM and VR for Room Planning,"Wai Tong, Haotian Li, Huan Wei, Liwenhan Xie, Yanna Lin, Huamin Qu",Wai Tong,English,"When communicating indoor room design, professional designers normally rely on software like Revit to export walk-through videos for their clients. However, a lack of in-situ experience restricts the ultimate users from evaluating the design and hence provides limited feedback, which may lead to a rework after actual construction. In this case study, we explore empowering end-users by exposing rich design details through a Virtual Reality (VR) application based on building an information model. Qualitative feedback in our user study shows promising results. We further discuss the benefits of the approach and opportunities for future research.",Conference paper,https://ieeexplore.ieee.org/abstract/document/9757646/,2,tong2022let,"Human-centered computing,Interaction paradigms,Virtual Reality"
2020,arXiv preprint arXiv:2006.12718,ICE: Identify and compare event sequence sets through multi-scale matrix and unit visualizations,"Siwei Fu, Jian Zhao, Linping Yuan, Zhicheng Liu, Kwan-Liu Ma, Huamin Qu",Siwei Fu,English,"Comparative analysis of event sequence data is essential in many application domains, such as website design and medical care. However, analysts often face two challenges: they may not always know which sets of event sequences in the data are useful to compare, and the comparison needs to be achieved at different granularity, due to the volume and complexity of the data. This paper presents, ICE, an interactive visualization that allows analysts to explore an event sequence dataset, and identify promising sets of event sequences to compare at both the pattern and sequence levels. More specifically, ICE incorporates a multi-level matrix-based visualization for browsing the entire dataset based on the prefixes and suffixes of sequences. To support comparison at multiple levels, ICE employs the unit visualization technique, and we further explore the design space of unit visualizations for event sequence comparison tasks. Finally, we demonstrate the effectiveness of ICE with three real-world datasets from different domains.",Article,https://arxiv.org/abs/2006.12718,2,fu2020ice,"Event sequence data, visual comparison, matrix-based visualization, unit visualization"
2024,US Patent 11,Visual analytics tool for proctoring online exams,"LI Haotian, Min Xu, Huan Wei, Huamin Qu, Yong Wang",LI Haotian,English,"A system for proctoring online exams includes a client-side computing system and a visual analytics system. The client-side computing system includes a camera configured to obtain video data corresponding to a user while taking an exam and one or more input devices configured to obtain interaction data, wherein the interaction data includes mouse movements of the user while taking the exam. The visual analytics system is configured to obtain the video data and the interaction data from the client-side computing system, analyze the exam data to detect abnormal behavior by the user based at least in part on mouse movement data, and generate one or more visualizations of the analyzed exam data to be used in determining whether or not the user has cheated during the exam.",Conference paper,https://patents.google.com/patent/US11961302B2/en,1,haotian2024visual,None
2024,arXiv preprint arXiv:2402.04991,Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults Explore and Learn Smartphone Applications,"Xiaofu Jin, Wai Tong, Xiaoying Wei, Xian Wang, Emily Kuang, Xiaoyu Mo, Huamin Qu, Mingming Fan",Xiaofu Jin,English,"The global aging trend compels older adults to navigate the evolving digital landscape, presenting a substantial challenge in mastering smartphone applications. While Augmented Reality (AR) holds promise for enhancing learning and user experience, its role in aiding older adults' smartphone app exploration remains insufficiently explored. Therefore, we conducted a two-phase study: (1) a workshop with 18 older adults to identify app exploration challenges and potential AR interventions, and (2) tech-probe participatory design sessions with 15 participants to co-create AR support tools. Our research highlights AR's effectiveness in reducing physical and cognitive strain among older adults during app exploration, especially during multi-app usage and the trial-and-error learning process. We also examined their interactional experiences with AR, yielding design considerations on tailoring AR tools for smartphone app exploration. Ultimately, our study unveils the prospective landscape of AR in supporting the older demographic, both presently and in future scenarios.",Article,https://arxiv.org/abs/2402.04991,1,jin2024exploring,"augmented reality, older adults, smartphone exploration, independent learning"
2023,Proceedings of the 31st ACM International Conference on Multimedia,Feeling Present! From Physical to Virtual Cinematography Lighting Education with Metashadow,"Zheng Wei, Xian Xu, Lik-Hang Lee, Wai Tong, Huamin Qu, Pan Hui",Zheng Wei,English,"The high cost and limited availability of soundstages for cinematography lighting education pose significant challenges for art institutions. Traditional teaching methods, combining basic lighting equipment operation with slide lectures, often yield unsatisfactory results, hindering students' mastery of cinematography lighting techniques. Therefore, we propose Metashadow, a virtual reality (VR) cinematography lighting education system demonstrating the feasibility of learning in a virtual soundstage. Based on the presence theory, Metashadow features high-fidelity lighting devices that enable users to adjust multiple parameters, providing a quantifiable learning approach. We evaluated Metashadow with 24 participants and found that it provides better learning outcomes than traditional teaching methods regarding presence, collaboration, usability, realism, creativity, and flexibility. Six experts also praised the?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3581783.3612580,1,wei2023feeling,"Presence,VirtualReality,Cinematography lighting,LearningEffect, VR Education, VR Creativity"
2023,Computer Graphics Forum,iFUNDit: Visual Profiling of Fund Investment Styles,"Rong Zhang, Bon Kyung Ku, Yong Wang, Xuanwu Yue, Siyuan Liu, Ke Li, Huamin Qu",Rong Zhang,English," Mutual funds are becoming increasingly popular with the emergence of Internet finance. Clear profiling of a fund's investment style is crucial for fund managers to evaluate their investment strategies, and for investors to understand their investment. However, it is challenging to profile a fund's investment style as it requires a comprehensive analysis of complex multi‐dimensional temporal data. In addition, different fund managers and investors have different focuses when analysing a fund's investment style. To address the issue, we propose iFUNDit, an interactive visual analytic system for fund investment style analysis. The system decomposes a fund's critical features into performance attributes and investment style factors, and visualizes them in a set of coupled views: a fund and manager view, to delineate the distribution of funds' and managers' critical attributes on the market; a cluster view, to show the similarity?…",Article,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14806,1,zhang2023ifundit,"visualization, visual analytics, financial visualization, business intelligence"
2023,Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?…,Is It the End? Guidelines for Cinematic Endings in Data Videos,"Xian Xu, Aoyu Wu, Leni Yang, Zheng Wei, Rong Huang, David Yip, Huamin Qu",Xian Xu,English," Data videos are becoming increasingly popular in society and academia. Yet little is known about how to create endings that strengthen a lasting impression and persuasion. To fulfill the gap, this work aims to develop guidelines for data video endings by drawing inspiration from cinematic arts. To contextualize cinematic endings in data videos, 111 film endings and 105 data video endings are first analyzed to identify four common styles using the framework of ending punctuation marks. ?We conducted expert interviews (N=11) and formulated 20 guidelines for creating cinematic endings in data videos. To validate our guidelines, we conducted a user study where 24 participants were invited to design endings with and without our guidelines, which are evaluated by experts and the general public. The participants praise the clarity and usability of the guidelines, and results show that the endings with guidelines are?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3544548.3580701,1,xu2023end,"Visualization, Storytelling, Interview, Lab Study, Data Video, Guideline"
2022,US Patent 11,System and a method for speech analysis,"Huamin Qu, Yuanzhe Chen, Siwei Fu, Linping Yuan, WU Aoyu",Huamin Qu,English,"A computer implemented method and system for processing an audio signal. The method includes the steps of extracting prosodic features from the audio signal, aligning the extracted prosodic features with a script derived from or associated with the audio signal, and segmenting the script with the aligned extracted prosodic features into structural blocks of a first type. The method may further include determining a distance measure between a structural block of a first type derived from the script with another structural block of the first type using, for example, the Damerau-Levenshtein distance.",Conference paper,https://patents.google.com/patent/US11282508B2/en,1,qu2022system,None
2021,2021 IEEE VIS Arts Program (VISAP),Explore Mindfulness Without Deflection: A Data Art Based On The Book Of Songs,"Yifang Wang, Yang Wang, Yifan Cao, Huamin Qu, Junxiu Tang, Yingcai Wu",Yifang Wang,English,"The Book of Songs is regarded as the origin of Chinese literature and has a prolonged impact on Chinese culture, aesthetics, and morality. In this work, we have analyzed the 305 poems in The Book of Songs from different dimensions. We aim to learn how various poetic imageries connect abstract themes and subjective emotions at the micro level, and how the poems connect people today and ancestors to understand the universal, everlasting, and poetical human lives at the macro level.",Conference paper,https://ieeexplore.ieee.org/abstract/document/9623013/,1,wang2021explore,"Digital Humanities, Cultural Heritage,Data Visualization, Data Art"
2024,arXiv preprint arXiv:2406.03317,"Save It for the"" Hot"" Day: An LLM-Empowered Visual Analytics System for Heat Risk Management","Haobo Li, Wong Kam-Kwai, Yan Luo, Juntong Chen, Chengzhong Liu, Yaxuan Zhang, Alexis Kai Hon Lau, Huamin Qu, Dongyu Liu",Haobo Li,English,"The escalating frequency and intensity of heat-related climate events, particularly heatwaves, emphasize the pressing need for advanced heat risk management strategies. Current approaches, primarily relying on numerical models, face challenges in spatial-temporal resolution and in capturing the dynamic interplay of environmental, social, and behavioral factors affecting heat risks. This has led to difficulties in translating risk assessments into effective mitigation actions. Recognizing these problems, we introduce a novel approach leveraging the burgeoning capabilities of Large Language Models (LLMs) to extract rich and contextual insights from news reports. We hence propose an LLM-empowered visual analytics system, Havior, that integrates the precise, data-driven insights of numerical models with nuanced news report information. This hybrid approach enables a more comprehensive assessment of heat risks and better identification, assessment, and mitigation of heat-related threats. The system incorporates novel visualization designs, such as ""thermoglyph"" and news glyph, enhancing intuitive understanding and analysis of heat risks. The integration of LLM-based techniques also enables advanced information retrieval and semantic knowledge extraction that can be guided by experts' analytics needs. Our case studies on two cities that faced significant heatwave events and interviews with five experts have demonstrated the usefulness of our system in providing in-depth and actionable insights for heat risk management.",Article,https://arxiv.org/abs/2406.03317,0,li2024save,"Heat risk management, climate change, numerical model, news data, large language model, visual analytics"
2024,IEEE Transactions on Visualization and Computer Graphics,NFTracer: Tracing NFT Impact Dynamics in Transaction-flow Substitutive Systems with Visual Analytics,"Yifan Cao, Qing Shi, Lue Shen, Kani Chen, Yang Wang, Wei Zeng, Huamin Qu",Yifan Cao,English,"Impact dynamics are crucial for estimating the growth patterns of NFT projects by tracking the diffusion and decay of their relative appeal among stakeholders. Machine learning methods for impact dynamics analysis are incomprehensible and rigid in terms of their interpretability and transparency, whilst stakeholders require interactive tools for informed decision-making. Nevertheless, developing such a tool is challenging due to the substantial, heterogeneous NFT transaction data and the requirements for flexible, customized interactions. To this end, we integrate intuitive visualizations to unveil the impact dynamics of NFT projects. We first conduct a formative study and summarize analysis criteria, including substitution mechanisms, impact attributes, and design requirements from stakeholders. Next, we propose the Minimal Substitution Model to simulate substitutive systems of NFT projects that can be feasibly?…",Article,https://ieeexplore.ieee.org/abstract/document/10534787/,0,cao2024nftracer,"Human-centered computing,Interaction paradigms,Virtual Reality"
2024,Extended Abstracts of the CHI Conference on Human Factors in Computing?…,Exploring Stage Lighting Education in Metaverse,"Wai Tong, Meng Xia, Huamin Qu",Wai Tong,English," This paper investigates stage lighting education in the metaverse from a practical perspective. We conducted participatory design with practitioners and stakeholders from a local university to develop a VR-based stage lighting system for the Technical Theater Arts course. Over six months, we derived a list of design requirements (e.g., Level of realism serves the purpose of learning) and developed a prototype VR system for stage lighting education. Our contributions include the establishment of design requirements for stage lighting education in the metaverse, the development of a prototype system, and insights from integrating VR in course development. This research paves the way for further exploration and refinement of VR applications in educational settings.",Conference paper,https://dl.acm.org/doi/abs/10.1145/3613905.3650924,0,tong2024exploring,"Stage lighting education, virtual reality, participatory design"
2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,OutlineSpark: Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines,"Fengjie Wang, Yanna Lin, Leni Yang, Haotian Li, Mingyang Gu, Min Zhu, Huamin Qu",Fengjie Wang,English," Computational notebooks are widely utilized for exploration and analysis. However, creating slides to communicate analysis results from these notebooks is quite tedious and time-consuming. Researchers have proposed automatic systems for generating slides from notebooks, which, however, often do not consider the process of users conceiving and organizing their messages from massive code cells. Those systems ask users to go directly into the slide creation process, which causes potentially ill-structured slides and burdens in further refinement. Inspired by the common and widely recommended slide creation practice: drafting outlines first and then adding concrete content, we introduce OutlineSpark, an AI-powered slide creation tool that generates slides from a slide outline written by the user. The tool automatically retrieves relevant notebook cells based on the outlines and converts them into slide content?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3613904.3642865,0,wang2024outlinespark,"computational notebooks, slides generation, outlines, data science"
2024,Proceedings of the CHI Conference on Human Factors in Computing Systems,VAID: Indexing View Designs in Visual Analytics System,"Lu Ying, Aoyu Wu, Haotian Li, Zikun Deng, Ji Lan, Jiang Wu, Yong Wang, Huamin Qu, Dazhen Deng, Yingcai Wu",Lu Ying,English,"Visual analytics (VA) systems have been widely used in various application domains. However, VA systems are complex in design, which imposes a serious problem: although the academic community constantly designs and implements new designs, the designs are difficult to query, understand, and refer to by subsequent designers. To mark a major step forward in tackling this problem, we index VA designs in an expressive and accessible way, transforming the designs into a structured format. We first conducted a workshop study with VA designers to learn user requirements for understanding and retrieving professional designs in VA systems. Thereafter, we came up with an index structure VAID to describe advanced and composited visualization designs with comprehensive labels about their analytical tasks and visual designs. The usefulness of VAID was validated through user studies. Our work opens new?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3613904.3642237,0,ying2024vaid,"Visual Analytics, Visualization Retrieval, Visualization Design"
2024,arXiv preprint arXiv:2404.11614,Dynamic Typography: Bringing Words to Life,"Zichen Liu, Yihao Meng, Hao Ouyang, Yue Yu, Bolin Zhao, Daniel Cohen-Or, Huamin Qu",Zichen Liu,English,"Text animation serves as an expressive medium, transforming static communication into dynamic experiences by infusing words with motion to evoke emotions, emphasize meanings, and construct compelling narratives. Crafting animations that are semantically aware poses significant challenges, demanding expertise in graphic design and animation. We present an automated text animation scheme, termed ""Dynamic Typography"", which combines two challenging tasks. It deforms letters to convey semantic meaning and infuses them with vibrant movements based on user prompts. Our technique harnesses vector graphics representations and an end-to-end optimization-based framework. This framework employs neural displacement fields to convert letters into base shapes and applies per-frame motion, encouraging coherence with the intended textual concept. Shape preservation techniques and perceptual loss regularization are employed to maintain legibility and structural integrity throughout the animation process. We demonstrate the generalizability of our approach across various text-to-video models and highlight the superiority of our end-to-end methodology over baseline methods, which might comprise separate tasks. Through quantitative and qualitative evaluations, we demonstrate the effectiveness of our framework in generating coherent text animations that faithfully interpret user prompts while maintaining readability. Our code is available at: https://animate-your-word.github.io/demo/.",Article,https://arxiv.org/abs/2404.11614,0,liu2024dynamic,None
2024,IEEE Transactions on Visualization and Computer Graphics,TacPrint: Visualizing the Biomechanical Fingerprint in Table Tennis,"Jiachen Wang, Ji Ma, Zheng Zhou, Xiao Xie, Hui Zhang, Yingcai Wu, Huamin Qu",Jiachen Wang,English,"Table tennis is a sport that demands high levels of technical proficiency and body coordination from players. Biomechanical fingerprints can provide valuable insights into players' habitual movement patterns and characteristics, allowing them to identify and improve technical weaknesses. Despite the potential, few studies have developed effective methods for generating such fingerprints. To address this gap, we propose TacPrint, a framework for generating a biomechanical fingerprint for each player. TacPrint leverages machine learning techniques to extract comprehensive features from biomechanics data collected by inertial measurement units (IMU) and employs the attention mechanism to enhance model interpretability. After generating fingerprints, TacPrint provides a visualization system to facilitate the exploration and investigation of these fingerprints. In order to validate the effectiveness of the framework?…",Article,https://ieeexplore.ieee.org/abstract/document/10500518/,0,wang2024tacprint,"Data transformation, biomechanical data,machine learning"
2024,IEEE Transactions on Learning Technologies,ADPS–A Pre-screening Tool for Students with Dyslexia in Learning Traditional Chinese,"Ka-Yan Fung, Kit-Yi Tang, Tze Leung Rick Lui, Kuen-Fung Sin, Lik-Hang Lee, Huamin Qu, Shenghui Song",Ka-Yan Fung,English,"Prescreening children for specific learning disabilities, e.g., dyslexia, is essential for effective intervention. With a quick and reliable prescreening result, special education coordinators (SENCOs) can provide students with early intervention and relieve their learning pressure. Unfortunately, due to the limited resources, many students in Hong Kong receive dyslexia assessments beyond the golden period, i.e., under the age of six. To this end, information technology could establish automatic prescreening tools to address this issue. However, dyslexia prescreening for children learning Chinese is challenging due to the lack of sound–script correlation in Chinese. In this article, an automatic dyslexia prescreening system (ADPS) is developed to provide a quick test to identify at-risk children. Through a two-stage approach, we first develop a gamified tool based on linguistic characteristics and then evaluate the result by?…",Article,https://ieeexplore.ieee.org/abstract/document/10488748/,0,fung2024adps,"Dyslexia, handwriting (HW), phonological awareness (PA), prescreening, Traditional Chinese, vocabulary knowledge (VK), working memory (WM)"
2024,2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR),Generating Virtual Reality Stroke Gesture Data from Out-of-Distribution Desktop Stroke Gesture Data,"Lin-Ping Yuan, Boyu Li, Jindong Wang, Huamin Qu, Wei Zeng",Lin-Ping Yuan,English,"This paper exploits ubiquitous desktop interaction data as an input source for generating virtual reality (VR) interaction data, which can benefit tasks like user behavior analysis and experience enhancement. Time-varying stroke gestures are selected as the primary focus because of their prevalence across various applications and their diverse patterns. The commonalities (e.g., features like velocity and curvature) between desktop and VR strokes allow the generation of additional dimensions (e.g., z vectors) in VR strokes. However, distribution shifts exist between different interaction environments (i.e., desktop vs. VR), and within the same interaction environment for different strokes by various users, making it challenging to build models capable of generalizing to unseen distributions. To address the challenges, we formulate the problem of generating VR strokes from desktop strokes as a conditional time series?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/10494175/,0,yuan2024generating,"Human-centered computing, Virtual reality"
2024,Education and Information Technologies,Humanoid robot-empowered language learning based on self-determination theory,"Ka Yan Fung, Lik Hang Lee, Kuen Fung Sin, Shenghui Song, Huamin Qu",Ka Yan Fung,English,"With the ability to provide feedback and assistance, humanoid educational robots have been proven effective in assisting students to overcome learning challenges and enhancing individual learning outcomes. However, the strength of humanoid robots in promoting social and emotional skills has not been well investigated. Socially supportive behaviour can contribute more to students’ learning engagement than knowledge transfer. This study focuses on the design of humanoid robots to engage students from functional and affective perspectives. To this end, a pilot test is conducted on 64 primary school students in Hong Kong, comprising a control group (N?=?33) and an experimental group (N?=?31). Questionnaires, observations, and language proficiency test are done to ensure the validity of the findings. The results show that the experimental group, which learned with the humanoid robots, significantly?…",Article,https://link.springer.com/article/10.1007/s10639-024-12570-w,0,fung2024humanoid,"Humanoid robots,Self-determination Theory (SDT),Human robot Interaction (HRI) , Robot-assisted, Engagement , Gesture, Mobility , Animacy"
2024,arXiv preprint arXiv:2403.04812,TrafPS: A Shapley-based Visual Analytics Approach to Interpret Traffic,"Zezheng Feng, Yifan Jiang, Hongjun Wang, Zipei Fan, Yuxin Ma, Shuang-Hua Yang, Huamin Qu, Xuan Song",Zezheng Feng,English,"Recent achievements in deep learning (DL) have shown its potential for predicting traffic flows. Such predictions are beneficial for understanding the situation and making decisions in traffic control. However, most state-of-the-art DL models are considered ""black boxes"" with little to no transparency for end users with respect to the underlying mechanisms. Some previous work tried to ""open the black boxes"" and increase the interpretability of how predictions are generated. However, it still remains challenging to handle complex models on large-scale spatio-temporal data and discover salient spatial and temporal patterns that significantly influence traffic flows. To overcome the challenges, we present TrafPS, a visual analytics approach for interpreting traffic prediction outcomes to support decision-making in traffic management and urban planning. The measurements, region SHAP and trajectory SHAP, are proposed to quantify the impact of flow patterns on urban traffic at different levels. Based on the task requirement from the domain experts, we employ an interactive visual interface for multi-aspect exploration and analysis of significant flow patterns. Two real-world case studies demonstrate the effectiveness of TrafPS in identifying key routes and decision-making support for urban planning.",Article,https://arxiv.org/abs/2403.04812,0,feng2024trafps,"Data Visualization, Model Interpretation, Urban Planning, Urban Visual Analytics"
2024,arXiv preprint arXiv:2403.03822,HoLens: A Visual Analytics Design for Higher-order Movement Modeling and Visualization,"Zezheng Feng, Fang Zhu, Hongjun Wang, Jianing Hao, ShuangHua Yang, Wei Zeng, Huamin Qu",Zezheng Feng,English,"Higher-order patterns reveal sequential multistep state transitions, which are usually superior to origin-destination analysis, which depicts only first-order geospatial movement patterns. Conventional methods for higher-order movement modeling first construct a directed acyclic graph (DAG) of movements, then extract higher-order patterns from the DAG. However, DAG-based methods heavily rely on the identification of movement keypoints that are challenging for sparse movements and fail to consider the temporal variants that are critical for movements in urban environments. To overcome the limitations, we propose HoLens, a novel approach for modeling and visualizing higher-order movement patterns in the context of an urban environment. HoLens mainly makes twofold contributions: first, we design an auto-adaptive movement aggregation algorithm that self-organizes movements hierarchically by considering spatial proximity, contextual information, and temporal variability; second, we develop an interactive visual analytics interface consisting of well-established visualization techniques, including the H-Flow for visualizing the higher-order patterns on the map and the higher-order state sequence chart for representing the higher-order state transitions. Two real-world case studies manifest that the method can adaptively aggregate the data and exhibit the process of how to explore the higher-order patterns by HoLens. We also demonstrate our approach's feasibility, usability, and effectiveness through an expert interview with three domain experts.",Article,https://arxiv.org/abs/2403.03822,0,feng2024holens,"Data Visualization, Movement Modeling, State Sequence Visualization, Movement Visualization, Urban Visual Analytics."
2024,IEEE Transactions on Visualization and Computer Graphics,VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality,"Wai Tong, Kento Shigyo, Lin-Ping Yuan, Mingming Fan, Ting-Chuen Pong, Huamin Qu, Meng Xia",Wai Tong,English,"With the rise of short-form video platforms and the increasing availability of data, we see the potential for people to share short-form videos embedded with data in situ (e.g., daily steps when running) to increase the credibility and expressiveness of their stories. However, creating and sharing such videos in situ is challenging since it involves multiple steps and skills (e.g., data visualization creation and video editing), especially for amateurs. By conducting a formative study (N=10) using three design probes, we collected the motivations and design requirements. We then built VisTellAR, a mobile AR authoring tool, to help amateur video creators embed data visualizations in short-form videos in situ. A two-day user study shows that participants (N=12) successfully created various videos with data visualizations in situ and they confirmed the ease of use and learning. AR pre-stage authoring was useful to assist people?…",Article,https://ieeexplore.ieee.org/abstract/document/10457053/,0,tong2024vistellar,"Personal data, augmented reality, data visualization, storytelling, short-form video"
2023,arXiv preprint arXiv:2312.14401,Towards an Exploratory Visual Analytics System for Griefer Identification in MOBA Games,"Zixin Chen, Shiyi Liu, Zhihua Jin, Gaoping Huang, Yang Chao, Zhenchuan Yang, Quan Li, Huamin Qu",Zixin Chen,English,"Multiplayer Online Battle Arenas (MOBAs) have gained a significant player base worldwide, generating over two billion US dollars in annual game revenue. However, the presence of griefers, who deliberately irritate and harass other players within the game, can have a detrimental impact on players' experience, compromising game fairness and potentially leading to the emergence of gray industries. Unfortunately, the absence of a standardized criterion, and the lack of high-quality labeled and annotated data has made it challenging to detect the presence of griefers. Given the complexity of the multivariant spatiotemporal data for MOBA games, game developers heavily rely on manual review of entire game video recordings to label and annotate griefers, which is a time-consuming process. To alleviate this issue, we have collaborated with a team of game specialists to develop an interactive visual analysis interface, called GrieferLens. It overviews players' behavior analysis and synthesizes their key match events. By presenting multiple views of information, GrieferLens can help the game design team efficiently recognize and label griefers in MOBA games and build up a foundation for creating a more enjoyable and fair gameplay environment.",Article,https://arxiv.org/abs/2312.14401,0,chen2023towards,"vocabulary learning, story generation, language models"
2023,US Patent App. 17/829,System and A Method for Analyzing A Video,"Xingbo Wang, Yong Wang, WU Aoyu, Huamin Qu",Xingbo Wang,English,"The invention relates to a computer implemented method and system for analyzing a video. The method comprises the steps of receiving, via a receiving module, a video data comprising a series of images showing a subject; extracting, via an extracting module, a transcript derived from an audio data associated with the video data; aligning, via an aligning module, the series of images of the video data with the transcript derived from the audio data associated with the video data based on timestamps derived from the video data; analyzing, via an analyzing module, gestures of the subject from the series of images, comprising the steps of: identifying a plurality of reference points from each of the series of images showing the subject; segmenting the series of images in accordance with one or more selected texts comprising the transcript; identifying a defined gesture type for each of the segmented images based on?…",Conference paper,https://patents.google.com/patent/US20230394884A1/en,0,wang2023system,None
2023,Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface?…,Knowledge Compass: A Question Answering System Guiding Students with Follow-Up Question Recommendations,"Rui Sheng, Leni Yang, Haotian Li, Yan Luo, Ziyang Xu, Zhilan Zhou, David Gotz, Huamin Qu",Rui Sheng,English," Pedagogical question-answering (QA) systems have been utilized for providing individual support in online learning courses. However, existing systems often neglect the education practice of guiding and encouraging students to think of relevant questions for deeper and more comprehensive learning. To address this gap, we introduce Knowledge Compass, an interactive QA system. The system can recommend follow-up questions that provide potential further explorations of the topics students ask about. Additionally, the system applies a course outline visualization and a set of interactive features for students to track the relationship between their questions and the course content.",Conference paper,https://dl.acm.org/doi/abs/10.1145/3586182.3615785,0,sheng2023knowledge,"Digital humanities, quantitative history, career mobility, visual analytics"
2023,2023 IEEE Visualization in Data Science (VDS),NeighViz: Towards Better Understanding of Neighborhood Effects on Social Groups with Spatial Data,"Yue Yu, Yifang Wang, Qisen Yang, Di Weng, Yongjun Zhang, Xiaogang Wu, Yingcai Wu, Huamin Qu",Yue Yu,English,"Understanding how local environments influence individual behaviors, such as voting patterns or suicidal tendencies, is crucial in social science to reveal and reduce spatial disparities and promote social well-being. With the increasing availability of large-scale individual-level census data, new analytical opportunities arise for social scientists to explore human behaviors (e.g., political engagement) among social groups at a fine-grained level. However, traditional statistical methods mostly focus on global, aggregated spatial correlations, which are limited to understanding and comparing the impact of local environments (e.g., neighborhoods) on human behaviors among social groups. In this study, we introduce a new analytical framework for analyzing multi-variate neighborhood effects between social groups. We then propose NeighViz, an interactive visual analytics system that helps social scientists explore?…",Conference paper,https://ieeexplore.ieee.org/abstract/document/10357756/,0,yu2023neighviz,"Online Learning, E-learning, Question Answering, Follow-up Ques- tion, Question Recommendation"
2023,Proceedings of the 16th International Symposium on Visual Information?…,NFTeller: Dual-centric Visual Analytics for Assessing Market Performance of NFT Collectibles,"Yifan Cao, Meng Xia, Kento Shigyo, Furui Cheng, Qianhang Yu, Xingxing Yang, Yang Wang, Wei Zeng, Huamin Qu",Yifan Cao,English," Non-fungible tokens (NFTs) have recently gained widespread popularity as an alternative investment. However, the lack of assessment criteria has caused intense volatility in NFT marketplaces. Identifying attributes impacting the market performance of NFT collectibles is crucial but challenging due to the massive amount of heterogeneous and multi-modal data in NFT transactions, e.g., social media texts, numerical trading data, and images. To address this challenge, we introduce an interactive dual-centric visual analytics system, NFTeller, to facilitate users’ analysis. First, we collaborate with five domain experts to distill static and dynamic impact attributes and collect relevant data. Next, we derive six analysis tasks and develop NFTeller to present the evolution of NFT transactions and correlate NFTs’ market performance with impact attributes. Notably, we create an augmented chord diagram with a radial stacked?…",Conference paper,https://dl.acm.org/doi/abs/10.1145/3615522.3615578,0,cao2023nfteller,"Machine Learning, Visualization, Crowdsourced, Visual Design, Image Quality Assessment"
2023,arXiv preprint arXiv:2307.09699,ActorLens: Visual Analytics for High-level Actor Identification in MOBA Games,"Zhihua Jin, Gaoping Huang, Zixin Chen, Shiyi Liu, Yang Chao, Zhenchuan Yang, Quan Li, Huamin Qu",Zhihua Jin,English,"Multiplayer Online Battle Arenas (MOBAs) have garnered a substantial player base worldwide. Nevertheless, the presence of noxious players, commonly referred to as ""actors"", can significantly compromise game fairness by exhibiting negative behaviors that diminish their team's competitive edge. Furthermore, high-level actors tend to engage in more egregious conduct to evade detection, thereby causing harm to the game community and necessitating their identification. To tackle this urgent concern, a partnership was formed with a team of game specialists from a prominent company to facilitate the identification and labeling of high-level actors in MOBA games. We first characterize the problem and abstract data and events from the game scene to formulate design requirements. Subsequently, ActorLens, a visual analytics system, was developed to exclude low-level actors, detect potential high-level actors, and assist users in labeling players. ActorLens furnishes an overview of players' status, summarizes behavioral patterns across three player cohorts (namely, focused players, historical matches of focused players, and matches of other players who played the same hero), and synthesizes key match events. By incorporating multiple views of information, users can proficiently recognize and label high-level actors in MOBA games. We conducted case studies and user studies to demonstrate the efficacy of the system.",Article,https://arxiv.org/abs/2307.09699,0,jin2023actorlens,"High-level Actors, MOBA Games, Visual Analytics"
2023,Proceedings of the AAAI Conference on Artificial Intelligence,"HAPI explorer: comprehension, discovery, and explanation on history of ML APIs","Lingjiao Chen, Zhihua Jin, Sabri Eyuboglu, Huamin Qu, Christopher Ré, Matei Zaharia, James Zou",Lingjiao Chen,English,"Machine learning prediction APIs offered by Google, Microsoft, Amazon, and many other providers have been continuously adopted in a plethora of applications, such as visual object detection, natural language comprehension, and speech recognition. Despite the importance of a systematic study and comparison of different APIs over time, this topic is currently under-explored because of the lack of data and user-friendly exploration tools. To address this issue, we present HAPI Explorer (History of API Explorer), an interactive system that offers easy access to millions of instances of commercial API applications collected in three years, prioritize attention on user-defined instance regimes, and explain interesting patterns across different APIs, subpopulations, and time periods via visual and natural languages. HAPI Explorer can facilitate further comprehension and exploitation of ML prediction APIs.",Article,https://ojs.aaai.org/index.php/AAAI/article/view/27064,0,chen2023hapi,None
2022,US Patent 11,System and method for visual analysis of emotional coherence in videos,"Haipeng Zeng, Xingbo Wang, WU Aoyu, Yong Wang, Quan Li, Huamin Qu",Haipeng Zeng,English,"A computer implemented method and system processing a video signal. The method comprises comprising the steps of: detecting a human face displayed in the video signal and extracting physiological, biological, or behavior state information from the displayed face at a first level of granularity of the video signal; processing any two or more of:(i) a script derived from or associated with the video signal to extract language tone information from said script at a first level of granularity of the script;(ii) an audio signal derived from or associated with the video signal to derive behavior state information from said audio signal at a first level of granularity of the audio signal;(iii) a video image derived from the video signal to detect one or more human gestures of the person whose face is displayed in the video signal; and merging said physiological, biological, or behavior state information extracted from the displayed face in?…",Conference paper,https://patents.google.com/patent/US11282297B2/en,0,zeng2022system,"Unsupervised Anomaly Detection, Skeleton- based Features, E-Exam Cheating Detection, Skeleton Similarity Measurement"
