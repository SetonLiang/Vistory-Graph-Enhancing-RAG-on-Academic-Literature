[{"Name": "Cycle-consistent inverse GAN for text-to-image synthesis", "Authors": ["Hao Wang", "Guosheng Lin", "Steven CH Hoi", "Chunyan Miao"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "This paper investigates an open research task of text-to-image synthesis for automatically generating or manipulating images from text descriptions. Prevailing methods mainly take the textual descriptions as the conditional input for the GAN generation, and need to train different models for the text-guided image generation and manipulation tasks. In this paper, we propose a novel unified framework of Cycle-consistent Inverse GAN (CI-GAN) for both text-to-image generation and text-guided image manipulation tasks. Specifically, we first train a GAN model without text input, aiming to generate images with high diversity and quality. Then we learn a GAN inversion model to convert the images back to the GAN latent space and obtain the inverted latent codes for each image, where we introduce the cycle-consistency training to learn more robust and consistent inverted latent codes. We further uncover the semantics of?\u2026", "IdName": "wang2021cycle", "Citation": "", "Keywords": ""}, {"Name": "Cross-modal food retrieval: learning a joint embedding of food images and recipes with semantic consistency and attention mechanism", "Authors": ["Hao Wang", "Doyen Sahoo", "Chenghao Liu", "Ke Shu", "Palakorn Achananuparp", "Ee-peng Lim", "Steven CH Hoi"], "Sources": "IEEE Transactions on Multimedia 24", "PublishedYears": "2021", "Doi": "", "Abstracts": "Food retrieval is an important task to perform analysis of food-related information, where we are interested in retrieving relevant information about the queried food item such as ingredients, cooking instructions, etc. In this paper, we investigate cross-modal retrieval between food images and cooking recipes. The goal is to learn an embedding of images and recipes in a common feature space, such that the corresponding image-recipe embeddings lie close to one another. Two major challenges in addressing this problem are 1) large intra-variance and small inter-variance across cross-modal food data; and 2) difficulties in obtaining discriminative recipe representations. To address these two problems, we propose Semantic-Consistent and Attention-based Networks (SCAN), which regularize the embeddings of the two modalities through aligning output semantic probabilities. Besides, we exploit a self-attention?\u2026", "IdName": "wang2021cross", "Citation": "", "Keywords": ""}, {"Name": "Structure-aware generation network for recipe generation from images", "Authors": ["Hao Wang", "Guosheng Lin", "Steven CH Hoi", "Chunyan Miao"], "Sources": "Computer Vision\u2013ECCV 2020: 16th European Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": " Sharing food has become very popular with the development of social media. For many real-world applications, people are keen to know the underlying recipes of a food item. In this paper, we are interested in automatically generating cooking instructions for food. We investigate an open research task of generating cooking instructions based on only food images and ingredients, which is similar to the image captioning task. However, compared with image captioning datasets, the target recipes are long-length paragraphs and do not have annotations on structure information. To address the above limitations, we propose a novel framework of Structure-aware Generation Network (SGN) to tackle the food recipe generation task. Our approach brings together several novel ideas in a systematic framework: (1) exploiting an unsupervised learning approach to obtain the sentence-level tree structure labels?\u2026", "IdName": "wang2020structure", "Citation": "", "Keywords": ""}, {"Name": "Learning structural representations for recipe generation and food retrieval", "Authors": ["Hao Wang", "Guosheng Lin", "Steven CH Hoi", "Chunyan Miao"], "Sources": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "PublishedYears": "2022", "Doi": "", "Abstracts": "Food is significant to human daily life. In this paper, we are interested in learning structural representations for lengthy recipes, that can benefit the recipe generation and food cross-modal retrieval tasks. Different from the common vision-language data, here the food images contain mixed ingredients and target recipes are lengthy paragraphs, where we do not have annotations on structure information. To address the above limitations, we propose a novel method to unsupervisedly learn the sentence-level tree structures for the cooking recipes. Our approach brings together several novel ideas in a systematic framework: (1) exploiting an unsupervised learning approach to obtain the sentence-level tree structure labels before training; (2) generating trees of target recipes from images with the supervision of tree structure labels learned from (1); and (3) integrating the learned tree structures into the recipe generation?\u2026", "IdName": "wang2022learning", "Citation": "", "Keywords": ""}, {"Name": "Llm-based agent society investigation: Collaboration and confrontation in avalon gameplay", "Authors": ["Yihuai Lan", "Zhiqiang Hu", "Lei Wang", "Yang Wang", "Deheng Ye", "Peilin Zhao", "Ee-Peng Lim", "Hui Xiong", "Hao Wang"], "Sources": "arXiv preprint arXiv:2310.14985", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper aims to investigate the open research problem of uncovering the social behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a representative communication game, as the environment and use system prompts to guide LLM agents to play the game. While previous studies have conducted preliminary investigations into gameplay with LLM agents, there lacks research on their social behaviors. In this paper, we present a novel framework designed to seamlessly adapt to Avalon gameplay. The core of our proposed framework is a multi-agent system that enables efficient communication and interaction among agents. We evaluate the performance of our framework based on metrics from two perspectives: winning the game and analyzing the social behaviors of LLM agents. Our results demonstrate the effectiveness of our framework in generating adaptive and intelligent agents and highlight the potential of LLM-based agents in addressing the challenges associated with dynamic social environment interaction. By analyzing the social behaviors of LLM agents from the aspects of both collaboration and confrontation, we provide insights into the research and applications of this domain.", "IdName": "lan2023llm", "Citation": "", "Keywords": ""}, {"Name": "TAPS3D: Text-Guided 3D Textured Shape Generation from Pseudo Supervision", "Authors": ["Jiacheng Wei*", "Hao Wang*", "Jiashi Feng", "Guosheng Lin", "Kim-Hui Yap"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "In this paper, we investigate an open research task of generating controllable 3D textured shapes from the given textual descriptions. Previous works either require ground truth caption labeling or extensive optimization time. To resolve these issues, we present a novel framework, TAPS3D, to train a text-guided 3D shape generator with pseudo captions. Specifically, based on rendered 2D images, we retrieve relevant words from the CLIP vocabulary and construct pseudo captions using templates. Our constructed captions provide high-level semantic supervision for generated 3D shapes. Further, in order to produce fine-grained textures and increase geometry diversity, we propose to adopt low-level image regularization to enable fake-rendered images to align with the real ones. During the inference phase, our proposed model can generate 3D textured shapes from the given text without any additional optimization. We conduct extensive experiments to analyze each of our proposed components and show the efficacy of our framework in generating high-fidelity 3D textured and text-relevant shapes.", "IdName": "wei2023taps3d", "Citation": "", "Keywords": ""}, {"Name": "Paired cross-modal data augmentation for fine-grained image-to-text retrieval", "Authors": ["Hao Wang", "Guosheng Lin", "Steven Hoi", "Chunyan Miao"], "Sources": "Proceedings of the 30th ACM International Conference on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "This paper investigates an open research problem of generating text-image pairs to improve the training of fine-grained image-to-text cross-modal retrieval task, and proposes a novel framework for paired data augmentation by uncovering the hidden semantic information of StyleGAN2 model. Specifically, we first train a StyleGAN2 model on the given dataset. We then project the real images back to the latent space of StyleGAN2 to obtain the latent codes. To make the generated images manipulatable, we further introduce a latent space alignment module to learn the alignment between StyleGAN2 latent codes and the corresponding textual caption features. When we do online paired data augmentation, we first generate augmented text through random token replacement, then pass the augmented text into the latent space alignment module to output the latent codes, which are finally fed to StyleGAN2 to generate?\u2026", "IdName": "wang2022paired", "Citation": "", "Keywords": ""}, {"Name": "Cross-modal graph with meta concepts for video captioning", "Authors": ["Hao Wang", "Guosheng Lin", "Steven CH Hoi", "Chunyan Miao"], "Sources": "IEEE Transactions on Image Processing 31", "PublishedYears": "2022", "Doi": "", "Abstracts": "Video captioning targets interpreting the complex visual contents as text descriptions, which requires the model to fully understand video scenes including objects and their interactions. Prevailing methods adopt off-the-shelf object detection networks to give object proposals and use the attention mechanism to model the relations between objects. They often miss some undefined semantic concepts of the pretrained model and fail to identify exact predicate relationships between objects. In this paper, we investigate an open research task of generating text descriptions for the given videos, and propose Cross-Modal Graph (CMG) with meta concepts for video captioning. Specifically, to cover the useful semantic concepts in video captions, we weakly learn the corresponding visual regions for text descriptions, where the associated visual regions and textual words are named cross-modal meta concepts. We further?\u2026", "IdName": "wang2022cross", "Citation": "", "Keywords": ""}, {"Name": "Decomposing generation networks with structure prediction for recipe generation", "Authors": ["Hao Wang", "Guosheng Lin", "Steven CH Hoi", "Chunyan Miao"], "Sources": "Pattern Recognition 126", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recipe generation from food images and ingredients is a challenging task, which requires the interpretation of the information from another modality. Different from the image captioning task, where the captions usually have one sentence, cooking instructions contain multiple sentences and have obvious structures. To help the model capture the recipe structure and avoid missing some cooking details, we propose a novel framework: Decomposing Generation Networks (DGN) with structure prediction, to get more structured and complete recipe generation outputs. Specifically, we split each cooking instruction into several phases, and assign different sub-generators to each phase. Our approach includes two novel ideas: (i) learning the recipe structures with the global structure prediction component and (ii) producing recipe phases in the sub-generator output component based on the predicted structure. Extensive?\u2026", "IdName": "wang2022decomposing", "Citation": "", "Keywords": ""}, {"Name": "Maniclip: Multi-attribute face manipulation from text", "Authors": ["Hao Wang", "Guosheng Lin", "Ana Garc\u00eda del Molino", "Anran Wang", "Jiashi Feng", "Zhiqi Shen"], "Sources": "International Journal of Computer Vision", "PublishedYears": "2024", "Doi": "", "Abstracts": "In this paper we present a novel multi-attribute face manipulation method based on textual descriptions. Previous text-based image editing methods either require test-time optimization for each individual image or are restricted to single attribute editing. Extending these methods to multi-attribute face image editing scenarios will introduce undesired excessive attribute change, eg, text-relevant attributes are overly manipulated and text-irrelevant attributes are also changed. In order to address these challenges and achieve natural editing over multiple face attributes, we propose a new decoupling training scheme where we use group sampling to get text segments from same attribute categories, instead of whole complex sentences. Further, to preserve other existing face attributes, we encourage the model to edit the latent code of each attribute separately via an entropy constraint. During the inference phase, our?\u2026", "IdName": "wang2024maniclip", "Citation": "", "Keywords": ""}, {"Name": "3D cartoon face generation with controllable expressions from a single GAN image", "Authors": ["Hao Wang", "Guosheng Lin", "Steven CH Hoi", "Chunyan Miao"], "Sources": "arXiv preprint arXiv:2207.14425", "PublishedYears": "2022", "Doi": "", "Abstracts": "In this paper, we investigate an open research task of generating 3D cartoon face shapes from single 2D GAN generated human faces and without 3D supervision, where we can also manipulate the facial expressions of the 3D shapes. To this end, we discover the semantic meanings of StyleGAN latent space, such that we are able to produce face images of various expressions, poses, and lighting by controlling the latent codes. Specifically, we first finetune the pretrained StyleGAN face model on the cartoon datasets. By feeding the same latent codes to face and cartoon generation models, we aim to realize the translation from 2D human face images to cartoon styled avatars. We then discover semantic directions of the GAN latent space, in an attempt to change the facial expressions while preserving the original identity. As we do not have any 3D annotations for cartoon faces, we manipulate the latent codes to generate images with different poses and lighting, such that we can reconstruct the 3D cartoon face shapes. We validate the efficacy of our method on three cartoon datasets qualitatively and quantitatively.", "IdName": "wang20223d", "Citation": "", "Keywords": ""}, {"Name": "Learning Temporal Variations for 4D Point Cloud Segmentation", "Authors": ["Hanyu Shi", "Jiacheng Wei", "Hao Wang", "Fayao Liu", "Guosheng Lin"], "Sources": "International Journal of Computer Vision", "PublishedYears": "2024", "Doi": "", "Abstracts": "LiDAR-based 3D scene perception is a fundamental and important task for autonomous driving. Most state-of-the-art methods on LiDAR-based 3D recognition tasks focus on single-frame 3D point cloud data, ignoring temporal information. We argue that the temporal information across the frames provides crucial knowledge for 3D scene perceptions, especially in the driving scenario. In this paper, we focus on spatial and temporal variations to better explore temporal information across 3D frames. We design a temporal variation-aware interpolation module and a temporal voxel-point refinement module to capture the temporal variation in the 4D point cloud. The temporal variation-aware interpolation generates local features from the previous and current frames by capturing spatial coherence and temporal variation information. The temporal voxel-point refinement module builds a temporal graph on the 3D point?\u2026", "IdName": "shi2024learning", "Citation": "", "Keywords": ""}, {"Name": "Smart decision-support system for pig farming", "Authors": ["Hao Wang", "Boyang Li", "Haoming Zhong", "Ahong Xu", "Yingjie Huang", "Jingfu Zou", "Yuanyuan Chen", "Pengcheng Wu", "Yiqiang Chen", "Cyril Leung", "Chunyan Miao"], "Sources": "Drones", "PublishedYears": "2022", "Doi": "", "Abstracts": "There are multiple participants, such as farmers, wholesalers, retailers, financial institutions, etc., involved in the modern food production process. All of these participants and stakeholders have a shared goal, which is to gather information on the food production process so that they can make appropriate decisions to increase productivity and reduce risks. However, real-time data collection and analysis continue to be difficult tasks, particularly in developing nations, where agriculture is the primary source of income for the majority of the population. In this paper, we present a smart decision-support system for pig farming. Specifically, we first adopt rail-based unmanned vehicles to capture pigsty images. We then conduct image stitching to avoid double-counting pigs so that we can use image segmentation method to give precise masks for each pig. Based on the segmentation masks, the pig weights can be estimated, and data can be integrated in our developed mobile app. The proposed system enables the above participants and stakeholders to have real-time data and intelligent analysis reports to help their decision-making.", "IdName": "wang2022smart", "Citation": "", "Keywords": ""}, {"Name": "BrainVis: Exploring the Bridge between Brain and Visual Signals via Image Reconstruction", "Authors": ["Honghao Fu", "Zhiqi Shen", "Jing Jih Chin", "Hao Wang"], "Sources": "arXiv preprint arXiv:2312.14871", "PublishedYears": "2023", "Doi": "", "Abstracts": "Analyzing and reconstructing visual stimuli from brain signals effectively advances understanding of the human visual system. However, the EEG signals are complex and contain a amount of noise. This leads to substantial limitations in existing works of visual stimuli reconstruction from EEG, such as difficulties in aligning EEG embeddings with the fine-grained semantic information and a heavy reliance on additional large self-collected dataset for training. To address these challenges, we propose a novel approach called BrainVis. Firstly, we divide the EEG signals into various units and apply a self-supervised approach on them to obtain EEG time-domain features, in an attempt to ease the training difficulty. Additionally, we also propose to utilize the frequency-domain features to enhance the EEG representations. Then, we simultaneously align EEG time-frequency embeddings with the interpolation of the coarse and fine-grained semantics in the CLIP space, to highlight the primary visual components and reduce the cross-modal alignment difficulty. Finally, we adopt the cascaded diffusion models to reconstruct images. Our proposed BrainVis outperforms state of the arts in both semantic fidelity reconstruction and generation quality. Notably, we reduce the training data scale to 10% of the previous work.", "IdName": "fu2023brainvis", "Citation": "", "Keywords": ""}, {"Name": "OSPC: Detecting Harmful Memes with Large Language Model as a Catalyst", "Authors": ["Jingtao Cao", "Zheng Zhang", "Hongru Wang", "Bin Liang", "Hao Wang", "Kam-Fai Wong"], "Sources": "arXiv preprint arXiv:2406.09779", "PublishedYears": "2024", "Doi": "", "Abstracts": "Memes, which rapidly disseminate personal opinions and positions across the internet, also pose significant challenges in propagating social bias and prejudice. This study presents a novel approach to detecting harmful memes, particularly within the multicultural and multilingual context of Singapore. Our methodology integrates image captioning, Optical Character Recognition (OCR), and Large Language Model (LLM) analysis to comprehensively understand and classify harmful memes. Utilizing the BLIP model for image captioning, PP-OCR and TrOCR for text recognition across multiple languages, and the Qwen LLM for nuanced language understanding, our system is capable of identifying harmful content in memes created in English, Chinese, Malay, and Tamil. To enhance the system's performance, we fine-tuned our approach by leveraging additional data labeled using GPT-4V, aiming to distill the understanding capability of GPT-4V for harmful memes to our system. Our framework achieves top-1 at the public leaderboard of the Online Safety Prize Challenge hosted by AI Singapore, with the AUROC as 0.7749 and accuracy as 0.7087, significantly ahead of the other teams. Notably, our approach outperforms previous benchmarks, with FLAVA achieving an AUROC of 0.5695 and VisualBERT an AUROC of 0.5561.", "IdName": "cao2024ospc", "Citation": "", "Keywords": ""}, {"Name": "COM3D: Leveraging Cross-View Correspondence and Cross-Modal Mining for 3D Retrieval", "Authors": ["Hao Wu", "Ruochong LI", "Hao Wang", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2405.04103", "PublishedYears": "2024", "Doi": "", "Abstracts": "In this paper, we investigate an open research task of cross-modal retrieval between 3D shapes and textual descriptions. Previous approaches mainly rely on point cloud encoders for feature extraction, which may ignore key inherent features of 3D shapes, including depth, spatial hierarchy, geometric continuity, etc. To address this issue, we propose COM3D, making the first attempt to exploit the cross-view correspondence and cross-modal mining to enhance the retrieval performance. Notably, we augment the 3D features through a scene representation transformer, to generate cross-view correspondence features of 3D shapes, which enrich the inherent features and enhance their compatibility with text matching. Furthermore, we propose to optimize the cross-modal matching process based on the semi-hard negative example mining method, in an attempt to improve the learning efficiency. Extensive quantitative and qualitative experiments demonstrate the superiority of our proposed COM3D, achieving state-of-the-art results on the Text2Shape dataset.", "IdName": "wu2024com3d", "Citation": "", "Keywords": ""}, {"Name": "PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models", "Authors": ["Jinyi Li", "Yihuai Lan", "Lei Wang", "Hao Wang"], "Sources": "arXiv preprint arXiv:2403.17411", "PublishedYears": "2024", "Doi": "", "Abstracts": "Prompt compression is an innovative method for efficiently condensing input prompts while preserving essential information. To facilitate quick-start services, user-friendly interfaces, and compatibility with common datasets and metrics, we present the Prompt Compression Toolkit (PCToolkit). This toolkit is a unified plug-and-play solution for compressing prompts in Large Language Models (LLMs), featuring cutting-edge prompt compressors, diverse datasets, and metrics for comprehensive performance evaluation. PCToolkit boasts a modular design, allowing for easy integration of new datasets and metrics through portable and user-friendly interfaces. In this paper, we outline the key components and functionalities of PCToolkit. We conducted evaluations of the compressors within PCToolkit across various natural language tasks, including reconstruction, summarization, mathematical problem-solving, question answering, few-shot learning, synthetic tasks, code completion, boolean expressions, multiple choice questions, and lies recognition.", "IdName": "li2024pctoolkit", "Citation": "", "Keywords": ""}, {"Name": "All in a Single Image: Large Multimodal Models are In-Image Learners", "Authors": ["Lei Wang", "Wanyu Xu", "Zhiqiang Hu", "Yihuai Lan", "Shan Dong", "Hao Wang", "Roy Ka-Wei Lee", "Ee-Peng Lim"], "Sources": "arXiv preprint arXiv:2402.17971", "PublishedYears": "2024", "Doi": "", "Abstracts": "This paper introduces a new in-context learning (ICL) mechanism called In-Image Learning (IL) that combines demonstration examples, visual cues, and instructions into a single image to enhance the capabilities of GPT-4V. Unlike previous approaches that rely on converting images to text or incorporating visual input into language models, IL consolidates all information into one image and primarily leverages image processing, understanding, and reasoning abilities. This has several advantages: it avoids inaccurate textual descriptions of complex images, provides flexibility in positioning demonstration examples, reduces the input burden, and avoids exceeding input limits by eliminating the need for multiple images and lengthy text. To further combine the strengths of different ICL methods, we introduce an automatic strategy to select the appropriate ICL method for a data example in a given task. We conducted experiments on MathVista and Hallusionbench to test the effectiveness of IL in complex multimodal reasoning tasks and mitigating language hallucination and visual illusion. Additionally, we explored the impact of image resolution, the number of demonstration examples, and their positions on the effectiveness of IL. Our code is publicly available at https://github.com/AGI-Edgerunners/IIL.", "IdName": "wang2024all", "Citation": "", "Keywords": ""}, {"Name": "The Garden of Forking Paths: Towards Multi-Future Trajectory Prediction", "Authors": ["Junwei Liang", "Lu Jiang", "Kevin Murphy", "Ting Yu", "Alexander Hauptmann"], "Sources": "CVPR", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper studies the problem of predicting the distribution over multiple possible future paths of people as they move through various visual scenes. We make two main contributions. The first contribution is a new dataset, created in a realistic 3D simulator, which is based on real world trajectory data, and then extrapolated by human annotators to achieve different latent goals. This provides the first benchmark for quantitative evaluation of the models to predict multi-future trajectories. The second contribution is a new model to generate multiple plausible future trajectories, which contains novel designs of using multi-scale location encodings and convolutional RNNs over graphs. We refer to our model as Multiverse. We show that our model achieves the best results on our dataset, as well as on the real-world VIRAT/ActEV dataset (which just contains one possible future).", "IdName": "liang2020garden", "Citation": "", "Keywords": ""}, {"Name": "Simaug: Learning robust representations from simulation for trajectory prediction", "Authors": ["Junwei Liang", "Lu Jiang", "Alexander Hauptmann"], "Sources": "ECCV", "PublishedYears": "2020", "Doi": "", "Abstracts": " This paper studies the problem of predicting future trajectories of people in unseen cameras of novel scenarios and views. We approach this problem through the real-data-free setting in which the model is trained only on 3D simulation data and applied out-of-the-box to a wide variety of real cameras. We propose a novel approach to learn robust representation through augmenting the simulation training data such that the representation can better generalize to unseen real-world test data. The key idea is to mix the feature of the hardest camera view with the adversarial feature of the original view. We refer to our method as SimAug. We show that SimAug achieves promising results on three real-world benchmarks using zero real training data, and state-of-the-art performance in the Stanford Drone and the VIRAT/ActEV dataset when using in-domain training data. Code and models are released at?\u2026", "IdName": "liang2020simaug", "Citation": "", "Keywords": ""}, {"Name": "MSNet: A Multilevel Instance Segmentation Network for Natural Disaster Damage Assessment in Aerial Videos", "Authors": ["Xiaoyu Zhu", "Junwei Liang", "Alexander Hauptmann"], "Sources": "WACV", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, we study the problem of efficiently assessing building damage after natural disasters like hurricanes, floods or fires, through aerial video analysis. We make two main contributions. The first contribution is a new dataset, consisting of user-generated aerial videos from social media with annotations of instance-level building damage masks. This provides the first benchmark for quantitative evaluation of models to assess building damage using aerial videos. The second contribution is a new model, namely MSNet, which contains novel region proposal network designs and an unsupervised score refinement network for confidence score calibration in both bounding box and mask branches. We show that our model achieves state-of-the-art results compared to previous methods in our dataset.", "IdName": "zhu2021msnet", "Citation": "", "Keywords": ""}, {"Name": "Argus: Efficient activity detection system for extended video analysis", "Authors": ["Wenhe Liu", "Guoliang Kang", "Po-Yao Huang", "Xiaojun Chang", "Yijun Qian", "Junwei Liang", "Liangke Gui", "Jing Wen", "Peng Chen"], "Sources": "WACVW", "PublishedYears": "2020", "Doi": "", "Abstracts": "We propose an Efficient Activity Detection System, Argus, for Extended Video Analysis in the surveillance scenario. For the spatial-temporal event detection in the surveillance video, we first generate video proposals by applying object detection and tracking algorithm which shared the detection features. After that, we extract several different features and apply sequential activity classification with them. Finally, we eliminate inaccurate events and fuse all the predictions from different features. The proposed system wins Trecvid Activities in Extended Video (ActEV) challenge 2019. It achieves the first place with 60.5 mean weighted Pmiss, out-performing the second place system by 14.5 and the baseline R-C3D by 29.0. In TRECVID 2019 Challenge, the proposed system wins the first place with pAUDC@ 0.2 tfa 0.48407", "IdName": "liu2020argus", "Citation": "", "Keywords": ""}, {"Name": "SoccerNet 2022 Challenges Results", "Authors": ["Silvio Giancola", "Anthony Cioppa", "Adrien Deli\u00e8ge", "Floriane Magera", "Vladimir Somers", "Le Kang", "Xin Zhou", "Olivier Barnich", "Christophe De Vleeschouwer", "Alexandre Alahi", "Bernard Ghanem", "Marc Van Droogenbroeck", "Abdulrahman Darwish", "Adrien Maglo", "Albert Clap\u00e9s", "Andreas Luyts", "Andrei Boiarov", "Artur Xarles", "Astrid Orcesi", "Avijit Shah", "Baoyu Fan", "Bharath Comandur", "Chen Chen", "Chen Zhang", "Chen Zhao", "Chengzhi Lin", "Cheuk-Yiu Chan", "Chun Chuen Hui", "Dengjie Li", "Fan Yang", "Fan Liang", "Fang Da", "Feng Yan", "Fufu Yu", "Guanshuo Wang", "H Anthony Chan", "He Zhu", "Hongwei Kan", "Jiaming Chu", "Jianming Hu", "Jianyang Gu", "Jin Chen", "Jo?o VB Soares", "Jonas Theiner", "Jorge De Corte", "Jos\u00e9 Henrique Brito", "Jun Zhang", "Junjie Li", "Junwei Liang", "Leqi Shen", "Lin Ma", "Lingchi Chen", "Miguel Santos Marques", "Mike Azatov", "Nikita Kasatkin", "Ning Wang", "Qiong Jia", "Quoc Cuong Pham", "Ralph Ewerth", "Ran Song", "Rengang Li", "Rikke Gade", "Ruben Debien", "Runze Zhang", "Sangrok Lee", "Sergio Escalera"], "Sources": "Proceedings of the 5th International ACM Workshop on Multimedia Content?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The SoccerNet 2022 challenges were the second annual video understanding challenges organized by the SoccerNet team. In 2022, the challenges were composed of 6 vision-based tasks: (1) action spotting, focusing on retrieving action timestamps in long untrimmed videos, (2) replay grounding, focusing on retrieving the live moment of an action shown in a replay, (3) pitch localization, focusing on detecting line and goal part elements, (4) camera calibration, dedicated to retrieving the intrinsic and extrinsic camera parameters, (5) player re-identification, focusing on retrieving the same players across multiple views, and (6) multiple object tracking, focusing on tracking players and the ball through unedited video streams. Compared to last year's challenges, tasks (1-2) had their evaluation metrics redefined to consider tighter temporal accuracies, and tasks (3-6) were novel, including their underlying data and?\u2026", "IdName": "giancola2022soccernet", "Citation": "", "Keywords": ""}, {"Name": "Stargazer: A transformer-based driver action detection system for intelligent transportation", "Authors": ["Junwei Liang", "He Zhu", "Enwei Zhang", "Jun Zhang"], "Sources": "CVPRW", "PublishedYears": "2022", "Doi": "", "Abstracts": "Distracted driver actions can be dangerous and cause severe accidents. Thus, it is important to detect and eliminate distracted driving behaviors on the road to save lives. To this end, we study driver action detection using videos captured inside the vehicle. We propose Stargazer, an efficient, transformer-based system exploiting rich temporal features about the human behavioral information, with a simple yet effective action temporal localization framework. The core of our system contains an improved version of the multi-scale vision transformer network, which learns a hierarchy of robust representations. We then use a sliding-window classification strategy to facilitate temporal localization of actions-of-interest. The proposed system wins the second place in the Naturalistic Driving Action Recognition of AI City Challenge 2022 (Track 3). The code and models are released.", "IdName": "liang2022stargazer", "Citation": "", "Keywords": ""}, {"Name": "A transformer-based system for action spotting in soccer videos", "Authors": ["He Zhu", "Junwei Liang", "Chengzhi Lin", "Jun Zhang", "Jianming Hu"], "Sources": "Proceedings of the 5th international acm workshop on multimedia content?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Action Spotting in the broadcast soccer game is important to understand salient actions and video summary applications. In this paper, we propose an efficient transformer-based system for action spotting in soccer videos. We first use the multi-scale vision transformer to extract features from the videos. Then we adopt a sliding window strategy to further utilize temporal features and enhanced temporal understanding. Finally, the features are input to NetVLAD++ model to obtain the final results. Our model can learn a hierarchy of robust representations and perform well in the Action Spotting Task of SoccerNet Challenge 2022. Our method achieves excellent results and outperforms the baseline and previous published works.", "IdName": "zhu2022transformer", "Citation": "", "Keywords": ""}, {"Name": "Weakly Supervised 3D Semantic Segmentation Using Cross-Image Consensus and Inter-Voxel Affinity Relations", "Authors": ["Xiaoyu Zhu", "Jeffrey Chen", "Xiangrui Zeng", "Junwei Liang", "Chengqi Li", "Sinuo Liu", "Sima Behpour", "Min Xu"], "Sources": "ICCV", "PublishedYears": "2021", "Doi": "", "Abstracts": "We propose a novel weakly supervised approach for 3D semantic segmentation on volumetric images. Unlike most existing methods that require voxel-wise densely labeled training data, our weakly-supervised CIVA-Net is the first model that only needs image-level class labels as guidance to learn accurate volumetric segmentation. Our model learns from cross-image co-occurrence for integral region generation, and explores inter-voxel affinity relations to predict segmentation with accurate boundaries. We empirically validate our model on both simulated and real cryo-ET datasets. Our experiments show that CIVA-Net achieves comparable performance to the state-of-the-art models trained with stronger supervision.", "IdName": "zhu2021weakly", "Citation": "", "Keywords": ""}, {"Name": "Text-Adaptive Multiple Visual Prototype Matching for Video-Text Retrieval", "Authors": ["Chengzhi Lin", "Ancong Wu", "Junwei Liang", "Jun Zhang", "Wenhang Ge", "Wei-Shi Zheng", "Chunhua Shen"], "Sources": "NeurIPS", "PublishedYears": "2022", "Doi": "", "Abstracts": "Cross-modal retrieval between videos and texts has gained increasing interest because of the rapid emergence of videos on the web. Generally, a video contains rich instance and event information and the query text only describes a part of the information. Thus, a video can have multiple different text descriptions and queries. We call it the Video-Text Correspondence Ambiguity problem. Current techniques mostly concentrate on mining local or multi-level alignment between contents of video and text (eg, object to entity and action to verb). It is difficult for these methods to alleviate video-text correspondence ambiguity by describing a video using only one feature, which is required to be matched with multiple different text features at the same time. To address this problem, we propose a Text-Adaptive Multiple Visual Prototype Matching Model. It automatically captures multiple prototypes to describe a video by adaptive aggregation on video token features. Given a query text, the similarity is determined by the most similar prototype to find correspondence in the video, which is called text-adaptive matching. To learn diverse prototypes for representing the rich information in videos, we propose a variance loss to encourage different prototypes to attend to different contents of the video. Our method outperforms the state-of-the-art methods on four public video retrieval datasets.", "IdName": "lin2022text", "Citation": "", "Keywords": ""}, {"Name": "STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition", "Authors": ["Xiaoyu Zhu", "Po-Yao Huang", "Junwei Liang", "Celso M de Melo", "Alexander G Hauptmann"], "Sources": "CVPR", "PublishedYears": "2023", "Doi": "", "Abstracts": "We study the problem of human action recognition using motion capture (MoCap) sequences. Unlike existing techniques that take multiple manual steps to derive standardized skeleton representations as model input, we propose a novel Spatial-Temporal Mesh Transformer (STMT) to directly model the mesh sequences. The model uses a hierarchical transformer with intra-frame off-set attention and inter-frame self-attention. The attention mechanism allows the model to freely attend between any two vertex patches to learn non-local relationships in the spatial-temporal domain. Masked vertex modeling and future frame prediction are used as two self-supervised tasks to fully activate the bi-directional and auto-regressive attention in our hierarchical transformer. The proposed method achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is available at https://github. com/zgzxy001/STMT.", "IdName": "zhu2023stmt", "Citation": "", "Keywords": ""}, {"Name": "Multi-dataset Training of Transformers for Robust Action Recognition", "Authors": ["Junwei Liang", "Enwei Zhang", "Jun Zhang", "Chunhua Shen"], "Sources": "NeurIPS", "PublishedYears": "2022", "Doi": "", "Abstracts": "We study the task of robust feature representations, aiming to generalize well on multiple datasets for action recognition. We build our method on Transformers for its efficacy. Although we have witnessed great progress for video action recognition in the past decade, it remains challenging yet valuable how to train a single model that can perform well across multiple datasets. Here, we propose a novel multi-dataset training paradigm, MultiTrain, with the design of two new loss terms, namely informative loss and projection loss, aiming tolearn robust representations for action recognition. In particular, the informative loss maximizes the expressiveness of the feature embedding while the projection loss for each dataset mines the intrinsic relations between classes across datasets. We verify the effectiveness of our method on five challenging datasets, Kinetics-400, Kinetics-700, Moments-in-Time, Activitynet and Something-something-v2 datasets. Extensive experimental results show that our method can consistently improve state-of-the-art performance. Code and models are released.", "IdName": "liang2022multi", "Citation": "", "Keywords": ""}, {"Name": "PatchMixer: A Patch-Mixing Architecture for Long-Term Time Series Forecasting", "Authors": ["Zeying Gong", "Yujin Tang", "Junwei Liang"], "Sources": "IJCAI Workshop", "PublishedYears": "2024", "Doi": "", "Abstracts": "Although the Transformer has been the dominant architecture for time series forecasting tasks in recent years, a fundamental challenge remains: the permutation-invariant self-attention mechanism within Transformers leads to a loss of temporal information. To tackle these challenges, we propose PatchMixer, a novel CNN-based model. It introduces a permutation-variant convolutional structure to preserve temporal information. Diverging from conventional CNNs in this field, which often employ multiple scales or numerous branches, our method relies exclusively on depthwise separable convolutions. This allows us to extract both local features and global correlations using a single-scale architecture. Furthermore, we employ dual forecasting heads that encompass both linear and nonlinear components to better model future curve trends and details. Our experimental results on seven time-series forecasting benchmarks indicate that compared with the state-of-the-art method and the best-performing CNN, PatchMixer yields  and  relative improvements, respectively, while being 2-3x faster than the most advanced method. We will release our code and model.", "IdName": "gong2023patchmixer", "Citation": "", "Keywords": ""}, {"Name": "Spatial-temporal alignment network for action recognition and detection", "Authors": ["Junwei Liang", "Liangliang Cao", "Xuehan Xiong", "Ting Yu", "Alexander Hauptmann"], "Sources": "arXiv preprint arXiv:2012.02426", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper studies how to introduce viewpoint-invariant feature representations that can help action recognition and detection. Although we have witnessed great progress of action recognition in the past decade, it remains challenging yet interesting how to efficiently model the geometric variations in large scale datasets. This paper proposes a novel Spatial-Temporal Alignment Network (STAN) that aims to learn geometric invariant representations for action recognition and action detection. The STAN model is very light-weighted and generic, which could be plugged into existing action recognition models like ResNet3D and the SlowFast with a very low extra computational cost. We test our STAN model extensively on AVA, Kinetics-400, AVA-Kinetics, Charades, and Charades-Ego datasets. The experimental results show that the STAN model can consistently improve the state of the arts in both action detection and action recognition tasks. We will release our data, models and code.", "IdName": "liang2020spatial", "Citation": "", "Keywords": ""}, {"Name": "VMRNN: Integrating Vision Mamba and LSTM for Efficient and Accurate Spatiotemporal Forecasting", "Authors": ["Yujin Tang", "Peijie Dong", "Zhenheng Tang", "Xiaowen Chu", "Junwei Liang"], "Sources": "CVPR Workshop 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Combining Convolutional Neural Networks (CNNs) or Vision Transformers (ViTs) with Recurrent Neural Networks (RNNs) for spatiotemporal forecasting has yielded unparalleled results in predicting temporal and spatial dynamics. However modeling extensive global information remains a formidable challenge; CNNs are limited by their narrow receptive fields and ViTs struggle with the intensive computational demands of their attention mechanisms. The emergence of recent Mamba-based architectures has been met with enthusiasm for their exceptional long-sequence modeling capabilities surpassing established vision models in efficiency and accuracy which motivates us to develop an innovative architecture tailored for spatiotemporal forecasting. In this paper we propose the VMRNN cell a new recurrent unit that integrates the strengths of Vision Mamba blocks with LSTM. We construct a network centered on VMRNN cells to tackle spatiotemporal prediction tasks effectively. Our extensive evaluations show that our proposed approach secures competitive results on a variety of tasks while maintaining a smaller model size. Our code is available at https://github. com/yyyujintang/VMRNN-PyTorch.", "IdName": "tang2024vmrnn", "Citation": "", "Keywords": ""}, {"Name": "Actionhub: a large-scale action video description dataset for zero-shot action recognition", "Authors": ["Jiaming Zhou", "Junwei Liang", "Kun-Yu Lin", "Jinrui Yang", "Wei-Shi Zheng"], "Sources": "arXiv preprint arXiv:2401.11654", "PublishedYears": "2024", "Doi": "", "Abstracts": "Zero-shot action recognition (ZSAR) aims to learn an alignment model between videos and class descriptions of seen actions that is transferable to unseen actions. The text queries (class descriptions) used in existing ZSAR works, however, are often short action names that fail to capture the rich semantics in the videos, leading to misalignment. With the intuition that video content descriptions (e.g., video captions) can provide rich contextual information of visual concepts in videos, we propose to utilize human annotated video descriptions to enrich the semantics of the class descriptions of each action. However, all existing action video description datasets are limited in terms of the number of actions, the semantics of video descriptions, etc. To this end, we collect a large-scale action video descriptions dataset named ActionHub, which covers a total of 1,211 common actions and provides 3.6 million action video descriptions. With the proposed ActionHub dataset, we further propose a novel Cross-modality and Cross-action Modeling (CoCo) framework for ZSAR, which consists of a Dual Cross-modality Alignment module and a Cross-action Invariance Mining module. Specifically, the Dual Cross-modality Alignment module utilizes both action labels and video descriptions from ActionHub to obtain rich class semantic features for feature alignment. The Cross-action Invariance Mining module exploits a cycle-reconstruction process between the class semantic feature spaces of seen actions and unseen actions, aiming to guide the model to learn cross-action invariant representations. Extensive experimental results demonstrate that our CoCo?\u2026", "IdName": "zhou2024actionhub", "Citation": "", "Keywords": ""}, {"Name": "An examination of the compositionality of large generative vision-language models", "Authors": ["Teli Ma", "Rong Li", "Junwei Liang"], "Sources": "NAACL 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the success of Large Language Models (LLMs), a surge of Generative Vision-Language Models (GVLMs) have been constructed via multimodal instruction tuning. The tuning recipe substantially deviates from the common contrastive vision-language learning. However, the performance of GVLMs in multimodal compositional reasoning remains largely unexplored, as existing evaluation metrics and benchmarks focus predominantly on assessing contrastive models like CLIP. In this paper, we examine the potential evaluation metrics to assess the GVLMs and hypothesize generative score methods are suitable for evaluating compositionality. In addition, current benchmarks tend to prioritize syntactic correctness over semantics. The presence of morphological bias in these benchmarks can be exploited by GVLMs, leading to ineffective evaluations. To combat this, we define a MorphoBias Score to quantify the morphological bias and propose a novel LLM-based strategy to calibrate the bias. Moreover, a challenging task is added to evaluate the robustness of GVLMs against inherent inclination toward syntactic correctness. We include the calibrated dataset and the task into a new benchmark, namely MOrphologicall De-biased Benchmark (MODE). Our study provides the first unbiased benchmark for the compositionality of GVLMs, facilitating future research in this direction. We will release our code and datasets.", "IdName": "ma2023examination", "Citation": "", "Keywords": ""}, {"Name": "TFNet: Exploiting Temporal Cues for Fast and Accurate LiDAR Semantic Segmentation", "Authors": ["Rong Li", "ShiJie Li", "Xieyuanli Chen", "Teli Ma", "Wang Hao", "Juergen Gall", "Junwei Liang"], "Sources": "CVPR Workshop 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "LiDAR semantic segmentation plays a crucial role in enabling autonomous driving and robots to understand their surroundings accurately and robustly. A multitude of methods exist within this domain including point-based range-image-based polar-coordinate-based and hybrid strategies. Among these range-image-based techniques have gained widespread adoption in practical applications due to their efficiency. However they face a significant challenge known as the\" many-to-one\" problem caused by the range image's limited horizontal and vertical angular resolution. As a result around 20% of the 3D points can be occluded. In this paper we present TFNet a range-image-based LiDAR semantic segmentation method that utilizes temporal information to address this issue. Specifically we incorporate a temporal fusion layer to extract useful information from previous scans and integrate it with the current scan. We then design a max-voting-based post-processing technique to correct false predictions particularly those caused by the\" many-to-one\" issue. We evaluated the approach on two benchmarks and demonstrated that the plug-in post-processing technique is generic and can be applied to various networks.", "IdName": "li2024tfnet", "Citation": "", "Keywords": ""}, {"Name": "PostRainBench: A comprehensive benchmark and a new model for precipitation forecasting", "Authors": ["Yujin Tang", "Jiaming Zhou", "Xiang Pan", "Zeying Gong", "Junwei Liang"], "Sources": "ICLR Workshop 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Accurate precipitation forecasting is a vital challenge of both scientific and societal importance. Data-driven approaches have emerged as a widely used solution for addressing this challenge. However, solely relying on data-driven approaches has limitations in modeling the underlying physics, making accurate predictions difficult. Coupling AI-based post-processing techniques with traditional Numerical Weather Prediction (NWP) methods offers a more effective solution for improving forecasting accuracy. Despite previous post-processing efforts, accurately predicting heavy rainfall remains challenging due to the imbalanced precipitation data across locations and complex relationships between multiple meteorological variables. To address these limitations, we introduce the PostRainBench, a comprehensive multi-variable NWP post-processing benchmark consisting of three datasets for NWP post-processing-based precipitation forecasting. We propose CAMT, a simple yet effective Channel Attention Enhanced Multi-task Learning framework with a specially designed weighted loss function. Its flexible design allows for easy plug-and-play integration with various backbones. Extensive experimental results on the proposed benchmark show that our method outperforms state-of-the-art methods by 6.3%, 4.7%, and 26.8% in rain CSI on the three datasets respectively. Most notably, our model is the first deep learning-based method to outperform traditional Numerical Weather Prediction (NWP) approaches in extreme precipitation conditions. It shows improvements of 15.6%, 17.4%, and 31.8% over NWP predictions in heavy rain CSI on respective?\u2026", "IdName": "tang2023postrainbench", "Citation": "", "Keywords": ""}, {"Name": "Adafocus: Towards end-to-end weakly supervised learning for long-video action understanding", "Authors": ["Jiaming Zhou", "Hanjun Li", "Kun-Yu Lin", "Junwei Liang"], "Sources": "arXiv preprint arXiv:2311.17118", "PublishedYears": "2023", "Doi": "", "Abstracts": "Developing end-to-end models for long-video action understanding tasks presents significant computational and memory challenges. Existing works generally build models on long-video features extracted by off-the-shelf action recognition models, which are trained on short-video datasets in different domains, making the extracted features suffer domain discrepancy. To avoid this, action recognition models can be end-to-end trained on clips, which are trimmed from long videos and labeled using action interval annotations. Such fully supervised annotations are expensive to collect. Thus, a weakly supervised method is needed for long-video action understanding at scale. Under the weak supervision setting, action labels are provided for the whole video without precise start and end times of the action clip. To this end, we propose an AdaFocus framework. AdaFocus estimates the spike-actionness and temporal positions of actions, enabling it to adaptively focus on action clips that facilitate better training without the need for precise annotations. Experiments on three long-video datasets show its effectiveness. Remarkably, on two of datasets, models trained with AdaFocus under weak supervision outperform those trained under full supervision. Furthermore, we form a weakly supervised feature extraction pipeline with our AdaFocus, which enables significant improvements on three long-video action understanding tasks.", "IdName": "zhou2023adafocus", "Citation": "", "Keywords": ""}, {"Name": "From Recognition to Prediction: Analysis of Human Action and Trajectory Prediction in Video", "Authors": ["Junwei Liang"], "Sources": "arXiv preprint arXiv:2011.10670", "PublishedYears": "2021", "Doi": "", "Abstracts": "With the advancement in computer vision deep learning, systems now are able to analyze an unprecedented amount of rich visual information from videos to enable applications such as autonomous driving, socially-aware robot assistant and public safety monitoring. Deciphering human behaviors to predict their future paths/trajectories and what they would do from videos is important in these applications. However, human trajectory prediction still remains a challenging task, as scene semantics and human intent are difficult to model. Many systems do not provide high-level semantic attributes to reason about pedestrian future. This design hinders prediction performance in video data from diverse domains and unseen scenarios. To enable optimal future human behavioral forecasting, it is crucial for the system to be able to detect and analyze human activities as well as scene semantics, passing informative features to the subsequent prediction module for context understanding.", "IdName": "liang2020recognition", "Citation": "", "Keywords": ""}, {"Name": "Prioritized Semantic Learning for Zero-shot Instance Navigation", "Authors": ["Xander Sun", "Louis Lau", "Hoyard Zhi", "Ronghe Qiu", "Junwei Liang"], "Sources": "ECCV", "PublishedYears": "2024", "Doi": "", "Abstracts": "We study zero-shot instance navigation, in which the agent navigates to a specific object without using object annotations for training. Previous object navigation approaches apply the image-goal navigation (ImageNav) task (go to the location of an image) for pretraining, and transfer the agent to achieve object goals using a vision-language model. However, these approaches lead to issues of semantic neglect, where the model fails to learn meaningful semantic alignments. In this paper, we propose a Prioritized Semantic Learning (PSL) method to improve the semantic understanding ability of navigation agents. Specifically, a semantic-enhanced PSL agent is proposed and a prioritized semantic training strategy is introduced to select goal images that exhibit clear semantic supervision and relax the reward function from strict exact view matching. At inference time, a semantic expansion inference scheme is designed to preserve the same granularity level of the goal-semantic as training. Furthermore, for the popular HM3D environment, we present an Instance Navigation (InstanceNav) task that requires going to a specific object instance with detailed descriptions, as opposed to the Object Navigation (ObjectNav) task where the goal is defined merely by the object category. Our PSL agent outperforms the previous state-of-the-art by 66% on zero-shot ObjectNav in terms of success rate and is also superior on the new InstanceNav task. Code will be released at https://anonymous.4open. science/r/PSL/.", "IdName": "sun2024prioritized", "Citation": "", "Keywords": ""}, {"Name": "Mitigating the Human-Robot Domain Discrepancy in Visual Pre-training for Robotic Manipulation", "Authors": ["Jiaming Zhou", "Teli Ma", "Kun-Yu Lin", "Ronghe Qiu", "Zifan Wang", "Junwei Liang"], "Sources": "arXiv preprint arXiv:2406.14235", "PublishedYears": "2024", "Doi": "", "Abstracts": "Learning generalizable visual dynamic representation across different embodied environments is crucial for real-world robotic manipulation. As the scale and diversity of robot demonstration data are limited, recent works have turned to large-scale pre-training using human data. However, the morphological differences between humans and robots introduce a significant human-robot domain discrepancy, challenging the generalization of these human-data pre-trained models to downstream manipulation tasks. To address this, we propose a novel adaptation paradigm that utilizes readily available paired human-robot video data to bridge the discrepancy. Following this paradigm, our method exploits a human-robot contrastive alignment loss to align the semantics of human and robot videos, adapting pre-trained models to the robotic domain in a parameter-efficient manner. The experiments demonstrate significant improvements on 25 tasks across three different benchmarks, where the single-task, language-conditioned multi-task settings are covered, and two different pre-trained models are evaluated. On the large RLBench benchmark, our adaptation method achieves an average improvement of  in success rate over the pre-trained R3M model across multiple tasks. We will release the code and models upon acceptance.", "IdName": "zhou2024mitigating", "Citation": "", "Keywords": ""}, {"Name": "Contrastive Imitation Learning for Language-guided Multi-Task Robotic Manipulation", "Authors": ["Teli Ma", "Jiaming Zhou", "Zifan Wang", "Ronghe Qiu", "Junwei Liang"], "Sources": "arXiv preprint arXiv:2406.09738", "PublishedYears": "2024", "Doi": "", "Abstracts": "Developing robots capable of executing various manipulation tasks, guided by natural language instructions and visual observations of intricate real-world environments, remains a significant challenge in robotics. Such robot agents need to understand linguistic commands and distinguish between the requirements of different tasks. In this work, we present Sigma-Agent, an end-to-end imitation learning agent for multi-task robotic manipulation. Sigma-Agent incorporates contrastive Imitation Learning (contrastive IL) modules to strengthen vision-language and current-future representations. An effective and efficient multi-view querying Transformer (MVQ-Former) for aggregating representative semantic information is introduced. Sigma-Agent shows substantial improvement over state-of-the-art methods under diverse settings in 18 RLBench tasks, surpassing RVT by an average of 5.2% and 5.9% in 10 and 100 demonstration training, respectively. Sigma-Agent also achieves 62% success rate with a single policy in 5 real-world manipulation tasks. The code will be released upon acceptance.", "IdName": "ma2024contrastive", "Citation": "", "Keywords": ""}, {"Name": "FinTextQA: A Dataset for Long-form Financial Question Answering", "Authors": ["Jian Chen", "Peilin Zhou", "Yining Hua", "Yingxin Loh", "Kehui Chen", "Ziyuan Li", "Bing Zhu", "Junwei Liang"], "Sources": "ACL", "PublishedYears": "2024", "Doi": "", "Abstracts": "Accurate evaluation of financial question answering (QA) systems necessitates a comprehensive dataset encompassing diverse question types and contexts. However, current financial QA datasets lack scope diversity and question complexity. This work introduces FinTextQA, a novel dataset for long-form question answering (LFQA) in finance. FinTextQA comprises 1,262 high-quality, source-attributed QA pairs extracted and selected from finance textbooks and government agency websites.Moreover, we developed a Retrieval-Augmented Generation (RAG)-based LFQA system, comprising an embedder, retriever, reranker, and generator. A multi-faceted evaluation approach, including human ranking, automatic metrics, and GPT-4 scoring, was employed to benchmark the performance of different LFQA system configurations under heightened noisy conditions. The results indicate that: (1) Among all compared generators, Baichuan2-7B competes closely with GPT-3.5-turbo in accuracy score; (2) The most effective system configuration on our dataset involved setting the embedder, retriever, reranker, and generator as Ada2, Automated Merged Retrieval, Bge-Reranker-Base, and Baichuan2-7B, respectively; (3) models are less susceptible to noise after the length of contexts reaching a specific threshold.", "IdName": "chen2024fintextqa", "Citation": "", "Keywords": ""}, {"Name": "Adversarially masked video consistency for unsupervised domain adaptation", "Authors": ["Xiaoyu Zhu", "Junwei Liang", "Po-Yao Huang", "Alex Hauptmann"], "Sources": "arXiv preprint arXiv:2403.16242", "PublishedYears": "2024", "Doi": "", "Abstracts": "We study the problem of unsupervised domain adaptation for egocentric videos. We propose a transformer-based model to learn class-discriminative and domain-invariant feature representations. It consists of two novel designs. The first module is called Generative Adversarial Domain Alignment Network with the aim of learning domain-invariant representations. It simultaneously learns a mask generator and a domain-invariant encoder in an adversarial way. The domain-invariant encoder is trained to minimize the distance between the source and target domain. The masking generator, conversely, aims at producing challenging masks by maximizing the domain distance. The second is a Masked Consistency Learning module to learn class-discriminative representations. It enforces the prediction consistency between the masked target videos and their full forms. To better evaluate the effectiveness of domain adaptation methods, we construct a more challenging benchmark for egocentric videos, U-Ego4D. Our method achieves state-of-the-art performance on the Epic-Kitchen and the proposed U-Ego4D benchmark.", "IdName": "zhu2024adversarially", "Citation": "", "Keywords": ""}, {"Name": "Spatial-Temporal Alignment Network for Action Recognition", "Authors": ["Jinhui Ye", "Junwei Liang"], "Sources": "arXiv preprint arXiv:2308.09897", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper studies introducing viewpoint invariant feature representations in existing action recognition architecture. Despite significant progress in action recognition, efficiently handling geometric variations in large-scale datasets remains challenging. To tackle this problem, we propose a novel Spatial-Temporal Alignment Network (STAN), which explicitly learns geometric invariant representations for action recognition. Notably, the STAN model is light-weighted and generic, which could be plugged into existing action recognition models (e.g., MViTv2) with a low extra computational cost. We test our STAN model on widely-used datasets like UCF101 and HMDB51. The experimental results show that the STAN model can consistently improve the state-of-the-art models in action recognition tasks in trained-from-scratch settings.", "IdName": "ye2023spatial", "Citation": "", "Keywords": ""}, {"Name": "Open-vocabulary Mobile Manipulation in Unseen Dynamic Environments with 3D Semantic Maps", "Authors": ["Dicong Qiu", "Wenzong Ma", "Zhenfu Pan", "Hui Xiong", "Junwei Liang"], "Sources": "arXiv preprint arXiv:2406.18115", "PublishedYears": "2024", "Doi": "", "Abstracts": "Open-Vocabulary Mobile Manipulation (OVMM) is a crucial capability for autonomous robots, especially when faced with the challenges posed by unknown and dynamic environments. This task requires robots to explore and build a semantic understanding of their surroundings, generate feasible plans to achieve manipulation goals, adapt to environmental changes, and comprehend natural language instructions from humans. To address these challenges, we propose a novel framework that leverages the zero-shot detection and grounded recognition capabilities of pretraining visual-language models (VLMs) combined with dense 3D entity reconstruction to build 3D semantic maps. Additionally, we utilize large language models (LLMs) for spatial region abstraction and online planning, incorporating human instructions and spatial semantic context. We have built a 10-DoF mobile manipulation robotic platform JSR-1 and demonstrated in real-world robot experiments that our proposed framework can effectively capture spatial semantics and process natural language user instructions for zero-shot OVMM tasks under dynamic environment settings, with an overall navigation and task success rate of 80.95% and 73.33% over 105 episodes, and better SFT and SPL by 157.18% and 19.53% respectively compared to the baseline. Furthermore, the framework is capable of replanning towards the next most probable candidate location based on the spatial semantic context derived from the 3D semantic map when initial plans fail, keeping an average success rate of 76.67%.", "IdName": "qiu2024open", "Citation": "", "Keywords": ""}, {"Name": "Vision-Language Models Meet Meteorology: Developing Models for Extreme Weather Events Detection with Heatmaps", "Authors": ["Jian Chen", "Peilin Zhou", "Yining Hua", "Dading Chong", "Meng Cao", "Yaowei Li", "Zixuan Yuan", "Bing Zhu", "Junwei Liang"], "Sources": "arXiv preprint arXiv:2406.09838", "PublishedYears": "2024", "Doi": "", "Abstracts": "Real-time detection and prediction of extreme weather protect human lives and infrastructure. Traditional methods rely on numerical threshold setting and manual interpretation of weather heatmaps with Geographic Information Systems (GIS), which can be slow and error-prone. Our research redefines Extreme Weather Events Detection (EWED) by framing it as a Visual Question Answering (VQA) problem, thereby introducing a more precise and automated solution. Leveraging Vision-Language Models (VLM) to simultaneously process visual and textual data, we offer an effective aid to enhance the analysis process of weather heatmaps. Our initial assessment of general-purpose VLMs (e.g., GPT-4-Vision) on EWED revealed poor performance, characterized by low accuracy and frequent hallucinations due to inadequate color differentiation and insufficient meteorological knowledge. To address these challenges, we introduce ClimateIQA, the first meteorological VQA dataset, which includes 8,760 wind gust heatmaps and 254,040 question-answer pairs covering four question types, both generated from the latest climate reanalysis data. We also propose Sparse Position and Outline Tracking (SPOT), an innovative technique that leverages OpenCV and K-Means clustering to capture and depict color contours in heatmaps, providing ClimateIQA with more accurate color spatial location information. Finally, we present Climate-Zoo, the first meteorological VLM collection, which adapts VLMs to meteorological applications using the ClimateIQA dataset. Experiment results demonstrate that models from Climate-Zoo substantially outperform state-of-the?\u2026", "IdName": "chen2024vision", "Citation": "", "Keywords": ""}, {"Name": "Improving Gloss-free Sign Language Translation by Reducing Representation Density", "Authors": ["Jinhui Ye", "Xing Wang", "Wenxiang Jiao", "Junwei Liang", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2405.14312", "PublishedYears": "2024", "Doi": "", "Abstracts": "Gloss-free sign language translation (SLT) aims to develop well-performing SLT systems with no requirement for the costly gloss annotations, but currently still lags behind gloss-based approaches significantly. In this paper, we identify a representation density problem that could be a bottleneck in restricting the performance of gloss-free SLT. Specifically, the representation density problem describes that the visual representations of semantically distinct sign gestures tend to be closely packed together in feature space, which makes gloss-free methods struggle with distinguishing different sign gestures and suffer from a sharp performance drop. To address the representation density problem, we introduce a simple but effective contrastive learning strategy, namely SignCL, which encourages gloss-free models to learn more discriminative feature representation in a self-supervised manner. Our experiments demonstrate that the proposed SignCL can significantly reduce the representation density and improve performance across various translation frameworks. Specifically, SignCL achieves a significant improvement in BLEU score for the Sign Language Transformer and GFSLT-VLP on the CSL-Daily dataset by 39% and 46%, respectively, without any increase of model parameters. Compared to Sign2GPT, a state-of-the-art method based on large-scale pre-trained vision and language models, SignCL achieves better performance with only 35% of its parameters. Implementation and Checkpoints are available at https://github.com/JinhuiYE/SignCL.", "IdName": "ye2024improving", "Citation": "", "Keywords": ""}, {"Name": "GeoDeformer: Geometric Deformable Transformer for Action Recognition", "Authors": ["Jinhui Ye", "Jiaming Zhou", "Hui Xiong", "Junwei Liang"], "Sources": "arXiv preprint arXiv:2311.17975", "PublishedYears": "2023", "Doi": "", "Abstracts": "Vision transformers have recently emerged as an effective alternative to convolutional networks for action recognition. However, vision transformers still struggle with geometric variations prevalent in video data. This paper proposes a novel approach, GeoDeformer, designed to capture the variations inherent in action video by integrating geometric comprehension directly into the ViT architecture. Specifically, at the core of GeoDeformer is the Geometric Deformation Predictor, a module designed to identify and quantify potential spatial and temporal geometric deformations within the given video. Spatial deformations adjust the geometry within individual frames, while temporal deformations capture the cross-frame geometric dynamics, reflecting motion and temporal progression. To demonstrate the effectiveness of our approach, we incorporate it into the established MViTv2 framework, replacing the standard self-attention blocks with GeoDeformer blocks. Our experiments at UCF101, HMDB51, and Mini-K200 achieve significant increases in both Top-1 and Top-5 accuracy, establishing new state-of-the-art results with only a marginal increase in computational cost. Additionally, visualizations affirm that GeoDeformer effectively manifests explicit geometric deformations and minimizes geometric variations. Codes and checkpoints will be released.", "IdName": "ye2023geodeformer", "Citation": "", "Keywords": ""}, {"Name": "The ninth visual object tracking vot2021 challenge results", "Authors": ["Matej Kristan", "Ji?\u00ed Matas", "Ale? Leonardis", "Michael Felsberg", "Roman Pflugfelder", "Joni-Kristian K?m?r?inen", "Hyung Jin Chang", "Martin Danelljan", "Luka Cehovin", "Alan Luke?i?", "Ondrej Drbohlav", "Jani K?pyl?", "Gustav H?ger", "Song Yan", "Jinyu Yang", "Zhongqun Zhang", "Gustavo Fern\u00e1ndez"], "Sources": "Proceedings of the IEEE/CVF international conference on computer vision?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "The Visual Object Tracking challenge VOT2021 is the ninth annual tracker benchmarking activity organized by the VOT initiative. Results of 71 trackers are presented; many are state-of-the-art trackers published at major com-puter vision conferences or in journals in recent years. The VOT2021 challenge was composed of four sub-challenges focusing on different tracking domains:(i) VOT-ST2021 challenge focused on short-term tracking in RGB,(ii) VOT-RT2021 challenge focused on\" real-time\" short-term track-ing in RGB,(iii) VOT-LT2021 focused on long-term track-ing, namely coping with target disappearance and reap-pearance and (iv) VOT-RGBD2021 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2021 dataset was refreshed, while VOT-RGBD2021 in-troduces a training dataset and sequestered dataset for win-ner identification. The source code for most of the trackers, the datasets, the evaluation kit and the results along with the source code for most trackers are publicly available at the challenge website.", "IdName": "kristan2021ninth", "Citation": "", "Keywords": ""}, {"Name": "Data-free Backdoor Removal based on Channel Lipschitzness", "Authors": ["Runkai Zheng", "Rongjun Tang", "Jianze Li", "Li Liu"], "Sources": "ECCV 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recent studies have shown that Deep Neural Networks (DNNs) are vulnerable to the backdoor attacks, which leads to malicious behaviors of DNNs when specific triggers are attached to the input images. It was further demonstrated that the infected DNNs possess a collection of channels, which are more sensitive to the backdoor triggers compared with normal channels. Pruning these channels was then shown to be effective in mitigating the backdoor behaviors. To locate those channels, it is natural to consider their Lipschitzness, which measures their sensitivity against worst-case perturbations on the inputs. In this work, we introduce a novel concept called Channel Lipschitz Constant (CLC), which is defined as the Lipschitz constant of the mapping from the input images to the output of each channel. Then we provide empirical evidences to show the strong correlation between an Upper bound of the CLC (UCLC?\u2026", "IdName": "zheng2022data", "Citation": "", "Keywords": ""}, {"Name": "A comprehensive survey on segment anything model for vision and beyond", "Authors": ["Chunhui Zhang", "Li Liu", "Yawen Cui", "Guanjie Huang", "Weilin Lin", "Yiqian Yang", "Yuehong Hu"], "Sources": "arXiv preprint arXiv:2305.08196", "PublishedYears": "2023", "Doi": "", "Abstracts": "Artificial intelligence (AI) is evolving towards artificial general intelligence, which refers to the ability of an AI system to perform a wide range of tasks and exhibit a level of intelligence similar to that of a human being. This is in contrast to narrow or specialized AI, which is designed to perform specific tasks with a high degree of efficiency. Therefore, it is urgent to design a general class of models, which we term foundation models, trained on broad data that can be adapted to various downstream tasks. The recently proposed segment anything model (SAM) has made significant progress in breaking the boundaries of segmentation, greatly promoting the development of foundation models for computer vision. To fully comprehend SAM, we conduct a survey study. As the first to comprehensively review the progress of segmenting anything task for vision and beyond based on the foundation model of SAM, this work focuses on its applications to various tasks and data types by discussing its historical development, recent progress, and profound impact on broad applications. We first introduce the background and terminology for foundation models including SAM, as well as state-of-the-art methods contemporaneous with SAM that are significant for segmenting anything task. Then, we analyze and summarize the advantages and limitations of SAM across various image processing applications, including software scenes, real-world scenes, and complex scenes. Importantly, many insights are drawn to guide future research to develop more versatile foundation models and improve the architecture of SAM. We also summarize massive other amazing?\u2026", "IdName": "zhang2023comprehensive", "Citation": "", "Keywords": ""}, {"Name": "Boosting black-box attack with partially transferred conditional adversarial distribution", "Authors": ["Yan Feng", "Baoyuan Wu", "Yanbo Fan", "Li Liu", "Zhifeng Li", "Shu-Tao Xia"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "This work studies black-box adversarial attacks against deep neural networks (DNNs), where the attacker can only access the query feedback returned by the attacked DNN model, while other information such as model parameters or the training datasets are unknown. One promising approach to improve attack performance is utilizing the adversarial transferability between some white-box surrogate models and the target model (ie, the attacked model). However, due to the possible differences on model architectures and training datasets between surrogate and target models, dubbed\" surrogate biases\", the contribution of adversarial transferability to improving the attack performance may be weakened. To tackle this issue, we innovatively propose a black-box attack method by developing a novel mechanism of adversarial transferability, which is robust to the surrogate biases. The general idea is transferring partial parameters of the conditional adversarial distribution (CAD) of surrogate models, while learning the untransferred parameters based on queries to the target model, to keep the flexibility to adjust the CAD of the target model on any new benign sample. Extensive experiments on benchmark datasets and attacking against real-world API demonstrate the superior attack performance of the proposed method.", "IdName": "feng2022boosting", "Citation": "", "Keywords": ""}, {"Name": "Self-supervised depth estimation via implicit cues from videos", "Authors": ["Jianrong Wang", "Ge Zhang", "Zhenyu Wu", "Xuewei Li", "Li Liu"], "Sources": "ICASSP 2021-2021 IEEE International Conference on Acoustics", "PublishedYears": "2021", "Doi": "", "Abstracts": "In self-supervised monocular depth estimation, the depth discontinuity and motion objects' artifacts are still challenging problems. Existing self-supervised methods usually utilize two views to train the depth estimation network and use one single view to make predictions. Compared with static views, abundant dynamic properties between video frames are beneficial to refining depth estimation, especially for dynamic objects. In this work, we improve the self-supervised learning framework for depth estimation using consecutive frames from monocular and stereo videos. The main idea is to exploit an implicit depth cue extractor which leverages dynamic and static cues to generate useful depth proposals. These cues can predict distinguishable motion contours and geometric scene structures. Moreover, a new high-dimensional attention module is proposed to extract a clear global transformation, which effectively?\u2026", "IdName": "wang2021self", "Citation": "", "Keywords": ""}, {"Name": "Uscl: Pretraining deep ultrasound image diagnosis model through video contrastive representation learning", "Authors": ["Yixiong Chen", "Chunhui Zhang", "Li Liu", "Cheng Feng", "Changfeng Dong", "Yongfang Luo", "Xiang Wan"], "Sources": "MICCAI-International Conference on Medical Image Computing and Computer?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " Most deep neural networks (DNNs) based ultrasound (US) medical image analysis models use pretrained backbones (e.g., ImageNet) for better model generalization. However, the domain gap between natural and medical images causes an inevitable performance bottleneck. To alleviate this problem, an US dataset named US-4 is constructed for direct pretraining on the same domain. It contains over 23,000 images from four US video sub-datasets. To learn robust features from US-4, we propose an US semi-supervised contrastive learning method, named USCL, for pretraining. In order to avoid high similarities between negative pairs as well as mine abundant visual features from limited US videos, USCL adopts a sample pair generation method to enrich the feature involved in a single step of contrastive optimization. Extensive experiments on several downstream tasks show the superiority of USCL?\u2026", "IdName": "chen2021uscl", "Citation": "", "Keywords": ""}, {"Name": "Re-synchronization using the hand preceding model for multi-modal fusion in automatic continuous cued speech recognition", "Authors": ["Li Liu", "Gang Feng", "Denis Beautemps", "Xiao-Ping Zhang"], "Sources": "IEEE Transactions on Multimedia 23", "PublishedYears": "2021", "Doi": "", "Abstracts": "Cued Speech (CS) is an augmented lip reading system complemented by hand coding, and it is very helpful to the deaf people. Automatic CS recognition can help communications between the deaf people and others. Due to the asynchronous nature of lips and hand movements, fusion of them in automatic CS recognition is a challenging problem. In this work, we propose a novel re-synchronization procedure for multi-modal fusion, which aligns the hand features with lips feature. It is realized by delaying hand position and hand shape with their optimal hand preceding time which is derived by investigating the temporal organizations of hand position and hand shape movements in CS. This re-synchronization procedure is incorporated into a practical continuous CS recognition system that combines convolutional neural network (CNN) with multi-stream hidden markov model (MSHMM). A significant improvement of?\u2026", "IdName": "liu2020re", "Citation": "", "Keywords": ""}, {"Name": "Semi-supervised active learning for COVID-19 lung ultrasound multi-symptom classification", "Authors": ["Lei Liu", "Wentao Lei", "Li Liu", "Xiang Wan", "Yongfang Luo", "Cheng Feng"], "Sources": "ICTAI-2020 IEEE 32nd International Conference on Tools with Artificial?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Ultrasound (US) is a non-invasive yet effective medical diagnostic imaging technique for the COVID-19 global pandemic. However, due to complex feature behaviors and expensive annotations of US images, it is difficult to apply Artificial Intelligence (AI) assisting approaches for the lung's multi-symptom (multi-label) classification. To overcome these difficulties, we propose a novel semi-supervised Two-Stream Active Learning (TSAL) method to model complicated features and reduce labeling costs in an iterative manner. The core component of TSAL is the multi-label learning mechanism, in which label correlation information is used to design a multi-label margin (MLM) strategy and a confidence validation for automatically selecting informative samples and confident labels. In this framework, a multi-symptom multi-label (MSML) classification network is proposed to learn discriminative features of lung symptoms?\u2026", "IdName": "liu2020semi", "Citation": "", "Keywords": ""}, {"Name": "Pre-activation Distributions Expose Backdoor Neurons", "Authors": ["Runkai Zheng", "Rongjun Tang", "Jianze Li", "Li Liu"], "Sources": "Neurips 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Convolutional neural networks (CNN) can be manipulated to perform specific behaviors when encountering a particular trigger pattern without affecting the performance on normal samples, which is referred to as backdoor attack. The backdoor attack is usually achieved by injecting a small proportion of poisoned samples into the training set, through which the victim trains a model embedded with the designated backdoor. In this work, we demonstrate that backdoor neurons are exposed by their pre-activation distributions, where populations from benign data and poisoned data show significantly different moments. This property is shown to be attack-invariant and allows us to efficiently locate backdoor neurons. On this basis, we make several proper assumptions on the neuron activation distributions, and propose two backdoor neuron detection strategies based on (1) the differential entropy of the neurons, and (2) the Kullback-Leibler divergence between the benign sample distribution and a poisoned statistics based hypothetical distribution. Experimental results show that our proposed defense strategies are both efficient and effective against various backdoor attacks.", "IdName": "zheng2022pre", "Citation": "", "Keywords": ""}, {"Name": "Adversarial machine learning: A systematic survey of backdoor attack, weight attack and adversarial example", "Authors": ["Baoyuan Wu", "Li Liu", "Zihao Zhu", "Qingshan Liu", "Zhaofeng He", "Siwei Lyu"], "Sources": "arXiv preprint arXiv:2302.09457 1", "PublishedYears": "2023", "Doi": "", "Abstracts": "", "IdName": "wu2023adversarial", "Citation": "", "Keywords": ""}, {"Name": "Adaptive semantic-spatio-temporal graph convolutional network for lip reading", "Authors": ["Changchong Sheng", "Xinzhong Zhu", "Huiying Xu", "Matti Pietik?inen", "Li Liu"], "Sources": "IEEE Transactions on Multimedia 24", "PublishedYears": "2021", "Doi": "", "Abstracts": "The goal of this work is to recognize words, phrases, and sentences being spoken by a talking face without given the audio. Current deep learning approaches for lip reading focus on exploring the appearance and optical flow information of videos. However, these methods do not fully exploit the characteristics of lip motion. In addition to appearance and optical flow, the mouth contour deformation usually conveys significant information that is complementary to others. However, the modeling of dynamic mouth contour has received little attention than that of appearance and optical flow. In this work, we propose a novel model of dynamic mouth contours called Adaptive Semantic-Spatio-Temporal Graph Convolution Network (ASST-GCN), to go beyond previous methods by automatically learning both the spatial and temporal information from videos. To combine the complementary information from appearance and?\u2026", "IdName": "sheng2021adaptive", "Citation": "", "Keywords": ""}, {"Name": "WebUAV-3M: A Benchmark Unveiling the Power of Million-Scale Deep UAV Tracking", "Authors": ["Chunhui Zhang", "Guanjie Huang", "Li Liu", "Shan Huang", "Yinan Yang", "Xiang Wan", "Shiming Ge", "Dacheng Tao"], "Sources": "TPAMI", "PublishedYears": "2022", "Doi": "", "Abstracts": "Unmanned aerial vehicle (UAV) tracking is of great significance for a wide range of applications, such as delivery and agriculture. Previous benchmarks in this area mainly focused on small-scale tracking problems while ignoring the amounts of data, types of data modalities, diversities of target categories and scenarios, and evaluation protocols involved, greatly hiding the massive power of deep UAV tracking. In this article, we propose WebUAV-3M, the largest public UAV tracking benchmark to date, to facilitate both the development and evaluation of deep UAV trackers. WebUAV-3M contains over 3.3 million frames across 4,500 videos and offers 223 highly diverse target categories. Each video is densely annotated with bounding boxes by an efficient and scalable semi-automatic target annotation (SATA) pipeline. Importantly, to take advantage of the complementary superiority of language and audio, we enrich?\u2026", "IdName": "zhang2022webuav", "Citation": "", "Keywords": ""}, {"Name": "X-IQE: eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models", "Authors": ["Yixiong Chen", "Li Liu", "Chris Ding"], "Sources": "arXiv preprint arXiv:2305.10843", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper introduces a novel explainable image quality evaluation approach called X-IQE, which leverages visual large language models (LLMs) to evaluate text-to-image generation methods by generating textual explanations. X-IQE utilizes a hierarchical Chain of Thought (CoT) to enable MiniGPT-4 to produce self-consistent, unbiased texts that are highly correlated with human evaluation. It offers several advantages, including the ability to distinguish between real and generated images, evaluate text-image alignment, and assess image aesthetics without requiring model training or fine-tuning. X-IQE is more cost-effective and efficient compared to human evaluation, while significantly enhancing the transparency and explainability of deep image quality evaluation models. We validate the effectiveness of our method as a benchmark using images generated by prevalent diffusion models. X-IQE demonstrates similar performance to state-of-the-art (SOTA) evaluation methods on COCO Caption, while overcoming the limitations of previous evaluation models on DrawBench, particularly in handling ambiguous generation prompts and text recognition in generated images. Project website: https://github.com/Schuture/Benchmarking-Awesome-Diffusion-Models", "IdName": "chen2023x", "Citation": "", "Keywords": ""}, {"Name": "Residual-Guided Personalized Speech Synthesis based on Face Image", "Authors": ["Jianrong Wang", "Zixuan Wang", "Xiaosheng Hu", "Xuewei Li", "Qiang Fang", "Li Liu"], "Sources": "ICASSP 2022-2022 IEEE International Conference on Acoustics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Previous works derive personalized speech features by training the model on a large dataset composed of his/her audio sounds. It was reported that face information has a strong link with the speech sound. Thus in this work, we innovatively extract personalized speech features from human faces to synthesize personalized speech using neural vocoder. A Face-based Residual Personalized Speech Synthesis Model (FR-PSS) containing a speech encoder, a speech synthesizer and a face encoder is designed for PSS. In this model, by designing two speech priors, a residual-guided strategy is introduced to guide the face feature to approach the true speech feature in the training. Moreover, considering the error of feature\u2019s absolute values and their directional bias, we formulate a novel tri-item loss function for face encoder. Experimental results show that the speech synthesized by our model is comparable to the?\u2026", "IdName": "wang2022residual", "Citation": "", "Keywords": ""}, {"Name": "Multi-modal active learning for automatic liver fibrosis diagnosis based on ultrasound shear wave elastography", "Authors": ["Lufei Gao", "Ruisong Zhou", "Changfeng Dong", "Cheng Feng", "Zhen Li", "Xiang Wan", "Li Liu"], "Sources": "2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)", "PublishedYears": "2021", "Doi": "", "Abstracts": "With the development of radiomics, noninvasive diagnosis like ultrasound (US) imaging plays a very important role in automatic liver fibrosis diagnosis (ALFD). Due to the noisy data, expensive annotations of US images, the application of Artificial Intelligence (AI) assisting approaches encounters a bottleneck. Besides, the use of single-modal US data limits the further improve of the classification results. In this work, we innovatively propose a multi-modal fusion network with active learning (MMFN-AL) for ALFD to exploit the information of multiple modalities, eliminate the noisy data and reduce the annotation cost. Four image modalities including US and three types of shear wave elastography (SWEs) are exploited. A new dataset containing these modalities from 214 candidates is collected and pre-processed, with the labels obtained from the liver biopsy results. Experimental results show that our proposed method?\u2026", "IdName": "gao2021multi", "Citation": "", "Keywords": ""}, {"Name": "Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and Compatible Triggers", "Authors": ["Ruotong Wang", "Hongrui Chen", "Zihao Zhu", "Li Liu", "Baoyuan Wu"], "Sources": "arXiv preprint arXiv:2306.00816", "PublishedYears": "2023", "Doi": "", "Abstracts": "Deep neural networks (DNNs) can be manipulated to exhibit specific behaviors when exposed to specific trigger patterns, without affecting their performance on benign samples, dubbed \\textit{backdoor attack}. Currently, implementing backdoor attacks in physical scenarios still faces significant challenges. Physical attacks are labor-intensive and time-consuming, and the triggers are selected in a manual and heuristic way. Moreover, expanding digital attacks to physical scenarios faces many challenges due to their sensitivity to visual distortions and the absence of counterparts in the real world. To address these challenges, we define a novel trigger called the \\textbf{V}isible, \\textbf{S}emantic, \\textbf{S}ample-Specific, and \\textbf{C}ompatible (VSSC) trigger, to achieve effective, stealthy and robust simultaneously, which can also be effectively deployed in the physical scenario using corresponding objects. To implement the VSSC trigger, we propose an automated pipeline comprising three modules: a trigger selection module that systematically identifies suitable triggers leveraging large language models, a trigger insertion module that employs generative models to seamlessly integrate triggers into images, and a quality assessment module that ensures the natural and successful insertion of triggers through vision-language models. Extensive experimental results and analysis validate the effectiveness, stealthiness, and robustness of the VSSC trigger. It can not only maintain robustness under visual distortions but also demonstrates strong practicality in the physical scenario. We hope that the proposed VSSC trigger and implementation approach?\u2026", "IdName": "wang2023versatile", "Citation": "", "Keywords": ""}, {"Name": "Fedads: A benchmark for privacy-preserving cvr estimation with vertical federated learning", "Authors": ["Penghui Wei", "Hongjian Dou", "Shaoguo Liu", "Rongjun Tang", "Li Liu", "Liang Wang", "Bo Zheng"], "Sources": "Proceedings of the 46th International ACM SIGIR Conference on Research and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Conversion rate (CVR) estimation aims to predict the probability of conversion event after a user has clicked an ad. Typically, online publisher has user browsing interests and click feedbacks, while demand-side advertising platform collects users' post-click behaviors such as dwell time and conversion decisions. To estimate CVR accurately and protect data privacy better, vertical federated learning (vFL) is a natural solution to combine two sides' advantages for training models, without exchanging raw data. Both CVR estimation and applied vFL algorithms have attracted increasing research attentions. However, standardized and systematical evaluations are missing: due to the lack of standardized datasets, existing studies adopt public datasets to simulate a vFL setting via hand-crafted feature partition, which brings challenges to fair comparison. We introduce FedAds, the first benchmark for CVR estimation with?\u2026", "IdName": "wei2023fedads", "Citation": "", "Keywords": ""}, {"Name": "Generating and Weighting Semantically Consistent Sample Pairs for Ultrasound Contrastive Learning", "Authors": ["Yixiong Chen", "Chunhui Zhang", "Chris HQ Ding", "Li Liu"], "Sources": "IEEE Transactions on Medical Imaging", "PublishedYears": "2022", "Doi": "", "Abstracts": "Well-annotated medical datasets enable deep neural networks (DNNs) to gain strong power in extracting lesion-related features. Building such large and well-designed medical datasets is costly due to the need for high-level expertise. Model pre-training based on ImageNet is a common practice to gain better generalization when the data amount is limited. However, it suffers from the domain gap between natural and medical images. In this work, we pre-train DNNs on ultrasound (US) domains instead of ImageNet to reduce the domain gap in medical US applications. To learn US image representations based on unlabeled US videos, we propose a novel meta-learning-based contrastive learning method, namely Meta Ultrasound Contrastive Learning (Meta-USCL). To tackle the key challenge of obtaining semantically consistent sample pairs for contrastive learning, we present a positive pair generation module?\u2026", "IdName": "chen2022generating", "Citation": "", "Keywords": ""}, {"Name": "Diagnosis of Significant Liver Fibrosis in Patients With Chronic Hepatitis B By Using a Deep Learning-Based Data Integration Network", "Authors": ["Zhong Liu", "Huiying Wen", "Ziqi Zhu", "Qinyuan Li", "Li Liu", "Tianjiao Li", "Wencong Xu", "Chao Hou", "Bin Huang", "Zhiyan Li", "Changfeng Dong", "Xin Chen"], "Sources": "Hepatology International", "PublishedYears": "2021", "Doi": "", "Abstracts": "Background and aimsChronic hepatitis B virus (CHB) infection remains a major global health burden and the non-invasive and accurate diagnosis of significant liver fibrosis (\u2265?F2) in CHB patients is clinically very important. This study aimed to assess the potential of the joint use of ultrasound images of liver parenchyma, liver stiffness values, and patients\u2019 clinical parameters in a deep learning model to improve the diagnosis of?\u2265?F2 in CHB patients.MethodsOf 527 CHB patients who underwent US examination, liver elastography and biopsy, 284 eligible patients were included. We developed a deep learning-based data integration network (DI-Net) to fuse the information of ultrasound images of liver parenchyma, liver stiffness values and patients\u2019 clinical parameters for diagnosing?\u2265?F2 in CHB patients. The performance of DI-Net was cross-validated in a main cohort (n?=?155) of the included patients and?\u2026", "IdName": "liu2022diagnosis", "Citation": "", "Keywords": ""}, {"Name": "Defenses in adversarial machine learning: A survey", "Authors": ["Baoyuan Wu", "Shaokui Wei", "Mingli Zhu", "Meixi Zheng", "Zihao Zhu", "Mingda Zhang", "Hongrui Chen", "Danni Yuan", "Li Liu", "Qingshan Liu"], "Sources": "arXiv preprint arXiv:2312.08890", "PublishedYears": "2023", "Doi": "", "Abstracts": "Adversarial phenomenon has been widely observed in machine learning (ML) systems, especially in those using deep neural networks, describing that ML systems may produce inconsistent and incomprehensible predictions with humans at some particular cases. This phenomenon poses a serious security threat to the practical application of ML systems, and several advanced attack paradigms have been developed to explore it, mainly including backdoor attacks, weight attacks, and adversarial examples. For each individual attack paradigm, various defense paradigms have been developed to improve the model robustness against the corresponding attack paradigm. However, due to the independence and diversity of these defense paradigms, it is difficult to examine the overall robustness of an ML system against different kinds of attacks.This survey aims to build a systematic review of all existing defense paradigms from a unified perspective. Specifically, from the life-cycle perspective, we factorize a complete machine learning system into five stages, including pre-training, training, post-training, deployment, and inference stages, respectively. Then, we present a clear taxonomy to categorize and review representative defense methods at each individual stage. The unified perspective and presented taxonomies not only facilitate the analysis of the mechanism of each defense paradigm but also help us to understand connections and differences among different defense paradigms, which may inspire future research to develop more advanced, comprehensive defenses.", "IdName": "wu2023defenses", "Citation": "", "Keywords": ""}, {"Name": "Metalr: Meta-tuning of learning rates for transfer learning in medical imaging", "Authors": ["Yixiong Chen", "Li Liu", "Jingxian Li", "Hua Jiang", "Chris Ding", "Zongwei Zhou"], "Sources": "International Conference on Medical Image Computing and Computer-Assisted?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "In medical image analysis, transfer learning is a powerful method for deep neural networks (DNNs) to generalize on limited medical data. Prior efforts have focused on developing pre-training algorithms on domains such as lung ultrasound, chest X-ray, and liver CT to bridge domain gaps. However, we find that model fine-tuning also plays a crucial role in adapting medical knowledge to target tasks. The common fine-tuning method is manually picking transferable layers (e.g., the last few layers) to update, which is labor-expensive. In this work, we propose a meta-learning-based learning rate (LR) tuner, named MetaLR, to make different layers automatically co-adapt to downstream tasks based on their transferabilities across domains. MetaLR learns LRs for different layers in an online manner, preventing highly transferable layers from forgetting their medical representation abilities and driving less transferable?\u2026", "IdName": "chen2023metalr", "Citation": "", "Keywords": ""}, {"Name": "Cross-Modal Mutual Learning for Cued Speech Recognition", "Authors": ["Lei Liu", "Li Liu"], "Sources": "ICASSP 2022  preprint arXiv:2212.01083", "PublishedYears": "2022", "Doi": "", "Abstracts": "Automatic Cued Speech Recognition (ACSR) provides an intelligent human-machine interface for visual communications, where the Cued Speech (CS) system utilizes lip movements and hand gestures to code spoken language for hearing-impaired people. Previous ACSR approaches often utilize direct feature concatenation as the main fusion paradigm. However, the asynchronous modalities (i.e., lip, hand shape and hand position) in CS may cause interference for feature concatenation. To address this challenge, we propose a transformer based cross-modal mutual learning framework to prompt multi-modal interaction. Compared with the vanilla self-attention, our model forces modality-specific information of different modalities to pass through a modality-invariant codebook, concatenating linguistic representations with tokens of each modality. Then the shared linguistic knowledge is used to re-synchronize?\u2026", "IdName": "liu2023cross", "Citation": "", "Keywords": ""}, {"Name": "Acoustic-to-Articulatory Inversion Based on Speech Decomposition and Auxiliary Feature", "Authors": ["Jianrong Wang", "Jinyu Liu", "Longxuan Zhao", "Shanyu Wang", "Ruiguo Yu", "Li Liu"], "Sources": "ICASSP 2022-2022 IEEE International Conference on Acoustics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Acoustic-to-articulatory inversion (AAI) is to obtain the movement of articulators from speech signals. Until now, achieving a speaker-independent AAI remains a challenge given the limited data. Besides, most current works only use audio speech as input, causing an inevitable performance bottleneck. To solve these problems, firstly, we pre-train a speech decomposition network to decompose audio speech into speaker embedding and content embedding as the new personalized speech features to adapt to the speaker-independent case. Secondly, to further improve the AAI, we propose a novel auxiliary feature network to estimate the lip auxiliary features from the above personalized speech features. Experimental results on three public datasets show that, compared with the state-of-the-art only using the audio speech feature, the proposed method reduces the average RMSE by 0.25 and increases the average?\u2026", "IdName": "wang2022acoustic", "Citation": "", "Keywords": ""}, {"Name": "Hico: Hierarchical contrastive learning for ultrasound video model pretraining", "Authors": ["Chunhui Zhang", "Yixiong Chen", "Li Liu", "Qiong Liu", "Xi Zhou"], "Sources": "Proceedings of the Asian Conference on Computer Vision", "PublishedYears": "2022", "Doi": "", "Abstracts": "The self-supervised ultrasound (US) video model pretraining can use a small amount of labeled data to achieve one of the most promising results on US diagnosis. However, it does not take full advantage of multi-level knowledge for learning deep neural networks (DNNs), and thus is difficult to learn transferable feature representations. This work proposes a hierarchical contrastive learning (HiCo) method to improve the transferability for the US video model pretraining. HiCo introduces both peer-level semantic alignment and cross-level semantic alignment to facilitate the interaction between different semantic levels, which can effectively accelerate the convergence speed, leading to better generalization and adaptation of the learned model. Additionally, a softened objective function is implemented by smoothing the hard labels, which can alleviate the negative effect caused by local similarities of images between different classes. Experiments with HiCo on five datasets demonstrate its favorable results over state-of-the-art approaches. The source code of this work is publicly available at https://github. com/983632847/HiCo.", "IdName": "zhang2022hico", "Citation": "", "Keywords": ""}, {"Name": "Emotional Talking Head Generation based on Memory-Sharing and Attention-Augmented Networks", "Authors": ["Jianrong Wang", "Yaxin Zhao", "Li Liu", "Tianyi Xu", "Qi Li", "Sen Li"], "Sources": "Interspeech preprint arXiv:2306.03594", "PublishedYears": "2023", "Doi": "", "Abstracts": "Given an audio clip and a reference face image, the goal of the talking head generation is to generate a high-fidelity talking head video. Although some audio-driven methods of generating talking head videos have made some achievements in the past, most of them only focused on lip and audio synchronization and lack the ability to reproduce the facial expressions of the target person. To this end, we propose a talking head generation model consisting of a Memory-Sharing Emotion Feature extractor (MSEF) and an Attention-Augmented Translator based on U-net (AATU). Firstly, MSEF can extract implicit emotional auxiliary features from audio to estimate more accurate emotional face landmarks.~Secondly, AATU acts as a translator between the estimated landmarks and the photo-realistic video frames. Extensive qualitative and quantitative experiments have shown the superiority of the proposed method to the previous works. Codes will be made publicly available.", "IdName": "wang2023emotional", "Citation": "", "Keywords": ""}, {"Name": "Memory-augmented contrastive learning for talking head generation", "Authors": ["Jianrong Wang", "Yaxin Zhao", "Hongkai Fan", "Tianyi Xu", "Qi Li", "Sen Li", "Li Liu"], "Sources": "ICASSP 2023-2023 IEEE International Conference on Acoustics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Given one reference facial image and a piece of speech as input, talking head generation aims to synthesize a realistic-looking talking head video. However, generating a lip-synchronized video with natural head movements is challenging. The same speech clip can generate multiple possible lip and head movements, that is, there is no one-to-one mapping relationship between them. To overcome this problem, we propose a Speech Feature Extractor (SFE) based on memory-augmented self-supervised contrastive learning, which introduces the memory module to store multiple different speech mapping results. In addition, we introduce the Mixed Density Networks (MDN) into the landmark regression task to generate multiple predicted facial landmarks. Extensive qualitative and quantitative experiments show that the quality of our facial animation is significantly superior to that of the state-of-the-art (SOTA). The?\u2026", "IdName": "wang2023memory", "Citation": "", "Keywords": ""}, {"Name": "Attacks in adversarial machine learning: A systematic survey from the life-cycle perspective", "Authors": ["Baoyuan Wu", "Zihao Zhu", "Li Liu", "Qingshan Liu", "Zhaofeng He", "Siwei Lyu"], "Sources": "arXiv preprint arXiv:2302.09457", "PublishedYears": "2023", "Doi": "", "Abstracts": "Adversarial machine learning (AML) studies the adversarial phenomenon of machine learning, which may make inconsistent or unexpected predictions with humans. Some paradigms have been recently developed to explore this adversarial phenomenon occurring at different stages of a machine learning system, such as backdoor attack occurring at the pre-training, in-training and inference stage; weight attack occurring at the post-training, deployment and inference stage; adversarial attack occurring at the inference stage. However, although these adversarial paradigms share a common goal, their developments are almost independent, and there is still no big picture of AML. In this work, we aim to provide a unified perspective to the AML community to systematically review the overall progress of this field. We firstly provide a general definition about AML, and then propose a unified mathematical framework to covering existing attack paradigms. According to the proposed unified framework, we build a full taxonomy to systematically categorize and review existing representative methods for each paradigm. Besides, using this unified framework, it is easy to figure out the connections and differences among different attack paradigms, which may inspire future researchers to develop more advanced attack paradigms. Finally, to facilitate the viewing of the built taxonomy and the related literature in adversarial machine learning, we further provide a website, \\ie, \\url{http://adversarial-ml.com}, where the taxonomies and literature will be continuously updated.", "IdName": "wu2023attacks", "Citation": "", "Keywords": ""}, {"Name": "Ultrasound score combined with liver stiffness measurement by sound touch elastography for staging liver fibrosis in patients with chronic hepatitis B: a clinical prospective study", "Authors": ["Kun Huang", "Qinyuan Li", "Weimei Zeng", "Xin Chen", "Li Liu", "Xiang Wan", "Cheng Feng", "Zhiyan Li", "Zhong Liu", "Changfeng Dong"], "Sources": "Ann Transl Med 2022;10(6):271", "PublishedYears": "2022", "Doi": "", "Abstracts": "BackgroundA noninvasive and precise diagnosis of liver fibrosis in patients with chronic hepatitis B (CHB) is crucial for establishing the optimal time and strategy of therapy and for predicting treatment response. This study aimed to assess the diagnostic performance of ultrasound (US) score and liver stiffness measurement (LSM) of sound touch elastography (STE) in diagnosing liver fibrosis stages and to investigate whether combining these methods would improve liver fibrosis staging.MethodsUS and STE examinations were performed in CHB patients included. Liver biopsy was used as a reference standard. A diagnostic marker with the optimal linear combination (LC) of US score and LSM of STE, namely LC marker, was established for noninvasive assessment of liver fibrosis stages. The diagnostic performance of the LC marker was evaluated by using receiver operating characteristic (ROC) curves and the?\u2026", "IdName": "huang2022ultrasound", "Citation": "", "Keywords": ""}, {"Name": "An Attention Self-supervised Contrastive Learning based Three-stage Model for Hand Shape Feature Representation in Cued Speech", "Authors": ["Jianrong Wang", "Nan Gu", "Mei Yu", "Xuewei Li", "Qiang Fang", "Li Liu"], "Sources": "Interspeech 2021: https://arxiv.org/abs/2106.14016", "PublishedYears": "2021", "Doi": "", "Abstracts": "Cued Speech (CS) is a communication system for deaf people or hearing impaired people, in which a speaker uses it to aid a lipreader in phonetic level by clarifying potentially ambiguous mouth movements with hand shape and positions. Feature extraction of multi-modal CS is a key step in CS recognition. Recent supervised deep learning based methods suffer from noisy CS data annotations especially for hand shape modality. In this work, we first propose a self-supervised contrastive learning method to learn the feature representation of image without using labels. Secondly, a small amount of manually annotated CS data are used to fine-tune the first module. Thirdly, we present a module, which combines Bi-LSTM and self-attention networks to further learn sequential features with temporal and contextual information. Besides, to enlarge the volume and the diversity of the current limited CS datasets, we build a new British English dataset containing 5 native CS speakers. Evaluation results on both French and British English datasets show that our model achieves over 90% accuracy in hand shape recognition. Significant improvements of 8.75% (for French) and 10.09% (for British English) are achieved in CS phoneme recognition correctness compared with the state-of-the-art.", "IdName": "wang2021attention", "Citation": "", "Keywords": ""}, {"Name": "Cuing Without Sharing: A Federated Cued Speech Recognition Framework via Mutual Knowledge Distillation", "Authors": ["Yuxuan Zhang", "Lei Liu", "Li Liu"], "Sources": "ACM MM preprint arXiv:2308.03432", "PublishedYears": "2023", "Doi": "", "Abstracts": "Cued Speech (CS) is a visual coding tool to encode spoken languages at the phonetic level, which combines lip-reading and hand gestures to effectively assist communication among people with hearing impairments. The Automatic CS Recognition (ACSR) task aims to recognize CS videos into linguistic texts, which involves both lips and hands as two distinct modalities conveying complementary information. However, the traditional centralized training approach poses potential privacy risks due to the use of facial and gesture videos in CS data. To address this issue, we propose a new Federated Cued Speech Recognition (FedCSR) framework to train an ACSR model over the decentralized CS data without sharing private information. In particular, a mutual knowledge distillation method is proposed to maintain cross-modal semantic consistency of the Non-IID CS data, which ensures learning a unified feature?\u2026", "IdName": "zhang2023cuing", "Citation": "", "Keywords": ""}, {"Name": "Objective Hand Complexity Comparison between Two Mandarin Chinese Cued Speech Systems", "Authors": ["Li Liu", "Gang Feng", "Xiaoxi Ren", "Xianping Ma"], "Sources": "ISCSLP 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recently, a pilot Mandarin Chinese Cued Speech (MCCS) system, called MCCS-1 was proposed with a main characteristic that each vowel is coded by only one specific hand position, without using any hand slides to code diphthongs. Indeed, hand slides are also used in some other languages of CS to code diphthongs. In order to demonstrate that the MCCS-1 system possesses real advantages over systems using hand slides, in this work, we first propose a novel MCCS-2 by introducing hand slides to code diphthongs, and a \u201cpush out move\u201d for ending consonants [n] or [ng] of nasalized vowels. Then, we present a multi-parameter hand complexity measure method to compare MCCS-1 and MCCS-2 by measuring three kinematic parameters, which are the time duration of words realization, hand move trajectory length and average speed of hand movements. Moreover, the first MCCS corpus for these two systems?\u2026", "IdName": "liu2022objective", "Citation": "", "Keywords": ""}, {"Name": "Learning Class Unique Features in Fine-Grained Visual Classification", "Authors": ["Runkai Zheng", "Zhijia Yu", "Yinqi Zhang", "Chris Ding", "Hei Victor Cheng", "Li Liu"], "Sources": "https://arxiv.org/abs/2011.10951", "PublishedYears": "2021", "Doi": "", "Abstracts": "A major challenge in Fine-Grained Visual Classification (FGVC) is distinguishing various categories with high inter-class similarity by learning the feature that differentiate the details. Conventional cross entropy trained Convolutional Neural Network (CNN) fails this challenge as it may suffer from producing inter-class invariant features in FGVC. In this work, we innovatively propose to regularize the training of CNN by enforcing the uniqueness of the features to each category from an information theoretic perspective. To achieve this goal, we formulate a minimax loss based on a game theoretic framework, where a Nash equilibria is proved to be consistent with this regularization objective. Besides, to prevent from a feasible solution of minimax loss that may produce redundant features, we present a Feature Redundancy Loss (FRL) based on normalized inner product between each selected feature map pair to complement the proposed minimax loss. Superior experimental results on several influential benchmarks along with visualization show that our method gives full play to the performance of the baseline model without additional computation and achieves comparable results with state-of-the-art models.", "IdName": "zheng2020learning", "Citation": "", "Keywords": ""}, {"Name": "Computation and parameter efficient multi-modal fusion transformer for cued speech recognition", "Authors": ["Lei Liu", "Li Liu", "Haizhou Li"], "Sources": "IEEE/ACM Transactions on Audio", "PublishedYears": "2024", "Doi": "", "Abstracts": "Cued Speech (CS) is a pure visual coding method used by hearing-impaired people that combines lip reading with several specific hand shapes to make the spoken language visible. Automatic CS recognition (ACSR) seeks to transcribe visual cues of speech into text, which can help hearing-impaired people to communicate effectively. The visual information of CS contains lip reading and hand cueing, thus the fusion of them plays an important role in ACSR. However, most previous fusion methods struggle to capture the global dependency present in long sequence inputs of multi-modal CS data. As a result, these methods generally fail to learn the effective cross-modal relationships that contribute to the fusion. Recently, attention-based transformers have been a prevalent idea for capturing the global dependency over the long sequence in multi-modal fusion, but existing multi-modal fusion transformers suffer from both?\u2026", "IdName": "liu2024computation", "Citation": "", "Keywords": ""}, {"Name": "Three-dimensional lip motion network for text-independent speaker recognition", "Authors": ["Jianrong Wang", "Tong Wu", "Shanyu Wang", "Mei Yu", "Qiang Fang", "Ju Zhang", "Li Liu"], "Sources": "2020 25th International Conference on Pattern Recognition (ICPR)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Lip motion reflects behavior characteristics of speakers, and thus can be used as a new kind of biometrics in speaker recognition. In the literature, lots of works used two-dimensional (2D) lip images to recognize speaker in a text-dependent context. However, 2D lip easily suffers from various face orientations. To this end, in this work, we present a novel end-to-end 3D lip motion Network (3LMNet) by utilizing the sentence-level 3D lip motion (S3DLM) to recognize speakers in both the text-independent and text-dependent contexts. A new regional feedback module (RFM) is proposed to obtain attentions in different lip regions. Besides, prior knowledge of lip motion is investigated to complement RFM, where landmark-level and frame-level features are merged to form a better feature representation. Moreover, we present two methods, i.e., coordinate transformation and face posture correction to pre-process the LSD-AV?\u2026", "IdName": "wang2021three", "Citation": "", "Keywords": ""}, {"Name": "All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment", "Authors": ["Chunhui Zhang", "Xin Sun", "Li Liu", "Yiqian Yang", "Qiong Liu", "Xi Zhou", "Yanfeng Wang"], "Sources": "ACM MM preprint arXiv:2307.03373", "PublishedYears": "2023", "Doi": "", "Abstracts": "Current mainstream vision-language (VL) tracking framework consists of three parts,i.e., a visual feature extractor, a language feature extractor, and a fusion model. To pursue better performance, a natural modus operandi for VL tracking is employing customized and heavier unimodal encoders, and multi-modal fusion models. Albeit effective, existing VL trackers separate feature extraction and feature integration, resulting in extracted features that lack semantic guidance and have limited target-aware capability in complex scenarios, e.g., similar distractors and extreme illumination. In this work, inspired by the recent success of exploring foundation models with unified architecture for both natural language and computer vision tasks, we propose an All-in-One framework, which learns joint feature extraction and interaction by adopting a unified transformer backbone. Specifically, we mix raw vision and language?\u2026", "IdName": "zhang2023all", "Citation": "", "Keywords": ""}, {"Name": "A Novel Interpretable and Generalizable Re-synchronization Model for Cued Speech based on a Multi-Cuer Corpus", "Authors": ["Lufei Gao", "Shan Huang", "Li Liu"], "Sources": "Interspeech", "PublishedYears": "2023", "Doi": "", "Abstracts": "Cued Speech (CS) is a multi-modal visual coding system combining lip reading with several hand cues at the phonetic level to make the spoken language visible to the hearing impaired. Previous studies solved asynchronous problems between lip and hand movements by a cuer\\footnote{The people who perform Cued Speech are called the cuer.}-dependent piecewise linear model for English and French CS. In this work, we innovatively propose three statistical measure on the lip stream to build an interpretable and generalizable model for predicting hand preceding time (HPT), which achieves cuer-independent by a proper normalization. Particularly, we build the first Mandarin CS corpus comprising annotated videos from five speakers including three normal and two hearing impaired individuals. Consequently, we show that the hand preceding phenomenon exists in Mandarin CS production with significant differences between normal and hearing impaired people. Extensive experiments demonstrate that our model outperforms the baseline and the previous state-of-the-art methods.", "IdName": "gao2023novel", "Citation": "", "Keywords": ""}, {"Name": "Two-Stream Joint-Training for Speaker Independent Acoustic-to-Articulatory Inversion", "Authors": ["Jianrong Wang", "Jinyu Liu", "Xuewei Li", "Mei Yu", "Jie Gao", "Qiang Fang", "Li Liu"], "Sources": "ICASSP 2023-2023 IEEE International Conference on Acoustics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Acoustic-to-articulatory inversion (AAI) aims to estimate the parameters of articulators from speech audio. There are two common challenges in AAI, which are the limited data and the unsatisfactory performance in speaker independent scenario. Most current works focus on extracting features directly from speech and ignoring the importance of phoneme information which may limit the performance of AAI. To this end, we propose a novel network called SPN that uses two different streams to carry out the AAI task. Firstly, to improve the performance of speaker-independent experiment, we propose a new phoneme stream network to estimate the articulatory parameters as the phoneme features. To the best of our knowledge, this is the first work that extracts the speaker-independent features from phonemes to improve the performance of AAI. Secondly, in order to better represent the speech information, we train a?\u2026", "IdName": "wang2023two", "Citation": "", "Keywords": ""}, {"Name": "Global Balanced Experts for Federated Long-Tailed Learning", "Authors": ["Yaopei Zeng", "Lei Liu", "Li Liu", "Li Shen", "Shaoguo Liu", "Baoyuan Wu"], "Sources": "Proceedings of the IEEE/CVF International Conference on Computer Vision?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Federated learning (FL) is a prevalent distributed machine learning approach that enables collaborative training of a global model across multiple devices without sharing local data. However, the presence of long-tailed data can negatively deteriorate the model's performance in real-world FL applications. Moreover, existing re-balance strategies are less effective for the federated long-tailed issue when directly utilizing local label distribution as the class prior at the clients' side. To this end, we propose a novel Global Balanced Multi-Expert (GBME) framework to optimize a balanced global objective, which does not require additional information beyond the standard FL pipeline. In particular, a proxy is derived from the accumulated gradients uploaded by the clients after local training, and is shared by all clients as the class prior for re-balance training. Such a proxy can also guide the client grouping to train a multi-expert model, where the knowledge from different clients can be aggregated via the ensemble of different experts corresponding to different client groups. To further strengthen the privacy-preserving ability, we present a GBME-p algorithm with a theoretical guarantee to prevent privacy leakage from the proxy. Extensive experiments on long-tailed decentralized datasets demonstrate the effectiveness of GBME and GBME-p, both of which show superior performance to state-of-the-art methods.", "IdName": "zeng2023global", "Citation": "", "Keywords": ""}, {"Name": "TAOTF: A Two-stage Approximately Orthogonal Training Framework in Deep Neural Networks", "Authors": ["Taoyong Cui", "Jianze Li", "Yuhan Dong", "Li Liu"], "Sources": "ECAI 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "The orthogonality constraints, including the hard and soft ones, have been used to normalize the weight matrices of Deep Neural Network (DNN) models, especially the Convolutional Neural Network (CNN) and Vision Transformer (ViT), to reduce model parameter redundancy and improve training stability. However, the robustness to noisy data of these models with constraints is not always satisfactory. In this work, we propose a novel two-stage approximately orthogonal training framework (TAOTF) to find a trade-off between the orthogonal solution space and the main task solution space to solve this problem in noisy data scenarios. In the first stage, we propose a novel algorithm called polar decomposition-based orthogonal initialization (PDOI) to find a good initialization for the orthogonal optimization. In the second stage, unlike other existing methods, we apply soft orthogonal constraints for all layers of DNN?\u2026", "IdName": "cui2023taotf", "Citation": "", "Keywords": ""}, {"Name": "MAVD: The First Open Large-Scale Mandarin Audio-Visual Dataset with Depth Information", "Authors": ["Jianrong Wang", "Yuchen Huo", "Li Liu", "Tianyi Xu", "Qi Li", "Sen Li"], "Sources": "Interspeech preprint arXiv:2306.02263", "PublishedYears": "2023", "Doi": "", "Abstracts": "Audio-visual speech recognition (AVSR) gains increasing attention from researchers as an important part of human-computer interaction. However, the existing available Mandarin audio-visual datasets are limited and lack the depth information. To address this issue, this work establishes the MAVD, a new large-scale Mandarin multimodal corpus comprising 12,484 utterances spoken by 64 native Chinese speakers. To ensure the dataset covers diverse real-world scenarios, a pipeline for cleaning and filtering the raw text material has been developed to create a well-balanced reading material. In particular, the latest data acquisition device of Microsoft, Azure Kinect is used to capture depth information in addition to the traditional audio signals and RGB images during data acquisition. We also provide a baseline experiment, which could be used to evaluate the effectiveness of the dataset. The dataset and code will be released at https://github.com/SpringHuo/MAVD.", "IdName": "wang2023mavd", "Citation": "", "Keywords": ""}, {"Name": "Investigate the Essence of Long-Tailed Recognition from a Unified Perspective", "Authors": ["Lei Liu", "Li Liu"], "Sources": "https://arxiv.org/abs/2107.03758", "PublishedYears": "2021", "Doi": "", "Abstracts": "As the data scale grows, deep recognition models often suffer from long-tailed data distributions due to the heavy imbalanced sample number across categories. Indeed, real-world data usually exhibit some similarity relation among different categories (eg, pigeons and sparrows), called category similarity in this work. It is doubly difficult when the imbalance occurs between such categories with similar appearances. However, existing solutions mainly focus on the sample number to re-balance data distribution. In this work, we systematically investigate the essence of the long-tailed problem from a unified perspective. Specifically, we demonstrate that long-tailed recognition suffers from both sample number and category similarity. Intuitively, using a toy example, we first show that sample number is not the unique influence factor for performance dropping of long-tailed recognition. Theoretically, we demonstrate that (1) category similarity, as an inevitable factor, would also influence the model learning under long-tailed distribution via similar samples,(2) using more discriminative representation methods (eg, self-supervised learning) for similarity reduction, the classifier bias can be further alleviated with greatly improved performance. Extensive experiments on several long-tailed datasets verify the rationality of our theoretical analysis, and show that based on existing state-of-the-arts (SOTAs), the performance could be further improved by similarity reduction. Our investigations highlight the essence behind the long-tailed problem, and claim several feasible directions for future work.", "IdName": "liu2021investigate", "Citation": "", "Keywords": ""}, {"Name": "Towards Class-Specific Unit", "Authors": ["Runkai Zheng", "Zhijia Yu", "Yinqi Zhang", "Chris Ding", "Hei Victor Cheng", "Li Liu"], "Sources": "CoRR", "PublishedYears": "2020", "Doi": "", "Abstracts": "Class selectivity is an attribute of a unit in deep neural networks, which characterizes the discriminative ability of units to a specific class. Intuitively, decisions made by several highly selective units are more interpretable since it is easier to be traced back to the origin while that made by complex combinations of lowly selective units are more difficult to interpret. In this work, we develop a novel way to directly train highly selective units, through which we are able to examine the performance of a network that only rely on highly selective units. Specifically, we train the network such that all the units in the penultimate layer only response to one specific class, which we named as class-specific unit. By innovatively formulating the problem using mutual information, we find that in such a case, the output of the model has a special form that all the probabilities over non-target classes are uniformly distributed. We then propose a minimax loss based on a game theoretic framework to achieve the goal. Nash equilibria are proved to exist and the outcome is consistent with our regularization objective. Experimental results show that the model trained with the proposed objective outperforms models trained with baseline objective among all the tasks we test. Our results shed light on the role of class-specific units by indicating that they can be directly used for decisions without relying on low selective units.", "IdName": "zheng2020towards", "Citation": "", "Keywords": ""}, {"Name": "WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark", "Authors": ["Chunhui Zhang", "Li Liu", "Guanjie Huang", "Hao Wen", "Xi Zhou", "Yanfeng Wang"], "Sources": "arXiv preprint arXiv:2405.19818", "PublishedYears": "2024", "Doi": "", "Abstracts": "Underwater object tracking (UOT) is a foundational task for identifying and tracing submerged entities in underwater video sequences. However, current UOT datasets suffer from limitations in scale, diversity of target categories and scenarios covered, hindering the training and evaluation of modern tracking algorithms. To bridge this gap, we take the first step and introduce WebUOT-1M, \\ie, the largest public UOT benchmark to date, sourced from complex and realistic underwater environments. It comprises 1.1 million frames across 1,500 video clips filtered from 408 target categories, largely surpassing previous UOT datasets, \\eg, UVOT400. Through meticulous manual annotation and verification, we provide high-quality bounding boxes for underwater targets. Additionally, WebUOT-1M includes language prompts for video sequences, expanding its application areas, \\eg, underwater vision-language tracking. Most existing trackers are tailored for open-air environments, leading to performance degradation when applied to UOT due to domain gaps. Retraining and fine-tuning these trackers are challenging due to sample imbalances and limited real-world underwater datasets. To tackle these challenges, we propose a novel omni-knowledge distillation framework based on WebUOT-1M, incorporating various strategies to guide the learning of the student Transformer. To the best of our knowledge, this framework is the first to effectively transfer open-air domain knowledge to the UOT model through knowledge distillation, as demonstrated by results on both existing UOT datasets and the newly proposed WebUOT-1M. Furthermore, we?\u2026", "IdName": "zhang2024webuot", "Citation": "", "Keywords": ""}, {"Name": "Awesome Multi-modal Object Tracking", "Authors": ["Chunhui Zhang", "Li Liu", "Hao Wen", "Xi Zhou", "Yanfeng Wang"], "Sources": "arXiv preprint arXiv:2405.14200", "PublishedYears": "2024", "Doi": "", "Abstracts": "Multi-modal object tracking (MMOT) is an emerging field that combines data from various modalities, \\eg vision (RGB), depth, thermal infrared, event, language and audio, to estimate the state of an arbitrary object in a video sequence. It is of great significance for many applications such as autonomous driving and intelligent surveillance. In recent years, MMOT has received more and more attention. However, existing MMOT algorithms mainly focus on two modalities (\\eg RGB+depth, RGB+thermal infrared, and RGB+language). To leverage more modalities, some recent efforts have been made to learn a unified visual object tracking model for any modality. Additionally, some large-scale multi-modal tracking benchmarks have been established by simultaneously providing more than two modalities, such as vision-language-audio (\\eg WebUAV-3M) and vision-depth-language (\\eg UniMod1K). To track the latest progress in MMOT, we conduct a comprehensive investigation in this report. Specifically, we first divide existing MMOT tasks into five main categories, \\ie RGBL tracking, RGBE tracking, RGBD tracking, RGBT tracking, and miscellaneous (RGB+X), where X can be any modality, such as language, depth, and event. Then, we analyze and summarize each MMOT task, focusing on widely used datasets and mainstream tracking algorithms based on their technical paradigms (\\eg self-supervised learning, prompt learning, knowledge distillation, generative models, and state space models). Finally, we maintain a continuously updated paper list for MMOT at https://github.com/983632847/Awesome-Multimodal-Object-Tracking.", "IdName": "zhang2024awesome", "Citation": "", "Keywords": ""}, {"Name": "Bridge to Non-Barrier Communication: Gloss-Prompted Fine-grained Cued Speech Gesture Generation with Diffusion Model", "Authors": ["Wentao Lei", "Li Liu", "Jun Wang"], "Sources": "IJCAI 2024: arXiv preprint arXiv:2404.19277", "PublishedYears": "2024", "Doi": "", "Abstracts": "Cued Speech (CS) is an advanced visual phonetic encoding system that integrates lip reading with hand codings, enabling people with hearing impairments to communicate efficiently. CS video generation aims to produce specific lip and gesture movements of CS from audio or text inputs. The main challenge is that given limited CS data, we strive to simultaneously generate fine-grained hand and finger movements, as well as lip movements, meanwhile the two kinds of movements need to be asynchronously aligned. Existing CS generation methods are fragile and prone to poor performance due to template-based statistical models and careful hand-crafted pre-processing to fit the models. Therefore, we propose a novel Gloss-prompted Diffusion-based CS Gesture generation framework (called GlossDiff). Specifically, to integrate additional linguistic rules knowledge into the model. we first introduce a bridging instruction called \\textbf{Gloss}, which is an automatically generated descriptive text to establish a direct and more delicate semantic connection between spoken language and CS gestures. Moreover, we first suggest rhythm is an important paralinguistic feature for CS to improve the communication efficacy. Therefore, we propose a novel Audio-driven Rhythmic Module (ARM) to learn rhythm that matches audio speech. Moreover, in this work, we design, record, and publish the first Chinese CS dataset with four CS cuers. Extensive experiments demonstrate that our method quantitatively and qualitatively outperforms current state-of-the-art (SOTA) methods. We release the code and data at https://glossdiff.github.io/.", "IdName": "lei2024bridge", "Citation": "", "Keywords": ""}, {"Name": "Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks", "Authors": ["Danni Yuan", "Shaokui Wei", "Mingda Zhang", "Li Liu", "Baoyuan Wu"], "Sources": "arXiv preprint arXiv:2312.06230", "PublishedYears": "2023", "Doi": "", "Abstracts": "This work focuses on defending against the data poisoning based backdoor attacks, which bring in serious security threats to deep neural networks (DNNs). Specifically, given a untrustworthy training dataset, we aim to filter out potential poisoned samples, \\ie, poisoned sample detection (PSD). The key solution for this task is to find a discriminative metric between clean and poisoned samples, even though there is no information about the potential poisoned samples (\\eg, the attack method, the poisoning ratio). In this work, we develop an innovative detection approach from the perspective of the gradient \\wrt activation (\\ie, activation gradient direction, AGD) of each sample in the backdoored model trained on the untrustworthy dataset. We present an interesting observation that the circular distribution of AGDs among all samples of the target class is much more dispersed than that of one clean class. Motivated by this observation, we firstly design a novel metric called Cosine similarity Variation towards Basis Transition (CVBT) to measure the circular distribution's dispersion of each class. Then, we design a simple yet effective algorithm with identifying the target class(es) using outlier detection on CVBT scores of all classes, followed by progressively filtering of poisoned samples according to the cosine similarities of AGDs between every potential sample and a few additional clean samples. Extensive experiments under various settings verify that given very few clean samples of each class, the proposed method could filter out most poisoned samples, while avoiding filtering out clean samples, verifying its effectiveness on the PSD task. Codes are?\u2026", "IdName": "yuan2023activation", "Citation": "", "Keywords": ""}, {"Name": "A Survey on Deep Multi-modal Learning for Body Language Recognition and Generation", "Authors": ["Li Liu", "Lufei Gao", "Wentao Lei", "Fengji Ma", "Xiaotian Lin", "Jinting Wang"], "Sources": "arXiv preprint arXiv:2308.08849", "PublishedYears": "2023", "Doi": "", "Abstracts": "Body language (BL) refers to the non-verbal communication expressed through physical movements, gestures, facial expressions, and postures. It is a form of communication that conveys information, emotions, attitudes, and intentions without the use of spoken or written words. It plays a crucial role in interpersonal interactions and can complement or even override verbal communication. Deep multi-modal learning techniques have shown promise in understanding and analyzing these diverse aspects of BL. The survey emphasizes their applications to BL generation and recognition. Several common BLs are considered i.e., Sign Language (SL), Cued Speech (CS), Co-speech (CoS), and Talking Head (TH), and we have conducted an analysis and established the connections among these four BL for the first time. Their generation and recognition often involve multi-modal approaches. Benchmark datasets for BL research are well collected and organized, along with the evaluation of SOTA methods on these datasets. The survey highlights challenges such as limited labeled data, multi-modal learning, and the need for domain adaptation to generalize models to unseen speakers or languages. Future research directions are presented, including exploring self-supervised learning techniques, integrating contextual information from other modalities, and exploiting large-scale pre-trained multi-modal models. In summary, this survey paper provides a comprehensive understanding of deep multi-modal learning for various BL generations and recognitions for the first time. By analyzing advancements, challenges, and future directions, it serves as a?\u2026", "IdName": "liu2023survey", "Citation": "", "Keywords": ""}, {"Name": "Spatio-Temporal Structure Consistency for Semi-Supervised Medical Image Classification", "Authors": ["Wentao Lei", "Lei Liu", "Li Liu"], "Sources": "ICASSP 2023-2023 IEEE International Conference on Acoustics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Intelligent medical diagnosis has shown remarkable progress on the large-scale datasets with full annotations. However, very few labeled images are available due to significantly expensive annotations by experts. To efficiently leverage abundant unlabeled data, we propose a novel Spatio-Temporal Structure Consistent (STSC) learning framework to combine both spatial and temporal structure consistency. Specifically, a gram matrix is derived to capture the structural similarity among different training samples in the representation space. At the spatial level, our framework explicitly enforces the consistency of structural similarity among different samples under perturbations. At the temporal level, we desire to maintain the consistency of the structural similarity in different training iterations by digging out the stable sub-structures in a relation graph. Experiments on two medical image datasets (i.e., ISIC 2018 and?\u2026", "IdName": "lei2023spatio", "Citation": "", "Keywords": ""}, {"Name": "Label-distribution-agnostic ensemble learning on federated long-tailed data", "Authors": ["Yaopei Zeng", "Lei Liu", "Baoyuan Wu", "ShaoGuo Liu", "Li Liu"], "Sources": "", "PublishedYears": "2023", "Doi": "", "Abstracts": "Federated Learning (FL) is a distributed machine learning paradigm that enables devices to collaboratively train a shared model. However, the long-tailed distribution in nature deteriorates the performance of the global model, which is difficult to address due to data heterogeneity, e.g., local clients may exhibit diverse imbalanced class distributions. Moreover, existing re-balance strategies generally utilize label distribution as the class prior, which may conflict with the privacy requirement of FL. To this end, we propose a Label-Distribution-Agnostic Ensemble (LDAE) learning framework to integrate heterogeneous data distributions using multiple experts, which targets to optimize a balanced global objective under privacy protection. In particular, we derive a privacy-preserving proxy from the model updates of clients to guide the grouping and updating of multiple experts. Knowledge from clients can be aggregated via implicit interactions among different expert groups. We theoretically and experimentally demonstrate that (1) there is a global objective gap between global and local re-balance strategies\\footnote{The local re-balance strategy means that each client utilizes re-balance methods based on the local label distribution, while the global re-balance strategy applies re-balance methods using global label distribution as the class-wise prior.} and (2) with protecting data privacy, the proxy can be used as an alternative to label distribution for existing class prior based re-balance strategies. Extensive experiments on long-tailed decentralized datasets demonstrate the effectiveness of our method, showing superior performance to state-of-the-art?\u2026", "IdName": "zeng2023label", "Citation": "", "Keywords": ""}, {"Name": "Rethinking Two Consensuses of the Transferability in Deep Learning", "Authors": ["Yixiong Chen", "Jingxian Li", "Chris Ding", "Li Liu"], "Sources": "arXiv preprint arXiv:2212.00399", "PublishedYears": "2022", "Doi": "", "Abstracts": "Deep transfer learning (DTL) has formed a long-term quest toward enabling deep neural networks (DNNs) to reuse historical experiences as efficiently as humans. This ability is named knowledge transferability. A commonly used paradigm for DTL is firstly learning general knowledge (pre-training) and then reusing (fine-tuning) them for a specific target task. There are two consensuses of transferability of pre-trained DNNs: (1) a larger domain gap between pre-training and downstream data brings lower transferability; (2) the transferability gradually decreases from lower layers (near input) to higher layers (near output). However, these consensuses were basically drawn from the experiments based on natural images, which limits their scope of application. This work aims to study and complement them from a broader perspective by proposing a method to measure the transferability of pre-trained DNN parameters. Our experiments on twelve diverse image classification datasets get similar conclusions to the previous consensuses. More importantly, two new findings are presented, i.e., (1) in addition to the domain gap, a larger data amount and huge dataset diversity of downstream target task also prohibit the transferability; (2) although the lower layers learn basic image features, they are usually not the most transferable layers due to their domain sensitivity.", "IdName": "chen2022rethinking", "Citation": "", "Keywords": ""}, {"Name": "A Comprehensive Survey on Human Video Generation: Challenges, Methods, and Insights", "Authors": ["Wentao Lei", "Jinting Wang", "Fengji Ma", "Guanjie Huang", "Li Liu"], "Sources": "arXiv preprint arXiv:2407.08428", "PublishedYears": "2024", "Doi": "", "Abstracts": "Human video generation is a dynamic and rapidly evolving task that aims to synthesize 2D human body video sequences with generative models given control conditions such as text, audio, and pose. With the potential for wide-ranging applications in film, gaming, and virtual communication, the ability to generate natural and realistic human video is critical. Recent advancements in generative models have laid a solid foundation for the growing interest in this area. Despite the significant progress, the task of human video generation remains challenging due to the consistency of characters, the complexity of human motion, and difficulties in their relationship with the environment. This survey provides a comprehensive review of the current state of human video generation, marking, to the best of our knowledge, the first extensive literature review in this domain. We start with an introduction to the fundamentals of human video generation and the evolution of generative models that have facilitated the field's growth. We then examine the main methods employed for three key sub-tasks within human video generation: text-driven, audio-driven, and pose-driven motion generation. These areas are explored concerning the conditions that guide the generation process. Furthermore, we offer a collection of the most commonly utilized datasets and the evaluation metrics that are crucial in assessing the quality and realism of generated videos. The survey concludes with a discussion of the current challenges in the field and suggests possible directions for future research. The goal of this survey is to offer the research community a clear and holistic view of the?\u2026", "IdName": "lei2024comprehensive", "Citation": "", "Keywords": ""}, {"Name": "Unveiling and Mitigating Backdoor Vulnerabilities based on Unlearning Weight Changes and Backdoor Activeness", "Authors": ["Weilin Lin", "Li Liu", "Shaokui Wei", "Jianze Li", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2405.20291", "PublishedYears": "2024", "Doi": "", "Abstracts": "The security threat of backdoor attacks is a central concern for deep neural networks (DNNs). Recently, without poisoned data, unlearning models with clean data and then learning a pruning mask have contributed to backdoor defense. Additionally, vanilla fine-tuning with those clean data can help recover the lost clean accuracy. However, the behavior of clean unlearning is still under-explored, and vanilla fine-tuning unintentionally induces back the backdoor effect. In this work, we first investigate model unlearning from the perspective of weight changes and gradient norms, and find two interesting observations in the backdoored model: 1) the weight changes between poison and clean unlearning are positively correlated, making it possible for us to identify the backdoored-related neurons without using poisoned data; 2) the neurons of the backdoored model are more active (i.e., larger changes in gradient norm) than those in the clean model, suggesting the need to suppress the gradient norm during fine-tuning. Then, we propose an effective two-stage defense method. In the first stage, an efficient Neuron Weight Change (NWC)-based Backdoor Reinitialization is proposed based on observation 1). In the second stage, based on observation 2), we design an Activeness-Aware Fine-Tuning to replace the vanilla fine-tuning. Extensive experiments, involving eight backdoor attacks on three benchmark datasets, demonstrate the superior performance of our proposed method compared to recent state-of-the-art backdoor defense approaches.", "IdName": "lin2024unveiling", "Citation": "", "Keywords": ""}, {"Name": "TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial Robustness and Generalization Ability", "Authors": ["Fengji Ma", "Li Liu", "Hei Victor Cheng"], "Sources": "arXiv preprint arXiv:2405.17678", "PublishedYears": "2024", "Doi": "", "Abstracts": "This work addresses the challenge of achieving zero-shot adversarial robustness while preserving zero-shot generalization in large-scale foundation models, with a focus on the popular Contrastive Language-Image Pre-training (CLIP). Although foundation models were reported to have exceptional zero-shot generalization, they are highly vulnerable to adversarial perturbations. Existing methods achieve a comparable good tradeoff between zero-shot adversarial robustness and generalization under small adversarial perturbations. However, they fail to achieve a good tradeoff under large adversarial perturbations. To this end, we propose a novel Text-Image Mutual Awareness (TIMA) method that strikes a balance between zero-shot adversarial robustness and generalization. More precisely, we propose an Image-Aware Text (IAT) tuning mechanism that increases the inter-class distance of text embeddings by incorporating the Minimum Hyperspherical Energy (MHE). Simultaneously, fixed pre-trained image embeddings are used as cross-modal auxiliary supervision to maintain the similarity between the MHE-tuned and original text embeddings by the knowledge distillation, preserving semantic information between different classes. Besides, we introduce a Text-Aware Image (TAI) tuning mechanism, which increases inter-class distance between image embeddings during the training stage by Text-distance based Adaptive Margin (TAM). Similarly, a knowledge distillation is utilized to retain the similarity between fine-tuned and pre-trained image embeddings. Extensive experimental results demonstrate the effectiveness of our approach?\u2026", "IdName": "ma2024tima", "Citation": "", "Keywords": ""}, {"Name": "Leveraging Noisy Labels of Nearest Neighbors for Label Correction and Sample Selection", "Authors": ["Hua Jiang", "Yixiong Chen", "Li Liu", "Xiaoguang Han", "Xiao-Ping Zhang"], "Sources": "ICASSP 2024-2024 IEEE International Conference on Acoustics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Dealing with noisy labels (LNL) emerges as a critical challenge when applying deep learning (DL) in practical settings. Previous methodologies primarily concentrated on harnessing model predictions to mitigate the impact of noisy labels. Nevertheless, their efficacy is strongly contingent on the accuracy of model predictions, a factor that cannot be assured in the context of LNL. Our empirical analysis shows that in noisy datasets, the spatial information of latent feature representation combined with original noisy labels is more robust than the methods using model predictions. To mitigate the unreliability introduced by model predictions, we propose a novel Feature Representation method, which utilizes noisy labels of nearest neighbors for label Correction and sample Selection (FRCS). Extensive experiments on various benchmark datasets demonstrate the superiority of FRCS compared with SOTA methods. Our?\u2026", "IdName": "jiang2024leveraging", "Citation": "", "Keywords": ""}, {"Name": "BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning", "Authors": ["Baoyuan Wu", "Hongrui Chen", "Mingda Zhang", "Zihao Zhu", "Shaokui Wei", "Danni Yuan", "Mingli Zhu", "Ruotong Wang", "Li Liu", "Chao Shen"], "Sources": "arXiv preprint arXiv:2401.15002", "PublishedYears": "2024", "Doi": "", "Abstracts": "As an emerging and vital topic for studying deep neural networks' vulnerability (DNNs), backdoor learning has attracted increasing interest in recent years, and many seminal backdoor attack and defense algorithms are being developed successively or concurrently, in the status of a rapid arms race. However, mainly due to the diverse settings, and the difficulties of implementation and reproducibility of existing works, there is a lack of a unified and standardized benchmark of backdoor learning, causing unfair comparisons, and unreliable conclusions (e.g., misleading, biased or even false conclusions). Consequently, it is difficult to evaluate the current progress and design the future development roadmap of this literature. To alleviate this dilemma, we build a comprehensive benchmark of backdoor learning called BackdoorBench. Our benchmark makes three valuable contributions to the research community. 1) We provide an integrated implementation of state-of-the-art (SOTA) backdoor learning algorithms (currently including 16 attack and 27 defense algorithms), based on an extensible modular-based codebase. 2) We conduct comprehensive evaluations of 12 attacks against 16 defenses, with 5 poisoning ratios, based on 4 models and 4 datasets, thus 11,492 pairs of evaluations in total. 3) Based on above evaluations, we present abundant analysis from 8 perspectives via 18 useful analysis tools, and provide several inspiring insights about backdoor learning. We hope that our efforts could build a solid foundation of backdoor learning to facilitate researchers to investigate existing algorithms, develop more innovative algorithms, and explore?\u2026", "IdName": "wu2024backdoorbench", "Citation": "", "Keywords": ""}, {"Name": "WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition", "Authors": ["Zhengyao Song", "Yongqiang Li", "Danni Yuan", "Li Liu", "Shaokui Wei", "Baoyuan Wu"], "Sources": "arXiv preprint arXiv:2401.13578", "PublishedYears": "2024", "Doi": "", "Abstracts": "This work explores an emerging security threat against deep neural networks (DNNs) based image classification, i.e., backdoor attack. In this scenario, the attacker aims to inject a backdoor into the model by manipulating training data, such that the backdoor could be activated by a particular trigger and bootstraps the model to make a target prediction at inference. Currently, most existing data poisoning-based attacks struggle to achieve success at low poisoning ratios, increasing the risk of being defended by defense methods. In this paper, we propose a novel frequency-based backdoor attack via Wavelet Packet Decomposition (WPD), WPD decomposes the original image signal to a spectrogram that contains frequency information with different semantic meanings. We leverage WPD to statistically analyze the frequency distribution of the dataset to infer the key frequency regions the DNNs would focus on, and the trigger information is only injected into the key frequency regions. Our method mainly includes three parts: 1) the selection of the poisoning frequency regions in spectrogram; 2) trigger generation; 3) the generation of the poisoned dataset. Our method is stealthy and precise, evidenced by the 98.12% Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio 0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can bypass most existing defense methods. Besides, we also provide visualization analyses to explain why our method works.", "IdName": "song2024wpda", "Citation": "", "Keywords": ""}, {"Name": "Realistic Speech-to-Face Generation with Speech-Conditioned Latent Diffusion Model with Face Prior", "Authors": ["Jinting Wang", "Li Liu", "Jun Wang", "Hei Victor Cheng"], "Sources": "arXiv preprint arXiv:2310.03363", "PublishedYears": "2023", "Doi": "", "Abstracts": "Speech-to-face generation is an intriguing area of research that focuses on generating realistic facial images based on a speaker's audio speech. However, state-of-the-art methods employing GAN-based architectures lack stability and cannot generate realistic face images. To fill this gap, we propose a novel speech-to-face generation framework, which leverages a Speech-Conditioned Latent Diffusion Model, called SCLDM. To the best of our knowledge, this is the first work to harness the exceptional modeling capabilities of diffusion models for speech-to-face generation. Preserving the shared identity information between speech and face is crucial in generating realistic results. Therefore, we employ contrastive pre-training for both the speech encoder and the face encoder. This pre-training strategy facilitates effective alignment between the attributes of speech, such as age and gender, and the corresponding facial characteristics in the face images. Furthermore, we tackle the challenge posed by excessive diversity in the synthesis process caused by the diffusion model. To overcome this challenge, we introduce the concept of residuals by integrating a statistical face prior to the diffusion process. This addition helps to eliminate the shared component across the faces and enhances the subtle variations captured by the speech condition. Extensive quantitative, qualitative, and user study experiments demonstrate that our method can produce more realistic face images while preserving the identity of the speaker better than state-of-the-art methods. Highlighting the notable enhancements, our method demonstrates significant gains in all metrics on?\u2026", "IdName": "wang2023realistic", "Citation": "", "Keywords": ""}, {"Name": "MVNet: Memory Assistance and Vocal Reinforcement Network for Speech Enhancement", "Authors": ["Jianrong Wang", "Xiaomin Li", "Xuewei Li", "Yu Mei", "Qiang Fang", "Li Liu"], "Sources": "ICONIP 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Speech enhancement improves speech quality and promotes the performance of various downstream tasks. However, most current speech enhancement work was mainly devoted to improving the performance of downstream automatic speech recognition (ASR), only a relatively small amount of work focused on the automatic speaker verification (ASV) task. In this work, we propose a MVNet consisted of a memory assistance module which improves the performance of downstream ASR and a vocal reinforcement module to boosts the performance of ASV. In addition, we design a new loss function to improve speaker vocal similarity. Experimental results on the Libri2mix dataset show that our method outperforms baseline methods in several metrics, including speech quality, intelligibility, and speaker vocal similarity.", "IdName": "wang2022mvnet", "Citation": "", "Keywords": ""}, {"Name": "Graph random neural networks for semi-supervised learning on graphs", "Authors": ["Wenzheng Feng", "Jie Zhang", "Yuxiao Dong", "Yu Han", "Huanbo Luan", "Qian Xu", "Qiang Yang", "Evgeny Kharlamov", "Jie Tang"], "Sources": "Advances in neural information processing systems 33", "PublishedYears": "2020", "Doi": "", "Abstracts": "We study the problem of semi-supervised learning on graphs, for which graph neural networks (GNNs) have been extensively explored. However, most existing GNNs inherently suffer from the limitations of over-smoothing, non-robustness, and weak-generalization when labeled nodes are scarce. In this paper, we propose a simple yet effective framework\u2014GRAPH RANDOM NEURAL NETWORKS (GRAND)\u2014to address these issues. In GRAND, we first design a random propagation strategy to perform graph data augmentation. Then we leverage consistency regularization to optimize the prediction consistency of unlabeled nodes across different data augmentations. Extensive experiments on graph benchmark datasets suggest that GRAND significantly outperforms state-of-the-art GNN baselines on semi-supervised node classification. Finally, we show that GRAND mitigates the issues of over-smoothing and non-robustness, exhibiting better generalization behavior than existing GNNs. The source code of GRAND is publicly available at https://github. com/Grand20/grand.", "IdName": "feng2020graph", "Citation": "", "Keywords": ""}, {"Name": "Fate: An industrial grade platform for collaborative learning with data protection", "Authors": ["Yang Liu", "Tao Fan", "Tianjian Chen", "Qian Xu", "Qiang Yang"], "Sources": "Journal of Machine Learning Research", "PublishedYears": "2021", "Doi": "", "Abstracts": "Collaborative and federated learning has become an emerging solution to many industrial applications where data values from different sites are exploit jointly with privacy protection. We introduce FATE, an industrial-grade project that supports enterprises and institutions to build machine learning models collaboratively at large-scale in a distributed manner. FATE supports a variety of secure computation protocols and machine learning algorithms, and features out-of-box usability with end-to-end building modules and visualization tools. Documentations are available at https://github.com/FederatedAI/FATE. Case studies and other information are available at https://www.fedai.org.", "IdName": "liu2021fate", "Citation": "", "Keywords": ""}, {"Name": "Deep generative learning via schrodinger bridge", "Authors": ["Gefei Wang", "Yuling Jiao", "Qian Xu", "Yang Wang", "Can Yang"], "Sources": "International conference on machine learning", "PublishedYears": "2021", "Doi": "", "Abstracts": "We propose to learn a generative model via entropy interpolation with a Schr {?} dinger Bridge. The generative learning task can be formulated as interpolating between a reference distribution and a target distribution based on the Kullback-Leibler divergence. At the population level, this entropy interpolation is characterized via an SDE on [0, 1] with a time-varying drift term. At the sample level, we derive our Schr {?} dinger Bridge algorithm by plugging the drift term estimated by a deep score estimator and a deep density ratio estimator into the Euler-Maruyama method. Under some mild smoothness assumptions of the target distribution, we prove the consistency of both the score estimator and the density ratio estimator, and then establish the consistency of the proposed Schr {?} dinger Bridge approach. Our theoretical results guarantee that the distribution learned by our approach converges to the target distribution. Experimental results on multimodal synthetic data and benchmark data support our theoretical findings and indicate that the generative model via Schr {?} dinger Bridge is comparable with state-of-the-art GANs, suggesting a new formulation of generative learning. We demonstrate its usefulness in image interpolation and image inpainting.", "IdName": "wang2021deep", "Citation": "", "Keywords": ""}, {"Name": "Contribution-aware federated learning for smart healthcare", "Authors": ["Zelei Liu", "Yuanyuan Chen", "Yansong Zhao", "Han Yu", "Yang Liu", "Renyi Bao", "Jinpeng Jiang", "Zaiqing Nie", "Qian Xu", "Qiang Yang"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2022", "Doi": "", "Abstracts": "Artificial intelligence (AI) is a promising technology to transform the healthcare industry. Due to the highly sensitive nature of patient data, federated learning (FL) is often leveraged to build models for smart healthcare applications. Existing deployed FL frameworks cannot address the key issues of varying data quality and heterogeneous data distributions across multiple institutions in this sector. In this paper, we report our experience developing and deploying the Contribution-Aware Federated Learning (CAFL) framework for smart healthcare. It provides an efficient and accurate approach to fairly evaluate FL participants' contribution to model performance without exposing their private data, and improves the FL model training protocol to allow the best performing intermediate models to be distributed to participants for FL training. Since its deployment in Yidu Cloud Technology Inc. in March 2021, CAFL has served 8 well-established medical institutions in China to build healthcare decision support models. It can perform contribution evaluations 2.84 times faster than the best existing approach, and has improved the average accuracy of the resulting models by 2.62% compared to the previous system (which is significant in industrial settings). To our knowledge, it is the first contribution-aware federated learning successfully deployed in the healthcare industry.", "IdName": "liu2022contribution", "Citation": "", "Keywords": ""}, {"Name": "Secureboost+: A high performance gradient boosting tree framework for large scale vertical federated learning", "Authors": ["Weijing Chen", "Guoqiang Ma", "Tao Fan", "Yan Kang", "Qian Xu", "Qiang Yang"], "Sources": "arXiv preprint arXiv:2110.10927", "PublishedYears": "2021", "Doi": "", "Abstracts": "Gradient boosting decision tree (GBDT) is a widely used ensemble algorithm in the industry. Its vertical federated learning version, SecureBoost, is one of the most popular algorithms used in cross-silo privacy-preserving modeling. As the area of privacy computation thrives in recent years, demands for large-scale and high-performance federated learning have grown dramatically in real-world applications. In this paper, to fulfill these requirements, we propose SecureBoost+ that is both novel and improved from the prior work SecureBoost. SecureBoost+ integrates several ciphertext calculation optimizations and engineering optimizations. The experimental results demonstrate that Secureboost+ has significant performance improvements on large and high dimensional data sets compared to SecureBoost. It makes effective and efficient large-scale vertical federated learning possible.", "IdName": "chen2021secureboost", "Citation": "", "Keywords": ""}, {"Name": "Joint entity and relation extraction with a hybrid transformer and reinforcement learning based model", "Authors": ["Ya Xiao", "Chengxiang Tan", "Zhijie Fan", "Qian Xu", "Wenye Zhu"], "Sources": "Proceedings of the AAAI conference on artificial intelligence", "PublishedYears": "2020", "Doi": "", "Abstracts": "Joint extraction of entities and relations is a task that extracts the entity mentions and semantic relations between entities from the unstructured texts with one single model. Existing entity and relation extraction datasets usually rely on distant supervision methods which cannot identify the corresponding relations between a relation and the sentence, thus suffers from noisy labeling problem. We propose a hybrid deep neural network model to jointly extract the entities and relations, and the model is also capable of filtering noisy data. The hybrid model contains a transformer-based encoding layer, an LSTM entity detection module and a reinforcement learning-based relation classification module. The output of the transformer encoder and the entity embedding generated from the entity detection module are combined as the input state of the reinforcement learning module to improve the relation classification and noisy data filtering. We conduct experiments on the public dataset produced by the distant supervision method to verify the effectiveness of our proposed model. Different experimental results show that our model gains better performance on entity and relation extraction than the compared methods and also has the ability to filter noisy sentences.", "IdName": "xiao2020joint", "Citation": "", "Keywords": ""}, {"Name": "A survey on vertical federated learning: From a layered perspective", "Authors": ["Liu Yang", "Di Chai", "Junxue Zhang", "Yilun Jin", "Leye Wang", "Hao Liu", "Han Tian", "Qian Xu", "Kai Chen"], "Sources": "arXiv preprint arXiv:2304.01829", "PublishedYears": "2023", "Doi": "", "Abstracts": "Vertical federated learning (VFL) is a promising category of federated learning for the scenario where data is vertically partitioned and distributed among parties. VFL enriches the description of samples using features from different parties to improve model capacity. Compared with horizontal federated learning, in most cases, VFL is applied in the commercial cooperation scenario of companies. Therefore, VFL contains tremendous business values. In the past few years, VFL has attracted more and more attention in both academia and industry. In this paper, we systematically investigate the current work of VFL from a layered perspective. From the hardware layer to the vertical federated system layer, researchers contribute to various aspects of VFL. Moreover, the application of VFL has covered a wide range of areas, e.g., finance, healthcare, etc. At each layer, we categorize the existing work and explore the challenges for the convenience of further research and development of VFL. Especially, we design a novel MOSP tree taxonomy to analyze the core component of VFL, i.e., secure vertical federated machine learning algorithm. Our taxonomy considers four dimensions, i.e., machine learning model (M), protection object (O), security model (S), and privacy-preserving protocol (P), and provides a comprehensive investigation.", "IdName": "yang2023survey", "Citation": "", "Keywords": ""}, {"Name": "Industrial federated topic modeling", "Authors": ["Di Jiang", "Yongxin Tong", "Yuanfeng Song", "Xueyang Wu", "Weiwei Zhao", "Jinhua Peng", "Rongzhong Lian", "Qian Xu", "Qiang Yang"], "Sources": "ACM Transactions on Intelligent Systems and Technology (TIST)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Probabilistic topic modeling has been applied in a variety of industrial applications. Training a high-quality model usually requires a massive amount of data to provide comprehensive co-occurrence information for the model to learn. However, industrial data such as medical or financial records are often proprietary or sensitive, which precludes uploading to data centers. Hence, training topic models in industrial scenarios using conventional approaches faces a dilemma: A party (i.e., a company or institute) has to either tolerate data scarcity or sacrifice data privacy. In this article, we propose a framework named Industrial Federated Topic Modeling (iFTM), in which multiple parties collaboratively train a high-quality topic model by simultaneously alleviating data scarcity and maintaining immunity to privacy adversaries. iFTM is inspired by federated learning, supports two representative topic models (i.e., Latent?\u2026", "IdName": "jiang2021industrial", "Citation": "", "Keywords": ""}, {"Name": "A GDPR-compliant ecosystem for speech recognition with transfer, federated, and evolutionary learning", "Authors": ["Di Jiang", "Conghui Tan", "Jinhua Peng", "Chaotao Chen", "Xueyang Wu", "Weiwei Zhao", "Yuanfeng Song", "Yongxin Tong", "Chang Liu", "Qian Xu", "Qiang Yang", "Li Deng"], "Sources": "ACM Transactions on Intelligent Systems and Technology (TIST)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Automatic Speech Recognition (ASR) is playing a vital role in a wide range of real-world applications. However, Commercial ASR solutions are typically \u201cone-size-fits-all\u201d products and clients are inevitably faced with the risk of severe performance degradation in field test. Meanwhile, with new data regulations such as the European Union\u2019s General Data Protection Regulation (GDPR) coming into force, ASR vendors, which traditionally utilize the speech training data in a centralized approach, are becoming increasingly helpless to solve this problem, since accessing clients\u2019 speech data is prohibited. Here, we show that by seamlessly integrating three machine learning paradigms (i.e., Transfer learning, Federated learning, and Evolutionary learning (TFE)), we can successfully build a win-win ecosystem for ASR clients and vendors and solve all the aforementioned problems plaguing them. Through large-scale?\u2026", "IdName": "jiang2021gdpr", "Citation": "", "Keywords": ""}, {"Name": "Understanding User Perceptions of Robot's Delay, Voice Quality-Speed Trade-off and GUI during Conversation", "Authors": ["Zhenhui Peng", "Kaixiang Mo", "Xiaogang Zhu", "Junlin Chen", "Zhijun Chen", "Qian Xu", "Xiaojuan Ma"], "Sources": "Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Conversational robots face the practical challenge of providing timely responses to ensure smooth interactions with users. Thus, those who design and implement robots will need to understand how different levels of delay in response may affect users' satisfaction with the conversation, how to balance the trade-off between a robot's quality of voice and response time, and how to design strategies to mitigate possible negative effects of a long delay. Via an online video-prototype study on a service robot with 94 Chinese participants, we find that users could tolerate up to 4s delay but their satisfaction drops at the 8s delay during both information-retrieval conversations and chitchats. We gain an in-depth understanding of users' preference for the trade-off between the voice quality and the response speed, as well as their opinions on possible robot graphic user interface (GUI) design to alleviate negative user?\u2026", "IdName": "peng2020understanding", "Citation": "", "Keywords": ""}, {"Name": "Decentralized and expressive data publish-subscribe scheme in cloud based on attribute-based keyword search", "Authors": ["Qian Xu", "Qing Zhang", "Bo Yu", "Nandi Shi", "Changshuai Wang", "Wei He"], "Sources": "Journal of Systems Architecture 119", "PublishedYears": "2021", "Doi": "", "Abstracts": "Data publish-subscribe scheme is a valuable approach to share and retrieve data from cloud platforms selectively. However, the common practice of standard encryption hinders the effective keyword-based data subscription over outsourced data. Attribute-based keyword search (ABKS), which fulfills the functionality of attribute-based encryption and searchable encryption, is a promising cryptographic primitive to construct secure data publish-subscribe scheme. In this paper, for the first time, we propose a decentralized and expressive CP-ABKS scheme with computation outsourcing and collusion resistance. Then we construct a novel data publish-subscribe scheme based on the proposed CP-ABKS to realize secure and flexible data sharing among multiple users. Both the access and subscription policies are expressed with the Linear Secret Sharing Scheme structure that can be derived from any monotonic?\u2026", "IdName": "xu2021decentralized", "Citation": "", "Keywords": ""}, {"Name": "Goldenretriever: A speech recognition system powered by modern information retrieval", "Authors": ["Yuanfeng Song", "Di Jiang", "Xiaoling Huang", "Yawen Li", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "Sources": "Proceedings of the 28th ACM International Conference on Multimedia", "PublishedYears": "2020", "Doi": "", "Abstracts": "Existing Automatic Speech Recognition (ASR) systems usually generate the N-best hypotheses list first, and then rescore them with the language model score and the acoustic model score to find the best one. This procedure is essentially analogous to the working mechanism of modern Information Retrieval (IR) systems, which retrieve a relatively large amount of relevant candidates first, re-rank them, and output the top-N list. Exploiting their commonality, this demonstration proposes a novel system named GoldenRetriever that marries IR with ASR. GoldenRetriever transforms the problem of N-best hypotheses rescoring as a Learning-to-Rescore (L2RS) problem and utilizes a wide range of features beyond the language model score and the acoustic model score. In this demonstration, the audience can experience the great potential of marrying IR with ASR for the first time. GoldenRetriever should inspire more?\u2026", "IdName": "song2020goldenretriever", "Citation": "", "Keywords": ""}, {"Name": "An efficient industrial federated learning framework for AIoT: a face recognition application", "Authors": ["Youlong Ding", "Xueyang Wu", "Zhitao Li", "Zeheng Wu", "Shengqi Tan", "Qian Xu", "Weike Pan", "Qiang Yang"], "Sources": "arXiv preprint arXiv:2206.13398", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recently, the artificial intelligence of things (AIoT) has been gaining increasing attention, with an intriguing vision of providing highly intelligent services through the network connection of things, leading to an advanced AI-driven ecology. However, recent regulatory restrictions on data privacy preclude uploading sensitive local data to data centers and utilizing them in a centralized approach. Directly applying federated learning algorithms in this scenario could hardly meet the industrial requirements of both efficiency and accuracy. Therefore, we propose an efficient industrial federated learning framework for AIoT in terms of a face recognition application. Specifically, we propose to utilize the concept of transfer learning to speed up federated training on devices and further present a novel design of a private projector that helps protect shared gradients without incurring additional memory consumption or computational cost. Empirical studies on a private Asian face dataset show that our approach can achieve high recognition accuracy in only 20 communication rounds, demonstrating its effectiveness in prediction and its efficiency in training.", "IdName": "ding2022efficient", "Citation": "", "Keywords": ""}, {"Name": "A de novo divide-and-merge paradigm for acoustic model optimization in automatic speech recognition", "Authors": ["Conghui Tan", "Di Jiang", "Jinhua Peng", "Xueyang Wu", "Qian Xu", "Qiang Yang"], "Sources": "Proceedings of the Twenty-Ninth International Conference on International?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Due to the rising awareness of privacy protection and the voluminous scale of speech data, it is becoming infeasible for Automatic Speech Recognition (ASR) system developers to train the acoustic model with complete data as before. In this paper, we propose a novel Divide-and-Merge paradigm to solve salient problems plaguing the ASR field. In the Divide phase, multiple acoustic models are trained based upon different subsets of the complete speech data, while in the Merge phase two novel algorithms are utilized to generate a highquality acoustic model based upon those trained on data subsets. We first propose the Genetic Merge Algorithm (GMA), which is a highly specialized algorithm for optimizing acoustic models but suffers from low efficiency. We further propose the SGD-Based Optimizational Merge Algorithm (SOMA), which effectively alleviates the efficiency bottleneck of GMA and maintains superior performance. Extensive experiments on public data show that the proposed methods can significantly outperform the state-of-the-art.", "IdName": "tan2021novo", "Citation": "", "Keywords": ""}, {"Name": "Federated acoustic model optimization for automatic speech recognition", "Authors": ["Conghui Tan", "Di Jiang", "Huaxiao Mo", "Jinhua Peng", "Yongxin Tong", "Weiwei Zhao", "Chaotao Chen", "Rongzhong Lian", "Yuanfeng Song", "Qian Xu"], "Sources": "Database Systems for Advanced Applications: 25th International Conference?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": " Traditional Automatic Speech Recognition (ASR) systems are usually trained with speech records centralized on the ASR vendor\u2019s machines. However, with data regulations such as General Data Protection Regulation (GDPR) coming into force, sensitive data such as speech records are not allowed to be utilized in such a centralized approach anymore. In this demonstration, we propose and show the method of federated acoustic model optimization in order to solve this problem. This demonstration does not only vividly show the underlying working mechanisms of the proposed method but also provides an interface for the user to customize its hyperparameters. With this demonstration, the audience can experience the effect of federated learning in an interactive fashion and we wish this demonstration would inspire more research on GDPR-compliant ASR technologies.", "IdName": "tan2020federated", "Citation": "", "Keywords": ""}, {"Name": "FedNP: Towards non-IID federated learning via federated neural propagation", "Authors": ["Xueyang Wu", "Hengguan Huang", "Youlong Ding", "Hao Wang", "Ye Wang", "Qian Xu"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Traditional federated learning (FL) algorithms, such as FedAvg, fail to handle non-iid data because they learn a global model by simply averaging biased local models that are trained on non-iid local data, therefore failing to model the global data distribution. In this paper, we present a novel Bayesian FL algorithm that successfully handles such a non-iid FL setting by enhancing the local training task with an auxiliary task that explicitly estimates the global data distribution. One key challenge in estimating the global data distribution is that the data are partitioned in FL, and therefore the ground-truth global data distribution is inaccessible. To address this challenge, we propose an expectation-propagation-inspired probabilistic neural network, dubbed federated neural propagation (FedNP), which efficiently estimates the global data distribution given non-iid data partitions. Our algorithm is sampling-free and end-to-end differentiable, can be applied with any conventional FL frameworks and learns richer global data representation. Experiments on both image classification tasks with synthetic non-iid image data partitions and real-world non-iid speech recognition tasks demonstrate that our framework effectively alleviates the performance deterioration caused by non-iid data.", "IdName": "wu2023fednp", "Citation": "", "Keywords": ""}, {"Name": "SmartMeeting: Automatic meeting transcription and summarization for in-person conversations", "Authors": ["Yuanfeng Song", "Di Jiang", "Xuefang Zhao", "Xiaoling Huang", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Meetings are a necessary part of the operations of any institution, whether they are held online or in-person. However, meeting transcription and summarization are always painful requirements since they involve tedious human effort. This drives the need for automatic meeting transcription and summarization (AMTS) systems. A successful AMTS system relies on systematic integration of multiple natural language processing (NLP) techniques, such as automatic speech recognition, speaker identification, and meeting summarization, which are traditionally developed separately and validated offline with standard datasets. In this demonstration, we provide a novel productive meeting tool named SmartMeeting, which enables users to automatically record, transcribe, summarize, and manage the information in an in-person meeting. SmartMeeting transcribes every word on the fly, enriches the transcript with speaker?\u2026", "IdName": "song2021smartmeeting", "Citation": "", "Keywords": ""}, {"Name": "L2rs: A learning-to-rescore mechanism for hybrid speech recognition", "Authors": ["Yuanfeng Song", "Di Jiang", "Xuefang Zhao", "Qian Xu", "Raymond Chi-Wing Wong", "Lixin Fan", "Qiang Yang"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "This paper aims to advance the performance of industrial ASR systems by exploring a more effective method for N-best rescoring, a critical step that greatly affects the final recognition accuracy. Existing rescoring approaches suffer the following issues: (i) limited performance since they optimize an unnecessarily harder problem, namely predicting accurate grammatical legitimacy scores of the N-best hypotheses rather than directly predicting their partial orders regarding a specific acoustic input; (ii) hard to incorporate various information by advanced natural language processing (NLP) models such as BERT to achieve a comprehensive evaluation of each N-best candidate. To relieve the above drawbacks, we propose a simple yet effective mechanism, Learning-to-Rescore (L2RS), to empower ASR systems with state-of-the-art information retrieval (IR) techniques. Specifically, L2RS utilizes a wide range of textual?\u2026", "IdName": "song2021l2rs", "Citation": "", "Keywords": ""}, {"Name": "A Platform for Deploying the TFE Ecosystem of Automatic Speech Recognition", "Authors": ["Yuanfeng Song", "Rongzhong Lian", "Yixin Chen", "Di Jiang", "Xuefang Zhao", "Conghui Tan", "Qian Xu", "Raymond Chi-Wing Wong"], "Sources": "Proceedings of the 30th ACM International Conference on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Since data regulations such as the European Union's General Data Protection Regulation (GDPR) have taken effect, the traditional two-step Automatic Speech Recognition (ASR) optimization strategy (i.e., training a one-size-fits-all model with vendor's centralized data and fine-tuning the model with clients' private data) has become infeasible. To meet these privacy requirements, TFE, a novel GDPR-compliant ASR ecosystem, has been proposed by us to incorporate transfer learning, federated learning, and evolutionary learning towards effective ASR model optimization. In this demonstration, we further design and implement a novel platform to promote the deployment and applicability of TFE. Our proposed platform allows enterprises to easily conduct the ASR optimization task using TFE across organizations.", "IdName": "song2022platform", "Citation": "", "Keywords": ""}, {"Name": "Memetic federated learning for biomedical natural language processing", "Authors": ["Xinya Zhou", "Conghui Tan", "Di Jiang", "Bosen Zhang", "Si Li", "Yajing Xu", "Qian Xu", "Sheng Gao"], "Sources": "Natural Language Processing and Chinese Computing: 10th CCF International?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " Privacy protection is an essential issue in biomedical natural language processing (BioNLP). Recently, some researchers apply federated learning (FL) in BioNLP to protect the privacy of biomedical data. However, their methods are only applicable for small NLP models, whose effectiveness is heavily limited in processing biomedical data. In this paper, we propose a novel memetic federated learning framework named Mem-Fed, which is tailored for federated learning of large-scale NLP models in the biomedical scenario. Experiments with large-scale BioNLP model on the public dataset show that the proposed framework significantly outperforms the state-of-the-art counterparts.", "IdName": "zhou2021memetic", "Citation": "", "Keywords": ""}, {"Name": "Attribute inference by link strength modeling in online social networks with user tags", "Authors": ["Ya Xiao", "Zhijie Fan", "Chengxiang Tan", "Qian Xu", "Wenye Zhu"], "Sources": "Journal of Internet Technology", "PublishedYears": "2020", "Doi": "", "Abstracts": "The link strength between two users in online social networks is generally latent and can not be observed directly. The strength is usually related to the interests, behaviors, posted texts, common friends, and common followings of two users. Most previous works have ignored the distinctions of the link strengths among different pairs of users, and some works simply classify the relationships into strong and weak instead of a particular value. Given the importance of link strength in link prediction or item recommendation system, in this paper, we propose a novel method for modeling the strength of links in social networks by jointly taking the common friends, common followings, user behaviors, and user tags into consideration. A new method to construct the tags for each user based on the semantics of open information is also presented. The attribute inference and tag prediction approach based on link strength is put forward and evaluated by the experiments on a real-world dataset, the inferred results prove the feasibility of the proposed model and demonstrate that the model substantially outperforms the compared methods.", "IdName": "xiao2020attribute", "Citation": "", "Keywords": ""}, {"Name": "WrapperFL: A Model Agnostic Plug-in for Industrial Federated Learning", "Authors": ["Xueyang Wu", "Shengqi Tan", "Qian Xu", "Qiang Yang"], "Sources": "arXiv preprint arXiv:2206.10407", "PublishedYears": "2022", "Doi": "", "Abstracts": "Federated learning, as a privacy-preserving collaborative machine learning paradigm, has been gaining more and more attention in the industry. With the huge rise in demand, there have been many federated learning platforms that allow federated participants to set up and build a federated model from scratch. However, exiting platforms are highly intrusive, complicated, and hard to integrate with built machine learning models. For many real-world businesses that already have mature serving models, existing federated learning platforms have high entry barriers and development costs. This paper presents a simple yet practical federated learning plug-in inspired by ensemble learning, dubbed WrapperFL, allowing participants to build/join a federated system with existing models at minimal costs. The WrapperFL works in a plug-and-play way by simply attaching to the input and output interfaces of an existing model, without the need of re-development, significantly reducing the overhead of manpower and resources. We verify our proposed method on diverse tasks under heterogeneous data distributions and heterogeneous models. The experimental results demonstrate that WrapperFL can be successfully applied to a wide range of applications under practical settings and improves the local model with federated learning at a low cost.", "IdName": "wu2022wrapperfl", "Citation": "", "Keywords": ""}, {"Name": "Heterogeneous identity trust management method based on risk assessment", "Authors": ["Wenye Zhu", "Chengxiang Tan", "Qian Xu", "Ya Xiao"], "Sources": "Journal of Intelligent & Fuzzy Systems", "PublishedYears": "2021", "Doi": "", "Abstracts": "The cross-trust domain environment in which heterogeneous identity alliances are located often does not have a completely trusted centralized trust root, and different trust domains and entities also have specific security requirements. In view of the above problems, we believe that trust measurement of cross-domain identities based on risk assessment is an effective method to achieve decentralized proof of user identities in heterogeneous cyberspace. There are various risk assessment models. We choose the more mature attack graph theory in the existing research to apply to the new field of cross-trust domain management of heterogeneous identities. We propose an attribute attack graph evaluation model to evaluate cross-domain identities through risk measurement of attributes. In addition, heterogeneous identity alliances also have architectural risks, especially the risk of decentralized underlying structures. In?\u2026", "IdName": "zhu2021heterogeneous", "Citation": "", "Keywords": ""}, {"Name": "EP-GAN: Unsupervised Federated Learning with Expectation-Propagation Prior GAN", "Authors": ["Xueyang Wu", "Hengguan Huang", "Hao Wang", "Ye Wang", "Qian Xu"], "Sources": "", "PublishedYears": "2021", "Doi": "", "Abstracts": "Generative Adversarial Networks (GANs) are overwhelming in unsupervised learning tasks due to their expressive power in modeling fine-grained data distributions. However, it is challenging for GANs to model distributions of separate non-i.i.d. data partitions as it usually adopts an over-general prior, limiting its capability in capturing the latent structure of multiple data partitions and thus leading to mode collapse. In this paper, we present a new Bayesian GAN, dubbed expectation propagation prior GAN (EP-GAN), which addresses the above challenge of modeling non-i.i.d. federated data through imposing a partition-invariant prior distribution on a Bayesian GAN. Furthermore, unlike most existing algorithms for deep-learning-based EP inference that require numerical quadrature, here we propose a closed-form solution for each update step of EP, leading to a more efficient solution for federated data modeling. Experiments on both synthetic extremely non-i.i.d. image data partitions and realistic non-i.i.d. speech recognition tasks demonstrate that our framework effectively alleviates the performance deterioration caused by non-i.i.d. data.", "IdName": "wu2021ep", "Citation": "", "Keywords": ""}, {"Name": "HQsFL: A Novel Training Strategy for Constructing High-performance and Quantum-safe Federated Learning", "Authors": ["Bo Yu", "Huajie Shen", "Qian Xu", "Wei He", "Wankui Mao", "Qing Zhang", "Fan Zhang"], "Sources": "Proceedings of the 19th ACM Asia Conference on Computer and Communications?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Federated Learning (FL) has attracted increasing attention from both academia and industry due to its merit of securely constructing AI models across multiple entities while preserving the privacy of local training data. However, recent research shows two persisting problems in FL that have yet to be solved: (1) limited practical adaptation of federated learning because of time-consuming conventional privacy-preserving methods, and (2) the absence of quantum-computing resistance in these methods. To address these problems, we propose a novel vertical federated learning strategy, HQsFL, which relies on Fully Homomorphic Encryption (FHE) and Matrix Vector Product basing on Coefficient Encoding. The proposed method can be widely applied to FL algorithms such as logistic regression and XGBoost, etc. We fully implement our approach and evaluate its utility and efficiency through extensive experiments?\u2026", "IdName": "yu2024hqsfl", "Citation": "", "Keywords": ""}, {"Name": "FedCORE: Federated Learning for Cross-Organization Recommendation Ecosystem", "Authors": ["Zhitao Li", "Xueyang Wu", "Weike Pan", "Youlong Ding", "Zeheng Wu", "Shengqi Tan", "Qian Xu", "Qiang Yang", "Zhong Ming"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2024", "Doi": "", "Abstracts": "A recommendation system is of vital importance in delivering personalization services, which often brings continuous dual improvement in user experience and organization revenue. However, the data of one single organization may not be enough to build an accurate recommendation model for inactive or new cold-start users. Moreover, due to the recent regulatory restrictions on user privacy and data security, as well as the commercial conflicts, the raw data in different organizations cannot be merged to alleviate the scarcity issue in training a model. In order to learn users\u2019 preferences from such cross-silo data of different organizations and then provide recommendations to the cold-start users, we propose a novel federated learning framework, i.e., federated cross-organization recommendation ecosystem (FedCORE). Specifically, we first focus on the ecosystem problem of cross-organization federated?\u2026", "IdName": "li2024fedcore", "Citation": "", "Keywords": ""}, {"Name": "CAreFL: Enhancing smart healthcare with Contribution\u2010Aware Federated Learning", "Authors": ["Zelei Liu", "Yuanyuan Chen", "Yansong Zhao", "Han Yu", "Yang Liu", "Renyi Bao", "Jinpeng Jiang", "Zaiqing Nie", "Qian Xu", "Qiang Yang"], "Sources": "AI Magazine", "PublishedYears": "2023", "Doi": "", "Abstracts": " Artificial intelligence (AI) is a promising technology to transform the healthcare industry. Due to the highly sensitive nature of patient data, federated learning (FL) is often leveraged to build models for smart healthcare applications. Existing deployed FL frameworks cannot address the key issues of varying data quality and heterogeneous data distributions across multiple institutions in this sector. In this paper, we report our experience developing and deploying the Contribution\u2010Aware Federated Learning (CAreFL) framework for smart healthcare. It provides an efficient and accurate approach to fairly evaluate FL participants\u2019 contributions to model performance without exposing their private data, and improves the FL model training protocol by allowing the best performing intermediate sub\u2010models to be distributed to participants for FL training. Since its deployment by Yidu Cloud Technology Inc. in March 2021?\u2026", "IdName": "liu2023carefl", "Citation": "", "Keywords": ""}, {"Name": "Enhance Mono-modal Sentiment Classification with Federated Cross-modal Transfer.", "Authors": ["Xueyang Wu", "Di Jiang", "Yuanfeng Song", "Qian Xu", "Qiang Yang"], "Sources": "IEEE Data Eng. Bull.", "PublishedYears": "2023", "Doi": "", "Abstracts": "Sentiment analysis is a complex process that involves multiple modalities, which can provide more accurate and informative results than using a single modality. Although existing multimodal approaches have shown to be superior to mono-modal sentiment classification, they are not always practical in real-world scenarios where only mono-modal input is available, or where multimodal data is limited due to data scarcity or privacy concerns. To address this issue, we propose a novel approach that enhances mono-modal sentiment classification through federated transfer learning. Specifically, we focus on a practical industrial problem where text and speech data are owned by different affiliations, and we aim to bridge these modalities by sharing a cross-modal feature generator and phone classifier. Our proposed framework also incorporates differential privacy techniques to ensure privacy-preserving cross-modal?\u2026", "IdName": "wu2023enhance", "Citation": "", "Keywords": ""}, {"Name": "FedTLBOHB: Efficient Hyperband with Transfer Learning for Vertical Federated Learning", "Authors": ["Bo Yu", "Huajie Shen", "Peng Huai", "Qian Xu", "Wei He"], "Sources": "2022 IEEE 8th International Conference on Computer and Communications (ICCC?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The issue of data privacy is receiving increasing attention nowadays. Federated learning, which is a distributed machine learning setting where many clients (e.g. mobile devices or organizations) train a model collaboratively while keeping the training data local, was born as a result. And it has been applied to an increasing number of business scenarios. Like traditional machine learning, federated learning methods are also very sensitive to hyperparameters. However, data privacy will be protected using cryptographic techniques such as homomorphic encryption and secret sharing in federated learning, resulting in significant data amounts transferred among clients. Given this, we should find a more efficient method to optimize hyperparameters, which means utilizing fewer budgets (time, iterations, etc.). In this paper, we proposed a new efficient method FedTLBOHB, which combines both Hyperband and?\u2026", "IdName": "yu2022fedtlbohb", "Citation": "", "Keywords": ""}, {"Name": "A Phonetic-Semantic Pre-Training Model for Robust Speech Recognition", "Authors": ["Xueyang Wu", "Rongzhong Lian", "Di Jiang", "Yuanfeng Song", "Weiwei Zhao", "Qian Xu", "Qiang Yang"], "Sources": "CAAI Artificial Intelligence Research", "PublishedYears": "2022", "Doi": "", "Abstracts": "Robustness is a long-standing challenge for automatic speech recognition (ASR) as the applied environment of any ASR system faces much noisier speech samples than clean training corpora. However, it is impractical to annotate every types of noisy environments. In this work, we propose a novel phonetic-semantic pre-training (PSP) framework that allows a model to effectively improve the performance of ASR against practical noisy environments via seamlessly integrating pre-training, self-supervised learning, and fine-tuning. In particular, there are three fundamental stages in PSP. First, pre-train the phone-to-word transducer (PWT) to map the generated phone sequence to the target text using only unpaired text data; second, continue training the PWT on more complex data generated from an empirical phone-perturbation heuristic, in additional to self-supervised signals by recovering the tainted phones; and?\u2026", "IdName": "wu2022phonetic", "Citation": "", "Keywords": ""}, {"Name": "SmartSales: An AI-Powered Telemarketing Coaching System in FinTech", "Authors": ["Yuanfeng Song", "Xuefang Zhao", "Di Jiang", "Xiaoling Huang", "Weiwei Zhao", "Qian Xu", "Raymond Chi-Wing Wong", "Qiang Yang"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Telemarketing is a primary and mature method for enterprises to solicit prospective customers to buy products or services. However, training telesales representatives is always a pain point for enterprises since it is usually conducted manually and costs great effort and time. In this demonstration, we propose a telemarketing coaching system named SmartSales to help enterprises develop better salespeople. Powered by artificial intelligence (AI), SmartSales aims to accumulate the experienced sales pitch from customer-sales dialogues and use it to coach junior salespersons. To the best of our knowledge, this is the first practice of an AI telemarketing coaching system in the domain of Chinese FinTech in the literature. SmartSales has been successfully deployed in the WeBank's telemarketing team. We expect that SmartSales will inspire more research on AI assistant systems.", "IdName": "song2021smartsales", "Citation": "", "Keywords": ""}, {"Name": "A Health-friendly Speaker Verification System Supporting Mask Wearing", "Authors": ["Chaotao Chen", "Di Jiang", "Jinhua Peng", "Rongzhong Lian", "Chen Jason Zhang", "Qian Xu", "Lixin Fan", "Qiang Yang"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2021", "Doi": "", "Abstracts": "We demonstrate a health-friendly speaker verification system for voice-based identity verification on mobile devices. The system is built upon a speech processing module, a ResNet-based local acoustic feature extractor and a multi-head attention-based embedding layer, and is optimized under an additive margin softmax loss for discriminative speaker verification. It is shown that the system achieves superior performance no matter whether there is mask wearing or not. This characteristic is important for speaker verification services operating in regions affected by the raging coronavirus pneumonia. With this demonstration, the audience will have an in-depth experience of how the accuracy of bio-metric verification and the personal health are simultaneously ensured. We wish that this demonstration would boost the development of next-generation bio-metric verification technologies.", "IdName": "chen2021health", "Citation": "", "Keywords": ""}, {"Name": "Heterogeneous Identity Expression and Association Method Based on Attribute Aggregation", "Authors": ["Wenye Zhu", "Chengxiang Tan", "Qian Xu", "Ya Xiao"], "Sources": "Journal of Web Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "Existing identity expression methods are often limited in a single security domain, and this is inadequate to meet the cross-domain access requirements of heterogeneous networks. In view of this problem, we propose an index system for the ubiquitous expression of heterogeneous identities, and introduce the concept pair matching based attribute aggregation method by combining the characteristics of heterogeneous identity alliances. The selection of concept pairs considers the original meaning of attribute characteristics, including the lexical level, i.e., class, ontology, label, description, the structural level, i.e., position, distance between nodes, and the semantic level, i.e., formal concept analysis. As for the attribute aggregation, if multiple attributes from a heterogeneous network contain the same or similar concepts, they are considered the same attribute for the user identity in a heterogeneous network. Relevant?\u2026", "IdName": "zhu2020heterogeneous", "Citation": "", "Keywords": ""}, {"Name": "Robust spammer detection by nash reinforcement learning", "Authors": ["Yingtong Dou", "Guixiang Ma", "Philip S Yu", "Sihong Xie"], "Sources": "Proceedings of the 26th ACM SIGKDD international conference on knowledge?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Online reviews provide product evaluations for customers to make decisions. Unfortunately, the evaluations can be manipulated using fake reviews (\"spams\") by professional spammers, who have learned increasingly insidious and powerful spamming strategies by adapting to the deployed detectors. Spamming strategies are hard to capture, as they can be varying quickly along time, different across spammers and target products, and more critically, remained unknown in most cases. Furthermore, most existing detectors focus on detection accuracy, which is not well-aligned with the goal of maintaining the trustworthiness of product evaluations. To address the challenges, we formulate a minimax game where the spammers and spam detectors compete with each other on their practical goals that are not solely based on detection accuracy. Nash equilibria of the game lead to stable detectors that are agnostic to any?\u2026", "IdName": "dou2020robust", "Citation": "", "Keywords": ""}, {"Name": "Inconsistent Matters: A Knowledge-guided Dual-consistency Network for Multi-modal Rumor Detection", "Authors": ["and Philip S. Yu Mengzhu Sun", "Xi Zhang", "Jianqiang Ma", "Sihong Xie", "Yazheng Liu"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Rumor spreaders are increasingly utilizing multimedia content to attract the attention and trust of news consumers. Though quite a few rumor detection models have exploited the multi-modal data, they seldom consider the inconsistent semantics between images and texts, and rarely spot the inconsistency among the post contents and background knowledge. In addition, they commonly assume the completeness of multiple modalities and thus are incapable of handling handle missing modalities in real-life scenarios. Motivated by the intuition that rumors in social media are more likely to have inconsistent semantics, a novel  Knowledge-guided Dual-consistency Network  is proposed to detect rumors with multimedia contents. It uses two consistency detection subnetworks to capture the inconsistency at the cross-modal level and the content-knowledge level simultaneously. It also enables robust multi-modal?\u2026", "IdName": "sun2023inconsistent", "Citation": "", "Keywords": ""}, {"Name": "Truth discovery in sequence labels from crowds", "Authors": ["Nasim Sabetpour", "Adithya Kulkarni", "Sihong Xie", "Qi Li"], "Sources": "21st IEEE International Conference on Data Mining (ICDM 2021)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Annotation quality and quantity positively affect the learning performance of sequence labeling, a vital task in Natural Language Processing. Hiring domain experts to annotate a corpus is very costly in terms of money and time. Crowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been deployed to assist in this purpose. However, the annotations collected this way are prone to human errors due to the lack of expertise of the crowd workers. Existing literature in annotation aggregation assumes that annotations are independent and thus faces challenges when handling the sequential label aggregation tasks with complex dependencies. To conquer the challenges, we propose an optimization-based method that infers the ground truth labels using annotations provided by workers for sequential labeling tasks. The proposed Aggregation method for Sequential Labels from Crowds (AggSLC) jointly?\u2026", "IdName": "sabetpour2021truth", "Citation": "", "Keywords": ""}, {"Name": "Certification and Trade-off of Multiple Fairness Criteria in Graph-based Spam Detection", "Authors": ["Kai Burkholder", "Kenny Kwock", "Yuesheng Xu", "Liu Jiaxin", "Chao Chen", "Sihong Xie"], "Sources": "30th ACM International Conference on Information and Knowledge Management?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Spamming reviews are prevalent in review systems to manipulate seller reputation and mislead customers. patterns to achieve state-of-the-art detection accuracy. The detection can influence a large number of real-world entities and it is ethical to treat different groups of entities as equally as possible. However, due to skewed distributions of the graphs, GNN can fail to meet diverse fairness criteria designed for different parties. We formulate linear systems of the input features and the adjacency matrix of the review graphs for the certification of multiple fairness criteria. When the criteria are competing, we relax the certification and design a multi-objective optimization (MOO) algorithm to explore multiple efficient trade-offs, so that no objective can be improved without harming another objective. We prove that the algorithm converges to a Pareto efficient solution using duality and the implicit function theorem. Since?\u2026", "IdName": "burkholder2021certification", "Citation": "", "Keywords": ""}, {"Name": "Multi-objective Explanations of GNN Predictions", "Authors": ["Yifei Liu", "Chao Chen", "Yazheng Liu", "Xi Zhang", "Sihong Xie"], "Sources": "21st IEEE International Conference on Data Mining (ICDM 2021)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Graph Neural Network (GNN) has achieved state-of-the-art performance in various high-stake prediction tasks, but multiple layers of aggregations on graphs with irregular structures make GNN a less interpretable model. Prior methods use simpler subgraphs to simulate the full model, or counterfactuals to identify the causes of a prediction. The two families of approaches aim at two distinct objectives, \u201csimulatability\u201d and \u201ccounterfactual relevance\u201d, but it is not clear how the objectives can jointly influence the human understanding of an explanation. We design a user-study to investigate such joint effects, and use the findings to design a multi-objective optimization (MOO) algorithm to find Pareto optimal explanations that are well-balanced in simulatability and counterfactual. Since the target model can be of any GNN variants and may not be accessible due to privacy concerns, we design a search algorithm using zero?\u2026", "IdName": "liu2021multi", "Citation": "", "Keywords": ""}, {"Name": "Energy-Efficient Models for High-Dimensional Spike Train Classification using Sparse Spiking Neural Network", "Authors": ["Hang Yin", "John Lee", "Xiangnan Kong", "Thomas Hartvigsen", "Sihong Xie"], "Sources": "27th ACM SIGKDD international conference on knowledge discovery and data?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Spike train classification is an important problem in many areas such as healthcare and mobile sensing, where each spike train is a high-dimensional time series of binary values. Conventional research on spike train classification mainly focus on developing Spiking Neural Networks (SNNs) under resource-sufficient settings (e.g., on GPU servers). The neurons of the SNNs are usually densely connected in each layer. However, in many real-world applications, we often need to deploy the SNN models on resource-constrained platforms (e.g., mobile devices) to analyze high-dimensional spike train data. The high resource requirement of the densely-connected SNNs can make them hard to deploy on mobile devices. In this paper, we study the problem of energy-efficient SNNs with sparsely-connected neurons. We propose an SNN model with sparse spatio-temporal coding. Our solution is based on the re?\u2026", "IdName": "yin2021energy", "Citation": "", "Keywords": ""}, {"Name": "Interpretable and Effective Reinforcement Learning for Attacking against Graph-based Rumor Detection", "Authors": ["Yuefei Lyu", "Xiaoyu Yang", "Jiaxin Liu", "Sihong Xie", "Philip S. Yu", "Xi Zhang"], "Sources": "International Joint Conference on Neural Networks (IJCNN)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Social networks are frequently polluted by rumors, which can be detected by advanced models such as graph neural networks. However, the models are vulnerable to attacks, and discovering and understanding the vulnerabilities is critical to robust rumor detection. To discover subtle vulnerabilities, we design a attacking algorithm based on reinforcement learning to camouflage rumors against black-box detectors. We address exponentially large state spaces, high-order graph dependencies, and ranking dependencies, which are unique to the problem setting but fundamentally challenging for the state-of-the-art end-to-end approaches. We design domain-specific features that have causal effect on the reward, so that even a linear policy can arrive at powerful attacks with additional interpretability. To speed up policy optimization, we devise: (i) a credit assignment method that proportionally decomposes delayed?\u2026", "IdName": "lyu2023interpretable", "Citation": "", "Keywords": ""}, {"Name": "Self-learn to Explain Siamese Networks Robustly", "Authors": ["Chao Chen", "Yifan Shen", "Guixiang Ma", "Xiangnan Kong", "Srinivas Rangarajan", "Xi Zhang", "Sihong Xie"], "Sources": "21st IEEE International Conference on Data Mining (ICDM 2021)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Learning to compare two objects are essential in applications, especially when labeled data are scarce and imbalanced. As these applications can involve humans and make high-stake decisions, it is critical to explain the learned models. We aim to study post-hoc explanations of Siamese networks (SN) widely used in learning to compare. We characterize the instability of gradient-based explanations due to the additional compared object in SN, in contrast to architectures with a single input instance. We optimize for global invariance based on unlabeled data using self-learning to promote the stability of local explanations for individual input. The invariance leads to constrained optimization problems that can be solved using gradient descent-ascent (GDA), or KL-divergence regularized unconstrained optimization solved by SGD. We provide convergence proofs when the objective functions are nonconvex due to?\u2026", "IdName": "chen2021self", "Citation": "", "Keywords": ""}, {"Name": "Shapley Values and Meta-Explanations for Probabilistic Graphical Model Inference", "Authors": ["Yifei Liu", "Chao Chen", "Yazheng Liu", "Xi Zhang", "Sihong Xie"], "Sources": "29TH ACM International Conference on Information and Knowledge Management", "PublishedYears": "2020", "Doi": "", "Abstracts": "Probabilistic graphical models, such as Markov random fields (MRF), exploit dependencies among random variables to model a rich family of joint probability distributions. Inference algorithms, such as belief propagation (BP), can effectively compute the marginal posteriors for decision making. Nonetheless, inferences involve sophisticated probability calculations and are difficult for humans to interpret. Among all existing explanation methods for MRFs, no method is designed for fair attributions of an inference outcome to elements on the MRF where the inference takes place. Shapley values provide rigorous attributions but so far have not been studied on MRFs. We thus define Shapley values for MRFs to capture both probabilistic and topological contributions of the variables on MRFs. We theoretically characterize the new definition regarding independence, equal contribution, additivity, and submodularity. As?\u2026", "IdName": "liu2020shapley", "Citation": "", "Keywords": ""}, {"Name": "Reaction-diffusion graph ordinary differential equation networks: Traffic-law-informed speed prediction under mismatched data", "Authors": ["Yue Sun", "Chao Chen", "Yuesheng Xu", "Sihong Xie", "Rick S Blum", "Parv Venkitasubramaniam"], "Sources": "URL https://par. nsf. gov/biblio/10466683", "PublishedYears": "2023", "Doi": "", "Abstracts": "Accurate traffic speed prediction is critical to many applications, from routing and urban planning to infrastructure management. With sufficient training data where all spatio-temporal patterns are wellrepresented, machine learning models such as Spatial-Temporal Graph Convolutional Networks (STGCN), can make reasonably accurate predictions. However, existing methods fail when the training data distribution (eg, traffic patterns on regular days) is different from test distribution (eg, traffic patterns on special days). We address this challenge by proposing a traffic-law-informed network called Reaction-Diffusion Graph Ordinary Differential Equation (RDGODE) network, which incorporates a physical model of traffic speed evolution based on a reliable and interpretable reactiondiffusion equation that allows the RDGODE to adapt to unseen traffic patterns. We show that with mismatched training data, RDGODE is more robust than the state-of-the-art machine learning methods in the following cases.(1) When the test dataset exhibits spatio-temporal patterns not represented in the training dataset, the performance of RDGODE is more consistent and reliable.(2) When the test dataset has missing data, RDGODE can maintain its accuracy by intrinsically imputing the missing values.", "IdName": "sun2023reaction", "Citation": "", "Keywords": ""}, {"Name": "Optimal budget allocation for crowdsourcing labels for graphs", "Authors": ["Adithya Kulkarni", "Mohna Chakraborty", "Sihong Xie", "Qi Li"], "Sources": "Uncertainty in Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Crowdsourcing is an effective and efficient paradigm for obtaining labels for unlabeled corpus employing crowd workers. This work considers the budget allocation problem for a generalized setting on a graph of instances to be labeled where edges encode instance dependencies. Specifically, given a graph and a labeling budget, we propose an optimal policy to allocate the budget among the instances to maximize the overall labeling accuracy. We formulate the problem as a Bayesian Markov Decision Process (MDP), where we define our task as an optimization problem that maximizes the overall label accuracy under budget constraints. Then, we propose a novel stage-wise reward function that considers the effect of worker labels on the whole graph at each timestamp. This reward function is utilized to find an optimal policy for the optimization problem. Theoretically, we show that our proposed policies are consistent when the budget is infinite. We conduct extensive experiments on five real-world graph datasets and demonstrate the effectiveness of the proposed policies to achieve a higher label accuracy under budget constraints.", "IdName": "kulkarni2023optimal", "Citation": "", "Keywords": ""}, {"Name": "Trade less Accuracy for Fairness and Trade-off Explanation for GNN", "Authors": ["Yazheng Liu", "Xi Zhang", "Sihong Xie"], "Sources": "2022 IEEE International Conference on Big Data (Big Data)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Graphs are widely found in social network analysis and e-commerce, where Graph Neural Networks (GNNs) are the state-of the-art model. GNNs can be biased due to sensitive attributes and network topology. With existing work that learns a fair node representation or adjacency matrix, achieving a strong guarantee of group fairness while preserving prediction accuracy is still challenging, with the fairness-accuracy trade-off remaining obscure to human decision-makers. We first define and analyze a novel upper bound of group fairness to optimize the adjacency matrix for fairness without significantly h arming prediction accuracy. To understand the nuance of fairness-accuracy tradeoff, we further propose macroscopic and microscopic explanation methods to reveal the trade-offs and the space that one can exploit. The macroscopic explanation method is based on stratified sampling and linear programming to?\u2026", "IdName": "liu2022trade", "Citation": "", "Keywords": ""}, {"Name": "DetectGPT-SC: Improving Detection of Text Generated by Large Language Models through Self-Consistency with Masked Predictions", "Authors": ["Rongsheng Wang", "Qi Li", "Sihong Xie"], "Sources": "arXiv preprint arXiv:2310.14479", "PublishedYears": "2023", "Doi": "", "Abstracts": "General large language models (LLMs) such as ChatGPT have shown remarkable success, but it has also raised concerns among people about the misuse of AI-generated texts. Therefore, an important question is how to detect whether the texts are generated by ChatGPT or by humans. Existing detectors are built on the assumption that there is a distribution gap between human-generated and AI-generated texts. These gaps are typically identified using statistical information or classifiers. In contrast to prior research methods, we find that large language models such as ChatGPT exhibit strong self-consistency in text generation and continuation. Self-consistency capitalizes on the intuition that AI-generated texts can still be reasoned with by large language models using the same logical reasoning when portions of the texts are masked, which differs from human-generated texts. Using this observation, we subsequently proposed a new method for AI-generated texts detection based on self-consistency with masked predictions to determine whether a text is generated by LLMs. This method, which we call DetectGPT-SC. We conducted a series of experiments to evaluate the performance of DetectGPT-SC. In these experiments, we employed various mask scheme, zero-shot, and simple prompt for completing masked texts and self-consistency predictions. The results indicate that DetectGPT-SC outperforms the current state-of-the-art across different tasks.", "IdName": "wang2023detectgpt", "Citation": "", "Keywords": ""}, {"Name": "A Differential Geometric View and Explainability of GNN on Evolving Graphs", "Authors": ["Yazheng Liu", "Xi Zhang", "Sihong Xie"], "Sources": "2023 International Conference on Learning Representations (ICLR 2023)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graphs are ubiquitous in social networks and biochemistry, where Graph Neural Networks (GNN) are the state-of-the-art models for prediction. Graphs can be evolving and it is vital to formally model and understand how a trained GNN responds to graph evolution. We propose a smooth parameterization of the GNN predicted distributions using axiomatic attribution, where the distributions are on a low-dimensional manifold within a high-dimensional embedding space. We exploit the differential geometric viewpoint to model distributional evolution as smooth curves on the manifold. We reparameterize families of curves on the manifold and design a convex optimization problem to find a unique curve that concisely approximates the distributional evolution for human interpretation. Extensive experiments on node classification, link prediction, and graph classification tasks with evolving graphs demonstrate the better sparsity, faithfulness, and intuitiveness of the proposed method over the state-of-the-art methods.", "IdName": "liu2024differential", "Citation": "", "Keywords": ""}, {"Name": "Subgroup Fairness in Graph-based Spam Detection", "Authors": ["Jiaxin Liu", "Yuefei Lyu", "Xi Zhang", "Sihong Xie"], "Sources": "arXiv preprint arXiv:2204.11164", "PublishedYears": "2022", "Doi": "", "Abstracts": "None", "IdName": "liu2022subgroup", "Citation": "", "Keywords": ""}, {"Name": "Explaining GNN over evolving graphs using information flow", "Authors": ["Yazheng Liu", "Xi Zhang", "Sihong Xie"], "Sources": "arXiv preprint arXiv:2111.10037", "PublishedYears": "2021", "Doi": "", "Abstracts": "Graphs are ubiquitous in many applications, such as social networks, knowledge graphs, smart grids, etc.. Graph neural networks (GNN) are the current state-of-the-art for these applications, and yet remain obscure to humans. Explaining the GNN predictions can add transparency. However, as many graphs are not static but continuously evolving, explaining changes in predictions between two graph snapshots is different but equally important. Prior methods only explain static predictions or generate coarse or irrelevant explanations for dynamic predictions. We define the problem of explaining evolving GNN predictions and propose an axiomatic attribution method to uniquely decompose the change in a prediction to paths on computation graphs. The attribution to many paths involving high-degree nodes is still not interpretable, while simply selecting the top important paths can be suboptimal in approximating the change. We formulate a novel convex optimization problem to optimally select the paths that explain the prediction evolution. Theoretically, we prove that the existing method based on Layer-Relevance-Propagation (LRP) is a special case of the proposed algorithm when an empty graph is compared with. Empirically, on seven graph datasets, with a novel metric designed for evaluating explanations of prediction change, we demonstrate the superiority of the proposed approach over existing methods, including LRP, DeepLIFT, and other path selection methods.", "IdName": "liu2021explaining", "Citation": "", "Keywords": ""}, {"Name": "Active search using meta-bandits", "Authors": ["Shengli Zhu", "Jakob Coles", "Sihong Xie"], "Sources": "Proceedings of the 29th ACM International Conference on Information?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "There are many applications where positive instances are rare but important to identify. For example, in NLP, positive sentences for a given relation are rare in a large corpus. Positive data are more informative for learning in these applications, but before one labels a certain amount of data, it is unknown where to find the rare positives. Since random sampling can lead to significant waste in labeling effort, previous 'active search' methods use a single bandit model to learn about the data distribution (exploration) while sampling from the regions potentially containing more positives (exploitation). Many bandit models are possible and a sub-optimal model reduces labeling efficiency, but the optimal model is unknown before any data are labeled. We propose Meta-AS (Meta Active Search) that uses a meta-bandit to evaluate a set of base bandits and aims to label positive examples efficiently, comparing to the optimal?\u2026", "IdName": "zhu2020active", "Citation": "", "Keywords": ""}, {"Name": "Robust Ranking Explanations", "Authors": ["Chao Chen", "Chenghua Guo", "Guixiang Ma", "Ming Zeng", "Xi Zhang", "Sihong Xie"], "Sources": "arXiv preprint arXiv:2307.04024", "PublishedYears": "2023", "Doi": "", "Abstracts": "Robust explanations of machine learning models are critical to establish human trust in the models. Due to limited cognition capability, most humans can only interpret the top few salient features. It is critical to make top salient features robust to adversarial attacks, especially those against the more vulnerable gradient-based explanations. Existing defense measures robustness using -norms, which have weaker protection power. We define explanation thickness for measuring salient features ranking stability, and derive tractable surrogate bounds of the thickness to design the \\textit{R2ET} algorithm to efficiently maximize the thickness and anchor top salient features. Theoretically, we prove a connection between R2ET and adversarial training. Experiments with a wide spectrum of network architectures and data modalities, including brain networks, demonstrate that R2ET attains higher explanation robustness under stealthy attacks while retaining accuracy.", "IdName": "chen2023robust", "Citation": "", "Keywords": ""}, {"Name": "Efficient first-order predictor-corrector multiple objective optimization for fair misinformation detection", "Authors": ["Eric Enouen", "Katja Mathesius", "Sean Wang", "Arielle Carr", "Sihong Xie"], "Sources": "2022 IEEE/ACM International Conference on Big Data Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Multiple-objective optimization (MOO) aims to simultaneously optimize multiple conflicting objectives and has found important applications in machine learning, such as minimizing classification loss and discrepancy in treating different populations for fairness. At optimality, further optimizing one objective will necessarily harm at least another objective, and decision-makers need to comprehensively explore multiple optima (called Pareto front) to pinpoint one final solution. We address the efficiency of finding the Pareto front. First, finding the front from scratch using stochastic multi-gradient descent (SMGD) is expensive with large neural networks and datasets. We propose to explore the Pareto front as a manifold from a few initial optima, based on a predictor-corrector method. Second, for each exploration step, the predictor solves a large-scale linear system that scales quadratically in the number of model parameters and requires one backpropagation to evaluate a second-order Hessian-vector product per iteration of the solver. We propose a Gauss-Newton approximation that only scales linearly, and that requires only first-order inner-product per iteration. This also allows for a choice between the MINRES and conjugate gradient methods when approximately solving the linear system. The innovations make predictor-corrector possible for large networks. Experiments on multi-objective (fairness and accuracy) misinformation detection tasks show that 1) the predictor-corrector method can find Pareto fronts better than or similar to SMGD with less time; and 2) the proposed first-order method does not harm the quality of the Pareto front identified by?\u2026", "IdName": "enouen2022efficient", "Citation": "", "Keywords": ""}, {"Name": "On the Generalization Discrepancy of Spatiotemporal Dynamics-informed Graph Convolutional Networks", "Authors": ["Yue Sun", "Chao Chen", "Yuesheng Xu", "Sihong Xie", "Rick S. Blum", "Parv Venkitasubramaniam"], "Sources": "Frontiers in Mechanical Engineering 10", "PublishedYears": "2024", "Doi": "", "Abstracts": "Graph neural networks (GNNs) have gained significant attention in diverse domains, ranging from urban planning to pandemic management. Ensuring both accuracy and robustness in GNNs remains a challenge due to insufficient quality data that contains sufficient features. With sufficient training data where all spatiotemporal patterns are well-represented, existing GNN models can make reasonably accurate predictions. However, existing methods fail when the training data are drawn from different circumstances (e.g., traffic patterns on regular days) than test data (e.g., traffic patterns after a natural disaster). Such challenges are usually classified under domain generalization. In this work, we show that one way to address this challenge in the context of spatiotemporal prediction is by incorporating domain differential equations into graph convolutional networks (GCNs). We theoretically derive conditions where GCNs incorporating such domain differential equations are robust to mismatched training and testing data compared to baseline domain agnostic models. To support our theory, we propose two domain-differential-equation-informed networks: Reaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates differential equations for traffic speed evolution, and the Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which incorporates a disease propagation model. Both RDGCN and SIRGCN are based on reliable and interpretable domain differential equations that allow the models to generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN are more robust with mismatched?\u2026", "IdName": "sun2024generalization", "Citation": "", "Keywords": ""}, {"Name": "Out-of-distribution Detection in Medical Image Analysis: A survey", "Authors": ["Zesheng Hong", "Yubiao Yue", "Yubin Chen", "Huanjie Lin", "Yuanmei Luo", "Mini Han Wang", "Weidong Wang", "Jialong Xu", "Xiaoqi Yang", "Zhenzhang Li", "Sihong Xie"], "Sources": "arXiv preprint arXiv:2404.18279", "PublishedYears": "2024", "Doi": "", "Abstracts": "Computer-aided diagnostics has benefited from the development of deep learning-based computer vision techniques in these years. Traditional supervised deep learning methods assume that the test sample is drawn from the identical distribution as the training data. However, it is possible to encounter out-of-distribution samples in real-world clinical scenarios, which may cause silent failure in deep learning-based medical image analysis tasks. Recently, research has explored various out-of-distribution (OOD) detection situations and techniques to enable a trustworthy medical AI system. In this survey, we systematically review the recent advances in OOD detection in medical image analysis. We first explore several factors that may cause a distributional shift when using a deep-learning-based model in clinic scenarios, with three different types of distributional shift well defined on top of these factors. Then a framework is suggested to categorize and feature existing solutions, while the previous studies are reviewed based on the methodology taxonomy. Our discussion also includes evaluation protocols and metrics, as well as the challenge and a research direction lack of exploration.", "IdName": "hong2024out", "Citation": "", "Keywords": ""}, {"Name": "Uncertainty Quantification on Graph Learning: A Survey", "Authors": ["Chao Chen", "Chenghua Guo", "Rui Xu", "Xiangwen Liao", "Xi Zhang", "Sihong Xie", "Hui Xiong", "Philip Yu"], "Sources": "arXiv preprint arXiv:2404.14642", "PublishedYears": "2024", "Doi": "", "Abstracts": "Graphical models, including Graph Neural Networks (GNNs) and Probabilistic Graphical Models (PGMs), have demonstrated their exceptional capabilities across numerous fields. These models necessitate effective uncertainty quantification to ensure reliable decision-making amid the challenges posed by model training discrepancies and unpredictable testing scenarios. This survey examines recent works that address uncertainty quantification within the model architectures, training, and inference of GNNs and PGMs. We aim to provide an overview of the current landscape of uncertainty in graphical models by organizing the recent methods into uncertainty representation and handling. By summarizing state-of-the-art methods, this survey seeks to deepen the understanding of uncertainty quantification in graphical models, thereby increasing their effectiveness and safety in critical applications.", "IdName": "chen2024uncertainty", "Citation": "", "Keywords": ""}, {"Name": "Incorporating Domain Differential Equations into Graph Convolutional Networks to Lower Generalization Discrepancy", "Authors": ["Yue Sun", "Chao Chen", "Yuesheng Xu", "Sihong Xie", "Rick S Blum", "Parv Venkitasubramaniam"], "Sources": "arXiv preprint arXiv:2404.01217", "PublishedYears": "2024", "Doi": "", "Abstracts": "Ensuring both accuracy and robustness in time series prediction is critical to many applications, ranging from urban planning to pandemic management. With sufficient training data where all spatiotemporal patterns are well-represented, existing deep-learning models can make reasonably accurate predictions. However, existing methods fail when the training data are drawn from different circumstances (e.g., traffic patterns on regular days) compared to test data (e.g., traffic patterns after a natural disaster). Such challenges are usually classified under domain generalization. In this work, we show that one way to address this challenge in the context of spatiotemporal prediction is by incorporating domain differential equations into Graph Convolutional Networks (GCNs). We theoretically derive conditions where GCNs incorporating such domain differential equations are robust to mismatched training and testing data compared to baseline domain agnostic models. To support our theory, we propose two domain-differential-equation-informed networks called Reaction-Diffusion Graph Convolutional Network (RDGCN), which incorporates differential equations for traffic speed evolution, and Susceptible-Infectious-Recovered Graph Convolutional Network (SIRGCN), which incorporates a disease propagation model. Both RDGCN and SIRGCN are based on reliable and interpretable domain differential equations that allow the models to generalize to unseen patterns. We experimentally show that RDGCN and SIRGCN are more robust with mismatched testing data than the state-of-the-art deep learning methods.", "IdName": "sun2024incorporating", "Citation": "", "Keywords": ""}, {"Name": "Robust Conformal Prediction under Distribution Shift via Physics-Informed Structural Causal Model", "Authors": ["Rui Xu", "Yue Sun", "Chao Chen", "Parv Venkitasubramaniam", "Sihong Xie"], "Sources": "arXiv preprint arXiv:2403.15025", "PublishedYears": "2024", "Doi": "", "Abstracts": "Uncertainty is critical to reliable decision-making with machine learning. Conformal prediction (CP) handles uncertainty by predicting a set on a test input, hoping the set to cover the true label with at least  confidence. This coverage can be guaranteed on test data even if the marginal distributions  differ between calibration and test datasets. However, as it is common in practice, when the conditional distribution  is different on calibration and test data, the coverage is not guaranteed and it is essential to measure and minimize the coverage loss under distributional shift at \\textit{all} possible confidence levels. To address these issues, we upper bound the coverage difference at all levels using the cumulative density functions of calibration and test conformal scores and Wasserstein distance. Inspired by the invariance of physics across data distributions, we propose a physics-informed structural causal model (PI-SCM) to reduce the upper bound. We validated that PI-SCM can improve coverage robustness along confidence level and test domain on a traffic speed prediction task and an epidemic spread task with multiple real-world datasets.", "IdName": "xu2024robust", "Citation": "", "Keywords": ""}, {"Name": "Implementing Recycling Methods for Linear Systems in Python with an Application to Multiple Objective Optimization", "Authors": ["Ainara Garcia", "Sihong Xie", "Arielle Carr"], "Sources": "2023 International Conference on Machine Learning and Applications (ICMLA?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Sequences of linear systems arise in the predictor-corrector method when computing the Pareto front for multi-objective optimization. Rather than discarding information generated when solving one system, it may be advantageous to recycle information for subsequent systems. To accomplish this, we seek to reduce the overall cost of computation when solving linear systems using common recycling methods. In this work, we assessed the performance of recycling minimum residual (RMIN-RES) method along with a map between coefficient matrices. For these methods to be fully integrated into the software used in Enouen et al. (2022), there must be working version of each in both Python and PyTorch. Herein, we discuss the challenges we encountered and solutions undertaken (and some ongoing) when computing efficient Python implementations of these recycling strategies. The goal of this project was to?\u2026", "IdName": "garcia2023implementing", "Citation": "", "Keywords": ""}, {"Name": "Towards Natural Language Interfaces for Data Visualization: A Survey", "Authors": ["Leixian Shen", "Enya Shen", "Yuyu Luo", "Xiaocong Yang", "Xuming Hu", "Xiongshuai Zhang", "Zhiwei Tai", "Jianmin Wang"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Utilizing Visualization-oriented Natural Language Interfaces (V-NLI) as a complementary input modality to direct manipulation for visual analytics can provide an engaging user experience. It enables users to focus on their tasks rather than having to worry about how to operate visualization tools on the interface. In the past two decades, leveraging advanced natural language processing technologies, numerous V-NLI systems have been developed in academic research and commercial software, especially in recent years. In this article, we conduct a comprehensive review of the existing V-NLIs. In order to classify each article, we develop categorical dimensions based on a classic information visualization pipeline with the extension of a V-NLI layer. The following seven stages are used: query interpretation, data transformation, visual mapping, view transformation, human interaction, dialogue management, and?\u2026", "IdName": "shen2022towards", "Citation": "", "Keywords": ""}, {"Name": "Survey on factuality in large language models: Knowledge, retrieval and domain-specificity", "Authors": ["Cunxiang Wang", "Xiaoze Liu", "Yuanhao Yue", "Xiangru Tang", "Tianhang Zhang", "Cheng Jiayang", "Yunzhi Yao", "Wenyang Gao", "Xuming Hu", "Zehan Qi", "Yidong Wang", "Linyi Yang", "Jindong Wang", "Xing Xie", "Zheng Zhang", "Yue Zhang"], "Sources": "arXiv preprint arXiv:2310.07521", "PublishedYears": "2023", "Doi": "", "Abstracts": "This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs.", "IdName": "wang2023survey", "Citation": "", "Keywords": ""}, {"Name": "SelfORE: Self-supervised Relational Feature Learning for Open Relation Extraction", "Authors": ["Xuming Hu", "Lijie Wen", "Yusong Xu", "Chenwei Zhang", "Philip S Yu"], "Sources": "EMNLP", "PublishedYears": "2020", "Doi": "", "Abstracts": "Open relation extraction is the task of extracting open-domain relation facts from natural language sentences. Existing works either utilize heuristics or distant-supervised annotations to train a supervised classifier over pre-defined relations, or adopt unsupervised methods with additional assumptions that have less discriminative power. In this work, we proposed a self-supervised framework named SelfORE, which exploits weak, self-supervised signals by leveraging large pretrained language model for adaptive clustering on contextualized relational features, and bootstraps the self-supervised signals by improving contextualized features in relation classification. Experimental results on three datasets show the effectiveness and robustness of SelfORE on open-domain Relation Extraction when comparing with competitive baselines.", "IdName": "hu2020selfore", "Citation": "", "Keywords": ""}, {"Name": "A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability", "Authors": ["Aiwei Liu", "Xuming Hu", "Lijie Wen", "Philip S Yu"], "Sources": "arXiv preprint arXiv:2303.13547", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL ability. Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation, we sought to evaluate its Text-to-SQL performance. We conducted experiments on 12 benchmark datasets with different languages, settings, or scenarios, and the results demonstrate that ChatGPT has strong text-to-SQL abilities. Although there is still a gap from the current state-of-the-art (SOTA) model performance, considering that the experiment was conducted in a zero-shot scenario, ChatGPT's performance is still impressive. Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1\\%, demonstrating its potential for use in practical applications. To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.", "IdName": "liu2023comprehensive", "Citation": "", "Keywords": ""}, {"Name": "Semi-supervised Relation Extraction via Incremental Meta Self-Training", "Authors": ["Xuming Hu", "Fukun Ma", "Chenyao Liu", "Chenwei Zhang", "Lijie Wen", "Philip S Yu"], "Sources": "EMNLP (Findings)", "PublishedYears": "2021", "Doi": "", "Abstracts": "To alleviate human efforts from obtaining large-scale annotations, Semi-Supervised Relation Extraction methods aim to leverage unlabeled data in addition to learning from limited samples. Existing self-training methods suffer from the gradual drift problem, where noisy pseudo labels on unlabeled data are incorporated during training. To alleviate the noise in pseudo labels, we propose a method called MetaSRE, where a Relation Label Generation Network generates quality assessment on pseudo labels by (meta) learning from the successful and failed attempts on Relation Classification Network as an additional meta-objective. To reduce the influence of noisy pseudo labels, MetaSRE adopts a pseudo label selection and exploitation scheme which assesses pseudo label quality on unlabeled samples and only exploits high-quality pseudo labels in a self-training fashion to incrementally augment labeled samples for both robustness and accuracy. Experimental results on two public datasets demonstrate the effectiveness of the proposed approach.", "IdName": "hu2020semi", "Citation": "", "Keywords": ""}, {"Name": "Gradient Imitation Reinforcement Learning for Low Resource Relation Extraction", "Authors": ["Xuming Hu", "Chenwei Zhang", "Yawen Yang", "Xiaohe Li", "Li Lin", "Lijie Wen", "Philip S Yu"], "Sources": "EMNLP", "PublishedYears": "2021", "Doi": "", "Abstracts": "Low-resource Relation Extraction (LRE) aims to extract relation facts from limited labeled corpora when human annotation is scarce. Existing works either utilize self-training scheme to generate pseudo labels that will cause the gradual drift problem, or leverage meta-learning scheme which does not solicit feedback explicitly. To alleviate selection bias due to the lack of feedback loops in existing LRE learning paradigms, we developed a Gradient Imitation Reinforcement Learning method to encourage pseudo label data to imitate the gradient descent direction on labeled data and bootstrap its optimization capability through trial and error. We also propose a framework called GradLRE, which handles two major scenarios in low-resource relation extraction. Besides the scenario where unlabeled data is sufficient, GradLRE handles the situation where no unlabeled data is available, by exploiting a contextualized augmentation method to generate data. Experimental results on two public datasets demonstrate the effectiveness of GradLRE on low resource relation extraction when comparing with baselines.", "IdName": "hu2021gradient", "Citation": "", "Keywords": ""}, {"Name": "CLASSIC: Continual and contrastive learning of aspect sentiment classification tasks", "Authors": ["Zixuan Ke", "Bing Liu", "Hu Xu", "Lei Shu"], "Sources": "arXiv preprint arXiv:2112.02714", "PublishedYears": "2021", "Doi": "", "Abstracts": "This paper studies continual learning (CL) of a sequence of aspect sentiment classification(ASC) tasks in a particular CL setting called domain incremental learning (DIL). Each task is from a different domain or product. The DIL setting is particularly suited to ASC because in testing the system needs not know the task/domain to which the test data belongs. To our knowledge, this setting has not been studied before for ASC. This paper proposes a novel model called CLASSIC. The key novelty is a contrastive continual learning method that enables both knowledge transfer across tasks and knowledge distillation from old tasks to the new task, which eliminates the need for task ids in testing. Experimental results show the high effectiveness of CLASSIC.", "IdName": "ke2021classic", "Citation": "", "Keywords": ""}, {"Name": "A Semantic Invariant Robust Watermark for Large Language Models", "Authors": ["A Liu", "L Pan", "X Hu", "S Meng", "L Wen"], "Sources": "The Twelfth International Conference on Learning Representations", "PublishedYears": "2024", "Doi": "", "Abstracts": "This paper studies continual learning (CL) of a sequence of aspect sentiment classification(ASC) tasks in a particular CL setting called domain incremental learning (DIL). Each task is from a different domain or product. The DIL setting is particularly suited to ASC because in testing the system needs not know the task/domain to which the test data belongs. To our knowledge, this setting has not been studied before for ASC. This paper proposes a novel model called CLASSIC. The key novelty is a contrastive continual learning method that enables both knowledge transfer across tasks and knowledge distillation from old tasks to the new task, which eliminates the need for task ids in testing. Experimental results show the high effectiveness of CLASSIC.", "IdName": "liu2023semantic", "Citation": "", "Keywords": ""}, {"Name": "Pair-level supervised contrastive learning for natural language inference", "Authors": ["Shuang Li", "Xuming Hu", "Li Lin", "Lijie Wen"], "Sources": "ICASSP", "PublishedYears": "2022", "Doi": "", "Abstracts": "Natural language inference (NLI) is an increasingly important task for natural language understanding, which requires one to infer the relationship between the sentence pair (premise and hypothesis). Many recent works have used contrastive learning by incorporating the relationship of the sentence pair from NLI datasets to learn sentence representation. However, these methods only focus on comparisons with sentence-level representations. In this paper, we propose a Pair-level Supervised Contrastive Learning approach (PairSCL). We adopt a cross attention module to learn the joint representations of the sentence pairs. A contrastive learning objective is designed to distinguish the varied classes of sentence pairs by pulling those in one class together and pushing apart the pairs in other classes. We evaluate PairSCL on two public datasets of NLI where the accuracy of PairSCL outperforms other methods by 2?\u2026", "IdName": "li2022pair", "Citation": "", "Keywords": ""}, {"Name": "HiURE: Hierarchical Exemplar Contrastive Learning for Unsupervised Relation Extraction", "Authors": ["Shuliang Liu*", "Xuming Hu*", "Chenwei Zhang", "Shuang Li", "Lijie Wen", "Philip S Yu"], "Sources": "NAACL", "PublishedYears": "2022", "Doi": "", "Abstracts": "Unsupervised relation extraction aims to extract the relationship between entities from natural language sentences without prior information on relational scope or distribution. Existing works either utilize self-supervised schemes to refine relational feature signals by iteratively leveraging adaptive clustering and classification that provoke gradual drift problems, or adopt instance-wise contrastive learning which unreasonably pushes apart those sentence pairs that are semantically similar. To overcome these defects, we propose a novel contrastive learning framework named HiURE, which has the capability to derive hierarchical signals from relational feature space using cross hierarchy attention and effectively optimize relation representation of sentences under exemplar-wise contrastive learning. Experimental results on two public datasets demonstrate the advanced effectiveness and robustness of HiURE on unsupervised relation extraction when compared with state-of-the-art models.", "IdName": "hu2022hiure", "Citation": "", "Keywords": ""}, {"Name": "CHEF: A Pilot Chinese Dataset for Evidence-Based Fact-Checking", "Authors": ["Xuming Hu", "Zhijiang Guo", "Guanyu Wu", "Aiwei Liu", "Lijie Wen", "Philip S Yu"], "Sources": "NAACL", "PublishedYears": "2022", "Doi": "", "Abstracts": "The explosion of misinformation spreading in the media ecosystem urges for automated fact-checking. While misinformation spans both geographic and linguistic boundaries, most work in the field has focused on English. Datasets and tools available in other languages, such as Chinese, are limited. In order to bridge this gap, we construct CHEF, the first CHinese Evidence-based Fact-checking dataset of 10K real-world claims. The dataset covers multiple domains, ranging from politics to public health, and provides annotated evidence retrieved from the Internet. Further, we develop established baselines and a novel approach that is able to model the evidence retrieval as a latent variable, allowing jointly training with the veracity prediction model in an end-to-end fashion. Extensive experiments show that CHEF will provide a challenging testbed for the development of fact-checking systems designed to retrieve and reason over non-English claims.", "IdName": "hu2022chef", "Citation": "", "Keywords": ""}, {"Name": "Do Large Language Models Know about Facts?", "Authors": ["Xuming Hu", "Junzhe Chen", "Xiaochuan Li", "Yufei Guo", "Lijie Wen", "Philip S Yu", "Zhijiang Guo"], "Sources": "ICLR (Spotlight)", "PublishedYears": "2024", "Doi": "", "Abstracts": "Large language models (LLMs) have recently driven striking performance improvements across a range of natural language processing tasks. The factual knowledge acquired during pretraining and instruction tuning can be useful in various downstream tasks, such as question answering, and language generation. Unlike conventional Knowledge Bases (KBs) that explicitly store factual knowledge, LLMs implicitly store facts in their parameters. Content generated by the LLMs can often exhibit inaccuracies or deviations from the truth, due to facts that can be incorrectly induced or become obsolete over time. To this end, we aim to comprehensively evaluate the extent and scope of factual knowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains 20K diverse factual questions that span different sources, timelines, domains, regions, and languages. Furthermore, we investigate whether LLMs are able to compose multiple facts, update factual knowledge temporally, reason over multiple pieces of facts, identify subtle factual differences, and resist adversarial examples. Extensive experiments on different sizes and types of LLMs show that existing LLMs still lack factual knowledge and suffer from various spurious correlations. We believe this is a critical bottleneck for realizing trustworthy artificial intelligence. The dataset Pinocchio and our codes will be publicly available.", "IdName": "hu2023large", "Citation": "", "Keywords": ""}, {"Name": "Continual training of language models for few-shot learning", "Authors": ["Zixuan Ke", "Haowei Lin", "Yijia Shao", "Hu Xu", "Lei Shu", "Bing Liu"], "Sources": "arXiv preprint arXiv:2210.05549", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recent work on applying large language models (LMs) achieves impressive performance in many NLP applications. Adapting or posttraining an LM using an unlabeled domain corpus can produce even better performance for end-tasks in the domain. This paper proposes the problem of continually extending an LM by incrementally post-train the LM with a sequence of unlabeled domain corpora to expand its knowledge without forgetting its previous skills. The goal is to improve the few-shot end-task learning in these domains. The resulting system is called CPT (Continual PostTraining), which to our knowledge, is the first continual post-training system. Experimental results verify its effectiveness.", "IdName": "ke2022continual", "Citation": "", "Keywords": ""}, {"Name": "Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph", "Authors": ["Aiwei Liu", "Xuming Hu", "Li Lin", "Lijie Wen"], "Sources": "SIGKDD", "PublishedYears": "2022", "Doi": "", "Abstracts": "The generalizability to new databases is of vital importance to Text-to-SQL systems which aim to parse human utterances into SQL statements. Existing works achieve this goal by leveraging the exact matching method to identify the lexical matching between the question words and the schema items. However, these methods fail in other challenging scenarios, such as the synonym substitution in which the surface form differs between the corresponding question words and schema items. In this paper, we propose a framework named ISESL-SQL to iteratively build a semantic enhanced schema-linking graph between question tokens and database schemas. First, we extract a schema linking graph from PLMs through a probing procedure in an unsupervised manner. Then the schema linking graph is further optimized during the training process through a deep graph learning method. Meanwhile, we also design an?\u2026", "IdName": "liu2022semantic", "Citation": "", "Keywords": ""}, {"Name": "An unforgeable publicly verifiable watermark for large language models", "Authors": ["Aiwei Liu", "Leyi Pan", "Xuming Hu", "Shuang Li", "Lijie Wen", "Irwin King", "S Yu Philip"], "Sources": "The Twelfth International Conference on Learning Representations", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, text watermarking algorithms for large language models (LLMs) have been proposed to mitigate the potential harms of text generated by LLMs, including fake news and copyright issues. However, current watermark detection algorithms require the secret key used in the watermark generation process, making them susceptible to security breaches and counterfeiting during public detection. To address this limitation, we propose an unforgeable publicly verifiable watermark algorithm named UPV that uses two different neural networks for watermark generation and detection, instead of using the same key at both stages. Meanwhile, the token embedding parameters are shared between the generation and detection networks, which makes the detection network achieve a high accuracy very efficiently. Experiments demonstrate that our algorithm attains high detection accuracy and computational efficiency through neural networks. Subsequent analysis confirms the high complexity involved in forging the watermark from the detection network. Our code is available at https://github.com/THU-BPM/unforgeable_watermark", "IdName": "liu2023unforgeable", "Citation": "", "Keywords": ""}, {"Name": "Character-level White-Box Adversarial Attacks against Transformers via Attachable Subwords Substitution", "Authors": ["Aiwei Liu", "Honghai Yu", "Xuming Hu", "Shu'ang Li", "Li Lin", "Fukun Ma", "Yawen Yang", "Lijie Wen"], "Sources": "EMNLP", "PublishedYears": "2022", "Doi": "", "Abstracts": "We propose the first character-level white-box adversarial attack method against transformer models. The intuition of our method comes from the observation that words are split into subtokens before being fed into the transformer models and the substitution between two close subtokens has a similar effect to the character modification. Our method mainly contains three steps. First, a gradient-based method is adopted to find the most vulnerable words in the sentence. Then we split the selected words into subtokens to replace the origin tokenization result from the transformer tokenizer. Finally, we utilize an adversarial loss to guide the substitution of attachable subtokens in which the Gumbel-softmax trick is introduced to ensure gradient propagation. Meanwhile, we introduce the visual and length constraint in the optimization process to achieve minimum character modifications. Extensive experiments on both sentence-level and token-level tasks demonstrate that our method could outperform the previous attack methods in terms of success rate and edit distance. Furthermore, human evaluation verifies our adversarial examples could preserve their origin labels.", "IdName": "liu2022character", "Citation": "", "Keywords": ""}, {"Name": "Graph Neural Network with Curriculum Learning for Imbalanced Node Classification", "Authors": ["Xiaohe Li", "Lijie Wen", "Yawen Deng", "Fuli Feng", "Xuming Hu", "Lei Wang", "Zide Fan"], "Sources": "arXiv preprint arXiv:2202.02529", "PublishedYears": "2022", "Doi": "", "Abstracts": "Graph Neural Network (GNN) stands as an emerging methodology for graph-based learning tasks, particularly for node classification. This study elucidates the susceptibility of GNN to discrepancies arising from imbalanced node labels. Conventional solutions for imbalanced classification, such as resampling, falter in node classification task, primarily due to their negligence of graph structure. Worse still, they often exacerbate the model\u2019s inclination towards overfitting or underfitting, especially in the absence of adequate priori knowledge. To circumvent these limitations, we introduce a novel Graph Neural Network framework with Curriculum Learning (GNN-CL). This framework integrates two pivotal components. Initially, leveraging the principles of smoothness and homophily, we endeavor to procure dependable interpolation nodes and edges via adaptive graph oversampling. For another, we combine the Graph?\u2026", "IdName": "li2024graph", "Citation": "", "Keywords": ""}, {"Name": "Mr2: A benchmark for multimodal retrieval-augmented rumor detection in social media", "Authors": ["Xuming Hu", "Zhijiang Guo", "Junzhe Chen", "Lijie Wen", "Philip S Yu"], "Sources": "Proceedings of the 46th international ACM SIGIR conference on research and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "As social media platforms are evolving from text-based forums into multi-modal environments, the nature of misinformation in social media is also transforming accordingly. Misinformation spreaders have recently targeted contextual connections between the modalities e.g., text and image. However, existing datasets for rumor detection mainly focus on a single modality i.e., text. To bridge this gap, we construct MR2, a multimodal multilingual retrieval-augmented dataset for rumor detection. The dataset covers rumors with images and texts, and provides evidence from both modalities that are retrieved from the Internet. Further, we develop established baselines and conduct a detailed analysis of the systems evaluated on the dataset. Extensive experiments show that MR2 will provide a challenging testbed for developing rumor detection systems designed to retrieve and reason over social media posts. Source code?\u2026", "IdName": "hu2023mr2", "Citation": "", "Keywords": ""}, {"Name": "A Multi-level Supervised Contrastive Learning Framework for Low-Resource Natural Language Inference", "Authors": ["Shu'ang Li", "Xuming Hu", "Li Lin", "Aiwei Liu", "Lijie Wen", "Philip S Yu"], "Sources": "Transactions on Audio", "PublishedYears": "2022", "Doi": "", "Abstracts": "Natural Language Inference (NLI) is a growingly essential task in natural language understanding, which requires inferring the relationship between the sentence pairs ( premise  and  hypothesis ). Recently, low-resource natural language inference has gained increasing attention, due to significant savings in manual annotation costs and a better fit with real-world scenarios. Existing works fail to characterize discriminative representations between different classes with limited training data, which may cause faults in label prediction. Here we propose a multi-level supervised contrastive learning framework named MultiSCL for low-resource natural language inference. MultiSCL leverages a sentence-level and pair-level contrastive learning objective to discriminate between different classes of sentence pairs by bringing those in one class together and pushing away those in different classes. MultiSCL adopts a data?\u2026", "IdName": "hu2023multi", "Citation": "", "Keywords": ""}, {"Name": "AMR-based network for aspect-based sentiment analysis", "Authors": ["Fukun Ma", "Xuming Hu", "Aiwei Liu", "Yawen Yang", "S Yu Philip", "Lijie Wen"], "Sources": "Proceedings of the 61st Annual Meeting of the Association for Computational?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment classification task. Many recent works have used dependency trees to extract the relation between aspects and contexts and have achieved significant improvements. However, further improvement is limited due to the potential mismatch between the dependency tree as a syntactic structure and the sentiment classification as a semantic task. To alleviate this gap, we replace the syntactic dependency tree with the semantic structure named Abstract Meaning Representation (AMR) and propose a model called AMR-based Path Aggregation Relational Network (APARN) to take full advantage of semantic structures. In particular, we design the path aggregator and the relation-enhanced self-attention mechanism that complement each other. The path aggregator extracts semantic features from AMRs under the guidance of sentence information, while the relation-enhanced self-attention mechanism in turn improves sentence features with refined semantic information. Experimental results on four public datasets demonstrate 1.13% average F1 improvement of APARN in ABSA when compared with state-of-the-art baselines.", "IdName": "ma2023amr", "Citation": "", "Keywords": ""}, {"Name": "Domain-Specific NER via Retrieving Correlated Samples", "Authors": ["Xin Zhang", "Yong Jiang", "Xiaobin Wang", "Xuming Hu", "Yueheng Sun", "Pengjun Xie", "Meishan Zhang"], "Sources": "COLING", "PublishedYears": "2022", "Doi": "", "Abstracts": "Successful Machine Learning based Named Entity Recognition models could fail on texts from some special domains, for instance, Chinese addresses and e-commerce titles, where requires adequate background knowledge. Such texts are also difficult for human annotators. In fact, we can obtain some potentially helpful information from correlated texts, which have some common entities, to help the text understanding. Then, one can easily reason out the correct answer by referencing correlated samples. In this paper, we suggest enhancing NER models with correlated samples. We draw correlated samples by the sparse BM25 retriever from large-scale in-domain unlabeled data. To explicitly simulate the human reasoning process, we perform a training-free entity type calibrating by majority voting. To capture correlation features in the training stage, we suggest to model correlated samples by the transformer-based multi-instance cross-encoder. Empirical results on datasets of the above two domains show the efficacy of our methods.", "IdName": "zhang2022domain", "Citation": "", "Keywords": ""}, {"Name": "What Makes the Story Forward? Inferring Commonsense Explanations as Prompts for Future Event Generation", "Authors": ["Li Lin", "Yixin Cao", "Lifu Huang", "Shuang Li", "Xuming Hu", "Lijie Wen", "Jianmin Wang"], "Sources": "SIGIR", "PublishedYears": "2022", "Doi": "", "Abstracts": "Prediction over event sequences is critical for many real-world applications in Information Retrieval and Natural Language Processing. Future Event Generation (FEG) is a challenging task in event sequence prediction because it requires not only fluent text generation but also commonsense reasoning to maintain the logical coherence of the entire event story. In this paper, we propose a novel explainable FEG framework, Coep. It highlights and integrates two types of event knowledge, sequential knowledge of direct event-event relations and inferential knowledge that reflects the intermediate character psychology between events, such as intents, causes, reactions, which intrinsically pushes the story forward. To alleviate the knowledge forgetting issue, we design two modules, IM and GM, for each type of knowledge, which are combined via prompt tuning. First, IM focuses on understanding inferential knowledge to?\u2026", "IdName": "lin2022makes", "Citation": "", "Keywords": ""}, {"Name": "GDA: Generative Data Augmentation Techniques for Relation Extraction Tasks", "Authors": ["Xuming Hu", "Aiwei Liu", "Zeqi Tan", "Xin Zhang", "Chenwei Zhang", "Irwin King", "Philip S Yu"], "Sources": "ACL (Findings)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations. In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augment diverse sentences. Experimental results in three datasets under a low-resource setting showed that GDA could bring {\\em 2.0\\%} F1 improvements compared with no augmentation technique. Source code and data are available.", "IdName": "hu2023gda", "Citation": "", "Keywords": ""}, {"Name": "Entity-to-text based data augmentation for various named entity recognition tasks", "Authors": ["Xuming Hu", "Yong Jiang", "Aiwei Liu", "Zhongqiang Huang", "Pengjun Xie", "Fei Huang", "Lijie Wen", "Philip S Yu"], "Sources": "arXiv preprint arXiv:2210.10343", "PublishedYears": "2022", "Doi": "", "Abstracts": "Data augmentation techniques have been used to alleviate the problem of scarce labeled data in various NER tasks (flat, nested, and discontinuous NER tasks). Existing augmentation techniques either manipulate the words in the original text that break the semantic coherence of the text, or exploit generative models that ignore preserving entities in the original text, which impedes the use of augmentation techniques on nested and discontinuous NER tasks. In this work, we propose a novel Entity-to-Text based data augmentation technique named EnTDA to add, delete, replace or swap entities in the entity list of the original texts, and adopt these augmented entity lists to generate semantically coherent and entity preserving texts for various NER tasks. Furthermore, we introduce a diversity beam search to increase the diversity during the text generation process. Experiments on thirteen NER datasets across three tasks (flat, nested, and discontinuous NER tasks) and two settings (full data and low resource settings) show that EnTDA could bring more performance improvements compared to the baseline augmentation techniques.", "IdName": "hu2022entity", "Citation": "", "Keywords": ""}, {"Name": "Multimodal Relation Extraction with Cross-Modal Retrieval and Synthesis", "Authors": ["Xuming Hu", "Zhijiang Guo", "Zhiyang Teng", "Irwin King", "Philip S Yu"], "Sources": "ACL", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multimodal relation extraction (MRE) is the task of identifying the semantic relationships between two entities based on the context of the sentence image pair. Existing retrieval-augmented approaches mainly focused on modeling the retrieved textual knowledge, but this may not be able to accurately identify complex relations. To improve the prediction, this research proposes to retrieve textual and visual evidence based on the object, sentence, and whole image. We further develop a novel approach to synthesize the object-level, image-level, and sentence-level information for better reasoning between the same and different modalities. Extensive experiments and analyses show that the proposed method is able to effectively select and compare evidence across modalities and significantly outperforms state-of-the-art models.", "IdName": "hu2023multimodal", "Citation": "", "Keywords": ""}, {"Name": "Graph Component Contrastive Learning for Concept Relatedness Estimation", "Authors": ["Yueen Ma", "Zixing Song", "Xuming Hu", "Jingjing Li", "Yifei Zhang", "Irwin King"], "Sources": "AAAI", "PublishedYears": "2023", "Doi": "", "Abstracts": "Concept relatedness estimation (CRE) aims to determine whether two given concepts are related. Existing methods only consider the pairwise relationship between concepts, while overlooking the higher-order relationship that could be encoded in a concept-level graph structure. We discover that this underlying graph satisfies a set of intrinsic properties of CRE, including reflexivity, commutativity, and transitivity. In this paper, we formalize the CRE properties and introduce a graph structure named ConcreteGraph. To address the data scarcity issue in CRE, we introduce a novel data augmentation approach to sample new concept pairs from the graph. As it is intractable for data augmentation to fully capture the structural information of the ConcreteGraph due to a large amount of potential concept pairs, we further introduce a novel Graph Component Contrastive Learning framework to implicitly learn the complete structure of the ConcreteGraph. Empirical results on three datasets show significant improvement over the state-of-the-art model. Detailed ablation studies demonstrate that our proposed approach can effectively capture the high-order relationship among concepts.", "IdName": "ma2023graph", "Citation": "", "Keywords": ""}, {"Name": "Read it Twice: Towards Faithfully Interpretable Fact Verification by Revisiting Evidence", "Authors": ["Xuming Hu", "Zhaochen Hong", "Zhijiang Guo", "Lijie Wen", "Philip S Yu"], "Sources": "SIGIR", "PublishedYears": "2023", "Doi": "", "Abstracts": "Real-world fact verification task aims to verify the factuality of a claim by retrieving evidence from the source document. The quality of the retrieved evidence plays an important role in claim verification. Ideally, the retrieved evidence should be faithful (reflecting the model's decision-making process in claim verification) and plausible (convincing to humans), and can improve the accuracy of verification task. Although existing approaches leverage the similarity measure of semantic or surface form between claims and documents to retrieve evidence, they all rely on certain heuristics that prevent them from satisfying all three requirements. In light of this, we propose a fact verification model named ReRead to retrieve evidence and verify claim that: (1) Train the evidence retriever to obtain interpretable evidence (i.e., faithfulness and plausibility criteria); (2) Train the claim verifier to revisit the evidence retrieved by the?\u2026", "IdName": "hu2023read", "Citation": "", "Keywords": ""}, {"Name": "MespaConfig: Memory-Sparing Configuration Auto-Tuning for Co-Located In-Memory Cluster Computing Jobs", "Authors": ["Zan Zong", "Lijie Wen", "Xuming Hu", "Rui Han", "Chen Qian", "Li Lin"], "Sources": "IEEE Transactions on Services Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "Distributed in-memory computing frameworks usually have lots of parameters (e.g., the buffer size of shuffle) to form a configuration for each execution. A well-tuned configuration can bring large improvements of performance. However, to improve resource utilization, jobs are often share the same cluster, which causes dynamic cluster load conditions. According to our observation, the variation of cluster load reduces effectiveness of configuration tuning. Besides, as a common problem of cluster computing jobs, overestimation of resources also occurs during configuration tuning. It is challenging to efficiently find the optimal configuration in a shared cluster with the consideration of memory-sparing. In this article, we introduce MespaConfig, a job-level configuration optimizer for distributed in-memory computing jobs. Advancements of MespaConfig over previous work are features including memory-sparing and load?\u2026", "IdName": "zong2021mespaconfig", "Citation": "", "Keywords": ""}, {"Name": "When llms meet cunning questions: A fallacy understanding benchmark for large language models", "Authors": ["Yinghui Li", "Qingyu Zhou", "Yuanzhen Luo", "Shirong Ma", "Yangning Li", "Hai-Tao Zheng", "Xuming Hu", "Philip S Yu"], "Sources": "arXiv preprint arXiv:2402.11100", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recently, Large Language Models (LLMs) have made remarkable evolutions in language understanding and generation. Following this, various benchmarks for measuring all kinds of capabilities of LLMs have sprung up. In this paper, we challenge the reasoning and understanding abilities of LLMs by proposing a FaLlacy Understanding Benchmark (FLUB) containing cunning questions that are easy for humans to understand but difficult for models to grasp. Specifically, the cunning questions that FLUB focuses on mainly consist of the tricky, humorous, and misleading questions collected from the real internet environment. And we design three tasks with increasing difficulty in the FLUB benchmark to evaluate the fallacy understanding ability of LLMs. Based on FLUB, we investigate the performance of multiple representative and advanced LLMs, reflecting our FLUB is challenging and worthy of more future study. Interesting discoveries and valuable insights are achieved in our extensive experiments and detailed analyses. We hope that our benchmark can encourage the community to improve LLMs' ability to understand fallacies.", "IdName": "li2024llms", "Citation": "", "Keywords": ""}, {"Name": "Gaussian Prior Reinforcement Learning for Nested Named Entity Recognition", "Authors": ["Yawen Yang", "Xuming Hu", "Fukun Ma", "Aiwei Liu", "Lijie Wen", "S Yu Philip"], "Sources": "ICASSP", "PublishedYears": "2023", "Doi": "", "Abstracts": "Named Entity Recognition (NER) is a well and widely studied task in natural language processing. Recently, the nested NER has attracted more attention since its practicality and difficulty. Existing works for nested NER ignore the recognition order and boundary position relation of nested entities. To address these issues, we propose a novel seq2seq model named GPRL, which formulates the nested NER task as an entity triplet sequence generation process. GPRL adopts the reinforcement learning method to generate entity triplets de-coupling the entity order in gold labels and expects to learn a reasonable recognition order of entities via trial and error. Based on statistics of boundary distance for nested entities, GPRL designs a Gaussian prior to represent the boundary distance distribution between nested entities and adjust the out-put probability distribution of nested boundary tokens. Experiments on three?\u2026", "IdName": "yang2023gaussian", "Citation": "", "Keywords": ""}, {"Name": "Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction", "Authors": ["Xuming Hu", "Zhaochen Hong", "Chenwei Zhang", "Irwin King", "Philip S Yu"], "Sources": "SIGIR", "PublishedYears": "2023", "Doi": "", "Abstracts": "Relation extraction (RE) aims to extract potential relations according to the context of two entities, thus, deriving rational contexts from sentences plays an important role. Previous works either focus on how to leverage the entity information (e.g., entity types, entity verbalization) to inference relations, but ignore context-focused content, or use counterfactual thinking to remove the model's bias of potential relations in entities, but the relation reasoning process will still be hindered by irrelevant content. Therefore, how to preserve relevant content and remove noisy segments from sentences is a crucial task. In addition, retained content needs to be fluent enough to maintain semantic coherence and interpretability. In this work, we propose a novel rationale extraction framework named RE2, which leverages two continuity and sparsity factors to obtain relevant and coherent rationales from sentences. To solve the problem?\u2026", "IdName": "hu2023think", "Citation": "", "Keywords": ""}, {"Name": "Prompt me up: Unleashing the power of alignments for multimodal entity and relation extraction", "Authors": ["Xuming Hu", "Junzhe Chen", "Aiwei Liu", "Shiao Meng", "Lijie Wen", "Philip S Yu"], "Sources": "Proceedings of the 31st ACM International Conference on Multimedia", "PublishedYears": "2023", "Doi": "", "Abstracts": "How can we better extract entities and relations from text? Using multimodal extraction with images and text obtains more signals for entities and relations, and aligns them through graphs or hierarchical fusion, aiding in extraction. Despite attempts at various fusions, previous works have overlooked many unlabeled image-caption pairs, such as NewsCLIPing. This paper proposes innovative pre-training objectives for entity-object and relation-image alignment, extracting objects from images and aligning them with entity and relation prompts for soft pseudo-labels. These labels are used as self-supervised signals for pre-training, enhancing the ability to extract entities and relations. Experiments on three datasets show an average 3.41% F1 improvement over prior SOTA. Additionally, our method is orthogonal to previous multimodal fusions, and using it on prior SOTA fusions further improves 5.47% F1.", "IdName": "hu2023prompt", "Citation": "", "Keywords": ""}, {"Name": "Query-based Instance Discrimination Network for Relational Triple Extraction", "Authors": ["Zeqi Tan", "Yongliang Shen", "Xuming Hu", "Wenqi Zhang", "Xiaoxia Cheng", "Weiming Lu", "Yueting Zhuang"], "Sources": "EMNLP", "PublishedYears": "2022", "Doi": "", "Abstracts": "Joint entity and relation extraction has been a core task in the field of information extraction. Recent approaches usually consider the extraction of relational triples from a stereoscopic perspective, either learning a relation-specific tagger or separate classifiers for each relation type. However, they still suffer from error propagation, relation redundancy and lack of high-level connections between triples. To address these issues, we propose a novel query-based approach to construct instance-level representations for relational triples. By metric-based comparison between query embeddings and token embeddings, we can extract all types of triples in one step, thus eliminating the error propagation problem. In addition, we learn the instance-level representation of relational triples via contrastive learning. In this way, relational triples can not only enclose rich class-level semantics but also access to high-order global connections. Experimental results show that our proposed method achieves the state of the art on five widely used benchmarks.", "IdName": "tan2022query", "Citation": "", "Keywords": ""}, {"Name": "Automatic table union search with tabular representation learning", "Authors": ["Xuming Hu", "Shen Wang", "Xiao Qin", "Chuan Lei", "Zhengyuan Shen", "Christos Faloutsos", "Asterios Katsifodimos", "George Karypis", "Lijie Wen", "S Yu Philip"], "Sources": "Findings of the Association for Computational Linguistics: ACL 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "Given a data lake of tabular data as well as a query table, how can we retrieve all the tables in the data lake that can be unioned with the query table? Table union search constitutes an essential task in data discovery and preparation as it enables data scientists to navigate massive open data repositories. Existing methods identify uniability based on column representations (word surface forms or token embeddings) and column relation represented by column representation similarity. However, the semantic similarity obtained between column representations is often insufficient to reveal latent relational features to describe the column relation between pair of columns and not robust to the table noise. To address these issues, in this paper, we propose a multi-stage self-supervised table union search framework called AutoTUS, which represents column relation as a vector\u2013column relational representation and learn column relational representation in a multi-stage manner that can better describe column relation for unionability prediction. In particular, the large language model powered contextualized column relation encoder is updated by adaptive clustering and pseudo label classification iteratively so that the better column relational representation can be learned. Moreover, to improve the robustness of the model against table noises, we propose table noise generator to add table noise to the training table data. Experiments on real-world datasets as well as synthetic test set augmented with table noise show that AutoTUS achieves 5.2% performance gain over the SOTA baseline.", "IdName": "hu2023automatic", "Citation": "", "Keywords": ""}, {"Name": "Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer", "Authors": ["Shuang Li", "Xuming Hu", "Aiwei Liu", "Yawen Yang", "Fukun Ma", "Philip S Yu", "Lijie Wen"], "Sources": "ACL (Findings)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Cross-lingual natural language inference is a fundamental problem in cross-lingual language understanding. Many recent works have used prompt learning to address the lack of annotated parallel corpora in XNLI. However, these methods adopt discrete prompting by simply translating the templates to the target language and need external expert knowledge to design the templates. Besides, discrete prompts of human-designed template words are not trainable vectors and can not be migrated to target languages in the inference stage flexibly. In this paper, we propose a novel Soft prompt learning framework with the Multilingual Verbalizer (SoftMV) for XNLI. SoftMV first constructs cloze-style question with soft prompts for the input sample. Then we leverage bilingual dictionaries to generate an augmented multilingual question for the original question. SoftMV adopts a multilingual verbalizer to align the representations of original and augmented multilingual questions into the same semantic space with consistency regularization. Experimental results on XNLI demonstrate that SoftMV can achieve state-of-the-art performance and significantly outperform the previous methods under the few-shot and full-shot cross-lingual transfer settings.", "IdName": "li2023enhancing", "Citation": "", "Keywords": ""}, {"Name": "Rethinking the Roles of Large Language Models in Chinese Grammatical Error Correction", "Authors": ["Yinghui Li", "Shang Qin", "Jingheng Ye", "Shirong Ma", "Yangning Li", "Libo Qin", "Xuming Hu", "Wenhao Jiang", "Hai-Tao Zheng", "Philip S Yu"], "Sources": "arXiv preprint arXiv:2402.11420", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recently, Large Language Models (LLMs) have been widely studied by researchers for their roles in various downstream NLP tasks. As a fundamental task in the NLP field, Chinese Grammatical Error Correction (CGEC) aims to correct all potential grammatical errors in the input sentences. Previous studies have shown that LLMs' performance as correctors on CGEC remains unsatisfactory due to its challenging task focus. To promote the CGEC field to better adapt to the era of LLMs, we rethink the roles of LLMs in the CGEC task so that they can be better utilized and explored in CGEC. Considering the rich grammatical knowledge stored in LLMs and their powerful semantic understanding capabilities, we utilize LLMs as explainers to provide explanation information for the CGEC small models during error correction to enhance performance. We also use LLMs as evaluators to bring more reasonable CGEC evaluations, thus alleviating the troubles caused by the subjectivity of the CGEC task. In particular, our work is also an active exploration of how LLMs and small models better collaborate in downstream tasks. Extensive experiments and detailed analyses on widely used datasets verify the effectiveness of our thinking intuition and the proposed methods.", "IdName": "li2024rethinking", "Citation": "", "Keywords": ""}, {"Name": "RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction", "Authors": ["Shiao Meng", "Xuming Hu", "Aiwei Liu", "Shu'ang Li", "Fukun Ma", "Yawen Yang", "Lijie Wen"], "Sources": "arXiv preprint arXiv:2310.15743", "PublishedYears": "2023", "Doi": "", "Abstracts": "How to identify semantic relations among entities in a document when only a few labeled documents are available? Few-shot document-level relation extraction (FSDLRE) is crucial for addressing the pervasive data scarcity problem in real-world scenarios. Metric-based meta-learning is an effective framework widely adopted for FSDLRE, which constructs class prototypes for classification. However, existing works often struggle to obtain class prototypes with accurate relational semantics: 1) To build prototype for a target relation type, they aggregate the representations of all entity pairs holding that relation, while these entity pairs may also hold other relations, thus disturbing the prototype. 2) They use a set of generic NOTA (none-of-the-above) prototypes across all tasks, neglecting that the NOTA semantics differs in tasks with different target relation types. In this paper, we propose a relation-aware prototype learning method for FSDLRE to strengthen the relational semantics of prototype representations. By judiciously leveraging the relation descriptions and realistic NOTA instances as guidance, our method effectively refines the relation prototypes and generates task-specific NOTA prototypes. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches by average 2.61%  across various settings of two FSDLRE benchmarks.", "IdName": "meng2023rapl", "Citation": "", "Keywords": ""}, {"Name": "Reading Broadly to Open Your Mind Improving Open Relation Extraction With Search Documents Under Self-Supervisions", "Authors": ["Xuming Hu", "Zhaochen Hong", "Chenwei Zhang", "Aiwei Liu", "Shiao Meng", "Lijie Wen", "Irwin King", "S Yu Philip"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Open relation extraction is the task of extracting open-domain relation facts from natural language sentences. Existing works either utilize distant-supervised annotations to train a supervised classifier over pre-defined relations, or adopt unsupervised methods with additional dependency on external assumptions. However, these works can only obtain information signals from limited existing knowledge bases or datasets. In this work, we propose a self-supervised framework named  Web-SelfORE , which exploits self-supervised signals by requiring a large pretrained language model to extensively read real-world relevant documents from the web, and obtain contextualized relational features by mixing contextualized representations of entities from different documents. We perform adaptive clustering on contextualized relational features and bootstrap the self-supervised signals by improving contextualized features?\u2026", "IdName": "hu2023reading", "Citation": "", "Keywords": ""}, {"Name": "Selflre: Self-refining representation learning for low-resource relation extraction", "Authors": ["Xuming Hu", "Junzhe Chen", "Shiao Meng", "Lijie Wen", "Philip S Yu"], "Sources": "Proceedings of the 46th International ACM SIGIR Conference on Research and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Low-resource relation extraction (LRE) aims to extract potential relations from limited labeled corpus to handle the problem of scarcity of human annotations. Previous works mainly consist of two categories of methods: (1) Self-training methods, which improve themselves through the models' predictions, thus suffering from confirmation bias when the predictions are wrong. (2) Self-ensembling methods, which learn task-agnostic representations, therefore, generally do not work well for specific tasks. In our work, we propose a novel LRE architecture named SelfLRE, which leverages two complementary modules, one module uses self-training to obtain pseudo-labels for unlabeled data, and the other module uses self-ensembling learning to obtain the task-agnostic representations, and leverages the existing pseudo-labels to refine the better task-specific representations on unlabeled data. The two models are jointly?\u2026", "IdName": "hu2023selflre", "Citation": "", "Keywords": ""}, {"Name": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments", "Authors": ["Junzhe Chen", "Xuming Hu", "Shuodi Liu", "Shiyu Huang", "Wei-Wei Tu", "Zhaofeng He", "Lijie Wen"], "Sources": "ACL", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent advancements in large language models (LLMs) have revealed their potential for achieving autonomous agents possessing human-level intelligence. However, existing benchmarks for evaluating LLM Agents either use static datasets, potentially leading to data leakage or focus only on single-agent scenarios, overlooking the complexities of multi-agent interactions. There is a lack of a benchmark that evaluates the diverse capabilities of LLM agents in multi-agent, dynamic environments. To this end, we introduce LLMArena, a novel and easily extensible framework for evaluating the diverse capabilities of LLM in multi-agent dynamic environments. LLMArena encompasses seven distinct gaming environments, employing Trueskill scoring to assess crucial abilities in LLM agents, including spatial reasoning, strategic planning, numerical reasoning, risk assessment, communication, opponent modeling, and team collaboration. We conduct an extensive experiment and human evaluation among different sizes and types of LLMs, showing that LLMs still have a significant journey ahead in their development towards becoming fully autonomous agents, especially in opponent modeling and team collaboration. We hope LLMArena could guide future research towards enhancing these capabilities in LLMs, ultimately leading to more sophisticated and practical applications in dynamic, multi-agent settings. The code and data will be available.", "IdName": "chen2024llmarena", "Citation": "", "Keywords": ""}, {"Name": "Scene Graph Modification as Incremental Structure Expanding", "Authors": ["Xuming Hu", "Zhijiang Guo", "Yu Fu", "Lijie Wen", "Philip S Yu"], "Sources": "COLING", "PublishedYears": "2022", "Doi": "", "Abstracts": "A scene graph is a semantic representation that expresses the objects, attributes, and relationships between objects in a scene. Scene graphs play an important role in many cross modality tasks, as they are able to capture the interactions between images and texts. In this paper, we focus on scene graph modification (SGM), where the system is required to learn how to update an existing scene graph based on a natural language query. Unlike previous approaches that rebuilt the entire scene graph, we frame SGM as a graph expansion task by introducing the incremental structure expanding (ISE). ISE constructs the target graph by incrementally expanding the source graph without changing the unmodified structure. Based on ISE, we further propose a model that iterates between nodes prediction and edges prediction, inferring more accurate and harmonious expansion decisions progressively. In addition, we construct a challenging dataset that contains more complicated queries and larger scene graphs than existing datasets. Experiments on four benchmarks demonstrate the effectiveness of our approach, which surpasses the previous state-of-the-art model by large margins.", "IdName": "hu2022scene", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Compositional Generalization in Context Dependent Text-to-SQL Parsing", "Authors": ["Aiwei Liu", "Wei Liu", "Xuming Hu", "Shuang Li", "Fukun Ma", "Yawen Yang", "Lijie Wen"], "Sources": "ACL (Findings)", "PublishedYears": "2023", "Doi": "", "Abstracts": "In the context-dependent Text-to-SQL task, the generated SQL statements are refined iteratively based on the user input utterance from each interaction. The input text from each interaction can be viewed as component modifications to the previous SQL statements, which could be further extracted as the modification patterns. Since these modification patterns could also be combined with other SQL statements, the models are supposed to have the compositional generalization to these novel combinations. This work is the first exploration of compositional generalization in context-dependent Text-to-SQL scenarios. To facilitate related studies, we constructed two challenging benchmarks named \\textsc{CoSQL-CG} and \\textsc{SParC-CG} by recombining the modification patterns and existing SQL statements. The following experiments show that all current models struggle on our proposed benchmarks. Furthermore, we found that better aligning the previous SQL statements with the input utterance could give models better compositional generalization ability. Based on these observations, we propose a method named \\texttt{p-align} to improve the compositional generalization of Text-to-SQL models. Further experiments validate the effectiveness of our method. Source code and data are available.", "IdName": "liu2023exploring", "Citation": "", "Keywords": ""}, {"Name": "Give Me More Details: Improving Fact-Checking with Latent Retrieval", "Authors": ["Xuming Hu", "Zhijiang Guo", "Guanyu Wu", "Lijie Wen", "Philip S Yu"], "Sources": "ACL", "PublishedYears": "2023", "Doi": "", "Abstracts": "Evidence plays a crucial role in automated fact-checking. When verifying real-world claims, existing fact-checking systems either assume the evidence sentences are given or use the search snippets returned by the search engine. Such methods ignore the challenges of collecting evidence and may not provide sufficient information to verify real-world claims. Aiming at building a better fact-checking system, we propose to incorporate full text from source documents as evidence and introduce two enriched datasets. The first one is a multilingual dataset, while the second one is monolingual (English). We further develop a latent variable model to jointly extract evidence sentences from documents and perform claim verification. Experiments indicate that including source documents can provide sufficient contextual clues even when gold evidence sentences are not annotated. The proposed system is able to achieve significant improvements upon best-reported models under different settings.", "IdName": "hu2023give", "Citation": "", "Keywords": ""}, {"Name": "Preventing and Detecting Misinformation Generated by Large Language Models", "Authors": ["Aiwei Liu", "Qiang Sheng", "Xuming Hu"], "Sources": "Proceedings of the 47th International ACM SIGIR Conference on Research and?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "As large language models (LLMs) become increasingly capable and widely deployed, the risk of them generating misinformation poses a critical challenge. Misinformation from LLMs can take various forms, from factual errors due to hallucination to intentionally deceptive content, and can have severe consequences in high-stakes domains.This tutorial covers comprehensive strategies to prevent and detect misinformation generated by LLMs. We first introduce the types of misinformation LLMs can produce and their root causes. We then explore two broad categories: Preventing misinformation generation: a) AI alignment training techniques to reduce LLMs' propensity for misinformation and refuse malicious instructions during model training. b) Training-free mitigation methods like prompt guardrails, retrieval-augmented generation (RAG), and decoding strategies to curb misinformation at inference time. Detecting?\u2026", "IdName": "liu2024preventing", "Citation": "", "Keywords": ""}, {"Name": "MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model", "Authors": ["Jiahao Huo", "Yibo Yan", "Boren Hu", "Yutao Yue", "Xuming Hu"], "Sources": "arXiv preprint arXiv:2406.11193", "PublishedYears": "2024", "Doi": "", "Abstracts": "Projecting visual features into word embedding space has become a significant fusion strategy adopted by Multimodal Large Language Models (MLLMs). However, its internal mechanisms have yet to be explored. Inspired by multilingual research, we identify domain-specific neurons in multimodal large language models. Specifically, we investigate the distribution of domain-specific neurons and the mechanism of how MLLMs process features from diverse domains. Furthermore, we propose a three-stage framework for language model modules in MLLMs when handling projected image features, and verify this hypothesis using logit lens. Extensive experiments indicate that while current MLLMs exhibit Visual Question Answering (VQA) capability, they may not fully utilize domain-specific information. Manipulating domain-specific neurons properly will result in a 10\\% change of accuracy at most, shedding light on the development of cross-domain, all-encompassing MLLMs in the future. Our code will be released upon paper notification.", "IdName": "huo2024mmneuron", "Citation": "", "Keywords": ""}, {"Name": "Refiner: Restructure Retrieval Content Efficiently to Advance Question-Answering Capabilities", "Authors": ["Zhonghao Li", "Xuming Hu", "Aiwei Liu", "Kening Zheng", "Sirui Huang", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2406.11357", "PublishedYears": "2024", "Doi": "", "Abstracts": "Large Language Models (LLMs) are limited by their parametric knowledge, leading to hallucinations in knowledge-extensive tasks. To address this, Retrieval-Augmented Generation (RAG) incorporates external document chunks to expand LLM knowledge. Furthermore, compressing information from document chunks through extraction or summarization can improve LLM performance. Nonetheless, LLMs still struggle to notice and utilize scattered key information, a problem known as the \"lost-in-the-middle\" syndrome. Therefore, we typically need to restructure the content for LLM to recognize the key information. We propose , an end-to-end extract-and-restructure paradigm that operates in the post-retrieval process of RAG.  leverages a single decoder-only LLM to adaptively extract query-relevant contents verbatim along with the necessary context, and section them based on their interconnectedness, thereby highlights information distinction, and aligns downstream LLMs with the original context effectively. Experiments show that a trained  (with 7B parameters) exhibits significant gain to downstream LLM in improving answer accuracy, and outperforms other state-of-the-art advanced RAG and concurrent compressing approaches in various single-hop and multi-hop QA tasks. Notably,  achieves a 80.5% tokens reduction and a 1.6-7.0% improvement margin in multi-hop tasks compared to the next best solution.  is a plug-and-play solution that can be seamlessly integrated with RAG systems, facilitating its application across diverse open-source frameworks.", "IdName": "li2024refiner", "Citation": "", "Keywords": ""}, {"Name": "On the Robustness of Document-Level Relation Extraction Models to Entity Name Variations", "Authors": ["Shiao Meng", "Xuming Hu", "Aiwei Liu", "Fukun Ma", "Yawen Yang", "Shuang Li", "Lijie Wen"], "Sources": "ACL (Findings)", "PublishedYears": "2024", "Doi": "", "Abstracts": "Driven by the demand for cross-sentence and large-scale relation extraction, document-level relation extraction (DocRE) has attracted increasing research interest. Despite the continuous improvement in performance, we find that existing DocRE models which initially perform well may make more mistakes when merely changing the entity names in the document, hindering the generalization to novel entity names. To this end, we systematically investigate the robustness of DocRE models to entity name variations in this work. We first propose a principled pipeline to generate entity-renamed documents by replacing the original entity names with names from Wikidata. By applying the pipeline to DocRED and Re-DocRED datasets, we construct two novel benchmarks named Env-DocRED and Env-Re-DocRED for robustness evaluation. Experimental results show that both three representative DocRE models and two in-context learned large language models consistently lack sufficient robustness to entity name variations, particularly on cross-sentence relation instances and documents with more entities. Finally, we propose an entity variation robust training method which not only improves the robustness of DocRE models but also enhances their understanding and reasoning capabilities. We further verify that the basic idea of this method can be effectively transferred to in-context learning for DocRE as well.", "IdName": "meng2024robustness", "Citation": "", "Keywords": ""}, {"Name": "MarkLLM: An Open-Source Toolkit for LLM Watermarking", "Authors": ["Leyi Pan", "Aiwei Liu", "Zhiwei He", "Zitian Gao", "Xuandong Zhao", "Yijian Lu", "Binglin Zhou", "Shuliang Liu", "Xuming Hu", "Lijie Wen", "Irwin King"], "Sources": "arXiv preprint arXiv:2405.10051", "PublishedYears": "2024", "Doi": "", "Abstracts": "LLM watermarking, which embeds imperceptible yet algorithmically detectable signals in model outputs to identify LLM-generated text, has become crucial in mitigating the potential misuse of large language models. However, the abundance of LLM watermarking algorithms, their intricate mechanisms, and the complex evaluation procedures and perspectives pose challenges for researchers and the community to easily experiment with, understand, and assess the latest advancements. To address these issues, we introduce MarkLLM, an open-source toolkit for LLM watermarking. MarkLLM offers a unified and extensible framework for implementing LLM watermarking algorithms, while providing user-friendly interfaces to ensure ease of access. Furthermore, it enhances understanding by supporting automatic visualization of the underlying mechanisms of these algorithms. For evaluation, MarkLLM offers a comprehensive suite of 12 tools spanning three perspectives, along with two types of automated evaluation pipelines. Through MarkLLM, we aim to support researchers while improving the comprehension and involvement of the general public in LLM watermarking technology, fostering consensus and driving further advancements in research and application. Our code is available at https://github.com/THU-BPM/MarkLLM.", "IdName": "pan2024markllm", "Citation": "", "Keywords": ""}, {"Name": "Three Heads Are Better than One: Improving Cross-Domain NER with Progressive Decomposed Network", "Authors": ["Xuming Hu", "Zhaochen Hong", "Yong Jiang", "Zhichao Lin", "Xiaobin Wang", "Pengjun Xie", "S Yu Philip"], "Sources": "AAAI", "PublishedYears": "2024", "Doi": "", "Abstracts": "Cross-domain named entity recognition (NER) tasks encourage NER models to transfer knowledge from data-rich source domains to sparsely labeled target domains. Previous works adopt the paradigms of pre-training on the source domain followed by fine-tuning on the target domain. However, these works ignore that general labeled NER source domain data can be easily retrieved in the real world, and soliciting more source domains could bring more benefits. Unfortunately, previous paradigms cannot efficiently transfer knowledge from multiple source domains. In this work, to transfer multiple source domains' knowledge, we decouple the NER task into the pipeline tasks of mention detection and entity typing, where the mention detection unifies the training object across domains, thus providing the entity typing with higher-quality entity mentions. Additionally, we request multiple general source domain models to suggest the potential named entities for sentences in the target domain explicitly, and transfer their knowledge to the target domain models through the knowledge progressive networks implicitly. Furthermore, we propose two methods to analyze in which source domain knowledge transfer occurs, thus helping us judge which source domain brings the greatest benefit. In our experiment, we develop a Chinese cross-domain NER dataset. Our model improved the F1 score by an average of 12.50% across 8 Chinese and English datasets compared to models without source domain data.", "IdName": "hu2024three", "Citation": "", "Keywords": ""}, {"Name": "UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed Entities", "Authors": ["Yangning Li", "Qingsong Lv", "Tianyu Yu", "Yinghui Li", "Shulin Huang", "Tingwei Lu", "Xuming Hu", "Wenhao JIang", "Hai-Tao Zheng", "Hui Wang"], "Sources": "arXiv preprint arXiv:2403.04247", "PublishedYears": "2024", "Doi": "", "Abstracts": "Entity Set Expansion (ESE) aims to identify new entities belonging to the same semantic class as a given set of seed entities. Traditional methods primarily relied on positive seed entities to represent a target semantic class, which poses challenge for the representation of ultra-fine-grained semantic classes. Ultra-fine-grained semantic classes are defined based on fine-grained semantic classes with more specific attribute constraints. Describing it with positive seed entities alone cause two issues: (i) Ambiguity among ultra-fine-grained semantic classes. (ii) Inability to define \"unwanted\" semantic. Due to these inherent shortcomings, previous methods struggle to address the ultra-fine-grained ESE (Ultra-ESE). To solve this issue, we first introduce negative seed entities in the inputs, which belong to the same fine-grained semantic class as the positive seed entities but differ in certain attributes. Negative seed entities eliminate the semantic ambiguity by contrast between positive and negative attributes. Meanwhile, it provide a straightforward way to express \"unwanted\". To assess model performance in Ultra-ESE, we constructed UltraWiki, the first large-scale dataset tailored for Ultra-ESE. UltraWiki encompasses 236 ultra-fine-grained semantic classes, where each query of them is represented with 3-5 positive and negative seed entities. A retrieval-based framework RetExpan and a generation-based framework GenExpan are proposed to comprehensively assess the efficacy of large language models from two different paradigms in Ultra-ESE. Moreover, we devised three strategies to enhance models' comprehension of ultra-fine-grained entities?\u2026", "IdName": "li2024ultrawiki", "Citation": "", "Keywords": ""}, {"Name": "Unraveling Babel: Exploring Multilingual Activation Patterns within Large Language Models", "Authors": ["Weize Liu", "Yinlong Xu", "Hongxia Xu", "Jintai Chen", "Xuming Hu", "Jian Wu"], "Sources": "arXiv preprint arXiv:2402.16367", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recently, large language models (LLMs) have achieved tremendous breakthroughs in the field of language processing, yet their mechanisms in processing multiple languages remain agnostic. Therefore, in this work we study the multilingual activation patterns of LLMs. By transforming the original Large Language Models (LLMs) into a Mixture of Experts (MoE) architecture, we analyze the expert activation patterns when processing various languages and demonstrate the connections of these activation patterns at the level of language families. We discover the existence of non-language-specific neurons as well as language-specific activation neurons. Further exploration even showcases that merely leveraging high-frequency activation neurons can accelerate inference while maintaining comparable performance. These findings shed light on the LLMs' multilingual processing mechanism, and are of significant importance in guiding the multilingual training and model pruning of LLMs.", "IdName": "liu2024unraveling", "Citation": "", "Keywords": ""}, {"Name": "Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions", "Authors": ["Xuming Hu", "Xiaochuan Li", "Junzhe Chen", "Yinghui Li", "Yangning Li", "Xiaoguang Li", "Yasheng Wang", "Qun Liu", "Lijie Wen", "Philip S Yu", "Zhijiang Guo"], "Sources": "ACL (Findings)", "PublishedYears": "2024", "Doi": "", "Abstracts": "Generative search engines have the potential to transform how people seek information online, but generated responses from existing large language models (LLMs)-backed generative search engines may not always be accurate. Nonetheless, retrieval-augmented generation exacerbates safety concerns, since adversaries may successfully evade the entire system by subtly manipulating the most vulnerable part of a claim. To this end, we propose evaluating the robustness of generative search engines in the realistic and high-risk setting, where adversaries have only black-box system access and seek to deceive the model into returning incorrect responses. Through a comprehensive human evaluation of various generative search engines, such as Bing Chat, PerplexityAI, and YouChat across diverse queries, we demonstrate the effectiveness of adversarial factual questions in inducing incorrect responses. Moreover, retrieval-augmented generation exhibits a higher susceptibility to factual errors compared to LLMs without retrieval. These findings highlight the potential security risks of these systems and emphasize the need for rigorous evaluation before deployment.", "IdName": "hu2024evaluating", "Citation": "", "Keywords": ""}, {"Name": "Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive Thinking from Large Language Models", "Authors": ["Weize Liu", "Guocong Li", "Kai Zhang", "Bang Du", "Qiyuan Chen", "Xuming Hu", "Hongxia Xu", "Jintai Chen", "Jian Wu"], "Sources": "arXiv preprint arXiv:2311.09214", "PublishedYears": "2023", "Doi": "", "Abstracts": "Large language models (LLMs) have achieved remarkable advancements in the field of natural language processing. However, the sheer scale and computational demands of these models present formidable challenges when considering their practical deployment in resource-constrained contexts. While techniques such as chain-of-thought (CoT) distillation have displayed promise in distilling LLMs into small language models (SLMs), there is a risk that distilled SLMs may still carry over flawed reasoning or hallucinations inherited from their LLM counterparts. To address these issues, we propose a twofold methodology: First, we introduce a novel method for distilling the self-evaluation capability inherent in LLMs into SLMs, which aims to mitigate the adverse effects of erroneous reasoning and reduce hallucinations. Second, we advocate for a comprehensive distillation process that incorporates multiple distinct chain-of-thought and self-evaluation paradigms and ensures a more holistic and robust knowledge transfer into SLMs. Experiments on three NLP benchmarks demonstrate that our method significantly improves the performance of distilled SLMs and sheds light on the path towards developing smaller models closely aligned with human cognition.", "IdName": "liu2023mind", "Citation": "", "Keywords": ""}, {"Name": "Gradient Imitation Reinforcement Learning for General Low-Resource Information Extraction", "Authors": ["Xuming Hu", "Shiao Meng", "Chenwei Zhang", "Xiangli Yang", "Lijie Wen", "Irwin King", "Philip S Yu"], "Sources": "arXiv preprint arXiv:2211.06014", "PublishedYears": "2022", "Doi": "", "Abstracts": "Information Extraction (IE) aims to extract structured information from heterogeneous sources. IE from natural language texts include sub-tasks such as Named Entity Recognition (NER), Relation Extraction (RE), and Event Extraction (EE). Most IE systems require comprehensive understandings of sentence structure, implied semantics, and domain knowledge to perform well; thus, IE tasks always need adequate external resources and annotations. However, it takes time and effort to obtain more human annotations. Low-Resource Information Extraction (LRIE) strives to use unsupervised data, reducing the required resources and human annotation. In practice, existing systems either utilize self-training schemes to generate pseudo labels that will cause the gradual drift problem, or leverage consistency regularization methods which inevitably possess confirmation bias. To alleviate confirmation bias due to the lack of feedback loops in existing LRIE learning paradigms, we develop a Gradient Imitation Reinforcement Learning (GIRL) method to encourage pseudo-labeled data to imitate the gradient descent direction on labeled data, which can force pseudo-labeled data to achieve better optimization capabilities similar to labeled data. Based on how well the pseudo-labeled data imitates the instructive gradient descent direction obtained from labeled data, we design a reward to quantify the imitation process and bootstrap the optimization capability of pseudo-labeled data through trial and error. In addition to learning paradigms, GIRL is not limited to specific sub-tasks, and we leverage GIRL to solve all IE sub-tasks (named entity recognition, relation?\u2026", "IdName": "hu2022gradient", "Citation": "", "Keywords": ""}, {"Name": "Learning to warm up cold item embeddings for cold-start recommendation with meta scaling and shifting networks", "Authors": ["Yongchun Zhu", "Ruobing Xie", "Fuzhen Zhuang", "Kaikai Ge", "Ying Sun", "Xu Zhang", "Leyu Lin", "Juan Cao"], "Sources": "Proceedings of the 44th International ACM SIGIR Conference on Research and?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Recently, embedding techniques have achieved impressive success in recommender systems. However, the embedding techniques are data demanding and suffer from the cold-start problem. Especially, for the cold-start item which only has limited interactions, it is hard to train a reasonable item ID embedding, called cold ID embedding, which is a major challenge for the embedding techniques. The cold item ID embedding has two main problems: (1) A gap is existing between the cold ID embedding and the deep model. (2) Cold ID embedding would be seriously affected by noisy interaction. However, most existing methods do not consider both two issues in the cold-start problem, simultaneously. To address these problems, we adopt two key ideas: (1) Speed up the model fitting for the cold item ID embedding (fast adaptation). (2) Alleviate the influence of noise. Along this line, we propose Meta Scaling and?\u2026", "IdName": "zhu2021learning", "Citation": "", "Keywords": ""}, {"Name": "Market-oriented job skill valuation with cooperative composition neural network", "Authors": ["Ying Sun", "Fuzhen Zhuang", "Hengshu Zhu", "Qi Zhang", "Qing He", "Hui Xiong"], "Sources": "Nature communications", "PublishedYears": "2021", "Doi": "", "Abstracts": "The value assessment of job skills is important for companies to select and retain the right talent. However, there are few quantitative ways available for this assessment. Therefore, we propose a data-driven solution to assess skill value from a market-oriented perspective. Specifically, we formulate the task of job skill value assessment as a Salary-Skill Value Composition Problem, where each job position is regarded as the composition of a set of required skills attached with the contextual information of jobs, and the job salary is assumed to be jointly influenced by the context-aware value of these skills. Then, we propose an enhanced neural network with cooperative structure, namely Salary-Skill Composition Network (SSCN), to separate the job skills and measure their value based on the massive job postings. Experiments show that SSCN can not only assign meaningful value to job skills, but also outperforms?\u2026", "IdName": "sun2021market", "Citation": "", "Keywords": ""}, {"Name": "Cost-effective and interpretable job skill recommendation with deep reinforcement learning", "Authors": ["Ying Sun", "Fuzhen Zhuang", "Hengshu Zhu", "Qing He", "Hui Xiong"], "Sources": "Proceedings of the Web Conference 2021", "PublishedYears": "2021", "Doi": "", "Abstracts": " Nowadays, as organizations operate in very fast-paced and competitive environments, workforce has to be agile and adaptable to regularly learning new job skills. However, it is nontrivial for talents to know which skills to develop at each working stage. To this end, in this paper, we aim to develop a cost-effective recommendation system based on deep reinforcement learning, which can provide personalized and interpretable job skill recommendation for each talent. Specifically, we first design an environment to estimate the utilities of skill learning by mining the massive job advertisement data, which includes a skill-matching-based salary estimator and a frequent itemset-based learning difficulty estimator. Based on the environment, we design a Skill Recommendation Deep Q-Network (SRDQN) with multi-task structure to estimate the long-term skill learning utilities. In particular, SRDQN recommends job skills in a?\u2026", "IdName": "sun2021cost", "Citation": "", "Keywords": ""}, {"Name": "A comprehensive survey of artificial intelligence techniques for talent analytics", "Authors": ["Chuan Qin", "Le Zhang", "Rui Zha", "Dazhong Shen", "Qi Zhang", "Ying Sun", "Chen Zhu", "Hengshu Zhu", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2307.03195", "PublishedYears": "2023", "Doi": "", "Abstracts": "In today's competitive and fast-evolving business environment, it is a critical time for organizations to rethink how to make talent-related decisions in a quantitative manner. Indeed, the recent development of Big Data and Artificial Intelligence (AI) techniques have revolutionized human resource management. The availability of large-scale talent and management-related data provides unparalleled opportunities for business leaders to comprehend organizational behaviors and gain tangible knowledge from a data science perspective, which in turn delivers intelligence for real-time decision-making and effective talent management at work for their organizations. In the last decade, talent analytics has emerged as a promising field in applied data science for human resource management, garnering significant attention from AI communities and inspiring numerous research efforts. To this end, we present an up-to-date and comprehensive survey on AI technologies used for talent analytics in the field of human resource management. Specifically, we first provide the background knowledge of talent analytics and categorize various pertinent data. Subsequently, we offer a comprehensive taxonomy of relevant research efforts, categorized based on three distinct application-driven scenarios: talent management, organization management, and labor market analysis. In conclusion, we summarize the open challenges and potential prospects for future research directions in the domain of AI-driven talent analytics.", "IdName": "qin2023comprehensive", "Citation": "", "Keywords": ""}, {"Name": "Automatic skill-oriented question generation and recommendation for intelligent job interviews", "Authors": ["Chuan Qin", "Hengshu Zhu", "Dazhong Shen", "Ying Sun", "Kaichun Yao", "Peng Wang", "Hui Xiong"], "Sources": "ACM Transactions on Information Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "Job interviews are the most widely accepted method for companies to select suitable candidates, and a critical challenge is finding the right questions to ask job candidates. Moreover, there is a lack of integrated tools for automatically generating interview questions and recommending the right questions to interviewers. To this end, in this paper, we propose an intelligent system for assisting job interviews, namely, DuerQues. To build this system, we first investigate how to automatically generate skill-oriented interview questions in a scalable way by learning external knowledge from online knowledge-sharing communities. Along this line, we develop a novel distantly supervised skill entity recognition method to identify skill entities from large-scale search queries and web page titles with less need for human annotation. Additionally, we propose a neural generative model for generating skill-oriented interview?\u2026", "IdName": "qin2023automatic", "Citation": "", "Keywords": ""}, {"Name": "Modeling the impact of person-organization fit on talent management with structure-aware attentive neural networks", "Authors": ["Ying Sun", "Fuzhen Zhuang", "Hengshu Zhu", "Xin Song", "Qing He", "Hui Xiong"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Person-Organization fit (P-O fit) refers to the compatibility between employees and their organizations. The study of P-O fit is important for enhancing proactive talent management. While considerable efforts have been made in this direction, it still lacks a quantitative and holistic way for measuring P-O fit and its impact on talent management. To this end, in this paper, we propose a novel data-driven neural network approach for dynamically modeling the compatibility in P-O fit and its meaningful relationships with two critical issues in talent management, namely talent turnover and job performance. Specifically, inspired by the practical management scenarios, we creatively propose a novel neural-network-based P-O fit model. We first designed three kinds of organization-aware compatibility features extraction layers for measuring P-O fit. Then, to capture the dynamic nature of P-O fit and its consequent impact, we?\u2026", "IdName": "sun2021modeling", "Citation": "", "Keywords": ""}, {"Name": "Talent demand forecasting with attentive neural sequential model", "Authors": ["Qi Zhang", "Hengshu Zhu", "Ying Sun", "Hao Liu", "Fuzhen Zhuang", "Hui Xiong"], "Sources": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "To cope with the fast-evolving business trend, it becomes critical for companies to continuously review their talent recruitment strategies by the timely forecast of talent demand in recruitment market. While many efforts have been made on recruitment market analysis, due to the sparsity of fine-grained talent demand time series and the complex temporal correlation of the recruitment market, there is still no effective approach for fine-grained talent demand forecast, which can quantitatively model the dynamics of the recruitment market. To this end, in this paper, we propose a data-driven neural sequential approach, namely Talent Demand Attention Network (TDAN), for forecasting fine-grained talent demand in the recruitment market. Specifically, we first propose to augment the univariate time series of talent demand at multiple grained levels and extract intrinsic attributes of both companies and job positions with?\u2026", "IdName": "zhang2021talent", "Citation": "", "Keywords": ""}, {"Name": "Rapid Learning of earthquake felt Area and intensity Distribution with Real-time Search engine Queries", "Authors": ["Hengshu Zhu", "Ying Sun", "Wenjia Zhao", "Fuzhen Zhuang", "Baoshan Wang", "Hui Xiong"], "Sources": "Scientific reports", "PublishedYears": "2020", "Doi": "", "Abstracts": "Immediately after a destructive earthquake, the real-time seismological community has a major focus on rapidly estimating the felt area and the extent of ground shaking. This estimate provides critical guidance for government emergency response teams to conduct orderly rescue and recovery operations in the damaged areas. While considerable efforts have been made in this direction, it still remains a realistic challenge for gathering macro-seismic data in a timely, accurate and cost-effective manner. To this end, we introduce a new direction to improve the information acquisition through monitoring the real-time information-seeking behaviors in the search engine queries, which are submitted by tens of millions of users after earthquakes. Specifically, we provide a very efficient, robust and machine-learning-assisted method for mapping the user-reported ground shaking distribution through the large-scale analysis?\u2026", "IdName": "zhu2020rapid", "Citation": "", "Keywords": ""}, {"Name": "Generative Learning Plan Recommendation for Employees: A Performance-aware Reinforcement Learning Approach", "Authors": ["Zhi Zheng", "Ying Sun", "Xin Song", "Hengshu Zhu", "Hui Xiong"], "Sources": "Proceedings of the 17th ACM Conference on Recommender Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": " With the rapid development of enterprise Learning Management Systems (LMS), more and more companies are trying to build enterprise training and course learning platforms for promoting the career development of employees. Indeed, through course learning, many employees have the opportunity to improve their knowledge and skills. For these systems, a major issue is how to recommend learning plans, i.e., a set of courses arranged in the order they should be learned, that can help employees improve their work performance. Existing studies mainly focus on recommending courses that users are most likely to click on by capturing their learning preferences. However, the learning preference of employees may not be the right fit for their career development, and thus it may not necessarily mean their work performance can be improved accordingly. Furthermore, how to capture the mutual correlation and?\u2026", "IdName": "zheng2023generative", "Citation": "", "Keywords": ""}, {"Name": "Adaptively sharing multi-levels of distributed representations in multi-task learning", "Authors": ["Tianxin Wang", "Fuzhen Zhuang", "Ying Sun", "Xiangliang Zhang", "Leyu Lin", "Feng Xia", "Lei He", "Qing He"], "Sources": "Information Sciences 591", "PublishedYears": "2022", "Doi": "", "Abstracts": "In multi-task learning, the performance is often sensitive to the relationships between tasks. Thus it is important to study how to exploit the complex relationships across different tasks. One line of research captures the complex task relationships, by increasing the model capacity and thus requiring a large training dataset. However in many real-world applications, the amount of labeled data is limited. In this paper, we propose a light weight and specially designed architecture, which aims to model task relationships for small or middle-sized datasets. The proposed framework learns a task-specific ensemble of sub-networks in different depths, and is able to adapt the model architecture for the given data. The task-specific ensemble parameters are learned simultaneously with the weights of the network by optimizing a single loss function defined with respect to the end task. The hierarchical model structure is able to?\u2026", "IdName": "wang2022adaptively", "Citation": "", "Keywords": ""}, {"Name": "Collaboration-Aware Hybrid Learning for Knowledge Development Prediction", "Authors": ["Liyi Chen", "Chuan Qin", "Ying Sun", "Xin Song", "Tong Xu", "Hengshu Zhu", "Hui Xiong"], "Sources": "Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "In recent years, the rise of online Knowledge Management Systems (KMSs) has significantly improved work efficiency in enterprises. Knowledge development prediction, as a critical application within these online platforms, enables organizations to proactively address knowledge gaps and align their learning initiatives with evolving job requirements. However, it still confronts challenges in exploring the influence of collaborative networks on knowledge development and adapting to ecological situations in working environment. To this end, in this paper, we propose a Collaboration-Aware Hybrid Learning approach (CAHL) for predicting the future knowledge acquisition of employees and quantifying the impact of various knowledge learning patterns. Specifically, to fully harness the inherent rules of knowledge development, we first learn the knowledge co-occurrence and prerequisite relationships with an?\u2026", "IdName": "chen2024collaboration", "Citation": "", "Keywords": ""}, {"Name": "Interactive interior design recommendation via coarse-to-fine multimodal reinforcement learning", "Authors": ["He Zhang", "Ying Sun", "Weiyu Guo", "Yafei Liu", "Haonan Lu", "Xiaodong Lin", "Hui Xiong"], "Sources": "Proceedings of the 31st ACM International Conference on Multimedia", "PublishedYears": "2023", "Doi": "", "Abstracts": "Personalized interior decoration design often incurs high labor costs. Recent efforts in developing intelligent interior design systems have focused on generating textual requirement-based decoration designs while neglecting the problem of how to mine homeowner's hidden preferences and choose the proper initial design. To fill this gap, we propose an Interactive Interior Design Recommendation System (IIDRS) based on reinforcement learning (RL). IIDRS aims to find an ideal plan by interacting with the user, who provides feedback on the gap between the recommended plan and their ideal one. To improve decision-making efficiency and effectiveness in large decoration spaces, we propose a Decoration Recommendation Coarse-to-Fine Policy Network (DecorRCFN). Additionally, to enhance generalization in online scenarios, we propose an object-aware feedback generation method that augments model?\u2026", "IdName": "zhang2023interactive", "Citation": "", "Keywords": ""}, {"Name": "Beyond Homophily: Robust Graph Anomaly Detection via Neural Sparsification.", "Authors": ["Zheng Gong", "Guifeng Wang", "Ying Sun", "Qi Liu", "Yuting Ning", "Hui Xiong", "Jingyu Peng"], "Sources": "IJCAI", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, graph-based anomaly detection (GAD) has attracted rising attention due to its effectiveness in identifying anomalies in relational and structured data. Unfortunately, the performance of most existing GAD methods suffers from the inherent structural noises of graphs induced by hidden anomalies connected with considerable benign nodes. In this work, we propose SparseGAD, a novel GAD framework that sparsifies the structures of target graphs to effectively reduce noises and collaboratively learns node representations. It then robustly detects anomalies by uncovering the underlying dependency among node pairs in terms of homophily and heterophily, two essential connection properties of GAD. Extensive experiments on real-world datasets of GAD demonstrate that the proposed framework achieves significantly better detection quality compared with the state-of-the-art methods, even when the graph is heavily attacked. Code will be available at https://github. com/KellyGong/SparseGAD. git.", "IdName": "gong2023beyond", "Citation": "", "Keywords": ""}, {"Name": "Meta-path hierarchical heterogeneous graph convolution network for high potential scholar recognition", "Authors": ["Yiqing Wu", "Ying Sun", "Fuzhen Zhuang", "Deqing Wang", "Xiangliang Zhang", "Qing He"], "Sources": "2020 IEEE International Conference on Data Mining (ICDM)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recognizing high potential scholars has become an important problem in recent years. However, conventional scholar evaluating methods based on hand-crafted metrics can not profile the scholars in a dynamic and comprehensive way. With the development of online academic databases, large-scale academic activity data become available, which implies detailed information on the scholars' achievements and academic activities. Inspired by the recent success of deep graph neural networks (GNNs), we propose a novel solution to recognize high potential scholars on the dynamic heterogeneous academic network. Specifically, we propose a novel Mate-path Hierarchical Heterogeneous Graph Convolution Network (MHHGCN) to effectively model the heterogeneous graph information. MHHGCN hierarchically aggregates entity and relational information on a set of metapaths, and can alleviate the information?\u2026", "IdName": "wu2020meta", "Citation": "", "Keywords": ""}, {"Name": "Discerning decision-making process of deep neural networks with hierarchical voting transformation", "Authors": ["Ying Sun", "Hengshu Zhu", "Chuan Qin", "Fuzhen Zhuang", "Qing He", "Hui Xiong"], "Sources": "Advances in Neural Information Processing Systems 34", "PublishedYears": "2021", "Doi": "", "Abstracts": "Neural network based deep learning techniques have shown great success for numerous applications. While it is expected to understand their intrinsic decision-making processes, these deep neural networks often work in a black-box way. To this end, in this paper, we aim to discern the decision-making processes of neural networks through a hierarchical voting strategy by developing an explainable deep learning model, namely Voting Transformation-based Explainable Neural Network (VOTEN). Specifically, instead of relying on massive feature combinations, VOTEN creatively models expressive single-valued voting functions between explicitly modeled latent concepts to achieve high fitting ability. Along this line, we first theoretically analyze the major components of VOTEN and prove the relationship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), the basic structure of deep neural networks. Moreover, we design efficient algorithms to improve the model usability by explicitly showing the decision processes of VOTEN. Finally, extensive experiments on multiple real-world datasets clearly validate the performances and explainability of VOTEN.", "IdName": "sun2021discerning", "Citation": "", "Keywords": ""}, {"Name": "Exploring the tidal effect of urban business district with large-scale human mobility data", "Authors": ["Hongting Niu", "Ying Sun", "Hengshu Zhu", "Cong Geng", "Jiuchun Yang", "Hui Xiong", "Bo Lang"], "Sources": "Frontiers of Computer Science", "PublishedYears": "2023", "Doi": "", "Abstracts": "Business districts are urban areas that have various functions for gathering people, such as work, consumption, leisure and entertainment. Due to the dynamic nature of business activities, there exists significant tidal effect on the boundary and functionality of business districts. Indeed, effectively analyzing the tidal patterns of business districts can benefit the economic and social development of a city. However, with the implicit and complex nature of business district evolution, it is non-trivial for existing works to support the fine-grained and timely analysis on the tidal effect of business districts. To this end, we propose a data-driven and multi-dimensional framework for dynamic business district analysis. Specifically, we use the large-scale human trajectory data in urban areas to dynamically detect and forecast the boundary changes of business districts in different time periods. Then, we detect and forecast the?\u2026", "IdName": "niu2023exploring", "Citation": "", "Keywords": ""}, {"Name": "Exploring the risky travel area and behavior of car-hailing service", "Authors": ["Hongting Niu", "Hengshu Zhu", "Ying Sun", "Xinjiang Lu", "Jing Sun", "Zhiyuan Zhao", "Hui Xiong", "Bo Lang"], "Sources": "ACM Transactions on Intelligent Systems and Technology (TIST)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Recent years have witnessed the rapid development of car-hailing services, which provide a convenient approach for connecting passengers and local drivers using their personal vehicles. At the same time, the concern on passenger safety has gradually emerged and attracted more and more attention. While car-hailing service providers have made considerable efforts on developing real-time trajectory tracking systems and alarm mechanisms, most of them only focus on providing rescue-supporting information rather than preventing potential crimes. Recently, the newly available large-scale car-hailing order data have provided an unparalleled chance for researchers to explore the risky travel area and behavior of car-hailing services, which can be used for building an intelligent crime early warning system. To this end, in this article, we propose a Risky Area and Risky Behavior Evaluation System (RARBEs?\u2026", "IdName": "niu2021exploring", "Citation": "", "Keywords": ""}, {"Name": "Graph Reasoning Enhanced Language Models for Text-to-SQL", "Authors": ["Zheng Gong", "Ying Sun"], "Sources": "Proceedings of the 47th International ACM SIGIR Conference on Research and?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Text-to-SQL parsing has attracted substantial attention recently due to its potential to remove barriers for non-expert end users interacting with databases. A key challenge in Text-to-SQL parsing is developing effective encoding mechanisms to capture the complex relationships between question words, database schemas, and their associated connections within the heterogeneous graph structure. Existing approaches typically introduce some useful multi-hop structures manually and then incorporate them into graph neural networks (GNNs) by stacking multiple layers, which (1) ignore the difficult-to-identify but meaningful semantics embedded in the multi-hop reasoning path, and (2) are limited by the expressive capability of GNN to capture long-range dependencies among the heterogeneous graph. To address these shortcomings, we introduce GRL-SQL, a graph reasoning enhanced language model, which?\u2026", "IdName": "gong2024graph", "Citation": "", "Keywords": ""}, {"Name": "Unified Dual-Intent Translation for Joint Modeling of Search and Recommendation", "Authors": ["Yuting Zhang", "Yiqing Wu", "Ruidong Han", "Ying Sun", "Yongchun Zhu", "Xiang Li", "Wei Lin", "Fuzhen Zhuang", "Zhulin An", "Yongjun Xu"], "Sources": "arXiv preprint arXiv:2407.00912", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recommendation systems, which assist users in discovering their preferred items among numerous options, have served billions of users across various online platforms. Intuitively, users' interactions with items are highly driven by their unchanging inherent intents (e.g., always preferring high-quality items) and changing demand intents (e.g., wanting a T-shirt in summer but a down jacket in winter). However, both types of intents are implicitly expressed in recommendation scenario, posing challenges in leveraging them for accurate intent-aware recommendations. Fortunately, in search scenario, often found alongside recommendation on the same online platform, users express their demand intents explicitly through their query words. Intuitively, in both scenarios, a user shares the same inherent intent and the interactions may be influenced by the same demand intent. It is therefore feasible to utilize the interaction data from both scenarios to reinforce the dual intents for joint intent-aware modeling. But the joint modeling should deal with two problems: 1) accurately modeling users' implicit demand intents in recommendation; 2) modeling the relation between the dual intents and the interactive items. To address these problems, we propose a novel model named Unified Dual-Intents Translation for joint modeling of Search and Recommendation (UDITSR). To accurately simulate users' demand intents in recommendation, we utilize real queries from search data as supervision information to guide its generation. To explicitly model the relation among the triplet , we propose a dual-intent translation propagation mechanism to learn the triplet in the?\u2026", "IdName": "zhang2024unified", "Citation": "", "Keywords": ""}, {"Name": "SpGesture: Source-Free Domain-adaptive sEMG-based Gesture Recognition with Jaccard Attentive Spiking Neural Network", "Authors": ["Weiyu Guo", "Ying Sun", "Yijie Xu", "Ziyue Qiao", "Yongkui Yang", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2405.14398", "PublishedYears": "2024", "Doi": "", "Abstracts": "Surface electromyography (sEMG) based gesture recognition offers a natural and intuitive interaction modality for wearable devices. Despite significant advancements in sEMG-based gesture-recognition models, existing methods often suffer from high computational latency and increased energy consumption. Additionally, the inherent instability of sEMG signals, combined with their sensitivity to distribution shifts in real-world settings, compromises model robustness. To tackle these challenges, we propose a novel SpGesture framework based on Spiking Neural Networks, which possesses several unique merits compared with existing methods: (1) Robustness: By utilizing membrane potential as a memory list, we pioneer the introduction of Source-Free Domain Adaptation into SNN for the first time. This enables SpGesture to mitigate the accuracy degradation caused by distribution shifts. (2) High Accuracy: With a novel Spiking Jaccard Attention, SpGesture enhances the SNNs' ability to represent sEMG features, leading to a notable rise in system accuracy. To validate SpGesture's performance, we collected a new sEMG gesture dataset which has different forearm postures, where SpGesture achieved the highest accuracy among the baselines (). Moreover, the actual deployment on the CPU demonstrated a system latency below 100ms, well within real-time requirements. This impressive performance showcases SpGesture's potential to enhance the applicability of sEMG in real-world scenarios. The code is available at https://anonymous.4open.science/r/SpGesture.", "IdName": "guo2024spgesture", "Citation": "", "Keywords": ""}, {"Name": "Towards Unified Representation Learning for Career Mobility Analysis with Trajectory Hypergraph", "Authors": ["Rui Zha", "Ying Sun", "Chuan Qin", "Le Zhang", "Tong Xu", "Hengshu Zhu", "Enhong Chen"], "Sources": "ACM Transactions on Information Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Career mobility analysis aims at understanding the occupational movement patterns of talents across distinct labor market entities, which enables a wide range of talent-centered applications, such as job recommendation, labor demand forecasting, and company competitive analysis. Existing studies in this field mainly focus on a single fixed scale, investigating either individual trajectories at the micro-level or crowd flows among market entities at the macro-level. Consequently, the intrinsic cross-scale interactions between talents and the labor market are largely overlooked. To bridge this gap, we propose UniTRep, a novel unified representation learning framework for cross-scale career mobility analysis. Specifically, we first introduce a trajectory hypergraph structure to organize the career mobility patterns in a low-information-loss manner, where market entities and talent trajectories are represented as nodes and?\u2026", "IdName": "zha2024towards", "Citation": "", "Keywords": ""}, {"Name": "Revisiting Noise Resilience Strategies in Gesture Recognition: Short-Term Enhancement in Surface Electromyographic Signal Analysis", "Authors": ["Weiyu Guo", "Ziyue Qiao", "Ying Sun", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2404.11213", "PublishedYears": "2024", "Doi": "", "Abstracts": "Gesture recognition based on surface electromyography (sEMG) has been gaining importance in many 3D Interactive Scenes. However, sEMG is easily influenced by various forms of noise in real-world environments, leading to challenges in providing long-term stable interactions through sEMG. Existing methods often struggle to enhance model noise resilience through various predefined data augmentation techniques. In this work, we revisit the problem from a short term enhancement perspective to improve precision and robustness against various common noisy scenarios with learnable denoise using sEMG intrinsic pattern information and sliding-window attention. We propose a Short Term Enhancement Module(STEM) which can be easily integrated with various models. STEM offers several benefits: 1) Learnable denoise, enabling noise reduction without manual data augmentation; 2) Scalability, adaptable to various models; and 3) Cost-effectiveness, achieving short-term enhancement through minimal weight-sharing in an efficient attention mechanism. In particular, we incorporate STEM into a transformer, creating the Short Term Enhanced Transformer (STET). Compared with best-competing approaches, the impact of noise on STET is reduced by more than 20%. We also report promising results on both classification and regression datasets and demonstrate that STEM generalizes across different gesture recognition tasks.", "IdName": "guo2024revisiting", "Citation": "", "Keywords": ""}, {"Name": "Large-scale online job search behaviors reveal labor market shifts amid COVID-19", "Authors": ["Ying Sun", "Hengshu Zhu", "Lu Wang", "Le Zhang", "Hui Xiong"], "Sources": "Nature Cities", "PublishedYears": "2024", "Doi": "", "Abstracts": "The COVID-19 pandemic has had an unprecedented impact on labor markets, significantly altering the structure of labor supply and demand in various regions. We use large-scale online job search queries and job postings in China as indicators to assess and understand the evolving dynamics in regional labor markets. Our analysis reflects the changing landscape of regional agglomeration and potential misalignment of the supply and demand of jobs in labor markets. Specifically, we observe that the intention of labor flow recovered quickly from pandemic conditions, with a trend of the central role shifting from large to small cities and from northern to southern regions, respectively. Following the pandemic, the demand for blue-collar workers was substantially reduced compared with demand for white-collar workers. In particular, our analysis reveals a decreased central role of the metropolises and a decreased?\u2026", "IdName": "sun2024large", "Citation": "", "Keywords": ""}, {"Name": "Triple Dual Learning for Opinion-based Explainable Recommendation", "Authors": ["Yuting Zhang", "Ying Sun", "Fuzhen Zhuang", "Yongchun Zhu", "Zhulin An", "Yongjun Xu"], "Sources": "ACM Transactions on Information Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, with the aim of enhancing the trustworthiness of recommender systems, explainable recommendation has attracted much attention from the research community. Intuitively, users\u2019 opinions toward different aspects of an item determine their ratings (i.e., users\u2019 preferences) for the item. Therefore, rating prediction from the perspective of opinions can realize personalized explanations at the level of item aspects and user preferences. However, there are several challenges in developing an opinion-based explainable recommendation: (1) The complicated relationship between users\u2019 opinions and ratings. (2) The difficulty of predicting the potential (i.e., unseen) user-item opinions because of the sparsity of opinion information. To tackle these challenges, we propose an overall preference-aware opinion-based explainable rating prediction model by jointly modeling the multiple observations of user-item?\u2026", "IdName": "zhang2023triple", "Citation": "", "Keywords": ""}, {"Name": "Towards Faithful Neural Network Intrinsic Interpretation with Shapley Additive Self-Attribution", "Authors": ["Ying Sun", "Hengshu Zhu", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2309.15559", "PublishedYears": "2023", "Doi": "", "Abstracts": "Self-interpreting neural networks have garnered significant interest in research. Existing works in this domain often (1) lack a solid theoretical foundation ensuring genuine interpretability or (2) compromise model expressiveness. In response, we formulate a generic Additive Self-Attribution (ASA) framework. Observing the absence of Shapley value in Additive Self-Attribution, we propose Shapley Additive Self-Attributing Neural Network (SASANet), with theoretical guarantees for the self-attribution value equal to the output's Shapley values. Specifically, SASANet uses a marginal contribution-based sequential schema and internal distillation-based training strategies to model meaningful outputs for any number of features, resulting in un-approximated meaningful value function. Our experimental results indicate SASANet surpasses existing self-attributing models in performance and rivals black-box models. Moreover, SASANet is shown more precise and efficient than post-hoc methods in interpreting its own predictions.", "IdName": "sun2023towards", "Citation": "", "Keywords": ""}, {"Name": "Cross-regional talent flow intention analysis method, electronic device, and storage medium", "Authors": ["Ying Sun", "Hengshu Zhu", "Chuan Qin", "Peng Wang", "Hui Xiong"], "Sources": "US Patent App. 17/945", "PublishedYears": "2023", "Doi": "", "Abstracts": "There is provided a method for cross-regional talent flow intention analysis, an electronic device, and a storage medium, which relates to technical fields such as big data processing and data statistics and analysis. A specific implementation solution involves: constructing a talent flow intention network based on search data in a network within a preset period of time; and performing cross-regional talent flow intention analysis based on the talent flow intention network to obtain a talent flow intention analysis result.", "IdName": "sun2023cross", "Citation": "", "Keywords": ""}, {"Name": "Large-Scale Assessment of Labour Market Dynamics in China during the COVID-19 Pandemic", "Authors": ["Ying Sun", "Hengshu Zhu", "Hui Xiong"], "Sources": "arXiv preprint arXiv:2305.00199", "PublishedYears": "2023", "Doi": "", "Abstracts": "The outbreak of the COVID-19 pandemic has had an unprecedented impact on China's labour market, and has largely changed the structure of labour supply and demand in different regions. It becomes critical for policy makers to understand the emerging dynamics of the post-pandemic labour market and provide the right policies for supporting the sustainable development of regional economies. To this end, in this paper, we provide a data-driven approach to assess and understand the evolving dynamics in regions' labour markets with large-scale online job search queries and job postings. In particular, we model the spatial-temporal patterns of labour flow and labour demand which reflect the attractiveness of regional labour markets. Our analysis shows that regional labour markets suffered from dramatic changes and demonstrated unusual signs of recovery during the pandemic. Specifically, the intention of labour flow quickly recovered with a trend of migrating from large to small cities and from northern to southern regions, respectively. Meanwhile, due to the pandemic, the demand of blue-collar workers has been substantially reduced compared to that of white-collar workers. In addition, the demand structure of blue-collar jobs also changed from manufacturing to service industries. Our findings reveal that the pandemic can cause varied impacts on regions with different structures of labour demand and control policies. This analysis provides timely information for both individuals and organizations in confronting the dynamic change in job markets during the extreme events, such as pandemics. Also, the governments can be better assisted for?\u2026", "IdName": "sun2023large", "Citation": "", "Keywords": ""}, {"Name": "Interpretation method for neural network model, electronic device and storage medium", "Authors": ["Ying Sun", "Hengshu Zhu", "Chuan Qin", "Fuzhen Zhuang", "Hui Xiong"], "Sources": "US Patent App. 18/070", "PublishedYears": "2023", "Doi": "", "Abstracts": "2022-11-29 Assigned to BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD. reassignment BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD. ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: ZHUANG, FUZHEN, QIN, CHUAN, SUN, YING, ZHU, HENGSHU, XIONG, HUI", "IdName": "sun2023interpretation", "Citation": "", "Keywords": ""}, {"Name": "Delving into deep imbalanced regression", "Authors": ["Yuzhe Yang", "Kaiwen Zha", "Yingcong Chen", "Hao Wang", "Dina Katabi"], "Sources": "International conference on machine learning", "PublishedYears": "2021", "Doi": "", "Abstracts": "Real-world data often exhibit imbalanced distributions, where certain target values have significantly fewer observations. Existing techniques for dealing with imbalanced data focus on targets with categorical indices, ie, different classes. However, many tasks involve continuous targets, where hard boundaries between classes do not exist. We define Deep Imbalanced Regression (DIR) as learning from such imbalanced data with continuous targets, dealing with potential missing data for certain target values, and generalizing to the entire target range. Motivated by the intrinsic difference between categorical and continuous label space, we propose distribution smoothing for both labels and features, which explicitly acknowledges the effects of nearby targets, and calibrates both label and learned feature distributions. We curate and benchmark large-scale DIR datasets from common real-world tasks in computer vision, natural language processing, and healthcare domains. Extensive experiments verify the superior performance of our strategies. Our work fills the gap in benchmarks and techniques for practical imbalanced regression problems. Code and data are available at: https://github. com/YyzHarry/imbalanced-regression.", "IdName": "yang2021delving", "Citation": "", "Keywords": ""}, {"Name": "Spatial-temporal graph convolutional network for video-based person re-identification", "Authors": ["Jinrui Yang", "Wei-Shi Zheng", "Qize Yang", "Ying-Cong Chen", "Qi Tian"], "Sources": "Proceedings of the IEEE/CVF conference on computer vision and pattern?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "While video-based person re-identification (Re-ID) has drawn increasing attention and made great progress in recent years, it is still very challenging to effectively overcome the occlusion problem and the visual ambiguity problem for visually similar negative samples. On the other hand, we observe that different frames of a video can provide complementary information for each other, and the structural information of pedestrians can provide extra discriminative cues for appearance features. Thus, modeling the temporal relations of different frames and the spatial relations within a frame has the potential for solving the above problems. In this work, we propose a novel Spatial-Temporal Graph Convolutional Network (STGCN) to solve these problems. The STGCN includes two GCN branches, a spatial one and a temporal one. The spatial branch extracts structural information of a human body. The temporal branch mines discriminative cues from adjacent frames. By jointly optimizing these branches, our model extracts robust spatial-temporal information that is complementary with appearance information. As shown in the experiments, our model achieves state-of-the-art results on MARS and DukeMTMC-VideoReID datasets.", "IdName": "yang2020spatial", "Citation": "", "Keywords": ""}, {"Name": "Artificial intelligence-enabled detection and assessment of Parkinson\u2019s disease using nocturnal breathing signals", "Authors": ["Yuzhe Yang", "Yuan Yuan", "Guo Zhang", "Hao Wang", "Ying-Cong Chen", "Yingcheng Liu", "Christopher G Tarolli", "Daniel Crepeau", "Jan Bukartyk", "Mithri R Junna", "Aleksandar Videnovic", "Terry D Ellis", "Melissa C Lipford", "Ray Dorsey", "Dina Katabi"], "Sources": "Nature medicine", "PublishedYears": "2022", "Doi": "", "Abstracts": "There are currently no effective biomarkers for diagnosing Parkinson\u2019s disease (PD) or tracking its progression. Here, we developed an artificial intelligence (AI) model to detect PD and track its progression from nocturnal breathing signals. The model was evaluated on a large dataset comprising 7,671 individuals, using data from several hospitals in the United States, as well as multiple public datasets. The AI model can detect PD with an area-under-the-curve of 0.90 and 0.85 on held-out and external test sets, respectively. The AI model can also estimate PD severity and progression in accordance with the Movement Disorder Society Unified Parkinson\u2019s Disease Rating Scale (R= 0.94, P= 3.6\u00d7 10\u201325). The AI model uses an attention layer that allows for interpreting its predictions with respect to sleep and electroencephalogram. Moreover, the model can assess PD in the home setting in a touchless manner, by?\u2026", "IdName": "yang2022artificial", "Citation": "", "Keywords": ""}, {"Name": "Representation compensation networks for continual semantic segmentation", "Authors": ["Chang-Bin Zhang", "Jia-Wen Xiao", "Xialei Liu", "Ying-Cong Chen", "Ming-Ming Cheng"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "In this work, we study the continual semantic segmentation problem, where the deep neural networks are required to incorporate new classes continually without catastrophic forgetting. We propose to use a structural re-parameterization mechanism, named representation compensation (RC) module, to decouple the representation learning of both old and new knowledge. The RC module consists of two dynamically evolved branches with one frozen and one trainable. Besides, we design a pooled cube knowledge distillation strategy on both spatial and channel dimensions to further enhance the plasticity and stability of the model. We conduct experiments on two challenging continual semantic segmentation scenarios, continual class segmentation and continual domain segmentation. Without any extra computational overhead and parameters during inference, our method outperforms state-of-the-art performance. The code is available at https://github. com/zhangchbin/RCIL.", "IdName": "zhang2022representation", "Citation": "", "Keywords": ""}, {"Name": "Vcnet: A robust approach to blind image inpainting", "Authors": ["Yi Wang", "Ying-Cong Chen", "Xin Tao", "Jiaya Jia"], "Sources": "Computer Vision\u2013ECCV 2020: 16th European Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": " Blind inpainting is a task to automatically complete visual contents without specifying masks for missing areas in an image. Previous work assumes known missing-region-pattern, limiting the application scope. We instead relax the assumption by defining a new blind inpainting setting, making training a neural system robust against various unknown missing region patterns. Specifically, we propose a two-stage visual consistency network (VCN) to estimate where to fill (via masks) and generate what to fill. In this procedure, the unavoidable potential mask prediction errors lead to severe artifacts in the subsequent repairing. To address it, our VCN predicts semantically inconsistent regions first, making mask prediction more tractable. Then it repairs these estimated missing regions using a new spatial normalization, making VCN robust to mask prediction errors. Semantically convincing and visually compelling?\u2026", "IdName": "wang2020vcnet", "Citation": "", "Keywords": ""}, {"Name": "Learning to know where to see: A visibility-aware approach for occluded person re-identification", "Authors": ["Jinrui Yang", "Jiawei Zhang", "Fufu Yu", "Xinyang Jiang", "Mengdan Zhang", "Xing Sun", "Ying-Cong Chen", "Wei-Shi Zheng"], "Sources": "Proceedings of the IEEE/CVF international conference on computer vision?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Person re-identification (ReID) has gained an impressive progress in recent years. However, the occlusion is still a common and challenging problem for recent ReID methods. Several mainstream methods utilize extra cues (eg, human pose information) to distinguish human parts from obstacles to alleviate the occlusion problem. Although achieving inspiring progress, these methods severely rely on the fine-grained extra cues, and are sensitive to the estimation error in the extra cues. In this paper, we show that existing methods may degrade if the extra information is sparse or noisy. Thus we propose a simple yet effective method that is robust to sparse and noisy pose information. This is achieved by discretizing pose information to the visibility label of body parts, so as to suppress the influence of occluded regions. We show in our experiments that leveraging pose information in this way is more effective and robust. Besides, our method can be embedded into most person ReID models easily. Extensive experiments validate the effectiveness of our model on common occluded person ReID datasets.", "IdName": "yang2021learning", "Citation": "", "Keywords": ""}, {"Name": "Image synthesis via semantic composition", "Authors": ["Yi Wang", "Lu Qi", "Ying-Cong Chen", "Xiangyu Zhang", "Jiaya Jia"], "Sources": "Proceedings of the IEEE/CVF International Conference on Computer Vision?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, we present a novel approach to synthesize realistic images based on their semantic layouts. It hypothesizes that for objects with similar appearance, they share similar representation. Our method establishes dependencies between regions according to their appearance correlation, yielding both spatially variant and associated representations. Conditioning on these features, we propose a dynamic weighted network constructed by spatially conditional computation (with both convolution and normalization). More than preserving semantic distinctions, the given dynamic network strengthens semantic relevance, benefiting global structure and detail synthesis. We demonstrate that our method gives the compelling generation performance qualitatively and quantitatively with extensive experiments on benchmarks.", "IdName": "wang2021image", "Citation": "", "Keywords": ""}, {"Name": "RC-MVSNet: Unsupervised multi-view stereo with neural rendering", "Authors": ["Di Chang", "Alja? Bo?i?", "Tong Zhang", "Qingsong Yan", "Yingcong Chen", "Sabine S\u00fcsstrunk", "Matthias Nie?ner"], "Sources": "European conference on computer vision", "PublishedYears": "2022", "Doi": "", "Abstracts": "Finding accurate correspondences among different views is the Achilles\u2019 heel of unsupervised Multi-View Stereo (MVS). Existing methods are built upon the assumption that corresponding pixels share similar photometric features. However, multi-view images in real scenarios observe non-Lambertian surfaces and experience occlusions. In this work, we propose a novel approach with neural rendering (RC-MVSNet) to solve such ambiguity issues of correspondences among views. Specifically, we impose a depth rendering consistency loss to constrain the geometry features close to the object surface to alleviate occlusions. Concurrently, we introduce a reference view synthesis loss to generate consistent supervision, even for non-Lambertian surfaces. Extensive experiments on DTU and Tanks &Temples benchmarks demonstrate that our RC-MVSNet approach achieves state-of-the-art performance over?\u2026", "IdName": "chang2022rc", "Citation": "", "Keywords": ""}, {"Name": "Attentive normalization for conditional image generation", "Authors": ["Yi Wang", "Ying-Cong Chen", "Xiangyu Zhang", "Jian Sun", "Jiaya Jia"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Traditional convolution-based generative adversarial networks synthesize images based on hierarchical local operations, where long-range dependency relation is implicitly modeled with a Markov chain. It is still not sufficient for categories with complicated structures. In this paper, we characterize long-range dependence with attentive normalization (AN), which is an extension to traditional instance normalization. Specifically, the input feature map is softly divided into several regions based on its internal semantic similarity, which are respectively normalized. It enhances consistency between distant regions with semantic correspondence. Compared with self-attention GAN, our attentive normalization does not need to measure the correlation of all locations, and thus can be directly applied to large-size feature maps without much computational burden. Extensive experiments on class-conditional image generation and semantic inpainting verify the efficacy of our proposed module.", "IdName": "wang2020attentive", "Citation": "", "Keywords": ""}, {"Name": "Luciddreamer: Towards high-fidelity text-to-3d generation via interval score matching", "Authors": ["Yixun Liang", "Xin Yang", "Jiantao Lin", "Haodong Li", "Xiaogang Xu", "Yingcong Chen"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "The recent advancements in text-to-3D generation mark a significant milestone in generative models unlocking new possibilities for creating imaginative 3D assets across various real-world scenarios. While recent advancements in text-to-3D generation have shown promise they often fall short in rendering detailed and high-quality 3D models. This problem is especially prevalent as many methods base themselves on Score Distillation Sampling (SDS). This paper identifies a notable deficiency in SDS that it brings inconsistent and low-quality updating direction for the 3D model causing the over-smoothing effect. To address this we propose a novel approach called Interval Score Matching (ISM). ISM employs deterministic diffusing trajectories and utilizes interval-based score matching to counteract over-smoothing. Furthermore we incorporate 3D Gaussian Splatting into our text-to-3D generation pipeline. Extensive experiments show that our model largely outperforms the state-of-the-art in quality and training efficiency.", "IdName": "liang2024luciddreamer", "Citation": "", "Keywords": ""}, {"Name": "DecoupleNet: Decoupled network for domain adaptive semantic segmentation", "Authors": ["Xin Lai", "Zhuotao Tian", "Xiaogang Xu", "Yingcong Chen", "Shu Liu", "Hengshuang Zhao", "Liwei Wang", "Jiaya Jia"], "Sources": "European Conference on Computer Vision", "PublishedYears": "2022", "Doi": "", "Abstracts": "Unsupervised domain adaptation in semantic segmentation alleviates the reliance on expensive pixel-wise annotation. It uses a labeled source domain dataset as well as unlabeled target domain images to learn a segmentation network. In this paper, we observe two main issues of existing domain-invariant learning framework. (1) Being distracted by the feature distribution alignment, the network cannot focus on the segmentation task. (2) Fitting source domain data well would compromise the target domain performance. To address these issues, we propose DecoupleNet to alleviate source domain overfitting and let the final model focus more on the segmentation task. Also, we put forward Self-Discrimination (SD) and introduce an auxiliary classifier to learn more discriminative target domain features with pseudo labels. Finally, we propose Online Enhanced Self-Training (OEST) to contextually enhance the quality?\u2026", "IdName": "lai2022decouplenet", "Citation": "", "Keywords": ""}, {"Name": "Pointins: Point-based instance segmentation", "Authors": ["Lu Qi", "Yi Wang", "Yukang Chen", "Ying-Cong Chen", "Xiangyu Zhang", "Jian Sun", "Jiaya Jia"], "Sources": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, we explore the mask representation in instance segmentation with Point-of-Interest (PoI) features. Differentiating multiple potential instances within a single PoI feature is challenging, because learning a high-dimensional mask feature for each instance using vanilla convolution demands a heavy computing burden. To address this challenge, we propose an instance-aware convolution. It decomposes this mask representation learning task into two tractable modules as instance-aware weights and instance-agnostic features. The former is to parametrize convolution for producing mask features corresponding to different instances, improving mask learning efficiency by avoiding employing several independent convolutions. Meanwhile, the latter serves as mask templates in a single point. Together, instance-aware mask features are computed by convolving the template with dynamic weights, used for the?\u2026", "IdName": "qi2021pointins", "Citation": "", "Keywords": ""}, {"Name": "Domain Adaptive Image-to-image Translation", "Authors": ["Ying-Cong Chen", "Xiaogang Xu", "Jiaya Jia"], "Sources": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "PublishedYears": "2020", "Doi": "", "Abstracts": "Unpaired image-to-image translation (I2I) has achieved great success in various applications. However, its generalization capacity is still an open question. In this paper, we show that existing I2I models do not generalize well for samples outside the training domain. The cause is twofold. First, an I2I model may not work well when testing samples are beyond its valid input domain. Second, results could be unreliable if the expected output is far from what the model is trained. To deal with these issues, we propose the Domain Adaptive Image-To-Image translation (DAI2I) framework that adapts an I2I model for out-of-domain samples. Our framework introduces two sub-modules--one maps testing samples to the valid input domain of the I2I model, and the other transforms the output of I2I model to expected results. Extensive experiments manifest that our framework improves the capacity of existing I2I models, allowing them to handle samples that are distinctively different from their primary targets.", "IdName": "chen2020domain", "Citation": "", "Keywords": ""}, {"Name": "Ref-neus: Ambiguity-reduced neural implicit surface learning for multi-view reconstruction with reflection", "Authors": ["Wenhang Ge", "Tao Hu", "Haoyu Zhao", "Shu Liu", "Ying-Cong Chen"], "Sources": "Proceedings of the IEEE/CVF International Conference on Computer Vision?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Neural implicit surface learning has shown significant progress in multi-view 3D reconstruction, where an object is represented by multilayer perceptrons that provide continuous implicit surface representation and view-dependent radiance. However, current methods often fail to accurately reconstruct reflective surfaces, leading to severe ambiguity. To overcome this issue, we propose Ref-NeuS, which aims to reduce ambiguity by attenuating the effect of reflective surfaces. Specifically, we utilize an anomaly detector to estimate an explicit reflection score with the guidance of multi-view context to localize reflective surfaces. Afterward, we design a reflection-aware photometric loss that adaptively reduces ambiguity by modeling rendered color as a Gaussian distribution, with the reflection score representing the variance. We show that together with a reflection direction-dependent radiance, our model achieves high-quality surface reconstruction on reflective surfaces and outperforms the state-of-the-arts by a large margin. Besides, our model is also comparable on general surfaces.", "IdName": "ge2023ref", "Citation": "", "Keywords": ""}, {"Name": "Neuron structure modeling for generalizable remote physiological measurement", "Authors": ["Hao Lu", "Zitong Yu", "Xuesong Niu", "Ying-Cong Chen"], "Sources": "Proceedings of the IEEE/CVF conference on computer vision and pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Remote photoplethysmography (rPPG) technology has drawn increasing attention in recent years. It can extract Blood Volume Pulse (BVP) from facial videos, making many applications like health monitoring and emotional analysis more accessible. However, as the BVP signal is easily affected by environmental changes, existing methods struggle to generalize well for unseen domains. In this paper, we systematically address the domain shift problem in the rPPG measurement task. We show that most domain generalization methods do not work well in this problem, as domain labels are ambiguous in complicated environmental changes. In light of this, we propose a domain-label-free approach called NEuron STructure modeling (NEST). NEST improves the generalization capacity by maximizing the coverage of feature space during training, which reduces the chance for under-optimized feature activation during inference. Besides, NEST can also enrich and enhance domain invariant features across multi-domain. We create and benchmark a large-scale domain generalization protocol for the rPPG measurement task. Extensive experiments show that our approach outperforms the state-of-the-art methods on both cross-dataset and intra-dataset settings.", "IdName": "lu2023neuron", "Citation": "", "Keywords": ""}, {"Name": "The robodrive challenge: Drive anytime anywhere in any condition", "Authors": ["Lingdong Kong", "Shaoyuan Xie", "Hanjiang Hu", "Yaru Niu", "Wei Tsang Ooi", "Benoit R Cottereau", "Lai Xing Ng", "Yuexin Ma", "Wenwei Zhang", "Liang Pan", "Kai Chen", "Ziwei Liu", "Weichao Qiu", "Wei Zhang", "Xu Cao", "Hao Lu", "Ying-Cong Chen", "Caixin Kang", "Xinning Zhou", "Chengyang Ying", "Wentao Shang", "Xingxing Wei", "Yinpeng Dong", "Bo Yang", "Shengyin Jiang", "Zeliang Ma", "Dengyi Ji", "Haiwen Li", "Xingliang Huang", "Yu Tian", "Genghua Kou", "Fan Jia", "Yingfei Liu", "Tiancai Wang", "Ying Li", "Xiaoshuai Hao", "Yifan Yang", "Hui Zhang", "Mengchuan Wei", "Yi Zhou", "Haimei Zhao", "Jing Zhang", "Jinke Li", "Xiao He", "Xiaoqiang Cheng", "Bingyang Zhang", "Lirong Zhao", "Dianlei Ding", "Fangsheng Liu", "Yixiang Yan", "Hongming Wang", "Nanfei Ye", "Lun Luo", "Yubo Tian", "Yiwei Zuo", "Zhe Cao", "Yi Ren", "Yunfan Li", "Wenjie Liu", "Xun Wu", "Yifan Mao", "Ming Li", "Jian Liu", "Jiayang Liu", "Zihan Qin", "Cunxi Chu", "Jialei Xu", "Wenbo Zhao", "Junjun Jiang", "Xianming Liu", "Ziyan Wang", "Chiwei Li", "Shilong Li", "Chendong Yuan", "Songyue Yang", "Wentao Liu", "Peng Chen", "Bin Zhou", "Yubo Wang", "Chi Zhang", "Jianhang Sun", "Hai Chen", "Xiao Yang", "Lizhong Wang", "Dongyi Fu", "Yongchun Lin", "Huitong Yang", "Haoang Li", "Yadan Luo", "Xianjing Cheng", "Yong Xu"], "Sources": "arXiv preprint arXiv:2405.08816", "PublishedYears": "2024", "Doi": "", "Abstracts": "In the realm of autonomous driving, robust perception under out-of-distribution conditions is paramount for the safe deployment of vehicles. Challenges such as adverse weather, sensor malfunctions, and environmental unpredictability can severely impact the performance of autonomous systems. The 2024 RoboDrive Challenge was crafted to propel the development of driving perception technologies that can withstand and adapt to these real-world variabilities. Focusing on four pivotal tasks -- BEV detection, map segmentation, semantic occupancy prediction, and multi-view depth estimation -- the competition laid down a gauntlet to innovate and enhance system resilience against typical and atypical disturbances. This year's challenge consisted of five distinct tracks and attracted 140 registered teams from 93 institutes across 11 countries, resulting in nearly one thousand submissions evaluated through our servers. The competition culminated in 15 top-performing solutions, which introduced a range of innovative approaches including advanced data augmentation, multi-sensor fusion, self-supervised learning for error correction, and new algorithmic strategies to enhance sensor robustness. These contributions significantly advanced the state of the art, particularly in handling sensor inconsistencies and environmental variability. Participants, through collaborative efforts, pushed the boundaries of current technologies, showcasing their potential in real-world scenarios. Extensive evaluations and analyses provided insights into the effectiveness of these solutions, highlighting key trends and successful strategies for improving the resilience of?\u2026", "IdName": "kong2024robodrive", "Citation": "", "Keywords": ""}, {"Name": "Text-guided human image manipulation via image-text shared space", "Authors": ["Xiaogang Xu", "Ying-Cong Chen", "Xin Tao", "Jiaya Jia"], "Sources": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "PublishedYears": "2021", "Doi": "", "Abstracts": "Text is a new way to guide human image manipulation. Albeit natural and flexible, text usually suffers from inaccuracy in spatial description, ambiguity in the description of appearance, and incompleteness. We in this paper address these issues. To overcome inaccuracy, we use structured information (e.g., poses) to help identify correct location to manipulate, by disentangling the control of appearance and spatial structure. Moreover, we learn the image-text shared space with derived disentanglement to improve accuracy and quality of manipulation, by separating relevant and irrelevant editing directions for the textual instructions in this space. Our model generates a series of manipulation results by moving source images in this space with different degrees of editing strength. Thus, to reduce the ambiguity in text, our model generates sequential output for manual selection. In addition, we propose an efficient?\u2026", "IdName": "xu2021text", "Citation": "", "Keywords": ""}, {"Name": "Semi-supervised monocular 3d object detection by multi-view consistency", "Authors": ["Qing Lian", "Yanbo Xu", "Weilong Yao", "Yingcong Chen", "Tong Zhang"], "Sources": "European Conference on Computer Vision", "PublishedYears": "2022", "Doi": "", "Abstracts": "The success of monocular 3D object detection highly relies on considerable labeled data, which is costly to obtain. To alleviate the annotation effort, we propose MVC-MonoDet, the first semi-supervised training framework that improves Monocular 3D object detection by enforcing multi-view consistency. In particular, a box-level regularization and an object-level regularization are designed to enforce the consistency of 3D bounding box predictions of the detection model across unlabeled multi-view data (stereo or video). The box-level regularizer requires the model to consistently estimate 3D boxes in different views so that the model can learn cross-view invariant features for 3D detection. The object-level regularizer employs an object-wise photometric consistency loss that mitigates 3D box estimation error through structure-from-motion (SFM). A key innovation in our approach to effectively utilize these consistency?\u2026", "IdName": "lian2022semi", "Citation": "", "Keywords": ""}, {"Name": "Lift3d: Synthesize 3d training data by lifting 2d gan to 3d generative radiance field", "Authors": ["Leheng Li", "Qing Lian", "Luozhou Wang", "Ningning Ma", "Ying-Cong Chen"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This work explores the use of 3D generative models to synthesize training data for 3D vision tasks. The key requirements of the generative models are that the generated data should be photorealistic to match the real-world scenarios, and the corresponding 3D attributes should be aligned with given sampling labels. However, we find that the recent NeRF-based 3D GANs hardly meet the above requirements due to their designed generation pipeline and the lack of explicit 3D supervision. In this work, we propose Lift3D, an inverted 2D-to-3D generation framework to achieve the data generation objectives. Lift3D has several merits compared to prior methods:(1) Unlike previous 3D GANs that the output resolution is fixed after training, Lift3D can generalize to any camera intrinsic with higher resolution and photorealistic output.(2) By lifting well-disentangled 2D GAN to 3D object NeRF, Lift3D provides explicit 3D information of generated objects, thus offering accurate 3D annotations for downstream tasks. We evaluate the effectiveness of our framework by augmenting autonomous driving datasets. Experimental results demonstrate that our data generation framework can effectively improve the performance of 3D object detectors. Code: len-li. github. io/lift3d-web", "IdName": "li2023lift3d", "Citation": "", "Keywords": ""}, {"Name": "Resolve domain conflicts for generalizable remote physiological measurement", "Authors": ["Weiyu Sun", "Xinyu Zhang", "Hao Lu", "Ying Chen", "Yun Ge", "Xiaolin Huang", "Jie Yuan", "Yingcong Chen"], "Sources": "Proceedings of the 31st ACM International Conference on Multimedia", "PublishedYears": "2023", "Doi": "", "Abstracts": "Remote photoplethysmography (rPPG) technology has become increasingly popular due to its non-invasive monitoring of various physiological indicators, making it widely applicable in multimedia interaction, healthcare, and emotion analysis. Existing rPPG methods utilize multiple datasets for training to enhance the generalizability of models. However, they often overlook the underlying conflict issues in the rPPG field, such as (1) label conflict resulting from different phase delays between physiological signal labels and face videos at the instance level, and (2) attribute conflict stemming from distribution shifts caused by head movements, illumination changes, skin types, etc. To address this, we introduce the DOmain-HArmonious framework (DOHA). Specifically, we first propose a harmonious phase strategy to eliminate uncertain phase delays and preserve the temporal variation of physiological signals. Next, we?\u2026", "IdName": "sun2023resolve", "Citation": "", "Keywords": ""}, {"Name": "Denoising diffusion step-aware models", "Authors": ["Shuai Yang", "Yukang Chen", "Luozhou Wang", "Shu Liu", "Yingcong Chen"], "Sources": "arXiv preprint arXiv:2310.03337", "PublishedYears": "2023", "Doi": "", "Abstracts": "Denoising Diffusion Probabilistic Models (DDPMs) have garnered popularity for data generation across various domains. However, a significant bottleneck is the necessity for whole-network computation during every step of the generative process, leading to high computational overheads. This paper presents a novel framework, Denoising Diffusion Step-aware Models (DDSM), to address this challenge. Unlike conventional approaches, DDSM employs a spectrum of neural networks whose sizes are adapted according to the importance of each generative step, as determined through evolutionary search. This step-wise network variation effectively circumvents redundant computational efforts, particularly in less critical steps, thereby enhancing the efficiency of the diffusion model. Furthermore, the step-aware design can be seamlessly integrated with other efficiency-geared diffusion models such as DDIMs and latent diffusion, thus broadening the scope of computational savings. Empirical evaluations demonstrate that DDSM achieves computational savings of 49% for CIFAR-10, 61% for CelebA-HQ, 59% for LSUN-bedroom, 71% for AFHQ, and 76% for ImageNet, all without compromising the generation quality. Our code and models will be publicly available.", "IdName": "yang2023denoising", "Citation": "", "Keywords": ""}, {"Name": "Not all steps are created equal: Selective diffusion distillation for image manipulation", "Authors": ["Luozhou Wang", "Shuai Yang", "Shu Liu", "Ying-cong Chen"], "Sources": "Proceedings of the IEEE/CVF International Conference on Computer Vision?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Conditional diffusion models have demonstrated impressive performance in image manipulation tasks. The general pipeline involves adding noise to the image and then denoising it. However, this method faces a trade-off problem: adding too much noise affects the fidelity of the image while adding too little affects its editability. This largely limits their practical applicability. In this paper, we propose a novel framework, Selective Diffusion Distillation (SDD), that ensures both the fidelity and editability of images. Instead of directly editing images with a diffusion model, we train a feedforward image manipulation network under the guidance of the diffusion model. Besides, we propose an effective indicator to select the semantic-related timestep to obtain the correct semantic guidance from the diffusion model. This approach successfully avoids the dilemma caused by the diffusion process. Our extensive experiments demonstrate the advantages of our framework.", "IdName": "wang2023not", "Citation": "", "Keywords": ""}, {"Name": "Adv3D: generating 3D adversarial examples in driving scenarios with nerf", "Authors": ["Leheng Li", "Qing Lian", "Ying-Cong Chen"], "Sources": "arXiv preprint arXiv:2309.01351", "PublishedYears": "2023", "Doi": "", "Abstracts": "Deep neural networks (DNNs) have been proven extremely susceptible to adversarial examples, which raises special safety-critical concerns for DNN-based autonomous driving stacks (i.e., 3D object detection). Although there are extensive works on image-level attacks, most are restricted to 2D pixel spaces, and such attacks are not always physically realistic in our 3D world. Here we present Adv3D, the first exploration of modeling adversarial examples as Neural Radiance Fields (NeRFs). Advances in NeRF provide photorealistic appearances and 3D accurate generation, yielding a more realistic and realizable adversarial example. We train our adversarial NeRF by minimizing the surrounding objects' confidence predicted by 3D detectors on the training set. Then we evaluate Adv3D on the unseen validation set and show that it can cause a large performance reduction when rendering NeRF in any sampled pose. To generate physically realizable adversarial examples, we propose primitive-aware sampling and semantic-guided regularization that enable 3D patch attacks with camouflage adversarial texture. Experimental results demonstrate that the trained adversarial NeRF generalizes well to different poses, scenes, and 3D detectors. Finally, we provide a defense method to our attacks that involves adversarial training through data augmentation. Project page: https://len-li.github.io/adv3d-web", "IdName": "li2023adv3d", "Citation": "", "Keywords": ""}, {"Name": "Dual-balancing for multi-task learning", "Authors": ["Baijiong Lin", "Weisen Jiang", "Feiyang Ye", "Yu Zhang", "Pengguang Chen", "Ying-Cong Chen", "Shu Liu", "James Kwok"], "Sources": "None", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multi-task learning (MTL), a learning paradigm to learn multiple related tasks simultaneously, has achieved great success in various fields. However, task balancing problem remains a significant challenge in MTL, with the disparity in loss/gradient scales often leading to performance compromises. In this paper, we propose a Dual-Balancing Multi-Task Learning (DB-MTL) method to alleviate the task balancing problem from both loss and gradient perspectives. Specifically, DB-MTL ensures loss-scale balancing by performing a logarithm transformation on each task loss, and guarantees gradient-magnitude balancing via normalizing all task gradients to the same magnitude as the maximum gradient norm. Extensive experiments conducted on several benchmark datasets consistently demonstrate the state-of-the-art performance of DB-MTL.", "IdName": "lin2023dual", "Citation": "", "Keywords": ""}, {"Name": "Real-time 6K Image Rescaling with Rate-distortion Optimization", "Authors": ["Chenyang Qi", "Xin Yang", "Ka Leong Cheng", "Ying-Cong Chen", "Qifeng Chen"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The task of image rescaling aims at embedding an high-resolution (HR) image into a low-resolution (LR) one that can contain embedded information for HR image reconstruction. Existing image rescaling methods do not optimize the LR image file size and recent flow-based rescaling methods are not real-time yet for HR image reconstruction (eg, 6K). To address these two challenges, we propose a novel framework (HyperThumbnail) for real-time 6K rate-distortion-aware image rescaling. Our HyperThumbnail first embeds an HR image into a JPEG LR image (thumbnail) by an encoder with our proposed learnable JPEG quantization module, which optimizes the file size of the embedding LR JPEG image. Then, an efficient decoder reconstructs a high-fidelity HR (6K) image from the LR one in real time. Extensive experiments demonstrate that our framework outperforms previous image rescaling baselines in both rate-distortion performance and is much faster than prior work in HR image reconstruction speed.", "IdName": "qi2023real", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical Style-Aware Domain Generalization for Remote Physiological Measurement", "Authors": ["Jiyao Wang", "Hao Lu", "Ange Wang", "Yingcong Chen", "Dengbo He"], "Sources": "IEEE Journal of Biomedical and Health Informatics", "PublishedYears": "2023", "Doi": "", "Abstracts": "The utilization of remote photoplethysmography (rPPG) technology has gained attention in recent years due to its ability to extract blood volume pulse (BVP) from facial videos, making it accessible for various applications such as health monitoring and emotional analysis. However, the BVP signal is susceptible to complex environmental changes or individual differences, causing existing methods to struggle in generalizing for unseen domains. This article addresses the domain shift problem in rPPG measurement and shows that most domain generalization methods fail to work well in this problem due to ambiguous instance-specific differences. To address this, the article proposes a novel approach called Hierarchical Style-aware Representation Disentangling (HSRD). HSRD improves generalization capacity by separating domain-invariant and instance-specific feature space during training, which increases the?\u2026", "IdName": "wang2023hierarchical", "Citation": "", "Keywords": ""}, {"Name": "Adaptive domain generalization via online disagreement minimization", "Authors": ["Xin Zhang", "Ying-Cong Chen"], "Sources": "IEEE Transactions on Image Processing", "PublishedYears": "2023", "Doi": "", "Abstracts": "Deep neural networks suffer from significant performance deterioration when there exists distribution shift between deployment and training. Domain Generalization (DG) aims to safely transfer a model to unseen target domains by only relying on a set of source domains. Although various DG approaches have been proposed, a recent study named DomainBed (Gulrajani and Lopez-Paz, 2020), reveals that most of them do not beat simple empirical risk minimization (ERM). To this end, we propose a general framework that is orthogonal to existing DG algorithms and could improve their performance consistently. Unlike previous DG works that stake on a static source model to be hopefully a universal one, our proposed AdaODM adaptively modifies the source model at test time for different target domains. Specifically, we create multiple domain-specific classifiers upon a shared domain-generic feature extractor. The?\u2026", "IdName": "zhang2023adaptive", "Citation": "", "Keywords": ""}, {"Name": "Label name is mantra: Unifying point cloud segmentation across heterogeneous datasets", "Authors": ["Yixun Liang", "Hao He", "Shishi Xiao", "Hao Lu", "Yingcong Chen"], "Sources": "arXiv preprint arXiv:2303.10585", "PublishedYears": "2023", "Doi": "", "Abstracts": "Point cloud segmentation is a fundamental task in 3D vision that serves a wide range of applications. Although great progresses have been made these years, its practical usability is still limited by the availability of training data. Existing approaches cannot make full use of multiple datasets on hand due to the label mismatch among different datasets. In this paper, we propose a principled approach that supports learning from heterogeneous datasets with different label sets. Our idea is to utilize a pre-trained language model to embed discrete labels to a continuous latent space with the help of their label names. This unifies all labels of different datasets, so that joint training is doable. Meanwhile, classifying points in the continuous 3D space by their vocabulary tokens significantly increase the generalization ability of the model in comparison with existing approaches that have fixed decoder architecture. Besides, we also integrate prompt learning in our framework to alleviate data shifts among different data sources. Extensive experiments demonstrate that our model outperforms the state-of-the-art by a large margin.", "IdName": "liang2023label", "Citation": "", "Keywords": ""}, {"Name": "Retr: Modeling rendering via transformer for generalizable neural surface reconstruction", "Authors": ["Yixun Liang", "Hao He", "Yingcong Chen"], "Sources": "Advances in Neural Information Processing Systems 36", "PublishedYears": "2024", "Doi": "", "Abstracts": "Generalizable neural surface reconstruction techniques have attracted great attention in recent years. However, they encounter limitations of low confidence depth distribution and inaccurate surface reasoning due to the oversimplified volume rendering process employed. In this paper, we present Reconstruction TRansformer (ReTR), a novel framework that leverages the transformer architecture to redesign the rendering process, enabling complex render interaction modeling. It introduces a learnable $\\textit {meta-ray token} $ and utilizes the cross-attention mechanism to simulate the interaction of rendering process with sampled points and render the observed color. Meanwhile, by operating within a high-dimensional feature space rather than the color space, ReTR mitigates sensitivity to projected colors in source views. Such improvements result in accurate surface assessment with high confidence. We demonstrate the effectiveness of our approach on various datasets, showcasing how our method outperforms the current state-of-the-art approaches in terms of reconstruction quality and generalization ability. $\\textit {Our code is available at} $ https://github. com/YixunLiang/ReTR.", "IdName": "liang2024retr", "Citation": "", "Keywords": ""}, {"Name": "Gpt as psychologist? preliminary evaluations for gpt-4v on visual affective computing", "Authors": ["Hao Lu", "Xuesong Niu", "Jiyao Wang", "Yin Wang", "Qingyong Hu", "Jiaqi Tang", "Yuting Zhang", "Kaishen Yuan", "Bin Huang", "Zitong Yu", "Dengbo He", "Shuiguang Deng", "Hao Chen", "Yingcong Chen", "Shiguang Shan"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Multimodal large language models (MLLMs) are designed to process and integrate information from multiple sources such as text speech images and videos. Despite its success in language understanding it is critical to evaluate the performance of downstream tasks for better human-centric applications. This paper assesses the application of MLLMs with 5 crucial abilities for affective computing spanning from visual affective tasks and reasoning tasks. The results show that\\gpt has high accuracy in facial action unit recognition and micro-expression detection while its general facial expression recognition performance is not accurate. We also highlight the challenges of achieving fine-grained micro-expression recognition and the potential for further study and demonstrate the versatility and potential of\\gpt for handling advanced tasks in emotion recognition and related fields by integrating with task-related agents for more complex tasks such as heart rate estimation through signal processing. In conclusion this paper provides valuable insights into the potential applications and challenges of MLLMs in human-centric computing.", "IdName": "lu2024gpt", "Citation": "", "Keywords": ""}, {"Name": "Towards generalizable multi-camera 3d object detection via perspective debiasing", "Authors": ["Hao Lu", "Yunpeng Zhang", "Qing Lian", "Dalong Du", "Yingcong Chen"], "Sources": "arXiv preprint arXiv:2310.11346", "PublishedYears": "2023", "Doi": "", "Abstracts": "Detecting objects in 3D space using multiple cameras, known as Multi-Camera 3D Object Detection (MC3D-Det), has gained prominence with the advent of bird's-eye view (BEV) approaches. However, these methods often struggle when faced with unfamiliar testing environments due to the lack of diverse training data encompassing various viewpoints and environments. To address this, we propose a novel method that aligns 3D detection with 2D camera plane results, ensuring consistent and accurate detections. Our framework, anchored in perspective debiasing, helps the learning of features resilient to domain shifts. In our approach, we render diverse view maps from BEV features and rectify the perspective bias of these maps, leveraging implicit foreground volumes to bridge the camera and BEV planes. This two-step process promotes the learning of perspective- and context-independent features, crucial for accurate object detection across varying viewpoints, camera parameters and environment conditions. Notably, our model-agnostic approach preserves the original network structure without incurring additional inference costs, facilitating seamless integration across various models and simplifying deployment. Furthermore, we also show our approach achieves satisfactory results in real data when trained only with virtual datasets, eliminating the need for real scene annotations. Experimental results on both Domain Generalization (DG) and Unsupervised Domain Adaptation (UDA) clearly demonstrate its effectiveness. Our code will be released.", "IdName": "lu2023towards", "Citation": "", "Keywords": ""}, {"Name": "Decompose and realign: Tackling condition misalignment in text-to-image diffusion models", "Authors": ["Luozhou Wang", "Guibao Shen", "Wenhang Ge", "Guangyong Chen", "Yijun Li", "Ying-cong Chen"], "Sources": "arXiv preprint arXiv:2306.14408", "PublishedYears": "2023", "Doi": "", "Abstracts": "Text-to-image diffusion models have advanced towards more controllable generation via supporting various additional conditions (e.g., depth map, bounding box) beyond text. However, these models are learned based on the premise of perfect alignment between the text and extra conditions. If this alignment is not satisfied, the final output could be either dominated by one condition, or ambiguity may arise, failing to meet user expectations.To address this issue, we present a training-free approach called ``Decompose and Realign'' to further improve the controllability of existing models when provided with partially aligned conditions. The ``Decompose'' phase separates conditions based on pair relationships, computing the result individually for each pair. This ensures that each pair no longer has conflicting conditions. The ``Realign'' phase aligns these independently calculated results via a cross-attention mechanism to avoid new conflicts when combining them back. Both qualitative and quantitative results demonstrate the effectiveness of our approach in handling unaligned conditions, which performs favorably against recent methods and more importantly adds flexibility to the controllable image generation process. Our code will be available at: https://github.com/EnVision-Research/Decompose-and-Realign.", "IdName": "wang2023decompose", "Citation": "", "Keywords": ""}, {"Name": "Addressing variable dependency in gnn-based SAT solving", "Authors": ["Zhiyuan Yan", "Min Li", "Zhengyuan Shi", "Wenjie Zhang", "Yingcong Chen", "Hongce Zhang"], "Sources": "arXiv preprint arXiv:2304.08738", "PublishedYears": "2023", "Doi": "", "Abstracts": "Boolean satisfiability problem (SAT) is fundamental to many applications. Existing works have used graph neural networks (GNNs) for (approximate) SAT solving. Typical GNN-based end-to-end SAT solvers predict SAT solutions concurrently. We show that for a group of symmetric SAT problems, the concurrent prediction is guaranteed to produce a wrong answer because it neglects the dependency among Boolean variables in SAT problems. % We propose AsymSAT, a GNN-based architecture which integrates recurrent neural networks to generate dependent predictions for variable assignments. The experiment results show that dependent variable prediction extends the solving capability of the GNN-based method as it improves the number of solved SAT instances on large test sets.", "IdName": "yan2023addressing", "Citation": "", "Keywords": ""}, {"Name": "Contactless oxygen monitoring with gated transformer", "Authors": ["Hao He", "Yuan Yuan", "Ying-Cong Chen", "Peng Cao", "Dina Katabi"], "Sources": "arXiv preprint arXiv:2212.03357", "PublishedYears": "2022", "Doi": "", "Abstracts": "With the increasing popularity of telehealth, it becomes critical to ensure that basic physiological signals can be monitored accurately at home, with minimal patient overhead. In this paper, we propose a contactless approach for monitoring patients' blood oxygen at home, simply by analyzing the radio signals in the room, without any wearable devices. We extract the patients' respiration from the radio signals that bounce off their bodies and devise a novel neural network that infers a patient's oxygen estimates from their breathing signal. Our model, called \\emph{Gated BERT-UNet}, is designed to adapt to the patient's medical indices (e.g., gender, sleep stages). It has multiple predictive heads and selects the most suitable head via a gate controlled by the person's physiological indices. Extensive empirical results show that our model achieves high accuracy on both medical and radio datasets.", "IdName": "he2022contactless", "Citation": "", "Keywords": ""}, {"Name": "Self-similarity Prior Distillation for Unsupervised Remote Physiological Measurement", "Authors": ["Xinyu Zhang", "Weiyu Sun", "Hao Lu", "Ying Chen", "Yun Ge", "Xiaolin Huang", "Jie Yuan", "Yingcong Chen"], "Sources": "IEEE Transactions on Multimedia", "PublishedYears": "2024", "Doi": "", "Abstracts": "Remote photoplethysmography (rPPG) is a non-invasive technique that aims to capture subtle variations in facial pixels caused by changes in blood volume resulting from cardiac activities. Most existing unsupervised methods for rPPG tasks focus on the contrastive learning between samples while neglecting the inherent self-similarity prior in physiological signals. In this paper, we propose a Self-Similarity Prior Distillation (SSPD) framework for unsupervised rPPG estimation, which capitalizes on the intrinsic temporal self-similarity of cardiac activities. Specifically, we first introduce a physical-prior embedded augmentation technique to mitigate the effect of various types of noise. Then, we tailor a self-similarity-aware network to disentangle more reliable self-similar physiological features. Finally, we develop a hierarchical self-distillation paradigm for self-similarity-aware learning and rPPG signal decoupling?\u2026", "IdName": "zhang2024self", "Citation": "", "Keywords": ""}, {"Name": "LLM-Optic: Unveiling the Capabilities of Large Language Models for Universal Visual Grounding", "Authors": ["Haoyu Zhao", "Wenhang Ge", "Ying-cong Chen"], "Sources": "arXiv preprint arXiv:2405.17104", "PublishedYears": "2024", "Doi": "", "Abstracts": "Visual grounding is an essential tool that links user-provided text queries with query-specific regions within an image. Despite advancements in visual grounding models, their ability to comprehend complex queries remains limited. To overcome this limitation, we introduce LLM-Optic, an innovative method that utilizes Large Language Models (LLMs) as an optical lens to enhance existing visual grounding models in comprehending complex text queries involving intricate text structures, multiple objects, or object spatial relationships, situations that current models struggle with. LLM-Optic first employs an LLM as a Text Grounder to interpret complex text queries and accurately identify objects the user intends to locate. Then a pre-trained visual grounding model is used to generate candidate bounding boxes given the refined query by the Text Grounder. After that, LLM-Optic annotates the candidate bounding boxes with numerical marks to establish a connection between text and specific image regions, thereby linking two distinct modalities. Finally, it employs a Large Multimodal Model (LMM) as a Visual Grounder to select the marked candidate objects that best correspond to the original text query. Through LLM-Optic, we have achieved universal visual grounding, which allows for the detection of arbitrary objects specified by arbitrary human language input. Importantly, our method achieves this enhancement without requiring additional training or fine-tuning. Extensive experiments across various challenging benchmarks demonstrate that LLM-Optic achieves state-of-the-art zero-shot visual grounding capabilities.", "IdName": "zhao2024llm", "Citation": "", "Keywords": ""}, {"Name": "Contactless Oxygen Monitoring with Radio Waves and Gated Transformer", "Authors": ["Hao He", "Yuan Yuan", "Ying-Cong Chen", "Peng Cao", "Dina Katabi"], "Sources": "Machine Learning for Healthcare Conference", "PublishedYears": "2023", "Doi": "", "Abstracts": "With the increasing popularity of telehealth, it is crucial to ensure accurate monitoring of basic physiological signals at home with minimal patient overhead. In this paper, we propose a contactless approach for monitoring blood oxygen levels simply by analyzing radio signals in a patient\u2019s room, without the need for wearable devices. Our method extracts a patient\u2019s respiration from radio signals that bounce off their body, and we use a novel neural network, called Gated BERT-UNet, to estimate blood oxygen saturation from the breathing signal. We designed our model to adapt to a patient\u2019s medical indices, such as gender and sleep stages, to provide personalized inference. Specifically, it uses multiple predictive heads, controlled by a gate, to make predictions for different sub-populations. Our extensive empirical results demonstrate that our model achieves high accuracy on both medical and radio-frequency datasets. It outperforms past work on contactless oxygen monitoring, reducing the mean absolute error in oxygen saturation from 2.0% to 1.3%.", "IdName": "he2023contactless", "Citation": "", "Keywords": ""}, {"Name": "Out-of-domain GAN inversion via Invertibility Decomposition for Photo-Realistic Human Face Manipulation", "Authors": ["Xin Yang", "Xiaogang Xu", "Yingcong Chen"], "Sources": "Proceedings of the IEEE/CVF International Conference on Computer Vision?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The fidelity of Generative Adversarial Networks (GAN) inversion is impeded by Out-Of-Domain (OOD) areas (eg, background, accessories) in the image. Detecting the OOD areas beyond the generation ability of the pre-trained model and blending these regions with the input image can enhance fidelity. The\" invertibility mask\" figures out these OOD areas, and existing methods predict the mask with the reconstruction error. However, the estimated mask is usually inaccurate due to the influence of the reconstruction error in the In-Domain (ID) area. In this paper, we propose a novel framework that enhances the fidelity of human face inversion by designing a new module to decompose the input images to ID and OOD partitions with invertibility masks. Unlike previous works, our invertibility detector is simultaneously learned with a spatial alignment module. We iteratively align the generated features to the input geometry and reduce the reconstruction error in the ID regions. Thus, the OOD areas are more distinguishable and can be precisely predicted. Then, we improve the fidelity of our results by blending the OOD areas from the input image with the ID GAN inversion results. Our method produces photo-realistic results for real-world human face image inversion and manipulation. Extensive experiments demonstrate our method's superiority over existing methods in the quality of GAN inversion and attribute manipulation.", "IdName": "yang2023out", "Citation": "", "Keywords": ""}, {"Name": "Homomorphic Interpolation Network for Unpaired Image-to-image Translation", "Authors": ["Ying-Cong Chen", "Jiaya Jia"], "Sources": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "PublishedYears": "2020", "Doi": "", "Abstracts": "Generative adversarial networks have achieved great success in unpaired image-to-image translation. Cycle consistency, a key component for this task, allows modeling the relationship between two distinct domains without paired data. In this paper, we propose an alternative framework, as an extension of latent space interpolation, to consider the intermediate region between two domains during translation. It is based on the assumption that in a flat and smooth latent space, there exist many paths that connect two sample points. Properly selecting paths makes it possible to change only certain image attributes, which is useful for generating intermediate images between the two domains. With this idea, our framework includes an encoder, an interpolator and a decoder. The encoder maps natural images to a convex and smooth latent space where interpolation is applicable. The interpolator controls the?\u2026", "IdName": "chen2020homomorphic", "Citation": "", "Keywords": ""}, {"Name": "Hawk: Learning to Understand Open-World Video Anomalies", "Authors": ["Jiaqi Tang", "Hao Lu", "Ruizheng Wu", "Xiaogang Xu", "Ke Ma", "Cheng Fang", "Bin Guo", "Jiangbo Lu", "Qifeng Chen", "Ying-Cong Chen"], "Sources": "arXiv preprint arXiv:2405.16886", "PublishedYears": "2024", "Doi": "", "Abstracts": "Video Anomaly Detection (VAD) systems can autonomously monitor and identify disturbances, reducing the need for manual labor and associated costs. However, current VAD systems are often limited by their superficial semantic understanding of scenes and minimal user interaction. Additionally, the prevalent data scarcity in existing datasets restricts their applicability in open-world scenarios. In this paper, we introduce Hawk, a novel framework that leverages interactive large Visual Language Models (VLM) to interpret video anomalies precisely. Recognizing the difference in motion information between abnormal and normal videos, Hawk explicitly integrates motion modality to enhance anomaly identification. To reinforce motion attention, we construct an auxiliary consistency loss within the motion and video space, guiding the video branch to focus on the motion modality. Moreover, to improve the interpretation of motion-to-language, we establish a clear supervisory relationship between motion and its linguistic representation. Furthermore, we have annotated over 8,000 anomaly videos with language descriptions, enabling effective training across diverse open-world scenarios, and also created 8,000 question-answering pairs for users' open-world questions. The final results demonstrate that Hawk achieves SOTA performance, surpassing existing baselines in both video description generation and question-answering. Our codes/dataset/demo will be released at https://github.com/jqtangust/hawk.", "IdName": "tang2024hawk", "Citation": "", "Keywords": ""}, {"Name": "SG-Adapter: Enhancing Text-to-Image Generation with Scene Graph Guidance", "Authors": ["Guibao Shen", "Luozhou Wang", "Jiantao Lin", "Wenhang Ge", "Chaozhe Zhang", "Xin Tao", "Yuan Zhang", "Pengfei Wan", "Zhongyuan Wang", "Guangyong Chen", "Yijun Li", "Ying-Cong Chen"], "Sources": "arXiv preprint arXiv:2405.15321", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent advancements in text-to-image generation have been propelled by the development of diffusion models and multi-modality learning. However, since text is typically represented sequentially in these models, it often falls short in providing accurate contextualization and structural control. So the generated images do not consistently align with human expectations, especially in complex scenarios involving multiple objects and relationships. In this paper, we introduce the Scene Graph Adapter(SG-Adapter), leveraging the structured representation of scene graphs to rectify inaccuracies in the original text embeddings. The SG-Adapter's explicit and non-fully connected graph representation greatly improves the fully connected, transformer-based text representations. This enhancement is particularly notable in maintaining precise correspondence in scenarios involving multiple relationships. To address the challenges posed by low-quality annotated datasets like Visual Genome, we have manually curated a highly clean, multi-relational scene graph-image paired dataset MultiRels. Furthermore, we design three metrics derived from GPT-4V to effectively and thoroughly measure the correspondence between images and scene graphs. Both qualitative and quantitative results validate the efficacy of our approach in controlling the correspondence in multiple relationships.", "IdName": "shen2024sg", "Citation": "", "Keywords": ""}, {"Name": "PhysMLE: Generalizable and Priors-Inclusive Multi-task Remote Physiological Measurement", "Authors": ["Jiyao Wang", "Hao Lu", "Ange Wang", "Xiao Yang", "Yingcong Chen", "Dengbo He", "Kaishun Wu"], "Sources": "arXiv preprint arXiv:2405.06201", "PublishedYears": "2024", "Doi": "", "Abstracts": "Remote photoplethysmography (rPPG) has been widely applied to measure heart rate from face videos. To increase the generalizability of the algorithms, domain generalization (DG) attracted increasing attention in rPPG. However, when rPPG is extended to simultaneously measure more vital signs (e.g., respiration and blood oxygen saturation), achieving generalizability brings new challenges. Although partial features shared among different physiological signals can benefit multi-task learning, the sparse and imbalanced target label space brings the seesaw effect over task-specific feature learning. To resolve this problem, we designed an end-to-end Mixture of Low-rank Experts for multi-task remote Physiological measurement (PhysMLE), which is based on multiple low-rank experts with a novel router mechanism, thereby enabling the model to adeptly handle both specifications and correlations within tasks. Additionally, we introduced prior knowledge from physiology among tasks to overcome the imbalance of label space under real-world multi-task physiological measurement. For fair and comprehensive evaluations, this paper proposed a large-scale multi-task generalization benchmark, named Multi-Source Synsemantic Domain Generalization (MSSDG) protocol. Extensive experiments with MSSDG and intra-dataset have shown the effectiveness and efficiency of PhysMLE. In addition, a new dataset was collected and made publicly available to meet the needs of the MSSDG.", "IdName": "wang2024physmle", "Citation": "", "Keywords": ""}, {"Name": "Backdoor Contrastive Learning via Bi-level Trigger Optimization", "Authors": ["Weiyu Sun", "Xinyu Zhang", "Hao Lu", "Yingcong Chen", "Ting Wang", "Jinghui Chen", "Lu Lin"], "Sources": "arXiv preprint arXiv:2404.07863", "PublishedYears": "2024", "Doi": "", "Abstracts": "Contrastive Learning (CL) has attracted enormous attention due to its remarkable capability in unsupervised representation learning. However, recent works have revealed the vulnerability of CL to backdoor attacks: the feature extractor could be misled to embed backdoored data close to an attack target class, thus fooling the downstream predictor to misclassify it as the target. Existing attacks usually adopt a fixed trigger pattern and poison the training set with trigger-injected data, hoping for the feature extractor to learn the association between trigger and target class. However, we find that such fixed trigger design fails to effectively associate trigger-injected data with target class in the embedding space due to special CL mechanisms, leading to a limited attack success rate (ASR). This phenomenon motivates us to find a better backdoor trigger design tailored for CL framework. In this paper, we propose a bi-level optimization approach to achieve this goal, where the inner optimization simulates the CL dynamics of a surrogate victim, and the outer optimization enforces the backdoor trigger to stay close to the target throughout the surrogate CL procedure. Extensive experiments show that our attack can achieve a higher attack success rate (e.g.,  ASR on ImageNet-100) with a very low poisoning rate (). Besides, our attack can effectively evade existing state-of-the-art defenses. Code is available at: https://github.com/SWY666/SSL-backdoor-BLTO.", "IdName": "sun2024backdoor", "Citation": "", "Keywords": ""}, {"Name": "Motion Inversion for Video Customization", "Authors": ["Luozhou Wang", "Guibao Shen", "Yixun Liang", "Xin Tao", "Pengfei Wan", "Di Zhang", "Yijun Li", "Yingcong Chen"], "Sources": "arXiv preprint arXiv:2403.20193", "PublishedYears": "2024", "Doi": "", "Abstracts": "In this research, we present a novel approach to motion customization in video generation, addressing the widespread gap in the thorough exploration of motion representation within video generative models. Recognizing the unique challenges posed by video's spatiotemporal nature, our method introduces Motion Embeddings, a set of explicit, temporally coherent one-dimensional embeddings derived from a given video. These embeddings are designed to integrate seamlessly with the temporal transformer modules of video diffusion models, modulating self-attention computations across frames without compromising spatial integrity. Our approach offers a compact and efficient solution to motion representation and enables complex manipulations of motion characteristics through vector arithmetic in the embedding space. Furthermore, we identify the Temporal Discrepancy in video generative models, which refers to variations in how different motion modules process temporal relationships between frames. We leverage this understanding to optimize the integration of our motion embeddings. Our contributions include the introduction of a tailored motion embedding for customization tasks, insights into the temporal processing differences in video models, and a demonstration of the practical advantages and effectiveness of our method through extensive experiments.", "IdName": "wang2024motion", "Citation": "", "Keywords": ""}, {"Name": "AsymSAT: Accelerating SAT Solving with Asymmetric Graph-Based Model Prediction", "Authors": ["Zhiyuan Yan", "Min Li", "Zhengyuan Shi", "Wenjie Zhang", "Yingcong Chen", "Hongce Zhang"], "Sources": "2024 Design", "PublishedYears": "2024", "Doi": "", "Abstracts": "Though graph neural networks (GNNs) have been used in SAT solution prediction, for a subset of symmetric SAT problems, we unveil that the current GNN-based end-to-end SAT solvers are bound to yield incorrect outcomes as they are unable to break symmetry in variable assignments. In response, we introduce AsymSAT, a new GNN architecture coupled where a recurrent neural network is (RNN) to produce asymmetric models. Moreover, we bring up a method to integrate machine-learning-based SAT assignment prediction with classic SAT solvers and demonstrate its performance on non-trivial SAT instances including logic equivalence checking and cryptographic analysis problems with as much as 75.45% time saving.", "IdName": "yan2024asymsat", "Citation": "", "Keywords": ""}, {"Name": "GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors", "Authors": ["LI Yang", "WU Ruizheng", "LI Jiyong", "CHEN Ying-cong"], "Sources": "arXiv preprint arXiv:2403.11899", "PublishedYears": "2024", "Doi": "", "Abstracts": "Learning surfaces from neural radiance field (NeRF) became a rising topic in Multi-View Stereo (MVS). Recent Signed Distance Function (SDF)-based methods demonstrated their ability to reconstruct accurate 3D shapes of Lambertian scenes. However, their results on reflective scenes are unsatisfactory due to the entanglement of specular radiance and complicated geometry. To address the challenges, we propose a Gaussian-based representation of normals in SDF fields. Supervised by polarization priors, this representation guides the learning of geometry behind the specular reflection and captures more details than existing methods. Moreover, we propose a reweighting strategy in the optimization process to alleviate the noise issue of polarization priors. To validate the effectiveness of our design, we capture polarimetric information, and ground truth meshes in additional reflective scenes with various geometry. We also evaluated our framework on the PANDORA dataset. Comparisons prove our method outperforms existing neural 3D reconstruction methods in reflective scenes by a large margin.", "IdName": "yang2024gnerp", "Citation": "", "Keywords": ""}, {"Name": "TSMA-BEV: Towards Robust Multi-Camera 3D Object Detection through Temporal Sequence Mix Augmentation", "Authors": ["Xu Cao", "Hao Lu", "Ying-Cong Chen"], "Sources": "None", "PublishedYears": "2024", "Doi": "", "Abstracts": "The advent of bird\u2019s-eye view (BEV) representation has witnessed significant advancements in camera-only 3D object detection. However, existing approaches usually struggle when applied to various corruptions that deviate from the original training domain. To address these vulnerabilities, we propose a novel framework, TSMA-BEV, which combines a new image augmentation module AugFFT based on fast fourier transformation (FFT) with a mix-sequence augmentation strategy SeqMixAug to enhance the robustness and adaptability of 3D object detection algorithms. The proposed AugFFT, involves stochastic frequency cutoffs and amplitude scaling to generate augmented images, while SeqMixAug extends this augmentation to temporal sequences, maintaining consistency across frames. This approach ensures improved performance stability in the face of multiple corruptions. As demonstrated in our experiments, the effectiveness and superiority of TSMA-BEV in handling real-world corruptions are verified.", "IdName": "caotsma", "Citation": "", "Keywords": ""}, {"Name": "Low-Rank Approximation for Sparse Attention in Multi-Modal LLMs", "Authors": ["Lin Song", "Yukang Chen", "Shuai Yang", "Xiaohan Ding", "Yixiao Ge", "Ying-Cong Chen", "Ying Shan"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "This paper focuses on the high computational complexity in Large Language Models (LLMs) a significant challenge in both natural language processing (NLP) and multi-modal tasks. We propose Low-Rank Approximation for Sparse At-tention (LoRA-Sparse) an innovative approach that strate-gically reduces this complexity. LoRA-Sparse introduces low-rank linear projection layers for sparse attention ap-proximation. It utilizes an order-mimic training methodol-ogy which is crucial for efficiently approximating the self-attention mechanism in LLMs. We empirically show that sparse attention not only reduces computational demands but also enhances model performance in both NLP and multi-modal tasks. This surprisingly shows that redundant attention in LLMs might be non-beneficial. We extensively validate LoRA-Sparse through rigorous empirical studies in both (NLP) and multi-modal tasks demonstrating its effec-tiveness and general applicability. Based on LLaMA and LLaVA models our methods can reduce more than half of the self-attention computation with even better performance than full-attention baselines.", "IdName": "song2024low", "Citation": "", "Keywords": ""}, {"Name": "Learning to Remove Wrinkled Transparent Film with Polarized Prior", "Authors": ["Jiaqi Tang", "Ruizheng Wu", "Xiaogang Xu", "Sixing Hu", "Ying-Cong Chen"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "In this paper we study a new problem Film Removal (FR) which attempts to remove the interference of wrinkled transparent films and reconstruct the original information under films for industrial recognition systems. We first physically model the imaging of industrial materials covered by the film. Considering the specular highlight from the film can be effectively recorded by the polarized camera we build a practical dataset with polarization information containing paired data with and without transparent film. We aim to remove interference from the film (specular highlights and other degradations) with an end-to-end framework. To locate the specular highlight we use an angle estimation network to optimize the polarization angle with the minimized specular highlight. The image with minimized specular highlight is set as a prior for supporting the reconstruction network. Based on the prior and the polarized images the reconstruction network can decouple all degradations from the film. Extensive experiments show that our framework achieves SOTA performance in both image reconstruction and industrial downstream tasks. Our code will be released at https://github. com/jqtangust/FilmRemoval.", "IdName": "tang2024learning", "Citation": "", "Keywords": ""}, {"Name": "An Incremental Unified Framework for Small Defect Inspection", "Authors": ["Jiaqi Tang", "Hao Lu", "Xiaogang Xu", "Ruizheng Wu", "Sixing Hu", "Tong Zhang", "Tsz Wa Cheng", "Ming Ge", "Ying-Cong Chen", "Fugee Tsung"], "Sources": "arXiv preprint arXiv:2312.08917", "PublishedYears": "2023", "Doi": "", "Abstracts": "Artificial Intelligence (AI)-driven defect inspection is pivotal in industrial manufacturing. Yet, many methods, tailored to specific pipelines, grapple with diverse product portfolios and evolving processes. Addressing this, we present the Incremental Unified Framework (IUF) that can reduce the feature conflict problem when continuously integrating new objects in the pipeline, making it advantageous in object-incremental learning scenarios. Employing a state-of-the-art transformer, we introduce Object-Aware Self-Attention (OASA) to delineate distinct semantic boundaries. Semantic Compression Loss (SCL) is integrated to optimize non-primary semantic space, enhancing network adaptability for novel objects. Additionally, we prioritize retaining the features of established objects during weight updates. Demonstrating prowess in both image and pixel-level defect inspection, our approach achieves state-of-the-art performance, proving indispensable for dynamic and scalable industrial inspections. Our code will be released at https://github.com/jqtangust/IUF.", "IdName": "tang2023incremental", "Citation": "", "Keywords": ""}, {"Name": "Defect Spectrum: A Granular Look of Large-Scale Defect Datasets with Rich Semantics", "Authors": ["Shuai Yang", "Zhifei Chen", "Pengguang Chen", "Xi Fang", "Shu Liu", "Yingcong Chen"], "Sources": "arXiv preprint arXiv:2310.17316", "PublishedYears": "2023", "Doi": "", "Abstracts": "Defect inspection is paramount within the closed-loop manufacturing system. However, existing datasets for defect inspection often lack precision and semantic granularity required for practical applications. In this paper, we introduce the Defect Spectrum, a comprehensive benchmark that offers precise, semantic-abundant, and large-scale annotations for a wide range of industrial defects. Building on four key industrial benchmarks, our dataset refines existing annotations and introduces rich semantic details, distinguishing multiple defect types within a single image. Furthermore, we introduce Defect-Gen, a two-stage diffusion-based generator designed to create high-quality and diverse defective images, even when working with limited datasets. The synthetic images generated by Defect-Gen significantly enhance the efficacy of defect inspection models. Overall, The Defect Spectrum dataset demonstrates its potential in defect inspection research, offering a solid platform for testing and refining advanced models.", "IdName": "yang2023defect", "Citation": "", "Keywords": ""}, {"Name": "CP\u2010NeRF: Conditionally Parameterized Neural Radiance Fields for Cross\u2010scene Novel View Synthesis", "Authors": ["Hao He", "Yixun Liang", "Shishi Xiao", "Jierun Chen", "Yingcong Chen"], "Sources": "Computer Graphics Forum", "PublishedYears": "2023", "Doi": "", "Abstracts": " Neural radiance fields (NeRF) have demonstrated a promising research direction for novel view synthesis. However, the existing approaches either require per\u2010scene optimization that takes significant computation time or condition on local features which overlook the global context of images. To tackle this shortcoming, we propose the Conditionally Parameterized Neural Radiance Fields (CP\u2010NeRF), a plug\u2010in module that enables NeRF to leverage contextual information from different scales. Instead of optimizing the model parameters of NeRFs directly, we train a Feature Pyramid hyperNetwork (FPN) that extracts view\u2010dependent global and local information from images within or across scenes to produce the model parameters. Our model can be trained end\u2010to\u2010end with standard photometric loss from NeRF. Extensive experiments demonstrate that our method can significantly boost the performance of NeRF?\u2026", "IdName": "he2023cp", "Citation": "", "Keywords": ""}, {"Name": "A Scale-Invariant Task Balancing Approach for Multi-Task Learning", "Authors": ["Baijiong Lin", "Weisen Jiang", "Feiyang Ye", "Yu Zhang", "Pengguang Chen", "Ying-Cong Chen", "Shu Liu"], "Sources": "arXiv preprint arXiv:2308.12029", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multi-task learning (MTL), a learning paradigm to learn multiple related tasks simultaneously, has achieved great success in various fields. However, task-balancing remains a significant challenge in MTL, with the disparity in loss/gradient scales often leading to performance compromises. In this paper, we propose a Scale-Invariant Multi-Task Learning (SI-MTL) method to alleviate the task-balancing problem from both loss and gradient perspectives. Specifically, SI-MTL contains a logarithm transformation which is performed on all task losses to ensure scale-invariant at the loss level, and a gradient balancing method, SI-G, which normalizes all task gradients to the same magnitude as the maximum gradient norm. Extensive experiments conducted on several benchmark datasets consistently demonstrate the effectiveness of SI-G and the state-of-the-art performance of SI-MTL.", "IdName": "lin2023scale", "Citation": "", "Keywords": ""}, {"Name": "High Dynamic Range Image Reconstruction via Deep Explicit Polynomial Curve Estimation", "Authors": ["Jiaqi Tang", "Xiaogang Xu", "Sixing Hu", "Ying-Cong Chen"], "Sources": "ECAI 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "Due to limited camera capacities, digital images usually have a narrower dynamic illumination range than real-world scene radiance. To resolve this problem, High Dynamic Range (HDR) reconstruction is proposed to recover the dynamic range to better represent real-world scenes. However, due to different physical imaging parameters, the tone-mapping functions between images and real radiance are highly diverse, which makes HDR reconstruction extremely challenging. Existing solutions can not explicitly clarify a corresponding relationship between the tone-mapping function and the generated HDR image, but this relationship is vital when guiding the reconstruction of HDR images. To address this problem, we propose a method to explicitly estimate the tone mapping function and its corresponding HDR image in one network. Firstly, based on the characteristics of the tone mapping function, we construct a?\u2026", "IdName": "tang2023high", "Citation": "", "Keywords": ""}, {"Name": "Particularity Beyond Commonality: Unpaired Identity Transfer with Multiple References", "Authors": ["Ruizheng Wu", "Xin Tao", "Yingcong Chen", "Xiaoyong Shen", "Jiaya Jia"], "Sources": "Computer Vision\u2013ECCV 2020: 16th European Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": " Unpaired image-to-image translation aims to translate images from the source class to target one by providing sufficient data for these classes. Current few-shot translation methods use multiple reference images to describe the target domain through extracting common features. In this paper, we focus on a more specific identity transfer problem and advocate that particular property in each individual image can also benefit generation. We accordingly propose a new multi-reference identity transfer framework by simultaneously making use of particularity and commonality of reference. It is achieved via a semantic pyramid alignment module to make proper use of geometric information for individual images, as well as an attention module to aggregate for the final transformation. Extensive experiments demonstrate the effectiveness of our framework given the promising results in a number of identity transfer?\u2026", "IdName": "wu2020particularity", "Citation": "", "Keywords": ""}, {"Name": "A diffusion theory for deep learning dynamics: Stochastic gradient descent exponentially favors flat minima", "Authors": ["Zeke Xie", "Issei Sato", "Masashi Sugiyama"], "Sources": "International Conference on Learning Representations (ICLR 2021)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Stochastic Gradient Descent (SGD) and its variants are mainstream methods for training deep networks in practice. SGD is known to find a flat minimum that often generalizes well. However, it is mathematically unclear how deep learning can select a flat minimum among so many minima. To answer the question quantitatively, we develop a density diffusion theory (DDT) to reveal how minima selection quantitatively depends on the minima sharpness and the hyperparameters. To the best of our knowledge, we are the first to theoretically and empirically prove that, benefited from the Hessian-dependent covariance of stochastic gradient noise, SGD favors flat minima exponentially more than sharp minima, while Gradient Descent (GD) with injected white noise favors flat minima only polynomially more than sharp minima. We also reveal that either a small learning rate or large-batch training requires exponentially many iterations to escape from minima in terms of the ratio of the batch size and learning rate. Thus, large-batch training cannot search flat minima efficiently in a realistic computational time.", "IdName": "xie2020diffusion", "Citation": "", "Keywords": ""}, {"Name": "Dataset Pruning: Reducing Training Data by Examining Generalization Influence", "Authors": ["Shuo Yang", "Zeke Xie", "Hanyu Peng", "Min Xu", "Mingming Sun", "Ping Li"], "Sources": "International Conference on Learning Representations (ICLR 2023)", "PublishedYears": "2023", "Doi": "", "Abstracts": "The great success of deep learning heavily relies on increasingly larger training data, which comes at a price of huge computational and infrastructural costs. This poses crucial questions that, do all training data contribute to model's performance? How much does each individual training sample or a sub-training-set affect the model's generalization, and how to construct the smallest subset from the entire training data as a proxy training set without significantly sacrificing the model's performance? To answer these, we propose dataset pruning, an optimization-based sample selection method that can (1) examine the influence of removing a particular set of training samples on model's generalization ability with theoretical guarantee, and (2) construct the smallest subset of training data that yields strictly constrained generalization gap. The empirically observed generalization gap of dataset pruning is substantially consistent with our theoretical expectations. Furthermore, the proposed method prunes 40% training examples on the CIFAR-10 dataset, halves the convergence time with only 1.3% test accuracy decrease, which is superior to previous score-based sample selection methods.", "IdName": "yang2022dataset", "Citation": "", "Keywords": ""}, {"Name": "Artificial Neural Variability for Deep Learning: On Overfitting, Noise Memorization, and Catastrophic Forgetting", "Authors": ["Zeke Xie", "Fengxiang He", "Shaopeng Fu", "Issei Sato", "Dacheng Tao", "Masashi Sugiyama"], "Sources": "Neural Computation", "PublishedYears": "2021", "Doi": "", "Abstracts": "Deep learning is often criticized by two serious issues that rarely exist in natural nervous systems: overfitting and catastrophic forgetting. It can even memorize randomly labeled data, which has little knowledge behind the instance-label pairs. When a deep network continually learns over time by accommodating new tasks, it usually quickly overwrites the knowledge learned from previous tasks. Referred to as the neural variability, it is well known in neuroscience that human brain reactions exhibit substantial variability even in response to the same stimulus. This mechanism balances accuracy and plasticity/flexibility in the motor learning of natural nervous systems. Thus, it motivates us to design a similar mechanism, named artificial neural variability (ANV), that helps artificial neural networks learn some advantages from \u201cnatural\u201d neural networks. We rigorously prove that ANV plays as an implicit regularizer of the?\u2026", "IdName": "xie2021artificial", "Citation": "", "Keywords": ""}, {"Name": "Adaptive Inertia: Disentangling the effects of adaptive learning rate and momentum", "Authors": ["Zeke Xie", "Xinrui Wang", "Huishuai Zhang", "Issei Sato", "Masashi Sugiyama"], "Sources": "International Conference on Machine Learning (ICML 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Adaptive Moment Estimation (Adam), which combines Adaptive Learning Rate and Momentum, would be the most popular stochastic optimizer for accelerating the training of deep neural networks. However, it is empirically known that Adam often generalizes worse than Stochastic Gradient Descent (SGD). The purpose of this paper is to unveil the mystery of this behavior in the diffusion theoretical framework. Specifically, we disentangle the effects of Adaptive Learning Rate and Momentum of the Adam dynamics on saddle-point escaping and flat minima selection. We prove that Adaptive Learning Rate can escape saddle points efficiently, but cannot select flat minima as SGD does. In contrast, Momentum provides a drift effect to help the training process pass through saddle points, and almost does not affect flat minima selection. This partly explains why SGD (with Momentum) generalizes better, while Adam generalizes worse but converges faster. Furthermore, motivated by the analysis, we design a novel adaptive optimization framework named Adaptive Inertia, which uses parameter-wise adaptive inertia to accelerate the training and provably favors flat minima as well as SGD. Our extensive experiments demonstrate that the proposed adaptive inertia method can generalize significantly better than SGD and conventional adaptive gradient methods.", "IdName": "xie2022adaptive", "Citation": "", "Keywords": ""}, {"Name": "Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization", "Authors": ["Zeke Xie", "Li Yuan", "Zhanxing Zhu", "Masashi Sugiyama"], "Sources": "International Conference on Machine Learning (ICML 2021) 139", "PublishedYears": "2021", "Doi": "", "Abstracts": "It is well-known that stochastic gradient noise (SGN) acts as implicit regularization for deep learning and is essentially important for both optimization and generalization of deep networks. Some works attempted to artificially simulate SGN by injecting random noise to improve deep learning. However, it turned out that the injected simple random noise cannot work as well as SGN, which is anisotropic and parameter-dependent. For simulating SGN at low computational costs and without changing the learning rate or batch size, we propose the Positive-Negative Momentum (PNM) approach that is a powerful alternative to conventional Momentum in classic optimizers. The introduced PNM method maintains two approximate independent momentum terms. Then, we can control the magnitude of SGN explicitly by adjusting the momentum difference. We theoretically prove the convergence guarantee and the generalization advantage of PNM over Stochastic Gradient Descent (SGD). By incorporating PNM into the two conventional optimizers, SGD with Momentum and Adam, our extensive experiments empirically verified the significant advantage of the PNM-based variants over the corresponding conventional Momentum-based optimizers. Code:\\url {https://github. com/zeke-xie/Positive-Negative-Momentum}.", "IdName": "xie2021positive", "Citation": "", "Keywords": ""}, {"Name": "Stable weight decay regularization", "Authors": ["Zeke Xie", "Issei Sato", "Masashi Sugiyama"], "Sources": "None", "PublishedYears": "2020", "Doi": "", "Abstracts": "Weight decay is a popular regularization technique for training of deep neural networks. Modern deep learning libraries mainly use  regularization as the default implementation of weight decay. \\citet{loshchilov2018decoupled} demonstrated that  regularization is not identical to weight decay for adaptive gradient methods, such as Adaptive Momentum Estimation (Adam), and proposed Adam with Decoupled Weight Decay (AdamW). However, we found that the popular implementations of weight decay, including  regularization and decoupled weight decay, in modern deep learning libraries usually damage performance. First, the  regularization is unstable weight decay for all optimizers that use Momentum, such as stochastic gradient descent (SGD). Second, decoupled weight decay is highly unstable for all adaptive gradient methods. We further propose the Stable Weight Decay (SWD) method to fix the unstable weight decay problem from a dynamical perspective. The proposed SWD method makes significant improvements over  regularization and decoupled weight decay in our experiments. Simply fixing weight decay in Adam by SWD, with no extra hyperparameter, can outperform complex Adam variants, which have more hyperparameters.", "IdName": "xie2020stable", "Citation": "", "Keywords": ""}, {"Name": "Sparse Double Descent: Where Network Pruning Aggravates Overfitting", "Authors": ["Zheng He", "Zeke Xie", "Quanzhi Zhu", "Zengchang Qin"], "Sources": "International Conference on Machine Learning (ICML 2022)", "PublishedYears": "2022", "Doi": "", "Abstracts": "People usually believe that network pruning not only reduces the computational cost of deep networks, but also prevents overfitting by decreasing model capacity. However, our work surprisingly discovers that network pruning sometimes even aggravates overfitting. We report an unexpected sparse double descent phenomenon that, as we increase model sparsity via network pruning, test performance first gets worse (due to overfitting), then gets better (due to relieved overfitting), and gets worse at last (due to forgetting useful information). While recent studies focused on the deep double descent with respect to model overparameterization, they failed to recognize that sparsity may also cause double descent. In this paper, we have three main contributions. First, we report the novel sparse double descent phenomenon through extensive experiments. Second, for this phenomenon, we propose a novel learning distance interpretation that the curve of l2 learning distance of sparse models (from initialized parameters to final parameters) may correlate with the sparse double descent curve well and reflect generalization better than minima flatness. Third, in the context of sparse double descent, a winning ticket in the lottery ticket hypothesis surprisingly may not always win.", "IdName": "he2022sparse", "Citation": "", "Keywords": ""}, {"Name": "On the Overlooked Pitfalls of Weight Decay and How to Mitigate Them: A Gradient-Norm Perspective", "Authors": ["Zeke Xie", "Zhiqiang Xu", "Jingzhao Zhang", "Issei Sato", "Masashi Sugiyama"], "Sources": "Neural Information Processing Systems (NeurIPS 2023)", "PublishedYears": "2024", "Doi": "", "Abstracts": "Weight decay is a simple yet powerful regularization technique that has been very widely used in training of deep neural networks (DNNs). While weight decay has attracted much attention, previous studies fail to discover some overlooked pitfalls on large gradient norms resulted by weight decay. In this paper, we discover that, weight decay can unfortunately lead to large gradient norms at the final phase (or the terminated solution) of training, which often indicates bad convergence and poor generalization. To mitigate the gradient-norm-centered pitfalls, we present the first practical scheduler for weight decay, called the Scheduled Weight Decay (SWD) method that can dynamically adjust the weight decay strength according to the gradient norm and significantly penalize large gradient norms during training. Our experiments also support that SWD indeed mitigates large gradient norms and often significantly outperforms the conventional constant weight decay strategy for Adaptive Moment Estimation (Adam).", "IdName": "xie2024overlooked", "Citation": "", "Keywords": ""}, {"Name": "S3IM: Stochastic Structural SIMilarity and Its Unreasonable Effectiveness for Neural Fields", "Authors": ["Zeke Xie", "Xindi Yang", "Yujie Yang", "Qi Sun", "Yixiang Jiang", "Haoran Wang", "Yunfeng Cai", "Mingming Sun"], "Sources": "International Conference on Computer Vision (ICCV 2023)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, Neural Radiance Field (NeRF) has shown great success in rendering novel-view images of a given scene by learning an implicit representation with only posed RGB images. NeRF and relevant neural field methods (eg, neural surface representation) typically optimize a point-wise loss and make point-wise predictions, where one data point corresponds to one pixel. Unfortunately, this line of research failed to use the collective supervision of distant pixels, although it is known that pixels in an image or scene can provide rich structural information. To the best of our knowledge, we are the first to design a nonlocal multiplex training paradigm for NeRF and relevant neural field methods via a novel Stochastic Structural SIMilarity (S3IM) loss that processes multiple data points as a whole set instead of process multiple inputs independently. Our extensive experiments demonstrate the unreasonable effectiveness of S3IM in improving NeRF and neural surface representation for nearly free. The improvements of quality metrics can be particularly significant for those relatively difficult tasks: eg, the test MSE loss unexpectedly drops by more than 90% for TensoRF and DVGO over eight novel view synthesis tasks; a 198% F-score gain and a 64% Chamfer L1 distance reduction for NeuS over eight surface reconstruction tasks. Moreover, S3IM is consistently robust even with sparse inputs, corrupted images, and dynamic scenes.", "IdName": "xie2023s3im", "Citation": "", "Keywords": ""}, {"Name": "On the power-law spectrum in deep learning: A bridge to protein science", "Authors": ["Zeke Xie", "Qian-Yuan Tang", "Yunfeng Cai", "Mingming Sun", "Ping Li"], "Sources": "arXiv preprint arXiv:2201.13011 2", "PublishedYears": "2022", "Doi": "", "Abstracts": "It is well-known that the Hessian matters to optimization, generalization, and even robustness of deep learning. Recent works empirically discovered that the Hessian spectrum in deep learning has a two-component structure that consists of a small number of large eigenvalues and a large number of nearly-zero eigenvalues. However, the theoretical mechanism behind the Hessian spectrum is still absent or under-explored. We are the first to theoretically and empirically demonstrate that the Hessian spectrums of well-trained deep neural networks exhibit simple power-law distributions. Our work further reveals how the power-law spectrum essentially matters to deep learning:(1) it leads to low-dimensional and robust learning space, and (2) it implicitly penalizes the variational free energy, which results in low-complexity solutions. We further used the power-law spectral framework as a powerful tool to demonstrate multiple novel behaviors of deep learning. Interestingly, the power-law spectrum is also known to be important in protein, which indicates a novel bridge between deep learning and protein science.", "IdName": "xie2022power", "Citation": "", "Keywords": ""}, {"Name": "SGD: Street View Synthesis with Gaussian Splatting and Diffusion Prior", "Authors": ["Zhongrui Yu", "Haoran Wang", "Jinze Yang", "Hanzhang Wang", "Zeke Xie", "Yunfeng Cai", "Jiale Cao", "Zhong Ji", "Mingming Sun"], "Sources": "arXiv preprint arXiv:2403.20079", "PublishedYears": "2024", "Doi": "", "Abstracts": "Novel View Synthesis (NVS) for street scenes play a critical role in the autonomous driving simulation. The current mainstream technique to achieve it is neural rendering, such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). Although thrilling progress has been made, when handling street scenes, current methods struggle to maintain rendering quality at the viewpoint that deviates significantly from the training viewpoints. This issue stems from the sparse training views captured by a fixed camera on a moving vehicle. To tackle this problem, we propose a novel approach that enhances the capacity of 3DGS by leveraging prior from a Diffusion Model along with complementary multi-modal data. Specifically, we first fine-tune a Diffusion Model by adding images from adjacent frames as condition, meanwhile exploiting depth data from LiDAR point clouds to supply additional spatial information. Then we apply the Diffusion Model to regularize the 3DGS at unseen views during training. Experimental results validate the effectiveness of our method compared with current state-of-the-art models, and demonstrate its advance in rendering images from broader views.", "IdName": "yu2024sgd", "Citation": "", "Keywords": ""}, {"Name": "HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced Diffusion Models", "Authors": ["Hanzhang Wang", "Haoran Wang", "Jinze Yang", "Zhongrui Yu", "Zeke Xie", "Lei Tian", "Xinyan Xiao", "Junjun Jiang", "Xianming Liu", "Mingming Sun"], "Sources": "arXiv preprint arXiv:2401.05870", "PublishedYears": "2024", "Doi": "", "Abstracts": "The goal of Arbitrary Style Transfer (AST) is injecting the artistic features of a style reference into a given image/video. Existing methods usually focus on pursuing the balance between style and content, whereas ignoring the significant demand for flexible and customized stylization results and thereby limiting their practical application. To address this critical issue, a novel AST approach namely HiCAST is proposed, which is capable of explicitly customizing the stylization results according to various source of semantic clues. In the specific, our model is constructed based on Latent Diffusion Model (LDM) and elaborately designed to absorb content and style instance as conditions of LDM. It is characterized by introducing of \\textit{Style Adapter}, which allows user to flexibly manipulate the output results by aligning multi-level style information and intrinsic knowledge in LDM. Lastly, we further extend our model to perform video AST. A novel learning objective is leveraged for video diffusion model training, which significantly improve cross-frame temporal consistency in the premise of maintaining stylization strength. Qualitative and quantitative comparisons as well as comprehensive user studies demonstrate that our HiCAST outperforms the existing SoTA methods in generating visually plausible stylization results.", "IdName": "wang2024hicast", "Citation": "", "Keywords": ""}, {"Name": "Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents", "Authors": ["Haoyi Xiong", "Zhiyuan Wang", "Xuhong Li", "Jiang Bian", "Zeke Xie", "Shahid Mumtaz", "Laura E Barnes"], "Sources": "arXiv preprint arXiv:2407.08516", "PublishedYears": "2024", "Doi": "", "Abstracts": "This article explores the convergence of connectionist and symbolic artificial intelligence (AI), from historical debates to contemporary advancements. Traditionally considered distinct paradigms, connectionist AI focuses on neural networks, while symbolic AI emphasizes symbolic representation and logic. Recent advancements in large language models (LLMs), exemplified by ChatGPT and GPT-4, highlight the potential of connectionist architectures in handling human language as a form of symbols. The study argues that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence. By utilizing LLMs for text-based knowledge modeling and representation, LAAs integrate neuro-symbolic AI principles, showcasing enhanced reasoning and decision-making capabilities. Comparing LAAs with Knowledge Graphs within the neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking human-like reasoning processes, scaling effectively with large datasets, and leveraging in-context samples without explicit re-training. The research underscores promising avenues in neuro-vector-symbolic integration, instructional encoding, and implicit reasoning, aimed at further enhancing LAA capabilities. By exploring the progression of neuro-symbolic AI and proposing future research trajectories, this work advances the understanding and development of AI technologies.", "IdName": "xiong2024converging", "Citation": "", "Keywords": ""}, {"Name": "VIP: Versatile Image Outpainting Empowered by Multimodal Large Language Model", "Authors": ["Jinze Yang", "Haoran Wang", "Zining Zhu", "Chenglong Liu", "Meng Wymond Wu", "Zeke Xie", "Zhong Ji", "Jungong Han", "Mingming Sun"], "Sources": "arXiv preprint arXiv:2406.01059", "PublishedYears": "2024", "Doi": "", "Abstracts": "In this paper, we focus on resolving the problem of image outpainting, which aims to extrapolate the surrounding parts given the center contents of an image. Although recent works have achieved promising performance, the lack of versatility and customization hinders their practical applications in broader scenarios. Therefore, this work presents a novel image outpainting framework that is capable of customizing the results according to the requirement of users. First of all, we take advantage of a Multimodal Large Language Model (MLLM) that automatically extracts and organizes the corresponding textual descriptions of the masked and unmasked part of a given image. Accordingly, the obtained text prompts are introduced to endow our model with the capacity to customize the outpainting results. In addition, a special Cross-Attention module, namely Center-Total-Surrounding (CTS), is elaborately designed to enhance further the the interaction between specific space regions of the image and corresponding parts of the text prompts. Note that unlike most existing methods, our approach is very resource-efficient since it is just slightly fine-tuned on the off-the-shelf stable diffusion (SD) model rather than being trained from scratch. Finally, the experimental results on three commonly used datasets, i.e. Scenery, Building, and WikiArt, demonstrate our model significantly surpasses the SoTA methods. Moreover, versatile outpainting results are listed to show its customized ability.", "IdName": "yang2024vip", "Citation": "", "Keywords": ""}, {"Name": "DistanciAR: Authoring Site-Specific Augmented Reality Experiences for Remote Environments", "Authors": ["Zeyu Wang", "Cuong Nguyen", "Paul Asente", "Julie Dorsey"], "Sources": "ACM CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2021", "Doi": "", "Abstracts": "Most augmented reality (AR) authoring tools only support the author\u2019s current environment, but designers often need to create site-specific experiences for a different environment. We propose DistanciAR, a novel tablet-based workflow for remote AR authoring. Our baseline solution involves three steps. A remote environment is captured by a camera with LiDAR; then, the author creates an AR experience from a different location using AR interactions; finally, a remote viewer consumes the AR content on site. A formative study revealed understanding and navigating the remote space as key challenges with this solution. We improved the authoring interface by adding two novel modes: Dollhouse, which renders a bird\u2019s-eye view, and Peek, which creates photorealistic composite images using captured images. A second study compared this improved system with the baseline, and participants reported that the new?\u2026", "IdName": "wang2021distanciar", "Citation": "", "Keywords": ""}, {"Name": "Tracing Versus Freehand for Evaluating Computer-Generated Drawings", "Authors": ["Zeyu Wang", "Sherry Qiu", "Nicole Feng", "Holly Rushmeier", "Leonard McMillan", "Julie Dorsey"], "Sources": "ACM Transactions on Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Non-photorealistic rendering (NPR) and image processing algorithms are widely assumed as a proxy for drawing. However, this assumption is not well assessed due to the difficulty in collecting and registering freehand drawings. Alternatively, tracings are easier to collect and register, but there is no quantitative evaluation of tracing as a proxy for freehand drawing. In this paper, we compare tracing, freehand drawing, and computer-generated drawing approximation (CGDA) to understand their similarities and differences. We collected a dataset of 1,498 tracings and freehand drawings by 110 participants for 100 image prompts. Our drawings are registered to the prompts and include vector-based timestamped strokes collected via stylus input. Comparing tracing and freehand drawing, we found a high degree of similarity in stroke placement and types of strokes used over time. We show that tracing can serve as a?\u2026", "IdName": "wang2021tracing", "Citation": "", "Keywords": ""}, {"Name": "The Role of Subsurface Scattering in Glossiness Perception", "Authors": ["Davit Gigilashvili", "Weiqi Shi", "Zeyu Wang", "Marius Pedersen", "Jon Yngve Hardeberg", "Holly Rushmeier"], "Sources": "ACM Transactions on Applied Perception", "PublishedYears": "2021", "Doi": "", "Abstracts": "This study investigates the potential impact of subsurface light transport on gloss perception for the purposes of broadening our understanding of visual appearance in computer graphics applications. Gloss is an important attribute for characterizing material appearance. We hypothesize that subsurface scattering of light impacts the glossiness perception. However, gloss has been traditionally studied as a surface-related quality and the findings in the state-of-the-art are usually based on fully opaque materials, although the visual cues of glossiness can be impacted by light transmission as well. To address this gap and to test our hypothesis, we conducted psychophysical experiments and found that subjects are able to tell the difference in terms of gloss between stimuli that differ in subsurface light transport but have identical surface qualities and object shape. This gives us a clear indication that subsurface light?\u2026", "IdName": "gigilashvili2021role", "Citation": "", "Keywords": ""}, {"Name": "SplattingAvatar: Realistic Real-Time Human Avatars with Mesh-Embedded Gaussian Splatting", "Authors": ["Zhijing Shao", "Zhaolong Wang", "Zhuang Li", "Duotun Wang", "Xiangru Lin", "Yu Zhang", "Mingming Fan", "Zeyu Wang"], "Sources": "IEEE/CVF Conference on Computer Vision and Pattern Recognition", "PublishedYears": "2024", "Doi": "", "Abstracts": "We present SplattingAvatar a hybrid 3D representation of photorealistic human avatars with Gaussian Splatting embedded on a triangle mesh which renders over 300 FPS on a modern GPU and 30 FPS on a mobile device. We disentangle the motion and appearance of a virtual human with explicit mesh geometry and implicit appearance modeling with Gaussian Splatting. The Gaussians are defined by barycentric coordinates and displacement on a triangle mesh as Phong surfaces. We extend lifted optimization to simultaneously optimize the parameters of the Gaussians while walking on the triangle mesh. SplattingAvatar is a hybrid representation of virtual humans where the mesh represents low-frequency motion and surface deformation while the Gaussians take over the high-frequency geometry and detailed appearance. Unlike existing deformation methods that rely on an MLP-based linear blend skinning (LBS) field for motion we control the rotation and translation of the Gaussians directly by mesh which empowers its compatibility with various animation techniques eg skeletal animation blend shapes and mesh editing. Trainable from monocular videos for both full-body and head avatars SplattingAvatar shows state-of-the-art rendering quality across multiple datasets.", "IdName": "shao2024splattingavatar", "Citation": "", "Keywords": ""}, {"Name": "A Low-Dimensional Perceptual Space for Intuitive BRDF Editing", "Authors": ["Weiqi Shi", "Zeyu Wang", "Cyril Soler", "Holly Rushmeier"], "Sources": "Eurographics Symposium on Rendering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Understanding and characterizing material appearance based on human perception is challenging because of the highdimensionality and nonlinearity of reflectance data. We refer to the process of identifying specific characteristics of material appearance within the same category as material estimation, in contrast to material categorization which focuses on identifying inter-category differences [FNG15]. In this paper, we present a method to simulate the material estimation process based on human perception. We create a continuous perceptual space for measured tabulated data based on its underlying low-dimensional manifold. Unlike many previous works that only address individual perceptual attributes (such as gloss), we focus on extracting all possible dimensions that can explain the perceived differences between appearances. Additionally, we propose a new material editing interface that combines image navigation and sliders to visualize each perceptual dimension and facilitate the editing of tabulated BRDFs. We conduct a user study to evaluate the efficacy of the perceptual space and the interface in terms of appearance matching.", "IdName": "shi2021low", "Citation": "", "Keywords": ""}, {"Name": "PointShopAR: Supporting Environmental Design Prototyping Using Point Cloud in Augmented Reality", "Authors": ["Zeyu Wang", "Cuong Nguyen", "Paul Asente", "Julie Dorsey"], "Sources": "ACM CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": " We present PointShopAR, a novel tablet-based system for AR environmental design using point clouds as the underlying representation. It integrates point cloud capture and editing in a single AR workflow to help users quickly prototype design ideas in their spatial context. We hypothesize that point clouds are well suited for prototyping, as they can be captured more rapidly than textured meshes and then edited immediately in situ on the capturing device. We based the design of PointShopAR on the practical needs of six architects in a formative study. Our system supports a variety of point cloud editing operations in AR, including selection, transformation, hole filling, drawing, morphing, and animation. We evaluate PointShopAR through a remote study on usability and an in-person study on environmental design support. Participants were able to iterate design rapidly, showing the merits of an integrated capture?\u2026", "IdName": "wang2023pointshopar", "Citation": "", "Keywords": ""}, {"Name": "Introducing Massive Open Metaverse Course and Its Enabling Technology", "Authors": ["Kang Zhang", "Zhijing Shao", "Yun Lu", "Ying Yu", "Wei Sun", "Zeyu Wang"], "Sources": "IEEE Transactions on Learning Technologies", "PublishedYears": "2023", "Doi": "", "Abstracts": "As metaverse becomes one of the most popular buzzwords in technology, there is still a lack of support to integrate true metaverse learning experiences in massive open online courses (MOOCs). This article introduces a new framework of massive open metaverse courses (MOMCs) and its major enabling technologies, which add immersive and 3-D learning experiences lacking in MOOCs. It then describes a detailed case study, the President's First Lecture at the Hong Kong University of Science and Technology (Guangzhou), which we consider the world's first true MOMC environment, enabled by the latest volumetric video and related virtual and augmented reality technologies. We describe in detail how this course is created and discuss the major advantages of MOMC over MOOC as well as its current limitations.", "IdName": "zhang2023introducing", "Citation": "", "Keywords": ""}, {"Name": "Reconstructing Dura-Europos From Sparse Photo Collections Using Deep Contour Extraction", "Authors": ["Yifen Shen", "Zeyu Wang", "Qinying Sun", "Anne Chen", "Holly Rushmeier"], "Sources": "Eurographics Workshop on Graphics and Cultural Heritage", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this short paper we present work in progress on creating tools to facilitate 3D reconstruction of cultural heritage. We propose three new types of tools to make reconstruction easier\u2013first we fetch linked open data to help organize source materials, next we extract key contours from photographs to speed up reconstruction, and finally we generate video tours of positioned photos and sketches. We also introduce a new, expanded 3D software system to support these tasks. The system is developed based on previous work on 3D sketching in the context of cultural heritage documentation, in particular CHER-ish. We demonstrate the potential of these tools by describing results obtained from the Dura-Europos data set.", "IdName": "shen2021reconstructing", "Citation": "", "Keywords": ""}, {"Name": "From Expanded Cinema to Extended Reality: How AI Can Expand and Extend Cinematic Experiences", "Authors": ["Junrong Song", "Bingyuan Wang", "Zeyu Wang", "David Kei-man Yip"], "Sources": "International Symposium on Visual Information Communication and Interaction?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " This paper explores the concept of expanded cinema and its relationship to extended reality (XR), focusing on the potential of artificial intelligence (AI) to expand and extend expressive possibilities. Expanded cinema refers to experimental film and multimedia art forms that challenge the conventions of traditional cinema by creating immersive and interactive experiences for audiences. XR, on the other hand, blurs the line between physical and virtual reality, offering immersive storytelling experiences. Both expanded cinema and XR aim to push the boundaries of traditional norms and create immersive experiences through the integration of technology, interactivity, and cross-sensory elements. The paper emphasizes the role of AI in optimizing 3D scene creation for XR and enhancing the overall experience through a case study. It also presents several AI-based techniques, such as generative models and AI?\u2026", "IdName": "song2023expanded", "Citation": "", "Keywords": ""}, {"Name": "Envisioning A Hyper-Learning System in the Age of Metaverse", "Authors": ["Anqi Wang", "Gao Ze", "Zeyu Wang", "Tristan Braud", "Pan Hui"], "Sources": "ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The digital technologies, such as interactive interfaces, augmented reality (AR), and virtual reality (VR), are emerging as the latest examples of an ongoing trend of digitizing learning in the metaverse. Their pervasive impact requires us to rethink the notion of information gathering and learning [Pokhrel and Chhetri 2021]. Although much research has been devoted to AR/VR/metaverse education, there is little research on the pedagogical interactions of pre-learning information in the metaverse. Pre-learning refers to", "IdName": "wang2022envisioning", "Citation": "", "Keywords": ""}, {"Name": "From \u2018wow\u2019to \u2018why\u2019: Guidelines for creating the opening of a data video with cinematic styles", "Authors": ["Xian Xu", "Leni Yang", "David Yip", "Mingming Fan", "Zheng Wei", "Huamin Qu"], "Sources": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Data videos are an increasingly popular storytelling form. The opening of a data video critically influences its success as the opening either attracts the audience to continue watching or bores them to abandon watching. However, little is known about how to create an attractive opening. We draw inspiration from the openings of famous films to facilitate designing data video openings. First, by analyzing over 200 films from several sources, we derived six primary cinematic opening styles adaptable to data videos. Then, we consulted eight experts from the film industry to formulate 28 guidelines. To validate the usability and effectiveness of the guidelines, we asked participants to create data video openings with and without the guidelines, which were then evaluated by experts and the general public. Results showed that the openings designed with the guidelines were perceived to be more attractive, and the?\u2026", "IdName": "xu2022wow", "Citation": "", "Keywords": ""}, {"Name": "The Invisible Art of Storytelling and Media Production", "Authors": ["David Kei-Man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2020", "Doi": "", "Abstracts": " As the early filmmakers were magicians, cinema has developed from the early days of visible \u2018tricks\u2019 to invisible \u2018effects\u2019 [1]. As narrative cinema is to engage the audience with the story, many of the cinematic effects have been made to look invisible to the untrained eyes and ears. Film is both magical and make-believe. Like a magician who manages to hide his or her trick in a magic act, a filmmaker often hides his or her magic tricks from the audience. The invisible art of hiding cinematic effects is one of the important skills in media production. In storytelling, the hidden subtext can be as important as the visual text. This comprehensive article discusses the invisible art of storytelling and filmmaking.", "IdName": "yip2020invisible", "Citation": "", "Keywords": ""}, {"Name": "Visual Elements and Design Principles in Media Production", "Authors": ["David Kei-man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2020", "Doi": "", "Abstracts": " Visual elements such as dot, line, plane and color are the basic components of an image. By applying design principles to these visual elements in visual expression, the creative possibilities are infinite. Cinematic style is created by the filmmaker\u2019s control over the medium. Many visual styles of media projects are the application of the design principles to the visual elements. This systematic approach is not only confined to a shot composition but also to the whole visual structure of the work involving the development of both story and visual elements. This article analyzes this design approach to visual styles by discussing the works of several film masters as examples of how media project can use this approach to design and structure visual content. ", "IdName": "yip2020visual", "Citation": "", "Keywords": ""}, {"Name": "The hidden art of transmedia storytelling across cinema and video game", "Authors": ["David Kei-man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2021", "Doi": "", "Abstracts": " Various forms of digital media such as computer game have borrowed greatly from cinematic art and expression in terms of its world building and narrative structure [1, 2]. Cinema and video game share similar screen, character and time-based properties. They are time-based because they have time dimension in duration and structure. Time itself is invisible and intangible. Time-based media employs the dramatic art of storytelling and content design sometimes with hidden effects invisible to untrained eyes. Despite these characteristic similarities, cinema and video game as both time and character-based media do function and entertain differently. Narrative and experience design can be invisible and relevant to the creation and experience of cinematic storytelling and video game. This article aims to offer an extended perspective of transmedia storytelling [3, 4] by discussing both the differences and also?\u2026", "IdName": "yip2021hidden", "Citation": "", "Keywords": ""}, {"Name": "Cinematic Surrealism of the Interactive Virtual Space", "Authors": ["David Kei-Man Yip"], "Sources": "Reconceptualizing the Digital Humanities in Asia: New Representations of Art?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "  Surrealism has been a revolutionary art movement since the early 1920s. It transcended the boundaries of previous art movements by visualizing the uncanny subconscious mind and dream. Surrealism was also very influential in the development of cinema through the creative collaboration of legendary artist Salvador Dal\u00ed and cinema masters such as Luis Bu?uel, Alfred Hitchcock, and Walt Disney. Standing on the shoulders of these giants, this 4D project built on this collaborative tradition between surreal arts and cinematic arts by adding digital arts into this fusion of cinematic surrealism. Through the use of latest VR digital technology, this project expanded the cinematic experience from the 2D screen into a 3D environment with interactivity (3?+?1D) and invited users to be \u201cactive creative dreamers\u201d in a virtual dream designed in the style of Salvador Dal\u00ed with reference to the works of Ren\u00e9 Magritte?\u2026", "IdName": "yip2020cinematic", "Citation": "", "Keywords": ""}, {"Name": "Crossing of the Dream Fantasy: AI Technique Application for Visualizing a Fictional Character's Dream", "Authors": ["Jiayang Huang", "Yiran Chen", "David Yip"], "Sources": "2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This research explores the creative potential of artificial intelligence (AI) technology in artistic practice by testing various AI tools for their usability and capability as mediums of artistic expression. The project focuses on visualizing a dream of Mulan, a classic Chinese female figure, using the predictable features of AI generative models, with the aim of exploring whether such methods can produce amazing results. The project employs a collaborative process that combines different AI platforms to generate a range of materials, which are then with subjectively integrated into Mulan's fantasy dreamscape. The main conclusion drawn from the project is that artists guide abstract concepts and provide micro-interference, while AI produces concrete components and variations. The findings suggest that AI tools have the potential to transform artistic creation modes, and collaborative art creation can result in unique and?\u2026", "IdName": "huang2023crossing", "Citation": "", "Keywords": ""}, {"Name": "Between Passive Viewing and Active Choosing in Storytelling", "Authors": ["David Kei-Man Yip"], "Sources": "Human Factors in Communication of Design 49", "PublishedYears": "2022", "Doi": "", "Abstracts": "Since the dawn of the Internet, abundance of content and information is constantly being created and shared at the speed of light across different media. Media technologies have given us almost unlimited access to choose and interact with vast amount of content and information. We seem to be in active control in choosing what information we want to see and interact with on the internet. Ironically, with all this interactive freedom, most of us still prefer to watch their favorite TV programs or films passively on interactive media platforms. New technologies such as streaming TV have provided many new platforms to present passive content but to what extent how these new technologies have affected the form and shape of content remains a question. Simply by looking at the ratio of programs for traditional passive viewing vs. programs with interactive content, the audience has spoken by choosing to watch conventional content passively. Interacting with content is more than just choosing what pre-made content to watch, for that we always have our remote control. Interacting with content is about having our own say or control about the outcome or direction of a story (Crawford, 2013; Roth, 2015). Unlike what many media theories have predicted many years ago, interactive narrative has not become mainstream and would never replace conventional form of storytelling. Nevertheless, as more content is being delivered on mobile or personal computer in addition to the big screen, more interactive content will be made available in the foreseeable future. Many popular 4As video games have already mixed conventional storytelling elements with some?\u2026", "IdName": "yip2022between", "Citation": "", "Keywords": ""}, {"Name": "Is It the End? Guidelines for Cinematic Endings in Data Videos", "Authors": ["Xian Xu", "Aoyu Wu", "Leni Yang", "Zheng Wei", "Rong Huang", "David Yip", "Huamin Qu"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Data videos are becoming increasingly popular in society and academia. Yet little is known about how to create endings that strengthen a lasting impression and persuasion. To fulfill the gap, this work aims to develop guidelines for data video endings by drawing inspiration from cinematic arts. To contextualize cinematic endings in data videos, 111 film endings and 105 data video endings are first analyzed to identify four common styles using the framework of ending punctuation marks. ?We conducted expert interviews (N=11) and formulated 20 guidelines for creating cinematic endings in data videos. To validate our guidelines, we conducted a user study where 24 participants were invited to design endings with and without our guidelines, which are evaluated by experts and the general public. The participants praise the clarity and usability of the guidelines, and results show that the endings with guidelines are?\u2026", "IdName": "xu2023end", "Citation": "", "Keywords": ""}, {"Name": "Disruptive Innovations in Cinematic Storytelling from 2D to 3D", "Authors": ["David Kei-Man Yip"], "Sources": "Human Factors in Communication of Design 49", "PublishedYears": "2022", "Doi": "", "Abstracts": "Long before the digital revolution, communication theorist Marshall McLuhan has taught us about how the different forms of media can shape content with his famous book Medium is the Message (McLuhan et al. 1967). Over the past several decades, the theory has certainly stood the test of time. New media technologies have advanced so rapidly that many news form of content creation and expression have been made possible. New tools have offered new and diverse forms of storytelling. Nevertheless, new ways can never completely replace old ways; they just evolve and build upon the conventional practices. Do some of the new digital tools simply offer new way of doing the old thing with better technology or are they completely change the old way entirely? This paper aims to examine these issues from a historical perspective on a few past innovation disruptions that sent destructive shockwave to how things were in the beginning but brought new heights in the long run. This paper discusses historical and ongoing examples of innovation disruptions in cinematic storytelling in hopes of shedding light on the dynamic relation between art and technology. How have innovation disruptions changed the form and content of cinematic storytelling from 2D to 3D?", "IdName": "yip2022disruptive", "Citation": "", "Keywords": ""}, {"Name": "Painterly Reality: Enhancing Audience Experience with Paintings through Interactive Art", "Authors": ["Aven Le Zhou", "Kang Zhang", "David Yip"], "Sources": "arXiv preprint arXiv:2312.01067", "PublishedYears": "2023", "Doi": "", "Abstracts": "Perceiving paintings entails more than merely engaging the audience's eyes and brains; their perceptions and experiences of a painting can be intricately connected with body movement. This paper proposes an interactive art approach entitled \"Painterly Reality\" that facilitates the perception and interaction with paintings in a three-dimensional manner. Its objective is to promote bodily engagement with the painting (i.e., embedded body embodiment and its movement and interaction) to enhance the audience's experience, while maintaining its essence. Unlike two-dimensional interactions, this approach constructs the Painterly Reality by capturing the audience's body embodiment in real-time and embedding into a three-dimensional painterly world derived from a given painting input. Through their body embodiment, the audience can navigate the painterly world and play with the magical realism (i.e., interactive painterly objects), fostering meaningful experiences via interactions. The Painterly Reality is subsequently projected through an Augmented Reality Mirror as a live painting and displayed in front of the audience. Hence, the audience can gain enhanced experiences through bodily engagement while simultaneously viewing and appreciating the live painting. The paper implements the proposed approach as an interactive artwork, entitled \"Everyday Conjunctive,\" with Fong Tse Ka's painting and installs in a local museum, which successfully enhances audience experience through bodily engagement.", "IdName": "zhou2023painterly", "Citation": "", "Keywords": ""}, {"Name": "Dreaming Phantom in Immersive Experience: AIGC For Artistic Practice", "Authors": ["Jiayang Huang", "Yiran Chen", "David Yip"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Artificial Intelligent Generation Content (AIGC), has been widely disseminated in the fields of technology, academia, and the arts. This project explores the application of various AI tools and the visualization of dream experiences through multimedia. It utilizes AI-generated multimodal materials as perceptible dream content, employs light and mechanical installations to create immersive dream atmospheres, and employs a fictional AI-Mulan narrator to recount her dream story. Through artistic practice, it delves into Mulan's unconscious realm and conducts a psychoanalysis of a historical figure. It represents an interdisciplinary exploration of art and psychoanalysis through AI visualization.", "IdName": "huang2023dreaming", "Citation": "", "Keywords": ""}, {"Name": "Simonstown: An AI-facilitated Interactive Story of Love, Life, and Pandemic", "Authors": ["Bingyuan Wang", "Pinxi Zhu", "Hao Li", "David Kei-man Yip", "Zeyu Wang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We present an interactive story named Simonstown that demonstrates the love and life of ordinary people in the fictional setting of a fatal pandemic. Technically, the artwork integrates different Artificial Intelligence (AI) technologies in the whole production pipeline, including concept formation, creation, and presentation stages; artistically, this interactive film explores the relationship between human and environment in the contemporary context, especially infused with advanced technologies in daily life. The project serves as a demonstration and case study of AI-facilitated interactive storytelling, including better control with AI and how they integrate with live image projects, as well as using the stand-alone camera for real-time synchronization. Our results highlight the significant contribution of AI in visualizing intricate story branching, translation, and adaptation, presenting AI visualization as a distinct, specialized?\u2026", "IdName": "wang2023simonstown", "Citation": "", "Keywords": ""}, {"Name": "AI-Generated Content for Academic Visualization and Communication in Maker Education", "Authors": ["Qingqing Xing", "Chenghong Zheng", "Nan Zhu", "David Yip"], "Sources": "2023 3rd International Conference on Educational Technology (ICET)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Collaborative learning in higher education, such as the emerging makerspaces, has contributed to research on innovation and participant expertise. However, there is little research on knowledge management in makerspaces or how learners transfer their individual tacit knowledge in the collaborative space. In addition, the functionality of maker education to promote individualized and personalized learning still needs to be explored. This study is based on Chinese STEM graduate students\u2019 experiences with project-based learning in a Maker Education environment to test how AIGC tools help to acquire and transfer students\u2019 individual tacit knowledge. The sample was formed from 266 MPhil students taking the \"Design Thinking and Effective Academic Communication\" course in their first academic year at the world\u2019s first interdisciplinary university in southern China. The AIGC teaching intervention was based on?\u2026", "IdName": "xing2023ai", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Intersection of AI Art and Film: A Case Study of Giant", "Authors": ["Junrong Song", "David Yip"], "Sources": "2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Artificial intelligence (AI) has recently been used as a tool for various visual storytelling, but text-to-image models are a stochastic machine learning process that requires human intervention to assist creation better. As we all know, pre-visualization is an important stage in film production, involving subjective choices by the creators. This paper investigates how AI can assist filmmakers during the pre-production stage by generating mood boards from text. We propose a novel preproduction pipeline and guidelines that leverage text-to-image models to create visual previews of film projects. We also conduct a case study to validate and evaluate our approach's effectiveness. Our case study suggests that following the guidelines we have developed can assist filmmakers in generating mood boards that effectively convey the desired atmosphere of their projects and potentially contribute to enhancing the creative process?\u2026", "IdName": "song2023exploring", "Citation": "", "Keywords": ""}, {"Name": "XR is more than the sum of AR, VR, and MR", "Authors": ["David Yip"], "Sources": "Human Factors in Communication of Design", "PublishedYears": "2023", "Doi": "", "Abstracts": "Extended reality XR as the latest reality enhancement technology is regarded by many as the sum of augmented reality AR, virtual reality VR and mixed reality MR. However, this article argues otherwise. This article discusses the misconceptions of LED-based XR as the sum of AR, VR and MR. Although MR is still the combined form of AR and VR, their focuses are different from the LED-based XR. While the common features of AR, VR and MR mostly focus on the different treatments of environment as reality, their limitations lay on their inability to integrate real-time high resolution video of human figures. VR is also limited by computing power. More advanced motion and other sensory capture devices are not inaccessible to regular VR consumers. VR users can only see real-time characters or avatars in low polygon resolution. While MR is still the sum of AR and VR by combining virtual reality with the physical world?\u2026", "IdName": "yip2023xr", "Citation": "", "Keywords": ""}, {"Name": "The Dark Art of Transmedia Storytelling", "Authors": ["David Kei-man Yip"], "Sources": "Advances in Creativity", "PublishedYears": "2021", "Doi": "", "Abstracts": " As one of the major art movements, German Expressionism of composing unbalanced images of high contrast geometric line and shape can often be seen as a distinct visual style in cinema, animation and video game. This article focuses on this particular visual style highly influenced by German Expressionism and has a rather dark tone in form and content. The visual style of Film Noir has occupied a very important part of cinema history from the 40?s that tell sinister crime and mystery stories. Film Noir is also called Dark Cinema. This article discusses that Film Noir or its revived form Neo Noir as more than just a film and game genre. It is a visual linkage of digital content across media. As a visual narrative media, cinema has influenced many works of visual and time-based media in animation and game, which in turn also influence cinema. The worlds of Neo Noir created by computer animation and game?\u2026", "IdName": "yip2021dark", "Citation": "", "Keywords": ""}, {"Name": "Creative Base Design: A New Form of Self-Expression in Competitive Games", "Authors": ["David Kei-man Yip"], "Sources": "New Media Spectacles and Multimodal Creativity in a Globalised Asia: Art?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": " As part of everyday life, mobile phones allow gamers to play online games wherever and whenever they wish. Since the first generation of smartphones, many of the most popular applications have been mobile games, with base defence games among the favourites, particularly with the implementation of real-time Player vs. Player (PvP) features. To protect their bases, gamers must not only strategically place their defence weapons in the base to guard against unpredictable attack and looting, but also launch attacks to loot others\u2019 bases for upgrades. Each base houses necessities collected from lootings and upgrades, and also provides a personal space for the individual gamer\u2019s creative expression and visual statement. Although strategic base creation is part of the core gameplay, the creative design of the base is not. Between 2013 and 2018, the game Clash of Clans (COC) has inspired many creative?\u2026", "IdName": "yip2020creative", "Citation": "", "Keywords": ""}, {"Name": "A survey on ML4VIS: Applying machine learning advances to data visualization", "Authors": ["Qianwen Wang", "Zhutian Chen", "Yong Wang", "Huamin Qu"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Inspired by the great success of machine learning (ML), researchers have applied ML techniques to visualizations to achieve a better design, development, and evaluation of visualizations. This branch of studies, known as ML4VIS, is gaining increasing research attention in recent years. To successfully adapt ML techniques for visualizations, a structured understanding of the integration of ML4VIS is needed. In this article, we systematically survey 88 ML4VIS studies, aiming to answer two motivating questions:  \u201cwhat visualization processes can be assisted by ML?\u201d  and  \u201chow ML techniques can be used to solve visualization problems? \u201d This survey reveals seven main processes where the employment of ML techniques can benefit visualizations:  Data Processing4VIS, Data-VIS Mapping, Insight Communication, Style Imitation, VIS Interaction, VIS Reading, and User Profiling . The seven processes are related to?\u2026", "IdName": "wang2021survey", "Citation": "", "Keywords": ""}, {"Name": "Ai4vis: Survey on artificial intelligence approaches for data visualization", "Authors": ["Aoyu Wu", "Yun Wang", "Xinhuan Shu", "Dominik Moritz", "Weiwei Cui", "Haidong Zhang", "Dongmei Zhang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Visualizations themselves have become a data format. Akin to other data formats such as text and images, visualizations are increasingly created, stored, shared, and (re-)used with artificial intelligence (AI) techniques. In this survey, we probe the underlying vision of formalizing visualizations as an emerging data format and review the recent advance in applying AI techniques to visualization data (AI4VIS). We define visualization data as the digital representations of visualizations in computers and focus on data visualization (e.g., charts and infographics). We build our survey upon a corpus spanning ten different fields in computer science with an eye toward identifying important common interests. Our resulting taxonomy is organized around WHAT is visualization data and its representation, WHY and HOW to apply AI to visualization data. We highlight a set of common tasks that researchers apply to the?\u2026", "IdName": "wu2021ai4vis", "Citation": "", "Keywords": ""}, {"Name": "Dece: Decision explorer with counterfactual explanations for machine learning models", "Authors": ["Furui Cheng", "Yao Ming", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable-a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports?\u2026", "IdName": "cheng2020dece", "Citation": "", "Keywords": ""}, {"Name": "KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation", "Authors": ["Haotian Li", "Yong Wang", "Songheng Zhang", "Yangqiu Song", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data?\u2026", "IdName": "li2021kg4vis", "Citation": "", "Keywords": ""}, {"Name": "EmotionCues: Emotion-Oriented Visual Summarization of Classroom Videos", "Authors": ["Haipeng Zeng", "Xinhuan Shu", "Yanbang Wang", "Yong Wang", "Liguo Zhang", "Ting-Chuen Pong", "Huamin Qu"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Analyzing students\u2019 emotions from classroom videos can help both teachers and parents quickly know the engagement of students in class. The availability of high-definition cameras creates opportunities to record class scenes. However, watching videos is time-consuming, and it is challenging to gain a quick overview of the emotion distribution and find abnormal emotions. In this article, we propose  EmotionCues , a visual analytics system to easily analyze classroom videos from the perspective of emotion summary and detailed analysis, which integrates emotion recognition algorithms with visualizations. It consists of three coordinated views: a summary view depicting the overall emotions and their dynamic evolution, a character view presenting the detailed emotion status of an individual, and a video view enhancing the video analysis with further details. Considering the possible inaccuracy of emotion?\u2026", "IdName": "zeng2020emotioncues", "Citation": "", "Keywords": ""}, {"Name": "M2lens: Visualizing and explaining multimodal models for sentiment analysis", "Authors": ["Xingbo Wang", "Jianben He", "Zhihua Jin", "Muqiao Yang", "Yong Wang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Multimodal sentiment analysis aims to recognize people's attitudes from multiple communication channels such as verbal content (i.e., text), voice, and facial expressions. It has become a vibrant and important research topic in natural language processing. Much research focuses on modeling the complex intra- and inter-modal interactions between different communication channels. However, current multimodal models with strong performance are often deep-learning-based techniques and work like black boxes. It is not clear how models utilize multimodal information for sentiment predictions. Despite recent advances in techniques for enhancing the explainability of machine learning models, they often target unimodal scenarios (e.g., images, sentences), and little research has been done on explaining multimodal models. In this paper, we present an interactive visual analytics system, M2 Lens, to visualize and?\u2026", "IdName": "wang2021m2lens", "Citation": "", "Keywords": ""}, {"Name": "A visual analytics approach to facilitate the proctoring of online exams", "Authors": ["Haotian Li", "Min Xu", "Yong Wang", "Huan Wei", "Huamin Qu"], "Sources": "Proceedings of the 2021 CHI conference on human factors in computing systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " Online exams have become widely used to evaluate students\u2019 performance in mastering knowledge in recent years, especially during the pandemic of COVID-19. However, it is challenging to conduct proctoring for online exams due to the lack of face-to-face interaction. Also, prior research has shown that online exams are more vulnerable to various cheating behaviors, which can damage their credibility. This paper presents a novel visual analytics approach to facilitate the proctoring of online exams by analyzing the exam video records and mouse movement data of each student. Specifically, we detect and visualize suspected head and mouse movements of students in three levels of detail, which provides course instructors and teachers with convenient, efficient and reliable proctoring for online exams. Our extensive evaluations, including usage scenarios, a carefully-designed user study and expert interviews?\u2026", "IdName": "li2021visual", "Citation": "", "Keywords": ""}, {"Name": "Augmenting static visualizations with paparvis designer", "Authors": ["Zhutian Chen", "Wai Tong", "Qianwen Wang", "Benjamin Bach", "Huamin Qu"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper presents an authoring environment for augmenting static visualizations with virtual content in augmented reality.Augmenting static visualizations can leverage the best of both physical and digital worlds, but its creation currently involves different tools and devices, without any means to explicitly design and debug both static and virtual content simultaneously. To address these issues, we design an environment that seamlessly integrates all steps of a design and deployment workflow through its main features: i) an extension to Vega, ii) a preview, and iii) debug hints that facilitate valid combinations of static and augmented content. We inform our design through a design space with four ways to augment static visualizations. We demonstrate the expressiveness of our tool through examples, including books, posters, projections, wall-sized visualizations. A user study shows high user satisfaction of our?\u2026", "IdName": "chen2020augmenting", "Citation": "", "Keywords": ""}, {"Name": "Augmenting sports videos with viscommentator", "Authors": ["Zhutian Chen", "Shuainan Ye", "Xiangtong Chu", "Haijun Xia", "Hui Zhang", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level  (what the constituents are)  and clip-level  (how those constituents are organized) . We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis?\u2026", "IdName": "chen2021augmenting", "Citation": "", "Keywords": ""}, {"Name": "What makes a data-GIF understandable?", "Authors": ["Xinhuan Shu", "Aoyu Wu", "Junxiu Tang", "Benjamin Bach", "Yingcai Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "GIFs are enjoying increasing popularity on social media as a format for data-driven storytelling with visualization; simple visual messages are embedded in short animations that usually last less than 15 seconds and are played in automatic repetition. In this paper, we ask the question, \u201cWhat makes a data-GIF understandable?\u201d While other storytelling formats such as data videos, infographics, or data comics are relatively well studied, we have little knowledge about the design factors and principles for \u201cdata-GIFs\u201d. To close this gap, we provide results from semi-structured interviews and an online study with a total of 118 participants investigating the impact of design decisions on the understandability of data-GIFs. The study and our consequent analysis are informed by a systematic review and structured design space of 108 data-GIFs that we found online. Our results show the impact of design dimensions from our?\u2026", "IdName": "shu2020makes", "Citation": "", "Keywords": ""}, {"Name": "PRAISE-HK: A personalized real-time air quality informatics system for citizen participation in exposure and health risk management", "Authors": ["Wenwei Che", "H Christopher Frey", "Jimmy CH Fung", "Zhi Ning", "Huamin Qu", "Hong Kam Lo", "Lei Chen", "Tze-Wai Wong", "Michelle KM Wong", "Ophelia CW Lee", "David Carruthers", "Freeman Cheung", "Jimmy WM Chan", "David W Yeung", "Yik Him Fung", "Xuguo Zhang", "Jenny Stocker", "Christina Hood", "Tilman Leo Hohenberger", "King Wai Leung", "Phillip YK Louie", "Alison TY Li", "Li Sun", "Peng Wei", "Zhiyuan Li", "Yumiao Zhang", "Meilan Wang", "Qiaomu Shen", "Wei Huang", "Enoch Lee", "Ashraf Patwary", "Xiayu Lei", "Steven Cheng", "Md Shakhaoat Hossain", "Kimberly Tasha Jiayi Tang", "XiangQian Lao", "Rae Leung", "Denise Chan", "Ying Li", "Zibing Yuan", "Alexis KH Lau"], "Sources": "Sustainable Cities and Society 54", "PublishedYears": "2020", "Doi": "", "Abstracts": "Exposure to air pollutants causes a range of adverse health effects. These harmful effects occur whenever and wherever people come into direct contact with air pollution. Therefore, individual actions that reduce the frequency, duration, and severity of personal contact with air pollution can reduce health risks. We developed a system that empowers the public with personalized information on air quality and exposure health risk. This system, the Personalised Real-Time Air Quality Informatics System for Exposure \u2013 Hong Kong (PRAISE-HK, http://praise.ust.hk/), is embodied in an interactive mobile application. PRAISE-HK is based on real-time data on emissions, high resolution urban morphology, meteorology, physical and chemical processes affecting pollutant transport and transformations, extensive measurements of air pollution concentrations in typical locations such as homes, schools, offices, and?\u2026", "IdName": "che2020praise", "Citation": "", "Keywords": ""}, {"Name": "Visual analysis of discrimination in machine learning", "Authors": ["Qianwen Wang", "Zhenhua Xu", "Zhutian Chen", "Yong Wang", "Shixia Liu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in?\u2026", "IdName": "wang2020visual", "Citation": "", "Keywords": ""}, {"Name": "MultiVision: Designing analytical dashboards with deep learning based recommendation", "Authors": ["Aoyu Wu", "Yun Wang", "Mengyu Zhou", "Xinyi He", "Haidong Zhang", "Huamin Qu", "Dongmei Zhang"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model?\u2026", "IdName": "wu2021multivision", "Citation": "", "Keywords": ""}, {"Name": "A design space for applying the freytag's pyramid structure to data stories", "Authors": ["Leni Yang", "Xian Xu", "XingYu Lan", "Ziyan Liu", "Shunan Guo", "Yang Shi", "Huamin Qu", "Nan Cao"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Data stories integrate compelling visual content to communicate data insights in the form of narratives. The narrative structure of a data story serves as the backbone that determines its expressiveness, and it can largely influence how audiences perceive the insights. Freytag's Pyramid is a classic narrative structure that has been widely used in film and literature. While there are continuous recommendations and discussions about applying Freytag's Pyramid to data stories, little systematic and practical guidance is available on how to use Freytag's Pyramid for creating structured data stories. To bridge this gap, we examined how existing practices apply Freytag's Pyramid by analyzing stories extracted from 103 data videos. Based on our findings, we proposed a design space of narrative patterns, data flows, and visual communications to provide practical guidance on achieving narrative intents, organizing data facts?\u2026", "IdName": "yang2021design", "Citation": "", "Keywords": ""}, {"Name": "Mobilevisfixer: Tailoring web visualizations for mobile phones leveraging an explainable reinforcement learning framework", "Authors": ["Aoyu Wu", "Wai Tong", "Tim Dwyer", "Bongshin Lee", "Petra Isenberg", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view?\u2026", "IdName": "wu2020mobilevisfixer", "Citation": "", "Keywords": ""}, {"Name": "Infocolorizer: Interactive recommendation of color palettes for infographics", "Authors": ["Lin-Ping Yuan", "Ziqi Zhou", "Jian Zhao", "Yiqiu Guo", "Fan Du", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "When designing infographics, general users usually struggle with getting desired color palettes using existing infographic authoring tools, which sometimes sacrifice customizability, require design expertise, or neglect the influence of elements\u2019 spatial arrangement. We propose a data-driven method that provides flexibility by considering users\u2019 preferences, lowers the expertise barrier via automation, and tailors suggested palettes to the spatial layout of elements. We build a recommendation engine by utilizing deep learning techniques to characterize good color design practices from data, and further develop InfoColorizer, a tool that allows users to obtain color palettes for their infographics in an interactive and dynamic manner. To validate our method, we conducted a comprehensive four-part evaluation, including case studies, a controlled user study, a survey study, and an interview study. The results indicate that?\u2026", "IdName": "yuan2021infocolorizer", "Citation": "", "Keywords": ""}, {"Name": "Development of a back-propagation neural network and adaptive grey wolf optimizer algorithm for thermal comfort and energy consumption prediction and optimization", "Authors": ["Lu Li", "Yunfei Fu", "Jimmy CH Fung", "Huamin Qu", "Alexis KH Lau"], "Sources": "Energy and Buildings 253", "PublishedYears": "2021", "Doi": "", "Abstracts": "Heating ventilation and air conditioning (HVAC) systems provide a comfortable indoor thermal environment, but in the process of attaining appropriate indoor thermal comfort levels, they usually entail high energy consumptions. It is therefore imperative to balance thermal comfort value with energy consumption. However, such research currently faces two problems: one, it is difficult to obtain accurate parameters pertaining to the indoor environment of buildings, particularly near heat source areas; two, it is the diametrical nature of having to simultaneously maintain thermal comfort and keep energy consumption low. Therefore, this study aims to propose a rapid thermal comfort level prediction and optimization algorithm, as well as a method to minimize the energy consumption using only a computational fluid dynamic (CFD) database that is compact in size. Firstly, CFD is used to implement the database that stores?\u2026", "IdName": "li2021development", "Citation": "", "Keywords": ""}, {"Name": "A coupled computational fluid dynamics and back-propagation neural network-based particle swarm optimizer algorithm for predicting and optimizing indoor air quality", "Authors": ["Lu Li", "Yumiao Zhang", "Jimmy CH Fung", "Huamin Qu", "Alexis KH Lau"], "Sources": "Building and Environment 207", "PublishedYears": "2022", "Doi": "", "Abstracts": "In the modern era, people spend approximately 90% of their time in indoor settings, such as offices and residential buildings. As prolonged exposure to indoor environments can significantly impact health outcomes, it is important to ensure that good indoor air quality (IAQ) is achieved. The main obstacles to achieving effective control of IAQ are twofold. First, it is very difficult to monitor the values of IAQ parameters, especially within a person's breathing zone. Second, current heating ventilation and air conditioning systems are unable to rapidly predict and optimize IAQ. This study aims to obtain accurate indoor environmental parameters for rapidly predicting and optimizing IAQ. To achieve this, a computational fluid dynamics (CFD)-based back propagation neural network (BPNN) combined with a particle swarm optimizer (PSO) algorithm is proposed. Notably, the BPNN-PSO algorithm can rapidly predict and?\u2026", "IdName": "li2022coupled", "Citation": "", "Keywords": ""}, {"Name": "Vbridge: Connecting the dots between features and data to explain healthcare models", "Authors": ["Furui Cheng", "Dongyu Liu", "Fan Du", "Yanna Lin", "Alexandra Zytek", "Haomin Li", "Huamin Qu", "Kalyan Veeramachaneni"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Machine learning (ML) is increasingly applied to Electronic Health Records (EHRs) to solve clinical prediction tasks. Although many ML models perform promisingly, issues with model transparency and interpretability limit their adoption in clinical practice. Directly using existing explainable ML techniques in clinical settings can be challenging. Through literature surveys and collaborations with six clinicians with an average of 17 years of clinical experience, we identified three key challenges, including clinicians' unfamiliarity with ML features, lack of contextual information, and the need for cohort-level evidence. Following an iterative design process, we further designed and developed VBridge, a visual analytics tool that seamlessly incorporates ML explanations into clinicians' decision-making workflow. The system includes a novel hierarchical display of contribution-based feature explanations and enriched?\u2026", "IdName": "cheng2021vbridge", "Citation": "", "Keywords": ""}, {"Name": "Topology density map for urban data visualization and analysis", "Authors": ["Zezheng Feng", "Haotian Li", "Wei Zeng", "Shuang-Hua Yang", "Huamin Qu"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Density map is an effective visualization technique for depicting the scalar field distribution in 2D space. Conventional methods for constructing density maps are mainly based on Euclidean distance, limiting their applicability in urban analysis that shall consider road network and urban traffic. In this work, we propose a new method named Topology Density Map, targeting for accurate and intuitive density maps in the context of urban environment. Based on the various constraints of road connections and traffic conditions, the method first constructs a directed acyclic graph (DAG) that propagates nonlinear scalar fields along 1D road networks. Next, the method extends the scalar fields to a 2D space by identifying key intersecting points in the DAG and calculating the scalar fields for every point, yielding a weighted Voronoi diagram like effect of space division. Two case studies demonstrate that the Topology Density?\u2026", "IdName": "feng2020topology", "Citation": "", "Keywords": ""}, {"Name": "Predicting student performance in interactive online question pools using mouse interaction features", "Authors": ["Huan Wei", "Haotian Li", "Meng Xia", "Yong Wang", "Huamin Qu"], "Sources": "Proceedings of the tenth international conference on learning analytics?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Modeling student learning and further predicting the performance is a well-established task in online learning and is crucial to personalized education by recommending different learning resources to different students based on their needs. Interactive online question pools (e.g., educational game platforms), an important component of online education, have become increasingly popular in recent years. However, most existing work on student performance prediction targets at online learning platforms with a well-structured curriculum, predefined question order and accurate knowledge tags provided by domain experts. It remains unclear how to conduct student performance prediction in interactive online question pools without such well-organized question orders or knowledge tags by experts. In this paper, we propose a novel approach to boost student performance prediction in interactive online question pools?\u2026", "IdName": "wei2020predicting", "Citation": "", "Keywords": ""}, {"Name": "Gnnlens: A visual analytics approach for prediction error diagnosis of graph neural networks", "Authors": ["Zhihua Jin", "Yong Wang", "Qianwen Wang", "Yao Ming", "Tengfei Ma", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph data and have achieved significant progress in graph analysis tasks (e.g., node classification) in recent years. However, similar to other deep neural networks like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), GNNs behave like a black box with their details hidden from model developers and users. It is therefore difficult to diagnose possible errors of GNNs. Despite many visual analytics studies being done on CNNs and RNNs, little research has addressed the challenges for GNNs. This paper fills the research gap with an interactive visual analysis tool,  GNNLens , to assist model developers and users in understanding and analyzing GNNs. Specifically, Parallel Sets View and Projection View enable users to quickly identify and validate error patterns in the set of wrong predictions; Graph View and?\u2026", "IdName": "jin2022gnnlens", "Citation": "", "Keywords": ""}, {"Name": "Visual interpretation of recurrent neural network on multi-dimensional time-series forecast", "Authors": ["Qiaomu Shen", "Yanhong Wu", "Yuzhe Jiang", "Wei Zeng", "KH Alexis", "Anna Vianova", "Huamin Qu"], "Sources": "2020 IEEE Pacific visualization symposium (PacificVis)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent attempts at utilizing visual analytics to interpret Recurrent Neural Networks (RNNs) mainly focus on natural language processing (NLP) tasks that take symbolic sequences as input. However, many real-world problems like environment pollution forecasting apply RNNs on sequences of multi-dimensional data where each dimension represents an individual feature with semantic meaning such as PM 2.5  and SO 2 . RNN interpretation on multi-dimensional sequences is challenging as users need to analyze what features are important at different time steps to better understand model behavior and gain trust in prediction. This requires effective and scalable visualization methods to reveal the complex many-to-many relations between hidden units and features. In this work, we propose a visual analytics system to interpret RNNs on multi-dimensional time-series forecasts. Specifically, to provide an overview to?\u2026", "IdName": "shen2020visual", "Citation": "", "Keywords": ""}, {"Name": "Voicecoach: Interactive evidence-based training for voice modulation skills in public speaking", "Authors": ["Xingbo Wang", "Haipeng Zeng", "Yong Wang", "Aoyu Wu", "Zhida Sun", "Xiaojuan Ma", "Huamin Qu"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "The modulation of voice properties, such as pitch, volume, and speed, is crucial for delivering a successful public speech. However, it is challenging to master different voice modulation skills. Though many guidelines are available, they are often not practical enough to be applied in different public speaking situations, especially for novice speakers. We present VoiceCoach, an interactive evidence-based approach to facilitate the effective training of voice modulation skills. Specifically, we have analyzed the voice modulation skills from 2623 high-quality speeches (i.e., TED Talks) and use them as the benchmark dataset. Given a voice input, VoiceCoach automatically recommends good voice modulation examples from the dataset based on the similarity of both sentence structures and voice modulation skills. Immediate and quantitative visual feedback is provided to guide further improvement. The expert interviews?\u2026", "IdName": "wang2020voicecoach", "Citation": "", "Keywords": ""}, {"Name": "Misinformed by visualization: What do we learn from misinformative visualizations?", "Authors": ["Leo Yu\u2010Ho Lo", "Ayush Gupta", "Kento Shigyo", "Aoyu Wu", "Enrico Bertini", "Huamin Qu"], "Sources": "Computer Graphics Forum", "PublishedYears": "2022", "Doi": "", "Abstracts": " Data visualization is powerful in persuading an audience. However, when it is done poorly or maliciously, a visualization may become misleading or even deceiving. Visualizations give further strength to the dissemination of misinformation on the Internet. The visualization research community has long been aware of visualizations that misinform the audience, mostly associated with the terms \u201clie\u201d and \u201cdeceptive.\u201d Still, these discussions have focused only on a handful of cases. To better understand the landscape of misleading visualizations, we open\u2010coded over one thousand real\u2010world visualizations that have been reported as misleading. From these examples, we discovered 74 types of issues and formed a taxonomy of misleading elements in visualizations. We found four directions that the research community can follow to widen the discussion on misleading visualizations: (1) informal fallacies in?\u2026", "IdName": "lo2022misinformed", "Citation": "", "Keywords": ""}, {"Name": "Dashbot: Insight-driven dashboard generation based on deep reinforcement learning", "Authors": ["Dazhen Deng", "Aoyu Wu", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Analytical dashboards are popular in business intelligence to facilitate insight discovery with multiple charts. However, creating an effective dashboard is highly demanding, which requires users to have adequate data analysis background and be familiar with professional tools, such as Power BI. To create a dashboard, users have to configure charts by selecting data columns and exploring different chart combinations to optimize the communication of insights, which is trial-and-error. Recent research has started to use deep learning methods for dashboard generation to lower the burden of visualization creation. However, such efforts are greatly hindered by the lack of large-scale and high-quality datasets of dashboards. In this work, we propose using deep reinforcement learning to generate analytical dashboards that can use well-established visualization knowledge and the estimation capacity of reinforcement?\u2026", "IdName": "deng2022dashbot", "Citation": "", "Keywords": ""}, {"Name": "Interactive visual exploration of longitudinal historical career mobility data", "Authors": ["Yifang Wang", "Hongye Liang", "Xinhuan Shu", "Jiachen Wang", "Ke Xu", "Zikun Deng", "Cameron Campbell", "Bijia Chen", "Yingcai Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "The increased availability of quantitative historical datasets has provided new research opportunities for multiple disciplines in social science. In this article, we work closely with the constructors of a new dataset, CGED-Q (China Government Employee Database-Qing), that records the career trajectories of over 340,000 government officials in the Qing bureaucracy in China from 1760 to 1912. We use these data to study career mobility from a historical perspective and understand social mobility and inequality. However, existing statistical approaches are inadequate for analyzing career mobility in this historical dataset with its fine-grained attributes and long time span, since they are mostly hypothesis-driven and require substantial effort. We propose  CareerLens , an interactive visual analytics system for assisting experts in exploring, understanding, and reasoning from historical career data. With  CareerLens?\u2026", "IdName": "wang2021interactive", "Citation": "", "Keywords": ""}, {"Name": "Peer-inspired student performance prediction in interactive online question pools with graph neural network", "Authors": ["Haotian Li", "Huan Wei", "Yong Wang", "Yangqiu Song", "Huamin Qu"], "Sources": "Proceedings of the 29th ACM International Conference on Information?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Student performance prediction is critical to online education. It can benefit many downstream tasks on online learning platforms, such as estimating dropout rates, facilitating strategic intervention, and enabling adaptive online learning. Interactive online question pools provide students with interesting interactive questions to practice their knowledge in online education. However, little research has been done on student performance prediction in interactive online question pools. Existing work on student performance prediction targets at online learning platforms with predefined course curriculum and accurate knowledge labels like MOOC platforms, but they are not able to fully model knowledge evolution of students in interactive online question pools. In this paper, we propose a novel approach using Graph Neural Networks (GNNs) to achieve better student performance prediction in interactive online question?\u2026", "IdName": "li2020peer", "Citation": "", "Keywords": ""}, {"Name": "Dfseer: A visual analytics approach to facilitate model selection for demand forecasting", "Authors": ["Dong Sun", "Zezheng Feng", "Yuanzhe Chen", "Yong Wang", "Jia Zeng", "Mingxuan Yuan", "Ting-Chuen Pong", "Huamin Qu"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Selecting an appropriate model to forecast product demand is critical to the manufacturing industry. However, due to the data complexity, market uncertainty and users' demanding requirements for the model, it is challenging for demand analysts to select a proper model. Although existing model selection methods can reduce the manual burden to some extent, they often fail to present model performance details on individual products and reveal the potential risk of the selected model. This paper presents DFSeer, an interactive visualization system to conduct reliable model selection for demand forecasting based on the products with similar historical demand. It supports model comparison and selection with different levels of details. Besides, it shows the difference in model performance on similar products to reveal the risk of model selection and increase users' confidence in choosing a forecasting model. Two case?\u2026", "IdName": "sun2020dfseer", "Citation": "", "Keywords": ""}, {"Name": "Learning to automate chart layout configurations using crowdsourced paired comparison", "Authors": ["Aoyu Wu", "Liwenhan Xie", "Bongshin Lee", "Yun Wang", "Weiwei Cui", "Huamin Qu"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " We contribute a method to automate parameter configurations for chart layouts by learning from human preferences. Existing charting tools usually determine the layout parameters using predefined heuristics, producing sub-optimal layouts. People can repeatedly adjust multiple parameters (e.g., chart size, gap) to achieve visually appealing layouts. However, this trial-and-error process is unsystematic and time-consuming, without a guarantee of improvement. To address this issue, we develop Layout Quality Quantifier (LQ2), a machine learning model that learns to score chart layouts from paired crowdsourcing data. Combined with optimization techniques, LQ2 recommends layout parameters that improve the charts\u2019 layout quality. We apply LQ2 on bar charts and conduct user studies to evaluate its effectiveness by examining the quality of layouts it produces. Results show that LQ2 can generate more visually?\u2026", "IdName": "wu2021learning", "Citation": "", "Keywords": ""}, {"Name": "Survey on artificial intelligence approaches for visualization data", "Authors": ["Aoyu Wu", "Yun Wang", "Xinhuan Shu", "Dominik Moritz", "Weiwei Cui", "Haidong Zhang", "Dongmei Zhang", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2102.01330 2", "PublishedYears": "2021", "Doi": "", "Abstracts": "", "IdName": "wu2021survey", "Citation": "", "Keywords": ""}, {"Name": "TaxThemis: Interactive Mining and Exploration of Suspicious Tax Evasion Groups", "Authors": ["Yating Lin", "Kamkwai Wong", "Yong Wang", "Rong Zhang", "Bo Dong", "Huamin Qu", "Qinghua Zheng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Tax evasion is a serious economic problem for many countries, as it can undermine the government's tax system and lead to an unfair business competition environment. Recent research has applied data analytics techniques to analyze and detect tax evasion behaviors of individual taxpayers. However, they have failed to support the analysis and exploration of the related party transaction tax evasion (RPTTE) behaviors (e.g., transfer pricing), where a group of taxpayers is involved. In this paper, we present TaxThemis, an interactive visual analytics system to help tax officers mine and explore suspicious tax evasion groups through analyzing heterogeneous tax-related data. A taxpayer network is constructed and fused with the respective trade network to detect suspicious RPTTE groups. Rich visualizations are designed to facilitate the exploration and investigation of suspicious transactions between related?\u2026", "IdName": "lin2020taxthemis", "Citation": "", "Keywords": ""}, {"Name": "Using information visualization to promote students' reflection on\" gaming the system\" in online learning", "Authors": ["Meng Xia", "Yuya Asano", "Joseph Jay Williams", "Huamin Qu", "Xiaojuan Ma"], "Sources": "Proceedings of the seventh ACM conference on Learning@ Scale", "PublishedYears": "2020", "Doi": "", "Abstracts": "\"Gaming the system\" is the phenomenon where students attempt to perform well by systematically exploiting properties of the learning system, rather than learning the material. Frequent gaming tends to cause bad learning outcomes. Though existing studies tackle the problem by redesigning the system workflow to change students' behaviors automatically, gaming students discover new ways to game. We instead propose a novel way, reflective nudge, to reflectively influence students' attitudes by conveying reasons not to game via information visualizations. Particularly, we identify three common gaming contexts and involve students and instructors in co-designing three context-specific persuasive visualizations. We deploy our information visualizations in a real online learning platform. Through embedded surveys and in-person interviews, we find some evidence that the designs can promote students' reflection?\u2026", "IdName": "xia2020using", "Citation": "", "Keywords": ""}, {"Name": "Xnli: Explaining and diagnosing nli-based visual data analysis", "Authors": ["Yingchaojie Feng", "Xingbo Wang", "Bo Pan", "Kam Kwai Wong", "Yi Ren", "Shi Liu", "Zihan Yan", "Yuxin Ma", "Huamin Qu", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Natural language interfaces (NLIs) enable users to flexibly specify analytical intentions in data visualization. However, diagnosing the visualization results without understanding the underlying generation process is challenging. Our research explores how to provide explanations for NLIs to help users locate the problems and further revise the queries. We present XNLI, an explainable NLI system for visual data analysis. The system introduces a Provenance Generator to reveal the detailed process of visual transformations, a suite of interactive widgets to support error adjustments, and a Hint Generator to provide query revision hints based on the analysis of user queries and interactions. Two usage scenarios of XNLI and a user study verify the effectiveness and usability of the system. Results suggest that XNLI can significantly enhance task accuracy without interrupting the NLI-based analysis process.", "IdName": "feng2023xnli", "Citation": "", "Keywords": ""}, {"Name": "Structure-aware visualization retrieval", "Authors": ["Haotian Li", "Yong Wang", "Aoyu Wu", "Huan Wei", "Huamin Qu"], "Sources": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " With the wide usage of data visualizations, a huge number of Scalable Vector Graphic?(SVG)-based visualizations have been created and shared online. Accordingly, there has been an increasing interest in exploring how to retrieve perceptually similar visualizations from a large corpus, since it can benefit various downstream applications such as visualization recommendation. Existing methods mainly focus on the visual appearance of visualizations by regarding them as bitmap images. However, the structural information intrinsically existing in SVG-based visualizations is ignored. Such structural information can delineate the spatial and hierarchical relationship among visual elements, and characterize visualizations thoroughly from a new perspective. This paper presents a structure-aware method to advance the performance of visualization retrieval by collectively considering both the visual and structural?\u2026", "IdName": "li2022structure", "Citation": "", "Keywords": ""}, {"Name": "Explaining with examples: Lessons learned from crowdsourced introductory description of information visualizations", "Authors": ["Leni Yang", "Cindy Xiong", "Jason K Wong", "Aoyu Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Data visualizations have been increasingly used in oral presentations to communicate data patterns to the general public. Clear verbal introductions of visualizations to explain how to interpret the visually encoded information are essential to convey the takeaways and avoid misunderstandings. We contribute a series of studies to investigate how to effectively introduce visualizations to the audience with varying degrees of visualization literacy. We begin with understanding how people are introducing visualizations. We crowdsource 110 introductions of visualizations and categorize them based on their content and structures. From these crowdsourced introductions, we identify different introduction strategies and generate a set of introductions for evaluation. We conduct experiments to systematically compare the effectiveness of different introduction strategies across four visualizations with 1,080 participants. We?\u2026", "IdName": "yang2021explaining", "Citation": "", "Keywords": ""}, {"Name": "Cohortva: A visual analytic system for interactive exploration of cohorts based on historical data", "Authors": ["Wei Zhang", "Jason K Wong", "Xumeng Wang", "Youcheng Gong", "Rongchen Zhu", "Kai Liu", "Zihan Yan", "Siwei Tan", "Huamin Qu", "Siming Chen", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In history research, cohort analysis seeks to identify social structures and figure mobilities by studying the group-based behavior of historical figures. Prior works mainly employ automatic data mining approaches, lacking effective visual explanation. In this paper, we present CohortVA, an interactive visual analytic approach that enables historians to incorporate expertise and insight into the iterative exploration process. The kernel of CohortVA is a novel identification model that generates candidate cohorts and constructs cohort features by means of pre-built knowledge graphs constructed from large-scale history databases. We propose a set of coordinated views to illustrate identified cohorts and features coupled with historical events and figure profiles. Two case studies and interviews with historians demonstrate that CohortVA can greatly enhance the capabilities of cohort identifications, figure authentications, and?\u2026", "IdName": "zhang2022cohortva", "Citation": "", "Keywords": ""}, {"Name": "Deep colormap extraction from visualizations", "Authors": ["Lin-Ping Yuan", "Wei Zeng", "Siwei Fu", "Zhiliang Zeng", "Haotian Li", "Chi-Wing Fu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "This article presents a new approach based on deep learning to automatically extract colormaps from visualizations. After summarizing colors in an input visualization image as a Lab color histogram, we pass the histogram to a pre-trained deep neural network, which learns to predict the colormap that produces the visualization. To train the network, we create a new dataset of   64K visualizations that cover a wide variety of data distributions, chart types, and colormaps. The network adopts an atrous spatial pyramid pooling module to capture color features at multiple scales in the input color histograms. We then classify the predicted colormap as discrete or continuous, and refine the predicted colormap based on its color histogram. Quantitative comparisons to existing methods show the superior performance of our approach on both synthetic and real-world visualizations. We further demonstrate the utility of our?\u2026", "IdName": "yuan2021deep", "Citation": "", "Keywords": ""}, {"Name": "Dancingwords: exploring animated word clouds to tell stories", "Authors": ["Xinhuan Shu", "Jiang Wu", "Xinke Wu", "Hongye Liang", "Weiwei Cui", "Yingcai Wu", "Huamin Qu"], "Sources": "Journal of Visualization 24", "PublishedYears": "2021", "Doi": "", "Abstracts": " Abstract By encoding semantic relations into relative positions, word clouds have shown the capability to deliver richer messages than purely visualizing word frequencies. Existing studies mainly focus on layout algorithms that cluster related words, preserve temporal coherence, and optimize spatial shapes. However, they cannot fully convey multiple relations among words and their evolvement through relative positions and static representations. In this paper, we explore animated word clouds that take advantage of storytelling strategies to present interactions between words and show the dynamic process of content changes, thus communicating the underlying stories. We initially create several exemplars of animated word clouds with designers through a structured iterative design process. These exemplars lead to a preliminary design space that distills essential narrative elements with design?\u2026", "IdName": "shu2021dancingwords", "Citation": "", "Keywords": ""}, {"Name": "Qlens: Visual analytics of multi-step problem-solving behaviors for improving question design", "Authors": ["Meng Xia", "Reshika Palaniyappan Velumani", "Yong Wang", "Huamin Qu", "Xiaojuan Ma"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "With the rapid development of online education in recent years, there has been an increasing number of learning platforms that provide students with multi-step questions to cultivate their problem-solving skills. To guarantee the high quality of such learning materials, question designers need to inspect how students' problem-solving processes unfold step by step to infer whether students' problem-solving logic matches their design intent. They also need to compare the behaviors of different groups (e.g., students from different grades) to distribute questions to students with the right level of knowledge. The availability of fine-grained interaction data, such as mouse movement trajectories from the online platforms, provides the opportunity to analyze problem-solving behaviors. However, it is still challenging to interpret, summarize, and compare the high dimensional problem-solving sequence data. In this paper, we?\u2026", "IdName": "xia2020qlens", "Citation": "", "Keywords": ""}, {"Name": "Seek for success: A visualization approach for understanding the dynamics of academic careers", "Authors": ["Yifang Wang", "Tai-Quan Peng", "Huihua Lu", "Haoren Wang", "Xiao Xie", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "How to achieve academic career success has been a long-standing research question in social science research. With the growing availability of large-scale well-documented academic profiles and career trajectories, scholarly interest in career success has been reinvigorated, which has emerged to be an active research domain called the Science of Science (i.e., SciSci). In this study, we adopt an innovative dynamic perspective to examine how individual and social factors will influence career success over time. We propose  ACSeeker , an interactive visual analytics approach to explore the potential factors of success and how the influence of multiple factors changes at different stages of academic careers. We first applied a Multi-factor Impact Analysis framework to estimate the effect of different factors on academic career success over time. We then developed a visual analytics system to understand the dynamic?\u2026", "IdName": "wang2021seek", "Citation": "", "Keywords": ""}, {"Name": "In defence of visual analytics systems: Replies to critics", "Authors": ["Aoyu Wu", "Dazhen Deng", "Furui Cheng", "Yingcai Wu", "Shixia Liu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "The last decade has witnessed many visual analytics (VA) systems that make successful applications to wide-ranging domains like urban analytics and explainable AI. However, their research rigor and contributions have been extensively challenged within the visualization community. We come in defence of VA systems by contributing two interview studies for gathering critics and responses to those criticisms. First, we interview 24 researchers to collect criticisms the review comments on their VA work. Through an iterative coding and refinement process, the interview feedback is summarized into a list of 36 common criticisms. Second, we interview 17 researchers to validate our list and collect their responses, thereby discussing implications for defending and improving the scientific values and rigor of VA systems. We highlight that the presented knowledge is deep, extensive, but also imperfect, provocative, and?\u2026", "IdName": "wu2022defence", "Citation": "", "Keywords": ""}, {"Name": "Why is ai not a panacea for data workers? an interview study on human-ai collaboration in data storytelling", "Authors": ["Haotian Li", "Yun Wang", "Q Vera Liao", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2304.08366", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data storytelling plays an important role in data workers' daily jobs since it boosts team collaboration and public communication. However, to make an appealing data story, data workers spend tremendous efforts on various tasks, including outlining and styling the story. Recently, a growing research trend has been exploring how to assist data storytelling with advanced artificial intelligence (AI). However, existing studies may focus on individual tasks in the workflow of data storytelling and do not reveal a complete picture of humans' preference for collaborating with AI. To better understand real-world needs, we interviewed eighteen data workers from both industry and academia to learn where and how they would like to collaborate with AI. Surprisingly, though the participants showed excitement about collaborating with AI, many of them also expressed reluctance and pointed out nuanced reasons. Based on their responses, we first characterize stages and tasks in the practical data storytelling workflows and the desired roles of AI. Then the preferred collaboration patterns in different tasks are identified. Next, we summarize the interviewees' reasons why and why not they would like to collaborate with AI. Finally, we provide suggestions for human-AI collaborative data storytelling to hopefully shed light on future related research.", "IdName": "li2023ai", "Citation": "", "Keywords": ""}, {"Name": "DMiner: Dashboard design mining and recommendation", "Authors": ["Yanna Lin", "Haotian Li", "Aoyu Wu", "Yong Wang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Dashboards, which comprise multiple views on a single display, help analyze and communicate multiple perspectives of data simultaneously. However, creating effective and elegant dashboards is challenging since it requires careful and logical arrangement and coordination of multiple visualizations. To solve the problem, we propose a data-driven approach for mining design rules from dashboards and automating dashboard organization. Specifically, we focus on two prominent aspects of the organization:  arrangement , which describes the position, size, and layout of each view in the display space; and  coordination , which indicates the interaction between pairwise views. We build a new dataset containing 854 dashboards crawled online, and develop feature engineering methods for describing the single views and view-wise relationships in terms of data, encoding, layout, and interactions. Further, we?\u2026", "IdName": "lin2023dashboard", "Citation": "", "Keywords": ""}, {"Name": "Numgpt: Improving numeracy ability of generative pre-trained models", "Authors": ["Zhihua Jin", "Xin Jiang", "Xingbo Wang", "Qun Liu", "Yong Wang", "Xiaozhe Ren", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2109.03137", "PublishedYears": "2021", "Doi": "", "Abstracts": "Existing generative pre-trained language models (e.g., GPT) focus on modeling the language structure and semantics of general texts. However, those models do not consider the numerical properties of numbers and cannot perform robustly on numerical reasoning tasks (e.g., math word problems and measurement estimation). In this paper, we propose NumGPT, a generative pre-trained model that explicitly models the numerical properties of numbers in texts. Specifically, it leverages a prototype-based numeral embedding to encode the mantissa of the number and an individual embedding to encode the exponent of the number. A numeral-aware loss function is designed to integrate numerals into the pre-training objective of NumGPT. We conduct extensive experiments on four different datasets to evaluate the numeracy ability of NumGPT. The experiment results show that NumGPT outperforms baseline models (e.g., GPT and GPT with DICE) on a range of numerical reasoning tasks such as measurement estimation, number comparison, math word problems, and magnitude classification. Ablation studies are also conducted to evaluate the impact of pre-training and model hyperparameters on the performance.", "IdName": "jin2021numgpt", "Citation": "", "Keywords": ""}, {"Name": "Notable: On-the-fly assistant for data storytelling in computational notebooks", "Authors": ["Haotian Li", "Lu Ying", "Haidong Zhang", "Yingcai Wu", "Huamin Qu", "Yun Wang"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Computational notebooks are widely used for data analysis. Their interleaved displays of code and execution results (e.g., visualizations) are welcomed since they enable iterative analysis and preserve the exploration process. However, the communication of data findings remains challenging in computational notebooks. Users have to carefully identify useful findings from useless ones, document them with texts and visual embellishments, and then organize them in different tools. Such workflow greatly increases their workload, according to our interviews with practitioners. To address the challenge, we designed Notable to offer on-the-fly assistance for data storytelling in computational notebooks. It provides intelligent support to minimize the work of documenting and organizing data findings and diminishes the cost of switching between data exploration and storytelling. To evaluate Notable, we conducted a user?\u2026", "IdName": "li2023notable", "Citation": "", "Keywords": ""}, {"Name": "Persua: A visual interactive system to enhance the persuasiveness of arguments in online discussion", "Authors": ["Meng Xia", "Qian Zhu", "Xingbo Wang", "Fei Nie", "Huamin Qu", "Xiaojuan Ma"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Persuading people to change their opinions is a common practice in online discussion forums on topics ranging from political campaigns to relationship consultation. Enhancing people's ability to write persuasive arguments could not only practice their critical thinking and reasoning but also contribute to the effectiveness and civility in online communication. It is, however, not an easy task in online discussion settings where written words are the primary communication channel. In this paper, we derived four design goals for a tool that helps users improve the persuasiveness of arguments in online discussions through a survey with 123 online forum users and interviews with five debating experts. To satisfy these design goals, we analyzed and built a labeled dataset of fine-grained persuasive strategies (i.e., logos, pathos, ethos, and evidence) in 164 arguments with high ratings on persuasiveness from?\u2026", "IdName": "xia2022persua", "Citation": "", "Keywords": ""}, {"Name": "Storyfier: Exploring Vocabulary Learning Support with Text Generation Models", "Authors": ["Zhenhui Peng", "Xingbo Wang", "Qiushi Han", "Junkai Zhu", "Xiaojuan Ma", "Huamin Qu"], "Sources": "Proceedings of the 36th Annual ACM Symposium on User Interface Software and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Vocabulary learning support tools have widely exploited existing materials, e.g., stories or video clips, as contexts to help users memorize each target word. However, these tools could not provide a coherent context for any target words of learners\u2019 interests, and they seldom help practice word usage. In this paper, we work with teachers and students to iteratively develop Storyfier, which leverages text generation models to enable learners to read a generated story that covers any target words, conduct a story cloze test, and use these words to write a new story with adaptive AI assistance. Our within-subjects study (N=28) shows that learners generally favor the generated stories for connecting target words and writing assistance for easing their learning workload. However, in the read-cloze-write learning sessions, participants using Storyfier perform worse in recalling and using target words than learning with a?\u2026", "IdName": "peng2023storyfier", "Citation": "", "Keywords": ""}, {"Name": "Towards an understanding of distributed asymmetric collaborative visualization on problem-solving", "Authors": ["Wai Tong", "Meng Xia", "Kam Kwai Wong", "Doug A Bowman", "Ting-Chuen Pong", "Huamin Qu", "Yalong Yang"], "Sources": "2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper provided empirical knowledge of the user experience for using collaborative visualization in a distributed asymmetrical setting through controlled user studies. With the ability to access various computing devices, such as Virtual Reality (VR) head-mounted displays, scenarios emerge when collaborators have to or prefer to use different computing environments in different places. However, we still lack an understanding of using VR in an asymmetric setting for collaborative visualization. To get an initial understanding and better inform the designs for asymmetric systems, we first conducted a formative study with 12 pairs of participants. All participants collaborated in asymmetric (PC-VR) and symmetric settings (PC-PC and VR-VR). We then improved our asymmetric design based on the key findings and observations from the first study. Another ten pairs of participants collaborated with enhanced PC-VR?\u2026", "IdName": "tong2023towards", "Citation": "", "Keywords": ""}, {"Name": "Anchorage: Visual analysis of satisfaction in customer service videos via anchor events", "Authors": ["Kam Kwai Wong", "Xingbo Wang", "Yong Wang", "Jianben He", "Rong Zhang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Delivering customer services through video communications has brought new opportunities to analyze customer satisfaction for quality management. However, due to the lack of reliable self-reported responses, service providers are troubled by the inadequate estimation of customer services and the tedious investigation into multimodal video recordings. We introduce  Anchorage , a visual analytics system to evaluate customer satisfaction by summarizing multimodal behavioral features in customer service videos and revealing abnormal operations in the service process. We leverage the semantically meaningful operations to introduce structured event understanding into videos which help service providers quickly navigate to events of their interest.  Anchorage  supports a comprehensive evaluation of customer satisfaction from the service and operation levels and efficient analysis of customer behavioral?\u2026", "IdName": "wong2023anchorage", "Citation": "", "Keywords": ""}, {"Name": "Exploring interactions with printed data visualizations in augmented reality", "Authors": ["Wai Tong", "Zhutian Chen", "Meng Xia", "Leo Yu-Ho Lo", "Linping Yuan", "Benjamin Bach", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "This paper presents a design space of interaction techniques to engage with visualizations that are printed on paper and augmented through Augmented Reality. Paper sheets are widely used to deploy visualizations and provide a rich set of tangible affordances for interactions, such as touch, folding, tilting, or stacking. At the same time, augmented reality can dynamically update visualization content to provide  commands  such as pan, zoom, filter, or detail on demand. This paper is the first to provide a structured approach to mapping possible actions with the paper to interaction commands. This design space and the findings of a controlled user study have implications for future designs of augmented reality systems involving paper sheets and visualizations. Through workshops (  ) and ideation, we identified 81 interactions that we classify in three dimensions: 1)  commands  that can be supported by an?\u2026", "IdName": "tong2022exploring", "Citation": "", "Keywords": ""}, {"Name": "Interactive data analysis with next-step natural language query recommendation", "Authors": ["Xingbo Wang", "Furui Cheng", "Yong Wang", "Ke Xu", "Jiang Long", "Hong Lu", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2201.04868", "PublishedYears": "2022", "Doi": "", "Abstracts": "Natural language interfaces (NLIs) provide users with a convenient way to interactively analyze data through natural language queries. Nevertheless, interactive data analysis is a demanding process, especially for novice data analysts. When exploring large and complex SQL databases from different domains, data analysts do not necessarily have sufficient knowledge about different data tables and application domains. It makes them unable to systematically elicit a series of topically-related and meaningful queries for insight discovery in target domains. We develop a NLI with a step-wise query recommendation module to assist users in choosing appropriate next-step exploration actions. The system adopts a data-driven approach to suggest semantically relevant and context-aware queries for application domains of users' interest based on their query logs. Also, the system helps users organize query histories and results into a dashboard to communicate the discovered data insights. With a comparative user study, we show that our system can facilitate a more effective and systematic data analysis process than a baseline without the recommendation module.", "IdName": "wang2022interactive", "Citation": "", "Keywords": ""}, {"Name": "DeHumor: Visual analytics for decomposing humor", "Authors": ["Xingbo Wang", "Yao Ming", "Tongshuang Wu", "Haipeng Zeng", "Yong Wang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Despite being a critical communication skill, grasping humor is challenging\u2014a successful use of humor requires a mixture of both engaging content build-up and an appropriate vocal delivery (e.g., pause). Prior studies on computational humor emphasize the textual and audio features immediately next to the punchline, yet overlooking longer-term context setup. Moreover, the theories are usually too abstract for understanding each concrete humor snippet. To fill in the gap, we develop  DeHumor , a visual analytical system for analyzing humorous behaviors in public speaking. To intuitively reveal the building blocks of each concrete example,  DeHumor  decomposes each humorous video into multimodal features and provides inline annotations of them on the video script. In particular, to better capture the build-ups, we introduce content repetition as a complement to features introduced in theories of computational?\u2026", "IdName": "wang2021dehumor", "Citation": "", "Keywords": ""}, {"Name": "Tradao: A visual analytics system for trading algorithm optimization", "Authors": ["Ka Wing Tsang", "Haotian Li", "Fuk Ming Lam", "Yifan Mu", "Yong Wang", "Huamin Qu"], "Sources": "2020 IEEE Visualization Conference (VIS)", "PublishedYears": "2020", "Doi": "", "Abstracts": "With the wide applications of algorithmic trading, it has become critical for traders to build a winning trading algorithm to beat the market. However, due to the lack of efficient tools, traders mainly rely on their memory to manually compare the algorithm instances of a trading algorithm and further select the best trading algorithm instance for the real trading deployment. We work closely with industry practitioners to discover and consolidate user requirements and develop an interactive visual analytics system for trading algorithm optimization. Structured expert interviews are conducted to evaluate TradAO and a representative case study is documented for illustrating the system effectiveness. To the best of our knowledge, previous financial data visual analyses have mainly aimed to assist investment managers in investment portfolio analysis but have neglected the need of traders in developing trading algorithms for?\u2026", "IdName": "tsang2020tradao", "Citation": "", "Keywords": ""}, {"Name": "Dpviscreator: Incorporating pattern constraints to privacy-preserving visualizations via differential privacy", "Authors": ["Jiehui Zhou", "Xumeng Wang", "Jason K Wong", "Huanliang Wang", "Zhongwei Wang", "Xiaoyu Yang", "Xiaoran Yan", "Haozhe Feng", "Huamin Qu", "Haochao Ying", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Data privacy is an essential issue in publishing data visualizations. However, it is challenging to represent multiple data patterns in privacy-preserving visualizations. The prior approaches target specific chart types or perform an anonymization model uniformly without considering the importance of data patterns in visualizations. In this paper, we propose a visual analytics approach that facilitates data custodians to generate multiple private charts while maintaining user-preferred patterns. To this end, we introduce pattern constraints to model users' preferences over data patterns in the dataset and incorporate them into the proposed Bayesian network-based Differential Privacy (DP) model  PriVis . A prototype system,  DPVisCreator , is developed to assist data custodians in implementing our approach. The effectiveness of our approach is demonstrated with quantitative evaluation of pattern utility under the different?\u2026", "IdName": "zhou2022dpviscreator", "Citation": "", "Keywords": ""}, {"Name": "SeqDynamics: Visual Analytics for Evaluating Online Problem\u2010solving Dynamics", "Authors": ["Meng Xia", "Min Xu", "Chuan\u2010en Lin", "Ta Ying Cheng", "Huamin Qu", "Xiaojuan Ma"], "Sources": "Computer Graphics Forum", "PublishedYears": "2020", "Doi": "", "Abstracts": " Problem\u2010solving dynamics refers to the process of solving a series of problems over time, from which a student's cognitive skills and non\u2010cognitive traits and behaviors can be inferred. For example, we can derive a student's learning curve (an indicator of cognitive skill) from the changes in the difficulty level of problems solved, or derive a student's self\u2010regulation patterns (an example of non\u2010cognitive traits and behaviors) based on the problem\u2010solving frequency over time. Few studies provide an integrated overview of both aspects by unfolding the problem\u2010solving process. In this paper, we present a visual analytics system named SeqDynamics that evaluates students \u2018problem\u2010solving dynamics from both cognitive and non\u2010cognitive perspectives. The system visualizes the chronological sequence of learners\u2019 problem\u2010solving behavior through a set of novel visual designs and coordinated contextual views?\u2026", "IdName": "xia2020seqdynamics", "Citation": "", "Keywords": ""}, {"Name": "Gesturelens: Visual analysis of gestures in presentation videos", "Authors": ["Haipeng Zeng", "Xingbo Wang", "Yong Wang", "Aoyu Wu", "Ting-Chuen Pong", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Appropriate gestures can enhance message delivery and audience engagement in both daily communication and public presentations. In this article, we contribute a visual analytic approach that assists professional public speaking coaches in improving their practice of gesture training through analyzing presentation videos. Manually checking and exploring gesture usage in the presentation videos is often tedious and time-consuming. There lacks an efficient method to help users conduct gesture exploration, which is challenging due to the intrinsically temporal evolution of gestures and their complex correlation to speech content. In this article, we propose  GestureLens , a visual analytics system to facilitate gesture-based and content-based exploration of gesture usage in presentation videos. Specifically, the exploration view enables users to obtain a quick overview of the spatial and temporal distributions of?\u2026", "IdName": "zeng2022gesturelens", "Citation": "", "Keywords": ""}, {"Name": "Improving engagement of animated visualization with visual foreshadowing", "Authors": ["Wenchao Li", "Yun Wang", "Haidong Zhang", "Huamin Qu"], "Sources": "2020 IEEE Visualization Conference (VIS)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Animated visualization is becoming increasingly popular as a compelling way to illustrate changes in time series data. However, maintaining the viewer's focus throughout the entire animation is difficult because of its time-consuming nature. Viewers are likely to become bored and distracted during the ever-changing animated visualization. Informed by the role of foreshadowing that builds the expectation in film and literature, we introduce visual foreshadowing to improve the engagement of animated visualizations. In specific, we propose designs of visual foreshadowing that engage the audience while watching the animation. To demonstrate our approach, we built a proof-of-concept animated visualization authoring tool that incorporates visual foreshadowing techniques with various styles. Our user study indicates the effectiveness of our foreshadowing techniques on improving engagement for animated?\u2026", "IdName": "li2020improving", "Citation": "", "Keywords": ""}, {"Name": "Inksight: Leveraging sketch interaction for documenting chart findings in computational notebooks", "Authors": ["Yanna Lin", "Haotian Li", "Leni Yang", "Aoyu Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Computational notebooks have become increasingly popular for exploratory data analysis due to their ability to support data exploration and explanation within a single document. Effective documentation for explaining chart findings during the exploration process is essential as it helps recall and share data analysis. However, documenting chart findings remains a challenge due to its time-consuming and tedious nature. While existing automatic methods alleviate some of the burden on users, they often fail to cater to users' specific interests. In response to these limitations, we present InkSight, a mixed-initiative computational notebook plugin that generates finding documentation based on the user's intent. InkSight allows users to express their intent in specific data subsets through sketching atop visualizations intuitively. To facilitate this, we designed two types of sketches, i.e., open-path and closed-path sketch?\u2026", "IdName": "lin2023inksight", "Citation": "", "Keywords": ""}, {"Name": "ShortcutLens: A visual analytics approach for exploring shortcuts in natural language understanding dataset", "Authors": ["Zhihua Jin", "Xingbo Wang", "Furui Cheng", "Chunhui Sun", "Qun Liu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Benchmark datasets play an important role in evaluating Natural Language Understanding (NLU) models. However, shortcuts\u2014unwanted biases in the benchmark datasets\u2014can damage the effectiveness of benchmark datasets in revealing models' real capabilities. Since shortcuts vary in coverage, productivity, and semantic meaning, it is challenging for NLU experts to systematically understand and avoid them when creating benchmark datasets. In this paper, we develop a visual analytics system,  ShortcutLens , to help NLU experts explore shortcuts in NLU benchmark datasets. The system allows users to conduct multi-level exploration of shortcuts. Specifically, Statistics View helps users grasp the statistics such as coverage and productivity of shortcuts in the benchmark dataset. Template View employs hierarchical and interpretable templates to summarize different types of shortcuts. Instance View allows users?\u2026", "IdName": "jin2023shortcutlens", "Citation": "", "Keywords": ""}, {"Name": "Polyphony: An interactive transfer learning framework for single-cell data analysis", "Authors": ["Furui Cheng", "Mark S Keller", "Huamin Qu", "Nils Gehlenborg", "Qianwen Wang"], "Sources": "IEEE transactions on visualization and computer graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Reference-based cell-type annotation can significantly reduce time and effort in single-cell analysis by transferring labels from a previously-annotated dataset to a new dataset. However, label transfer by end-to-end computational methods is challenging due to the entanglement of technical ( e.g. , from different sequencing batches or techniques) and biological ( e.g. , from different cellular microenvironments) variations, only the first of which must be removed. To address this issue, we propose  Polyphony , an interactive transfer learning (ITL) framework, to complement biologists' knowledge with advanced computational methods.  Polyphony  is motivated and guided by domain experts' needs for a controllable, interactive, and algorithm-assisted annotation process, identified through interviews with seven biologists. We introduce anchors,  i.e. , analogous cell populations across datasets, as a paradigm to explain the?\u2026", "IdName": "cheng2022polyphony", "Citation": "", "Keywords": ""}, {"Name": "Causal perception in question-answering systems", "Authors": ["Po-Ming Law", "Leo Yu-Ho Lo", "Alex Endert", "John Stasko", "Huamin Qu"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Root cause analysis is a common data analysis task. While question-answering systems enable people to easily articulate a why question (e.g., why students in Massachusetts have high ACT Math scores on average) and obtain an answer, these systems often produce questionable causal claims. To investigate how such claims might mislead users, we conducted two crowdsourced experiments to study the impact of showing different information on user perceptions of a question-answering system. We found that in a system that occasionally provided unreasonable responses, showing a scatterplot increased the plausibility of unreasonable causal claims. Also, simply warning participants that correlation is not causation seemed to lead participants to accept reasonable causal claims more cautiously. We observed a strong tendency among participants to associate correlation with causation. Yet, the warning?\u2026", "IdName": "law2021causal", "Citation": "", "Keywords": ""}, {"Name": "Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration", "Authors": ["Haotian Li", "Yun Wang", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2309.15723", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these patterns, and further illustrate research opportunities for human-AI collaboration in data storytelling.", "IdName": "li2023we", "Citation": "", "Keywords": ""}, {"Name": "Creating emordle: Animating word cloud for emotion expression", "Authors": ["Liwenhan Xie", "Xinhuan Shu", "Jeon Cheol Su", "Yun Wang", "Siming Chen", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "We propose emordle, a conceptual design that animates wordles (compact word clouds) to deliver their emotional context to audiences. To inform the design, we first reviewed online examples of animated texts and animated wordles, and summarized strategies for injecting emotion into the animations. We introduced a composite approach that extends an existing animation scheme for one word to multiple words in a wordle with two global factors: the randomness of text animation (entropy) and the animation speed (speed). To create an emordle, general users can choose one predefined animated scheme that matches the intended emotion class and fine-tune the emotion intensity with the two parameters. We designed proof-of-concept emordle examples for four basic emotion classes, namely happiness, sadness, anger, and fear. We conducted two controlled crowdsourcing studies to evaluate our approach. The?\u2026", "IdName": "xie2023creating", "Citation": "", "Keywords": ""}, {"Name": "Computableviz: Mathematical operators as a formalism for visualisation processing and analysis", "Authors": ["Aoyu Wu", "Wai Tong", "Haotian Li", "Dominik Moritz", "Yong Wang", "Huamin Qu"], "Sources": "Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Data visualizations are created and shared on the web at an unprecedented speed, raising new needs and questions for processing and analyzing visualizations after they have been generated and digitized. However, existing formalisms focus on operating on a single visualization instead of multiple visualizations, making it challenging to perform analysis tasks such as sorting and clustering visualizations. Through a systematic analysis of previous work, we abstract visualization-related tasks into mathematical operators such as union and propose a design space of visualization operations. We realize the design by developing ComputableViz, a library that supports operations on multiple visualization specifications. To demonstrate its usefulness and extensibility, we present multiple usage scenarios concerning processing and analyzing visualization, such as generating visualization embeddings and?\u2026", "IdName": "wu2022computableviz", "Citation": "", "Keywords": ""}, {"Name": "AQX: Explaining air quality forecast for verifying domain knowledge using feature importance visualization", "Authors": ["Reshika Palaniyappan Velumani", "Meng Xia", "Jun Han", "Chaoli Wang", "ALEXIS K LAU", "Huamin Qu"], "Sources": "27th International Conference on Intelligent User Interfaces", "PublishedYears": "2022", "Doi": "", "Abstracts": " Air pollution forecast has become critical because of its direct impact on human health and its increased production caused by rapid industrialization. Machine learning (ML) solutions are being drastically explored in this domain because they can potentially produce highly accurate results with access to historical data. However, experts in the environmental area are skeptical about adopting ML solutions in real-world applications and policy making due to their black-box nature. In contrast, despite having low accuracy sometimes, the existing traditional simulation model (e.g., CMAQ) are widely used and follows well-defined and transparent equations. Therefore, presenting the knowledge learned by the ML model can make it transparent as well as comprehensible. In addition, validating the ML model\u2019s learning with the existing domain knowledge might aid in addressing their skepticism, building appropriate trust?\u2026", "IdName": "palaniyappan2022aqx", "Citation": "", "Keywords": ""}, {"Name": "iQUANT: interactive quantitative investment using sparse regression factors", "Authors": ["Xuanwu Yue", "Qiao Gu", "Deyun Wang", "Huamin Qu", "Yong Wang"], "Sources": "Computer Graphics Forum", "PublishedYears": "2021", "Doi": "", "Abstracts": " The model\u2010based investing using financial factors is evolving as a principal method for quantitative investment. The main challenge lies in the selection of effective factors towards excess market returns. Existing approaches, either hand\u2010picking factors or applying feature selection algorithms, do not orchestrate both human knowledge and computational power. This paper presents iQUANT, an interactive quantitative investment system that assists equity traders to quickly spot promising financial factors from initial recommendations suggested by algorithmic models, and conduct a joint refinement of factors and stocks for investment portfolio composition. We work closely with professional traders to assemble empirical characteristics of \u201cgood\u201d factors and propose effective visualization designs to illustrate the collective performance of financial factors, stock portfolios, and their interactions. We evaluate iQUANT?\u2026", "IdName": "yue2021iquant", "Citation": "", "Keywords": ""}, {"Name": "HypoML: Visual analysis for hypothesis-based evaluation of machine learning models", "Authors": ["Qianwen Wang", "William Alexander", "Jack Pegg", "Huamin Qu", "Min Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a \u201cconcept\u201d or \u201cfeature\u201d may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have?\u2026", "IdName": "wang2020hypoml", "Citation": "", "Keywords": ""}, {"Name": "Rankbooster: Visual analysis of ranking predictions", "Authors": ["Abishek Puri", "Bon Kyung Ku", "Yong Wang", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2004.06435", "PublishedYears": "2020", "Doi": "", "Abstracts": "Ranking is a natural and ubiquitous way to facilitate decision-making in various applications. However, different rankings are often used for the same set of entities, with each ranking method placing emphasis on different factors. These factors can also be multi-dimensional in nature, compounding the problem. This complexity can make it challenging for an entity which is being ranked to understand what they can do to improve their rankings, and to analyze the effect of changes in various factors to their overall rank. In this paper, we present RankBooster, a novel visual analytics system to help users conveniently investigate ranking predictions. We take university rankings as an example and focus on helping universities to better explore their rankings, where they can compare themselves to their rivals in key areas as well as overall. Novel visualizations are proposed to enable efficient analysis of rankings, including a Scenario Analysis View to show a high-level summary of different ranking scenarios, a Relationship View to visualize the influence of each attribute on different indicators and a Rival View to compare the ranking of a university and those of its rivals. A case study demonstrates the usefulness and effectiveness of RankBooster in facilitating the visual analysis of ranking predictions and helping users better understand their current situation.", "IdName": "puri2020rankbooster", "Citation": "", "Keywords": ""}, {"Name": "Reviving static charts into live charts", "Authors": ["Lu Ying", "Yun Wang", "Haotian Li", "Shuguang Dou", "Haidong Zhang", "Xinyang Jiang", "Huamin Qu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Data charts are prevalent across various fields due to their efficacy in conveying complex data relationships. However, static charts may sometimes struggle to engage readers and efficiently present intricate information, potentially resulting in limited understanding. We introduce \u201cLive Charts,\u201d a new format of presentation that decomposes complex information within a chart and explains the information pieces sequentially through rich animations and accompanying audio narration. We propose an automated approach to revive static charts into Live Charts. Our method integrates GNN-based techniques to analyze the chart components and extract data from charts. Then we adopt large natural language models to generate appropriate animated visuals along with a voice-over to produce Live Charts from static ones. We conducted a thorough evaluation of our approach, which involved the model performance, use?\u2026", "IdName": "ying2024reviving", "Citation": "", "Keywords": ""}, {"Name": "Geocamera: Telling stories in geographic visualizations with camera movements", "Authors": ["Wenchao Li", "Zhan Wang", "Yun Wang", "Di Weng", "Liwenhan Xie", "Siming Chen", "Haidong Zhang", "Huamin Qu"], "Sources": "Proceedings of the 2023 CHI conference on human factors in computing systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "In geographic data videos, camera movements are frequently used and combined to present information from multiple perspectives. However, creating and editing camera movements requires significant time and professional skills. This work aims to lower the barrier of crafting diverse camera movements for geographic data videos. First, we analyze a corpus of 66 geographic data videos and derive a design space of camera movements with a dimension for geospatial targets and one for narrative purposes. Based on the design space, we propose a set of adaptive camera shots and further develop an interactive tool called GeoCamera. This interactive tool allows users to flexibly design camera movements for geographic visualizations. We verify the expressiveness of our tool through case studies and evaluate its usability with a user study. The participants find that the tool facilitates the design of camera movements. ", "IdName": "li2023geocamera", "Citation": "", "Keywords": ""}, {"Name": "Rankfirst: Visual analysis for factor investment by ranking stock timeseries", "Authors": ["Huijie Guo", "Meijun Liu", "Bowen Yang", "Ye Sun", "Huamin Qu", "Lei Shi"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In the era of quantitative investment, factor-based investing models are widely adopted in the construction of stock portfolios. These models explain the performance of individual stocks by a set of financial factors, e.g., market beta and company size. In industry, open investment platforms allow the online building of factor-based models, yet set a high bar on the engineering expertise of end-users. State-of-the-art visualization systems integrate the whole factor investing pipeline, but do not directly address domain users' core requests on ranking factors and stocks for portfolio construction. The current model lacks explainability, which downgrades its credibility with stock investors. To fill the gap in modeling, ranking, and visualizing stock time series for factor investment, we designed and implemented a visual analytics system, namely RankFIRST. The system offers built-in support for an established factor collection and?\u2026", "IdName": "guo2022rankfirst", "Citation": "", "Keywords": ""}, {"Name": "Saliency-aware color harmony models for outdoor signboard", "Authors": ["Yanna Lin", "Wei Zeng", "Yu Ye", "Huamin Qu"], "Sources": "Computers & Graphics 105", "PublishedYears": "2022", "Doi": "", "Abstracts": "This paper introduces a geometric approach for assessing color harmony of a signboard, and color coherence of a signboard with the environment. We propose to incorporate visual saliency as an inherent color characteristic residing in the image space, to better cope with the attention mechanism when people view a scene. In doing so, our color harmony models consider saliency-weighted color differences and area balance in CIELab color space. We collect 5.2?K valid subjective ratings on 375 diverse signboards in the real world, and translate them into quantitative measures for model construction. Experimental results show that our models improve the overall performance, especially for modeling color coherence between a signboard and the environment. The study also reveals that color combinations with similar chroma but distinctive lightness lead to harmonic signboards, while simple color patches in?\u2026", "IdName": "lin2022saliency", "Citation": "", "Keywords": ""}, {"Name": "Blocklens: visual analytics of student coding behaviors in block-based programming environments", "Authors": ["Sean Tsung", "Huan Wei", "Haotian Li", "Yong Wang", "Meng Xia", "Huamin Qu"], "Sources": "Proceedings of the Ninth ACM Conference on Learning@ Scale", "PublishedYears": "2022", "Doi": "", "Abstracts": "Block-based programming environments have been widely used to introduce K-12 students to coding. To guide students effectively, instructors and platform owners often need to understand behaviors like how students solve certain questions or where they get stuck and why. However, it is challenging for them to effectively analyze students' coding data. To this end, we propose BlockLens, a novel visual analytics system to assist instructors and platform owners in analyzing students' block-based coding behaviors, mistakes, and problem-solving patterns. BlockLens enables the grouping of students by question progress and performance, identification of common problem-solving strategies and pitfalls, and presentation of insights at multiple granularity levels, from a high-level overview of all students to a detailed analysis of one student's behavior and performance. A usage scenario using real-world data?\u2026", "IdName": "tsung2022blocklens", "Citation": "", "Keywords": ""}, {"Name": "Scrolltimes: Tracing the provenance of paintings as a window into history", "Authors": ["Wei Zhang", "Wong Kam-Kwai", "Yitian Chen", "Ailing Jia", "Luwei Wang", "Jian-Wei Zhang", "Lechao Cheng", "Huamin Qu", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "The study of cultural artifact provenance, tracing ownership and preservation, holds significant importance in archaeology and art history. Modern technology has advanced this field, yet challenges persist, including recognizing evidence from diverse sources, integrating sociocultural context, and enhancing interactive automation for comprehensive provenance analysis. In collaboration with art historians, we examined the handscroll, a traditional Chinese painting form that provides a rich source of historical data and a unique opportunity to explore history through cultural artifacts. We present a three-tiered methodology encompassing artifact, contextual, and provenance levels, designed to create a \u201cBiography\u201d for handscroll. Our approach incorporates the application of image processing techniques and language models to extract, validate, and augment elements within handscroll using various cultural heritage?\u2026", "IdName": "zhang2024scrolltimes", "Citation": "", "Keywords": ""}, {"Name": "A survey of visual analytics in urban area", "Authors": ["Zezheng Feng", "Huamin Qu", "Shuang\u2010Hua Yang", "Yulong Ding", "Jie Song"], "Sources": "Expert Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": " Nowadays, the population has been overgrowing due to urbanization, yielding many severe problems in the urban area, including traffic congestion, unbalanced distribution of urban hotspots, air pollution and so on. Due to the uncertainty of the urban environment, it always needs to integrate experts' domain knowledge into solving these issues. In recent years, the visual analytics method has been widely used to assist domain experts in solving urban problems with its intuitiveness, interactivity and interpretability. In this survey, we first introduce the background of urban computing, present the motivation of visual analytics in the urban area and point out the characteristics of visual analytics methods. Second, we introduce the most frequently used urban data, analyse the main properties and provide an overview on how to use these data. Thereafter, we propose our taxonomy for visual analytics in the urban area?\u2026", "IdName": "feng2022survey", "Citation": "", "Keywords": ""}, {"Name": "Aqeyes: visual analytics for anomaly detection and examination of air quality data", "Authors": ["Dongyu Liu", "Kalyan Veeramachaneni", "Alexander Geiger", "Victor OK Li", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2103.12910", "PublishedYears": "2021", "Doi": "", "Abstracts": "Anomaly detection plays a key role in air quality analysis by enhancing situational awareness and alerting users to potential hazards. However, existing anomaly detection approaches for air quality analysis have their own limitations regarding parameter selection (e.g., need for extensive domain knowledge), computational expense, general applicability (e.g., require labeled data), interpretability, and the efficiency of analysis. Furthermore, the poor quality of collected air quality data (inconsistently formatted and sometimes missing) also increases the difficulty of analysis substantially. In this paper, we systematically formulate design requirements for a system that can solve these limitations and then propose AQEyes, an integrated visual analytics system for efficiently monitoring, detecting, and examining anomalies in air quality data. In particular, we propose a unified end-to-end tunable machine learning pipeline that includes several data pre-processors and featurizers to deal with data quality issues. The pipeline integrates an efficient unsupervised anomaly detection method that works without the use of labeled data and overcomes the limitations of existing approaches. Further, we develop an interactive visualization system to visualize the outputs from the pipeline. The system incorporates a set of novel visualization and interaction designs, allowing analysts to visually examine air quality dynamics and anomalous events in multiple scales and from multiple facets. We demonstrate the performance of this pipeline through a quantitative evaluation and show the effectiveness of the visualization system using qualitative case studies on real-world?\u2026", "IdName": "liu2021aqeyes", "Citation": "", "Keywords": ""}, {"Name": "PoeticAR: Reviving traditional poetry of the heritage site of jichang garden via augmented reality", "Authors": ["Jin Tian", "Yifan Cao", "Lingyi Feng", "Dongting Fu", "Linping Yuan", "Huamin Qu", "Yang Wang", "Mingming Fan"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "As a famed Chinese classical garden, the Jichang Garden was a constant inspiration to many poets in its hundreds of years\u2019 history, who composed a rich body of poems\u2014a valuable intangible cultural heritage. While tourists tend to pay attention to tangible natural scenery and historical architectures, they often neglect intangible cultural heritage\u2014poems. We interviewed 23 tourists and found that augmented reality (AR) was viable for tourists to enjoy the physical scenery and the poetry simultaneously. We developed an initial prototype of PoeticAR, which presents poems based on physical scenery to enhance tourists\u2019 cultural and aesthetic experience. We further revised the prototype based on the ideas generated from a workshop with 18 tourists. We conducted a between-subject user study with 30 tourists to compare PoeticAR with Video. Results showed that PoeticAR significantly motivated tourists\u2019 interest in?\u2026", "IdName": "tian2024poeticar", "Citation": "", "Keywords": ""}, {"Name": "CommonsenseVIS: Visualizing and Understanding Commonsense Reasoning Capabilities of Natural Language Models", "Authors": ["Xingbo Wang", "Renfei Huang", "Zhihua Jin", "Tianqing Fang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, large pretrained language models have achieved compelling performance on commonsense benchmarks. Nevertheless, it is unclear what commonsense knowledge the models learn and whether they solely exploit spurious patterns. Feature attributions are popular explainability techniques that identify important input concepts for model outputs. However, commonsense knowledge tends to be implicit and rarely explicitly presented in inputs. These methods cannot infer models' implicit reasoning over mentioned concepts. We present  CommonsenseVIS , a visual explanatory system that utilizes external commonsense knowledge bases to contextualize model behavior for commonsense question-answering. Specifically, we extract relevant commonsense knowledge in inputs as references to align model behavior with human knowledge. Our system features multi-level visualization and interactive model?\u2026", "IdName": "wang2023commonsensevis", "Citation": "", "Keywords": ""}, {"Name": "VideoPro: A Visual Analytics Approach for Interactive Video Programming", "Authors": ["Jianben He", "Xingbo Wang", "Kam Kwai Wong", "Xijie Huang", "Changjian Chen", "Zixin Chen", "Fengjie Wang", "Min Zhu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Constructing supervised machine learning models for real-world video analysis require substantial labeled data, which is costly to acquire due to scarce domain expertise and laborious manual inspection. While data programming shows promise in generating labeled data at scale with user-defined labeling functions, the high dimensional and complex temporal information in videos poses additional challenges for effectively composing and evaluating labeling functions. In this paper, we propose  VideoPro , a visual analytics approach to support flexible and scalable video data programming for model steering with reduced human effort. We first extract human-understandable events from videos using computer vision techniques and treat them as atomic components of labeling functions. We further propose a two-stage template mining algorithm that characterizes the sequential patterns of these events to serve as?\u2026", "IdName": "he2023videopro", "Citation": "", "Keywords": ""}, {"Name": "Cinematography in the Metaverse: Exploring the Lighting Education on a Soundstage", "Authors": ["Xian Xu", "Wai Tong", "Zheng Wei", "Meng Xia", "Lik-Hang Lee", "Huamin Qu"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Lighting education is a foundational component of cinematography education. However, there is still a lack of knowledge on the design of a VR system for teaching cinematography. In this work, we present our VR soundstage system for instructors and learners to emulate cinematography lighting in virtual scenarios and then evaluate it from five aspects in the user study. Qualitative and quantitative feedback in our user study shows promising results. We further discuss the benefits of the approach and opportunities for future research.", "IdName": "xu2023cinematography", "Citation": "", "Keywords": ""}, {"Name": "Designing a game for pre-screening students with specific learning disabilities in Chinese", "Authors": ["Ka Yan Fung", "Kuen Fung Sin", "Zikai Alex Wen", "Lik-Hang Lee", "Shenghui Song", "Huamin Qu"], "Sources": "Proceedings of the 24th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Most students with specific learning disabilities (SLDs) have difficulties in reading and writing. The SLDs pre-screening is crucial because the golden period for therapy is before six years old. However, many students in Hong Kong receive SLDs assessments after the golden period. Also, the SLDs pre-screening is challenging, especially in a language with the logographic script but without prominent sound-script correspondence (e.g., Chinese, Japanese). To make pre-screening SLDs in Chinese more effective and efficient, we designed a new comprehensive pre-screening game for SLDs in Chinese (i.e., dyslexia, dysgraphia, and dyspraxia). Notably, we designed a Chinese morphological awareness puzzle that challenges students to recognize different words made up with the first character that is identical and the second character that is different, such as\u6a39\u679d (literally means tree branch),\u6a39\u5e79 (literally means?\u2026", "IdName": "fung2022designing", "Citation": "", "Keywords": ""}, {"Name": "Method and system for analyzing user activities related to a video", "Authors": ["Huamin Qu", "Conglei Shi", "Siwei Fu", "Qing Chen"], "Sources": "US Patent 10", "PublishedYears": "2020", "Doi": "", "Abstracts": "The present teaching relates to analyzing user activities related to a video. The video is provided to a plurality of users. The plurality of users is monitored to detect one or more types of user activities performed in time with respect to different portions of the video. One or more visual representations of the monitored one or more types of user activities are generated. The one or more visual representations capture a level of attention paid by the plurality of users to the different portions of the video at any time instance. Interests of at least some of the plurality of users are determined with respect to the different portions of the video based on the one or more visual representations.", "IdName": "qu2020method", "Citation": "", "Keywords": ""}, {"Name": "Understanding 3D Data Videos: From Screens to Virtual Reality", "Authors": ["Leni Yang", "Aoyu Wu", "Wai Tong", "Xian Xu", "Zheng Wei", "Huamin Qu"], "Sources": "2023 IEEE 16th Pacific Visualization Symposium (PacificVis)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data storytelling explores how to communicate data insights to the general public engagingly and effectively. It combines the power of data visualizations and storytelling techniques and is popular in various media such as newspapers, interactive websites, and videos. Recently, virtual reality has brought new opportunities to enhance data storytelling with an incomparable sense of immersion. However, there exists a limited understanding of data stories in virtual reality (VR) as they are still in the early stage. In this paper, we investigated the idea of VR data videos by drawing inspiration from popular 3D data videos and studying how to transfer them from screens to VR. We systematically analyzed 100 highly-watched 3D data videos from Youtube and Tiktok channels to derive their design space. We then conducted a user study with 12 participants to explore the effects of four design factors on user experience?\u2026", "IdName": "yang2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Kb4va: A knowledge base of visualization designs for visual analytics", "Authors": ["Dazhen Deng", "Aoyu Wu", "Haotian Li", "Ji Lan", "Yong Wang", "Huamin Qu", "Yingcai Wu"], "Sources": "arXiv preprint arXiv:2211.02567", "PublishedYears": "2022", "Doi": "", "Abstracts": "Visual analytics (VA) systems have been widely used to facilitate decision-making and analytical reasoning in various application domains. VA involves visual designs, interaction designs, and data mining, which is a systematic and complex paradigm. In this work, we focus on the design of effective visualizations for complex data and analytical tasks, which is a critical step in designing a VA system. This step is challenging because it requires extensive knowledge about domain problems and visualization to design effective encodings. Existing visualization designs published in top venues are valuable resources to inspire designs for problems with similar data structures and tasks. However, those designs are hard to understand, parse, and retrieve due to the lack of specifications. To address this problem, we build KB4VA, a knowledge base of visualization designs in VA systems with comprehensive labels about their analytical tasks and visual encodings. Our labeling scheme is inspired by a workshop study with 12 VA researchers to learn user requirements in understanding and retrieving professional visualization designs in VA systems. The theme extends Vega-Lite specifications for describing advanced and composited visualization designs in a declarative manner, thus facilitating human understanding and automatic indexing. To demonstrate the usefulness of our knowledge base, we present a user study about design inspirations for VA tasks. In summary, our work opens new perspectives for enhancing the accessibility and reusability of professional visualization designs.", "IdName": "deng2022kb4va", "Citation": "", "Keywords": ""}, {"Name": "AniVis: Generating Animated Transitions Between Statistical Charts with a Tree Model", "Authors": ["Wenchao Li", "Yun Wang", "He Huang", "Weiwei Cui", "Haidong Zhang", "Huamin Qu", "Dongmei Zhang"], "Sources": "arXiv preprint arXiv:2106.14313", "PublishedYears": "2021", "Doi": "", "Abstracts": "Animated transitions help viewers understand changes between related visualizations. To clearly present the underlying relations between statistical charts, animation authors need to have a high level of expertise and a considerable amount of time to describe the relations with reasonable animation stages. We present AniVis, an automated approach for generating animated transitions to demonstrate the changes between two statistical charts. AniVis models each statistical chart into a tree-based structure. Given an input chart pair, the differences of data and visual properties of the chart pair are formalized as tree edit operations. The edit operations can be mapped to atomic transition units. Through this approach, the animated transition between two charts can be expressed as a set of transition units. Then, we conduct a formative study to understand people's preferences for animation sequences. Based on the study, we propose a set of principles and a sequence composition algorithm to compose the transition units into a meaningful animation sequence. Finally, we synthesize these units together to deliver a smooth and intuitive animated transition between charts. To test our approach, we present a prototype system and its generated results to illustrate the usage of our framework. We perform a comparative study to assess the transition sequence derived from the tree model. We further collect qualitative feedback to evaluate the effectiveness and usefulness of our method.", "IdName": "li2021anivis", "Citation": "", "Keywords": ""}, {"Name": "SirenLess: Reveal the intention behind news", "Authors": ["Xumeng Chen", "Leo Yu-Ho Lo", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2001.02731", "PublishedYears": "2020", "Doi": "", "Abstracts": "News articles tend to be increasingly misleading nowadays, preventing readers from making subjective judgments towards certain events. While some machine learning approaches have been proposed to detect misleading news, most of them are black boxes that provide limited help for humans in decision making. In this paper, we present SirenLess, a visual analytical system for misleading news detection by linguistic features. The system features article explorer, a novel interactive tool that integrates news metadata and linguistic features to reveal semantic structures of news articles and facilitate textual analysis. We use SirenLess to analyze 18 news articles from different sources and summarize some helpful patterns for misleading news detection. A user study with journalism professionals and university students is conducted to confirm the usefulness and effectiveness of our system.", "IdName": "chen2020sirenless", "Citation": "", "Keywords": ""}, {"Name": "Prismatic: Interactive Multi-View Cluster Analysis of Concept Stocks", "Authors": ["Wong Kam-Kwai", "Yan Luo", "Xuanwu Yue", "Wei Chen", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2402.08978", "PublishedYears": "2024", "Doi": "", "Abstracts": "Financial cluster analysis allows investors to discover investment alternatives and avoid undertaking excessive risks. However, this analytical task faces substantial challenges arising from many pairwise comparisons, the dynamic correlations across time spans, and the ambiguity in deriving implications from business relational knowledge. We propose Prismatic, a visual analytics system that integrates quantitative analysis of historical performance and qualitative analysis of business relational knowledge to cluster correlated businesses interactively. Prismatic features three clustering processes: dynamic cluster generation, knowledge-based cluster exploration, and correlation-based cluster validation. Utilizing a multi-view clustering approach, it enriches data-driven clusters with knowledge-driven similarity, providing a nuanced understanding of business correlations. Through well-coordinated visual views, Prismatic facilitates a comprehensive interpretation of intertwined quantitative and qualitative features, demonstrating its usefulness and effectiveness via case studies on formulating concept stocks and extensive interviews with domain experts.", "IdName": "kam2024prismatic", "Citation": "", "Keywords": ""}, {"Name": "Wakey-Wakey: Animate Text by Mimicking Characters in a GIF", "Authors": ["Liwenhan Xie", "Zhaoyu Zhou", "Kerun Yu", "Yun Wang", "Huamin Qu", "Siming Chen"], "Sources": "Proceedings of the 36th Annual ACM Symposium on User Interface Software and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "With appealing visual effects, kinetic typography (animated text) has prevailed in movies, advertisements, and social media. However, it remains challenging and time-consuming to craft its animation scheme. We propose an automatic framework to transfer the animation scheme of a rigid body on a given meme GIF to text in vector format. First, the trajectories of key points on the GIF anchor are extracted and mapped to the text\u2019s control points based on local affine transformation. Then the temporal positions of the control points are optimized to maintain the text topology. We also develop an authoring tool that allows intuitive human control in the generation process. A questionnaire study provides evidence that the output results are aesthetically pleasing and well preserve the animation patterns in the original GIF, where participants were impressed by a similar emotional semantics of the original GIF. In addition, we?\u2026", "IdName": "xie2023wakey", "Citation": "", "Keywords": ""}, {"Name": "Why Change My Design: Explaining Poorly Constructed Visualization Designs with Explorable Explanations", "Authors": ["Leo Yu-Ho Lo", "Yifan Cao", "Leni Yang", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Although visualization tools are widely available and accessible, not everyone knows the best practices and guidelines for creating accurate and honest visual representations of data. Numerous books and articles have been written to expose the misleading potential of poorly constructed charts and teach people how to avoid being deceived by them or making their own mistakes. These readings use various rhetorical devices to explain the concepts to their readers. In our analysis of a collection of books, online materials, and a design workshop, we identified six common explanation methods. To assess the effectiveness of these methods, we conducted two crowdsourced studies (each with   ) to evaluate their ability to teach and persuade people to make design changes. In addition to these existing methods, we brought in the idea of Explorable Explanations, which allows readers to experiment with?\u2026", "IdName": "lo2023change", "Citation": "", "Keywords": ""}, {"Name": "Adavis: Adaptive and explainable visualization recommendation for tabular data", "Authors": ["Songheng Zhang", "Yong Wang", "Haotian Li", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Automated visualization recommendation facilitates the rapid creation of effective visualizations, which is especially beneficial for users with limited time and limited knowledge of data visualization. There is an increasing trend in leveraging machine learning (ML) techniques to achieve an end-to-end visualization recommendation. However, existing ML-based approaches implicitly assume that there is only one appropriate visualization for a specific dataset, which is often not true for real applications. Also, they often work like a black box, and are difficult for users to understand the reasons for recommending specific visualizations. To fill the research gap, we propose AdaVis, an adaptive and explainable approach to recommend one or multiple appropriate visualizations for a tabular dataset. It leverages a box embedding-based knowledge graph to well model the possible one-to-many mapping relations among?\u2026", "IdName": "zhang2023adavis", "Citation": "", "Keywords": ""}, {"Name": "FoodWise: Food Waste Reduction and Behavior Change on Campus with Data Visualization and Gamification", "Authors": ["Yue Yu", "Sophia Yi", "Xi Nan", "Leo Yu-Ho Lo", "Kento Shigyo", "Liwenhan Xie", "Jeffry Wicaksana", "Kwang-Ting Cheng", "Huamin Qu"], "Sources": "Proceedings of the 6th ACM SIGCAS/SIGCHI Conference on Computing and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Food waste presents a substantial challenge with significant environmental and economic ramifications, and its severity on campus environments is of particular concern. In response to this, we introduce FoodWise, a dual-component system tailored to inspire and incentivize campus communities to reduce food waste. The system consists of a data storytelling dashboard that graphically displays food waste information from university canteens, coupled with a mobile web application that encourages users to log their food waste reduction actions and rewards active participants for their efforts.  Deployed during a two-week food-saving campaign at The Hong Kong University of Science and Technology (HKUST) in March 2023, FoodWise engaged over 200 participants from the university community, resulting in the logging of over 800 daily food-saving actions. Feedback collected post-campaign underscores the?\u2026", "IdName": "yu2023foodwise", "Citation": "", "Keywords": ""}, {"Name": "Tax-Scheduler: An interactive visualization system for staff shifting and scheduling at tax authorities", "Authors": ["Linping Yuan", "Boyu Li", "Siqi Li", "Kam Kwai Wong", "Rong Zhang", "Huamin Qu"], "Sources": "Visual Informatics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Given a large number of applications and complex processing procedures, how to efficiently shift and schedule tax officers to provide good services to taxpayers is now receiving more attention from tax authorities. The availability of historical application data makes it possible for tax managers to shift and schedule staff with data support, but it is unclear how to properly leverage the historical data. To investigate the problem, this study adopts a user-centered design approach. We first collect user requirements by conducting interviews with tax managers and characterize their requirements of shifting and scheduling into time series prediction and resource scheduling problems. Then, we propose Tax-Scheduler, an interactive visualization system with a time-series prediction algorithm and genetic algorithm to support staff shifting and scheduling in the tax scenarios. To evaluate the effectiveness of the system and?\u2026", "IdName": "yuan2023tax", "Citation": "", "Keywords": ""}, {"Name": "Networknarratives: Data tours for visual network exploration and analysis", "Authors": ["Wenchao Li", "Sarah Sch?ttler", "James Scott-Brown", "Yun Wang", "Siming Chen", "Huamin Qu", "Benjamin Bach"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " This paper introduces semi-automatic data tours to aid the exploration of complex networks. Exploring networks requires significant effort and expertise and can be time-consuming and challenging. Distinct from guidance and recommender systems for visual analytics, we provide a set of goal-oriented tours for network overview, ego-network analysis, community exploration, and other tasks. Based on interviews with five network analysts, we developed a user interface (NetworkNarratives) and 10 example tours. The interface allows analysts to navigate an interactive slideshow featuring facts about the network using visualizations and textual annotations. On each slide, an analyst can freely explore the network and specify nodes, links, or subgraphs as seed elements for follow-up tours. Two studies, comprising eight expert and 14 novice analysts, show that data tours reduce exploration effort, support learning about?\u2026", "IdName": "li2023networknarratives", "Citation": "", "Keywords": ""}, {"Name": "ProtoSteer:Steering deep sequence model with prototypes", "Authors": ["Panpan Xu", "Liu Ren", "MING Yao", "Furui Cheng", "Huamin Qu"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "Int. Cl. G06F 3/04847(2022.01) G06N 3/08(2006.01) G06F 370482(2013.01)(52) US CI. CPC G06F 3/04847 (2013.01); G06F 3/0482 (2013.01); GOON 3/08 (2013.01)", "IdName": "xu2022steering", "Citation": "", "Keywords": ""}, {"Name": "Let Every Seat Be Perfect! A Case Study on Combining BIM and VR for Room Planning", "Authors": ["Wai Tong", "Haotian Li", "Huan Wei", "Liwenhan Xie", "Yanna Lin", "Huamin Qu"], "Sources": "2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "When communicating indoor room design, professional designers normally rely on software like Revit to export walk-through videos for their clients. However, a lack of in-situ experience restricts the ultimate users from evaluating the design and hence provides limited feedback, which may lead to a rework after actual construction. In this case study, we explore empowering end-users by exposing rich design details through a Virtual Reality (VR) application based on building an information model. Qualitative feedback in our user study shows promising results. We further discuss the benefits of the approach and opportunities for future research.", "IdName": "tong2022let", "Citation": "", "Keywords": ""}, {"Name": "ICE: Identify and compare event sequence sets through multi-scale matrix and unit visualizations", "Authors": ["Siwei Fu", "Jian Zhao", "Linping Yuan", "Zhicheng Liu", "Kwan-Liu Ma", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2006.12718", "PublishedYears": "2020", "Doi": "", "Abstracts": "Comparative analysis of event sequence data is essential in many application domains, such as website design and medical care. However, analysts often face two challenges: they may not always know which sets of event sequences in the data are useful to compare, and the comparison needs to be achieved at different granularity, due to the volume and complexity of the data. This paper presents, ICE, an interactive visualization that allows analysts to explore an event sequence dataset, and identify promising sets of event sequences to compare at both the pattern and sequence levels. More specifically, ICE incorporates a multi-level matrix-based visualization for browsing the entire dataset based on the prefixes and suffixes of sequences. To support comparison at multiple levels, ICE employs the unit visualization technique, and we further explore the design space of unit visualizations for event sequence comparison tasks. Finally, we demonstrate the effectiveness of ICE with three real-world datasets from different domains.", "IdName": "fu2020ice", "Citation": "", "Keywords": ""}, {"Name": "Visual analytics tool for proctoring online exams", "Authors": ["LI Haotian", "Min Xu", "Huan Wei", "Huamin Qu", "Yong Wang"], "Sources": "US Patent 11", "PublishedYears": "2024", "Doi": "", "Abstracts": "A system for proctoring online exams includes a client-side computing system and a visual analytics system. The client-side computing system includes a camera configured to obtain video data corresponding to a user while taking an exam and one or more input devices configured to obtain interaction data, wherein the interaction data includes mouse movements of the user while taking the exam. The visual analytics system is configured to obtain the video data and the interaction data from the client-side computing system, analyze the exam data to detect abnormal behavior by the user based at least in part on mouse movement data, and generate one or more visualizations of the analyzed exam data to be used in determining whether or not the user has cheated during the exam.", "IdName": "haotian2024visual", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Opportunity of Augmented Reality (AR) in Supporting Older Adults Explore and Learn Smartphone Applications", "Authors": ["Xiaofu Jin", "Wai Tong", "Xiaoying Wei", "Xian Wang", "Emily Kuang", "Xiaoyu Mo", "Huamin Qu", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2402.04991", "PublishedYears": "2024", "Doi": "", "Abstracts": "The global aging trend compels older adults to navigate the evolving digital landscape, presenting a substantial challenge in mastering smartphone applications. While Augmented Reality (AR) holds promise for enhancing learning and user experience, its role in aiding older adults' smartphone app exploration remains insufficiently explored. Therefore, we conducted a two-phase study: (1) a workshop with 18 older adults to identify app exploration challenges and potential AR interventions, and (2) tech-probe participatory design sessions with 15 participants to co-create AR support tools. Our research highlights AR's effectiveness in reducing physical and cognitive strain among older adults during app exploration, especially during multi-app usage and the trial-and-error learning process. We also examined their interactional experiences with AR, yielding design considerations on tailoring AR tools for smartphone app exploration. Ultimately, our study unveils the prospective landscape of AR in supporting the older demographic, both presently and in future scenarios.", "IdName": "jin2024exploring", "Citation": "", "Keywords": ""}, {"Name": "Feeling Present! From Physical to Virtual Cinematography Lighting Education with Metashadow", "Authors": ["Zheng Wei", "Xian Xu", "Lik-Hang Lee", "Wai Tong", "Huamin Qu", "Pan Hui"], "Sources": "Proceedings of the 31st ACM International Conference on Multimedia", "PublishedYears": "2023", "Doi": "", "Abstracts": "The high cost and limited availability of soundstages for cinematography lighting education pose significant challenges for art institutions. Traditional teaching methods, combining basic lighting equipment operation with slide lectures, often yield unsatisfactory results, hindering students' mastery of cinematography lighting techniques. Therefore, we propose Metashadow, a virtual reality (VR) cinematography lighting education system demonstrating the feasibility of learning in a virtual soundstage. Based on the presence theory, Metashadow features high-fidelity lighting devices that enable users to adjust multiple parameters, providing a quantifiable learning approach. We evaluated Metashadow with 24 participants and found that it provides better learning outcomes than traditional teaching methods regarding presence, collaboration, usability, realism, creativity, and flexibility. Six experts also praised the?\u2026", "IdName": "wei2023feeling", "Citation": "", "Keywords": ""}, {"Name": "iFUNDit: Visual Profiling of Fund Investment Styles", "Authors": ["Rong Zhang", "Bon Kyung Ku", "Yong Wang", "Xuanwu Yue", "Siyuan Liu", "Ke Li", "Huamin Qu"], "Sources": "Computer Graphics Forum", "PublishedYears": "2023", "Doi": "", "Abstracts": " Mutual funds are becoming increasingly popular with the emergence of Internet finance. Clear profiling of a fund's investment style is crucial for fund managers to evaluate their investment strategies, and for investors to understand their investment. However, it is challenging to profile a fund's investment style as it requires a comprehensive analysis of complex multi\u2010dimensional temporal data. In addition, different fund managers and investors have different focuses when analysing a fund's investment style. To address the issue, we propose iFUNDit, an interactive visual analytic system for fund investment style analysis. The system decomposes a fund's critical features into performance attributes and investment style factors, and visualizes them in a set of coupled views: a fund and manager view, to delineate the distribution of funds' and managers' critical attributes on the market; a cluster view, to show the similarity?\u2026", "IdName": "zhang2023ifundit", "Citation": "", "Keywords": ""}, {"Name": "System and a method for speech analysis", "Authors": ["Huamin Qu", "Yuanzhe Chen", "Siwei Fu", "Linping Yuan", "WU Aoyu"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "A computer implemented method and system for processing an audio signal. The method includes the steps of extracting prosodic features from the audio signal, aligning the extracted prosodic features with a script derived from or associated with the audio signal, and segmenting the script with the aligned extracted prosodic features into structural blocks of a first type. The method may further include determining a distance measure between a structural block of a first type derived from the script with another structural block of the first type using, for example, the Damerau-Levenshtein distance.", "IdName": "qu2022system", "Citation": "", "Keywords": ""}, {"Name": "Explore Mindfulness Without Deflection: A Data Art Based On The Book Of Songs", "Authors": ["Yifang Wang", "Yang Wang", "Yifan Cao", "Huamin Qu", "Junxiu Tang", "Yingcai Wu"], "Sources": "2021 IEEE VIS Arts Program (VISAP)", "PublishedYears": "2021", "Doi": "", "Abstracts": "The Book of Songs is regarded as the origin of Chinese literature and has a prolonged impact on Chinese culture, aesthetics, and morality. In this work, we have analyzed the 305 poems in The Book of Songs from different dimensions. We aim to learn how various poetic imageries connect abstract themes and subjective emotions at the micro level, and how the poems connect people today and ancestors to understand the universal, everlasting, and poetical human lives at the macro level.", "IdName": "wang2021explore", "Citation": "", "Keywords": ""}, {"Name": "Save It for the\" Hot\" Day: An LLM-Empowered Visual Analytics System for Heat Risk Management", "Authors": ["Haobo Li", "Wong Kam-Kwai", "Yan Luo", "Juntong Chen", "Chengzhong Liu", "Yaxuan Zhang", "Alexis Kai Hon Lau", "Huamin Qu", "Dongyu Liu"], "Sources": "arXiv preprint arXiv:2406.03317", "PublishedYears": "2024", "Doi": "", "Abstracts": "The escalating frequency and intensity of heat-related climate events, particularly heatwaves, emphasize the pressing need for advanced heat risk management strategies. Current approaches, primarily relying on numerical models, face challenges in spatial-temporal resolution and in capturing the dynamic interplay of environmental, social, and behavioral factors affecting heat risks. This has led to difficulties in translating risk assessments into effective mitigation actions. Recognizing these problems, we introduce a novel approach leveraging the burgeoning capabilities of Large Language Models (LLMs) to extract rich and contextual insights from news reports. We hence propose an LLM-empowered visual analytics system, Havior, that integrates the precise, data-driven insights of numerical models with nuanced news report information. This hybrid approach enables a more comprehensive assessment of heat risks and better identification, assessment, and mitigation of heat-related threats. The system incorporates novel visualization designs, such as \"thermoglyph\" and news glyph, enhancing intuitive understanding and analysis of heat risks. The integration of LLM-based techniques also enables advanced information retrieval and semantic knowledge extraction that can be guided by experts' analytics needs. Our case studies on two cities that faced significant heatwave events and interviews with five experts have demonstrated the usefulness of our system in providing in-depth and actionable insights for heat risk management.", "IdName": "li2024save", "Citation": "", "Keywords": ""}, {"Name": "NFTracer: Tracing NFT Impact Dynamics in Transaction-flow Substitutive Systems with Visual Analytics", "Authors": ["Yifan Cao", "Qing Shi", "Lue Shen", "Kani Chen", "Yang Wang", "Wei Zeng", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Impact dynamics are crucial for estimating the growth patterns of NFT projects by tracking the diffusion and decay of their relative appeal among stakeholders. Machine learning methods for impact dynamics analysis are incomprehensible and rigid in terms of their interpretability and transparency, whilst stakeholders require interactive tools for informed decision-making. Nevertheless, developing such a tool is challenging due to the substantial, heterogeneous NFT transaction data and the requirements for flexible, customized interactions. To this end, we integrate intuitive visualizations to unveil the impact dynamics of NFT projects. We first conduct a formative study and summarize analysis criteria, including substitution mechanisms, impact attributes, and design requirements from stakeholders. Next, we propose the Minimal Substitution Model to simulate substitutive systems of NFT projects that can be feasibly?\u2026", "IdName": "cao2024nftracer", "Citation": "", "Keywords": ""}, {"Name": "Exploring Stage Lighting Education in Metaverse", "Authors": ["Wai Tong", "Meng Xia", "Huamin Qu"], "Sources": "Extended Abstracts of the CHI Conference on Human Factors in Computing?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": " This paper investigates stage lighting education in the metaverse from a practical perspective. We conducted participatory design with practitioners and stakeholders from a local university to develop a VR-based stage lighting system for the Technical Theater Arts course. Over six months, we derived a list of design requirements (e.g., Level of realism serves the purpose of learning) and developed a prototype VR system for stage lighting education. Our contributions include the establishment of design requirements for stage lighting education in the metaverse, the development of a prototype system, and insights from integrating VR in course development. This research paves the way for further exploration and refinement of VR applications in educational settings.", "IdName": "tong2024exploring", "Citation": "", "Keywords": ""}, {"Name": "OutlineSpark: Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines", "Authors": ["Fengjie Wang", "Yanna Lin", "Leni Yang", "Haotian Li", "Mingyang Gu", "Min Zhu", "Huamin Qu"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Computational notebooks are widely utilized for exploration and analysis. However, creating slides to communicate analysis results from these notebooks is quite tedious and time-consuming. Researchers have proposed automatic systems for generating slides from notebooks, which, however, often do not consider the process of users conceiving and organizing their messages from massive code cells. Those systems ask users to go directly into the slide creation process, which causes potentially ill-structured slides and burdens in further refinement. Inspired by the common and widely recommended slide creation practice: drafting outlines first and then adding concrete content, we introduce OutlineSpark, an AI-powered slide creation tool that generates slides from a slide outline written by the user. The tool automatically retrieves relevant notebook cells based on the outlines and converts them into slide content?\u2026", "IdName": "wang2024outlinespark", "Citation": "", "Keywords": ""}, {"Name": "VAID: Indexing View Designs in Visual Analytics System", "Authors": ["Lu Ying", "Aoyu Wu", "Haotian Li", "Zikun Deng", "Ji Lan", "Jiang Wu", "Yong Wang", "Huamin Qu", "Dazhen Deng", "Yingcai Wu"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Visual analytics (VA) systems have been widely used in various application domains. However, VA systems are complex in design, which imposes a serious problem: although the academic community constantly designs and implements new designs, the designs are difficult to query, understand, and refer to by subsequent designers. To mark a major step forward in tackling this problem, we index VA designs in an expressive and accessible way, transforming the designs into a structured format. We first conducted a workshop study with VA designers to learn user requirements for understanding and retrieving professional designs in VA systems. Thereafter, we came up with an index structure VAID to describe advanced and composited visualization designs with comprehensive labels about their analytical tasks and visual designs. The usefulness of VAID was validated through user studies. Our work opens new?\u2026", "IdName": "ying2024vaid", "Citation": "", "Keywords": ""}, {"Name": "Dynamic Typography: Bringing Words to Life", "Authors": ["Zichen Liu", "Yihao Meng", "Hao Ouyang", "Yue Yu", "Bolin Zhao", "Daniel Cohen-Or", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2404.11614", "PublishedYears": "2024", "Doi": "", "Abstracts": "Text animation serves as an expressive medium, transforming static communication into dynamic experiences by infusing words with motion to evoke emotions, emphasize meanings, and construct compelling narratives. Crafting animations that are semantically aware poses significant challenges, demanding expertise in graphic design and animation. We present an automated text animation scheme, termed \"Dynamic Typography\", which combines two challenging tasks. It deforms letters to convey semantic meaning and infuses them with vibrant movements based on user prompts. Our technique harnesses vector graphics representations and an end-to-end optimization-based framework. This framework employs neural displacement fields to convert letters into base shapes and applies per-frame motion, encouraging coherence with the intended textual concept. Shape preservation techniques and perceptual loss regularization are employed to maintain legibility and structural integrity throughout the animation process. We demonstrate the generalizability of our approach across various text-to-video models and highlight the superiority of our end-to-end methodology over baseline methods, which might comprise separate tasks. Through quantitative and qualitative evaluations, we demonstrate the effectiveness of our framework in generating coherent text animations that faithfully interpret user prompts while maintaining readability. Our code is available at: https://animate-your-word.github.io/demo/.", "IdName": "liu2024dynamic", "Citation": "", "Keywords": ""}, {"Name": "TacPrint: Visualizing the Biomechanical Fingerprint in Table Tennis", "Authors": ["Jiachen Wang", "Ji Ma", "Zheng Zhou", "Xiao Xie", "Hui Zhang", "Yingcai Wu", "Huamin Qu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Table tennis is a sport that demands high levels of technical proficiency and body coordination from players. Biomechanical fingerprints can provide valuable insights into players' habitual movement patterns and characteristics, allowing them to identify and improve technical weaknesses. Despite the potential, few studies have developed effective methods for generating such fingerprints. To address this gap, we propose TacPrint, a framework for generating a biomechanical fingerprint for each player. TacPrint leverages machine learning techniques to extract comprehensive features from biomechanics data collected by inertial measurement units (IMU) and employs the attention mechanism to enhance model interpretability. After generating fingerprints, TacPrint provides a visualization system to facilitate the exploration and investigation of these fingerprints. In order to validate the effectiveness of the framework?\u2026", "IdName": "wang2024tacprint", "Citation": "", "Keywords": ""}, {"Name": "ADPS\u2013A Pre-screening Tool for Students with Dyslexia in Learning Traditional Chinese", "Authors": ["Ka-Yan Fung", "Kit-Yi Tang", "Tze Leung Rick Lui", "Kuen-Fung Sin", "Lik-Hang Lee", "Huamin Qu", "Shenghui Song"], "Sources": "IEEE Transactions on Learning Technologies", "PublishedYears": "2024", "Doi": "", "Abstracts": "Prescreening children for specific learning disabilities, e.g., dyslexia, is essential for effective intervention. With a quick and reliable prescreening result, special education coordinators (SENCOs) can provide students with early intervention and relieve their learning pressure. Unfortunately, due to the limited resources, many students in Hong Kong receive dyslexia assessments beyond the golden period, i.e., under the age of six. To this end, information technology could establish automatic prescreening tools to address this issue. However, dyslexia prescreening for children learning Chinese is challenging due to the lack of sound\u2013script correlation in Chinese. In this article, an automatic dyslexia prescreening system (ADPS) is developed to provide a quick test to identify at-risk children. Through a two-stage approach, we first develop a gamified tool based on linguistic characteristics and then evaluate the result by?\u2026", "IdName": "fung2024adps", "Citation": "", "Keywords": ""}, {"Name": "Generating Virtual Reality Stroke Gesture Data from Out-of-Distribution Desktop Stroke Gesture Data", "Authors": ["Lin-Ping Yuan", "Boyu Li", "Jindong Wang", "Huamin Qu", "Wei Zeng"], "Sources": "2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2024", "Doi": "", "Abstracts": "This paper exploits ubiquitous desktop interaction data as an input source for generating virtual reality (VR) interaction data, which can benefit tasks like user behavior analysis and experience enhancement. Time-varying stroke gestures are selected as the primary focus because of their prevalence across various applications and their diverse patterns. The commonalities (e.g., features like velocity and curvature) between desktop and VR strokes allow the generation of additional dimensions (e.g., z vectors) in VR strokes. However, distribution shifts exist between different interaction environments (i.e., desktop vs. VR), and within the same interaction environment for different strokes by various users, making it challenging to build models capable of generalizing to unseen distributions. To address the challenges, we formulate the problem of generating VR strokes from desktop strokes as a conditional time series?\u2026", "IdName": "yuan2024generating", "Citation": "", "Keywords": ""}, {"Name": "Humanoid robot-empowered language learning based on self-determination theory", "Authors": ["Ka Yan Fung", "Lik Hang Lee", "Kuen Fung Sin", "Shenghui Song", "Huamin Qu"], "Sources": "Education and Information Technologies", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the ability to provide feedback and assistance, humanoid educational robots have been proven effective in assisting students to overcome learning challenges and enhancing individual learning outcomes. However, the strength of humanoid robots in promoting social and emotional skills has not been well investigated. Socially supportive behaviour can contribute more to students\u2019 learning engagement than knowledge transfer. This study focuses on the design of humanoid robots to engage students from functional and affective perspectives. To this end, a pilot test is conducted on 64 primary school students in Hong Kong, comprising a control group (N?=?33) and an experimental group (N?=?31). Questionnaires, observations, and language proficiency test are done to ensure the validity of the findings. The results show that the experimental group, which learned with the humanoid robots, significantly?\u2026", "IdName": "fung2024humanoid", "Citation": "", "Keywords": ""}, {"Name": "TrafPS: A Shapley-based Visual Analytics Approach to Interpret Traffic", "Authors": ["Zezheng Feng", "Yifan Jiang", "Hongjun Wang", "Zipei Fan", "Yuxin Ma", "Shuang-Hua Yang", "Huamin Qu", "Xuan Song"], "Sources": "arXiv preprint arXiv:2403.04812", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent achievements in deep learning (DL) have shown its potential for predicting traffic flows. Such predictions are beneficial for understanding the situation and making decisions in traffic control. However, most state-of-the-art DL models are considered \"black boxes\" with little to no transparency for end users with respect to the underlying mechanisms. Some previous work tried to \"open the black boxes\" and increase the interpretability of how predictions are generated. However, it still remains challenging to handle complex models on large-scale spatio-temporal data and discover salient spatial and temporal patterns that significantly influence traffic flows. To overcome the challenges, we present TrafPS, a visual analytics approach for interpreting traffic prediction outcomes to support decision-making in traffic management and urban planning. The measurements, region SHAP and trajectory SHAP, are proposed to quantify the impact of flow patterns on urban traffic at different levels. Based on the task requirement from the domain experts, we employ an interactive visual interface for multi-aspect exploration and analysis of significant flow patterns. Two real-world case studies demonstrate the effectiveness of TrafPS in identifying key routes and decision-making support for urban planning.", "IdName": "feng2024trafps", "Citation": "", "Keywords": ""}, {"Name": "HoLens: A Visual Analytics Design for Higher-order Movement Modeling and Visualization", "Authors": ["Zezheng Feng", "Fang Zhu", "Hongjun Wang", "Jianing Hao", "ShuangHua Yang", "Wei Zeng", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2403.03822", "PublishedYears": "2024", "Doi": "", "Abstracts": "Higher-order patterns reveal sequential multistep state transitions, which are usually superior to origin-destination analysis, which depicts only first-order geospatial movement patterns. Conventional methods for higher-order movement modeling first construct a directed acyclic graph (DAG) of movements, then extract higher-order patterns from the DAG. However, DAG-based methods heavily rely on the identification of movement keypoints that are challenging for sparse movements and fail to consider the temporal variants that are critical for movements in urban environments. To overcome the limitations, we propose HoLens, a novel approach for modeling and visualizing higher-order movement patterns in the context of an urban environment. HoLens mainly makes twofold contributions: first, we design an auto-adaptive movement aggregation algorithm that self-organizes movements hierarchically by considering spatial proximity, contextual information, and temporal variability; second, we develop an interactive visual analytics interface consisting of well-established visualization techniques, including the H-Flow for visualizing the higher-order patterns on the map and the higher-order state sequence chart for representing the higher-order state transitions. Two real-world case studies manifest that the method can adaptively aggregate the data and exhibit the process of how to explore the higher-order patterns by HoLens. We also demonstrate our approach's feasibility, usability, and effectiveness through an expert interview with three domain experts.", "IdName": "feng2024holens", "Citation": "", "Keywords": ""}, {"Name": "VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality", "Authors": ["Wai Tong", "Kento Shigyo", "Lin-Ping Yuan", "Mingming Fan", "Ting-Chuen Pong", "Huamin Qu", "Meng Xia"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the rise of short-form video platforms and the increasing availability of data, we see the potential for people to share short-form videos embedded with data in situ (e.g., daily steps when running) to increase the credibility and expressiveness of their stories. However, creating and sharing such videos in situ is challenging since it involves multiple steps and skills (e.g., data visualization creation and video editing), especially for amateurs. By conducting a formative study (N=10) using three design probes, we collected the motivations and design requirements. We then built VisTellAR, a mobile AR authoring tool, to help amateur video creators embed data visualizations in short-form videos in situ. A two-day user study shows that participants (N=12) successfully created various videos with data visualizations in situ and they confirmed the ease of use and learning. AR pre-stage authoring was useful to assist people?\u2026", "IdName": "tong2024vistellar", "Citation": "", "Keywords": ""}, {"Name": "Towards an Exploratory Visual Analytics System for Griefer Identification in MOBA Games", "Authors": ["Zixin Chen", "Shiyi Liu", "Zhihua Jin", "Gaoping Huang", "Yang Chao", "Zhenchuan Yang", "Quan Li", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2312.14401", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multiplayer Online Battle Arenas (MOBAs) have gained a significant player base worldwide, generating over two billion US dollars in annual game revenue. However, the presence of griefers, who deliberately irritate and harass other players within the game, can have a detrimental impact on players' experience, compromising game fairness and potentially leading to the emergence of gray industries. Unfortunately, the absence of a standardized criterion, and the lack of high-quality labeled and annotated data has made it challenging to detect the presence of griefers. Given the complexity of the multivariant spatiotemporal data for MOBA games, game developers heavily rely on manual review of entire game video recordings to label and annotate griefers, which is a time-consuming process. To alleviate this issue, we have collaborated with a team of game specialists to develop an interactive visual analysis interface, called GrieferLens. It overviews players' behavior analysis and synthesizes their key match events. By presenting multiple views of information, GrieferLens can help the game design team efficiently recognize and label griefers in MOBA games and build up a foundation for creating a more enjoyable and fair gameplay environment.", "IdName": "chen2023towards", "Citation": "", "Keywords": ""}, {"Name": "System and A Method for Analyzing A Video", "Authors": ["Xingbo Wang", "Yong Wang", "WU Aoyu", "Huamin Qu"], "Sources": "US Patent App. 17/829", "PublishedYears": "2023", "Doi": "", "Abstracts": "The invention relates to a computer implemented method and system for analyzing a video. The method comprises the steps of receiving, via a receiving module, a video data comprising a series of images showing a subject; extracting, via an extracting module, a transcript derived from an audio data associated with the video data; aligning, via an aligning module, the series of images of the video data with the transcript derived from the audio data associated with the video data based on timestamps derived from the video data; analyzing, via an analyzing module, gestures of the subject from the series of images, comprising the steps of: identifying a plurality of reference points from each of the series of images showing the subject; segmenting the series of images in accordance with one or more selected texts comprising the transcript; identifying a defined gesture type for each of the segmented images based on?\u2026", "IdName": "wang2023system", "Citation": "", "Keywords": ""}, {"Name": "Knowledge Compass: A Question Answering System Guiding Students with Follow-Up Question Recommendations", "Authors": ["Rui Sheng", "Leni Yang", "Haotian Li", "Yan Luo", "Ziyang Xu", "Zhilan Zhou", "David Gotz", "Huamin Qu"], "Sources": "Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Pedagogical question-answering (QA) systems have been utilized for providing individual support in online learning courses. However, existing systems often neglect the education practice of guiding and encouraging students to think of relevant questions for deeper and more comprehensive learning. To address this gap, we introduce Knowledge Compass, an interactive QA system. The system can recommend follow-up questions that provide potential further explorations of the topics students ask about. Additionally, the system applies a course outline visualization and a set of interactive features for students to track the relationship between their questions and the course content.", "IdName": "sheng2023knowledge", "Citation": "", "Keywords": ""}, {"Name": "NeighViz: Towards Better Understanding of Neighborhood Effects on Social Groups with Spatial Data", "Authors": ["Yue Yu", "Yifang Wang", "Qisen Yang", "Di Weng", "Yongjun Zhang", "Xiaogang Wu", "Yingcai Wu", "Huamin Qu"], "Sources": "2023 IEEE Visualization in Data Science (VDS)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Understanding how local environments influence individual behaviors, such as voting patterns or suicidal tendencies, is crucial in social science to reveal and reduce spatial disparities and promote social well-being. With the increasing availability of large-scale individual-level census data, new analytical opportunities arise for social scientists to explore human behaviors (e.g., political engagement) among social groups at a fine-grained level. However, traditional statistical methods mostly focus on global, aggregated spatial correlations, which are limited to understanding and comparing the impact of local environments (e.g., neighborhoods) on human behaviors among social groups. In this study, we introduce a new analytical framework for analyzing multi-variate neighborhood effects between social groups. We then propose NeighViz, an interactive visual analytics system that helps social scientists explore?\u2026", "IdName": "yu2023neighviz", "Citation": "", "Keywords": ""}, {"Name": "NFTeller: Dual-centric Visual Analytics for Assessing Market Performance of NFT Collectibles", "Authors": ["Yifan Cao", "Meng Xia", "Kento Shigyo", "Furui Cheng", "Qianhang Yu", "Xingxing Yang", "Yang Wang", "Wei Zeng", "Huamin Qu"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Non-fungible tokens (NFTs) have recently gained widespread popularity as an alternative investment. However, the lack of assessment criteria has caused intense volatility in NFT marketplaces. Identifying attributes impacting the market performance of NFT collectibles is crucial but challenging due to the massive amount of heterogeneous and multi-modal data in NFT transactions, e.g., social media texts, numerical trading data, and images. To address this challenge, we introduce an interactive dual-centric visual analytics system, NFTeller, to facilitate users\u2019 analysis. First, we collaborate with five domain experts to distill static and dynamic impact attributes and collect relevant data. Next, we derive six analysis tasks and develop NFTeller to present the evolution of NFT transactions and correlate NFTs\u2019 market performance with impact attributes. Notably, we create an augmented chord diagram with a radial stacked?\u2026", "IdName": "cao2023nfteller", "Citation": "", "Keywords": ""}, {"Name": "ActorLens: Visual Analytics for High-level Actor Identification in MOBA Games", "Authors": ["Zhihua Jin", "Gaoping Huang", "Zixin Chen", "Shiyi Liu", "Yang Chao", "Zhenchuan Yang", "Quan Li", "Huamin Qu"], "Sources": "arXiv preprint arXiv:2307.09699", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multiplayer Online Battle Arenas (MOBAs) have garnered a substantial player base worldwide. Nevertheless, the presence of noxious players, commonly referred to as \"actors\", can significantly compromise game fairness by exhibiting negative behaviors that diminish their team's competitive edge. Furthermore, high-level actors tend to engage in more egregious conduct to evade detection, thereby causing harm to the game community and necessitating their identification. To tackle this urgent concern, a partnership was formed with a team of game specialists from a prominent company to facilitate the identification and labeling of high-level actors in MOBA games. We first characterize the problem and abstract data and events from the game scene to formulate design requirements. Subsequently, ActorLens, a visual analytics system, was developed to exclude low-level actors, detect potential high-level actors, and assist users in labeling players. ActorLens furnishes an overview of players' status, summarizes behavioral patterns across three player cohorts (namely, focused players, historical matches of focused players, and matches of other players who played the same hero), and synthesizes key match events. By incorporating multiple views of information, users can proficiently recognize and label high-level actors in MOBA games. We conducted case studies and user studies to demonstrate the efficacy of the system.", "IdName": "jin2023actorlens", "Citation": "", "Keywords": ""}, {"Name": "HAPI explorer: comprehension, discovery, and explanation on history of ML APIs", "Authors": ["Lingjiao Chen", "Zhihua Jin", "Sabri Eyuboglu", "Huamin Qu", "Christopher R\u00e9", "Matei Zaharia", "James Zou"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Machine learning prediction APIs offered by Google, Microsoft, Amazon, and many other providers have been continuously adopted in a plethora of applications, such as visual object detection, natural language comprehension, and speech recognition. Despite the importance of a systematic study and comparison of different APIs over time, this topic is currently under-explored because of the lack of data and user-friendly exploration tools. To address this issue, we present HAPI Explorer (History of API Explorer), an interactive system that offers easy access to millions of instances of commercial API applications collected in three years, prioritize attention on user-defined instance regimes, and explain interesting patterns across different APIs, subpopulations, and time periods via visual and natural languages. HAPI Explorer can facilitate further comprehension and exploitation of ML prediction APIs.", "IdName": "chen2023hapi", "Citation": "", "Keywords": ""}, {"Name": "System and method for visual analysis of emotional coherence in videos", "Authors": ["Haipeng Zeng", "Xingbo Wang", "WU Aoyu", "Yong Wang", "Quan Li", "Huamin Qu"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "A computer implemented method and system processing a video signal. The method comprises comprising the steps of: detecting a human face displayed in the video signal and extracting physiological, biological, or behavior state information from the displayed face at a first level of granularity of the video signal; processing any two or more of:(i) a script derived from or associated with the video signal to extract language tone information from said script at a first level of granularity of the script;(ii) an audio signal derived from or associated with the video signal to derive behavior state information from said audio signal at a first level of granularity of the audio signal;(iii) a video image derived from the video signal to detect one or more human gestures of the person whose face is displayed in the video signal; and merging said physiological, biological, or behavior state information extracted from the displayed face in?\u2026", "IdName": "zeng2022system", "Citation": "", "Keywords": ""}, {"Name": "Generating layout designs from high-level specifications", "Authors": ["Xiao-Yu Wang", "Kang Zhang"], "Sources": "Automation in Construction 119", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper presents a framework for the automatic generation of floor plans based on adjacency relations among rooms. The adjacency can be generated from user-specified design requirements using a graph grammar formalism. We propose a set of grammar rules to generate graphs that represent adjacency relationships. Our solution overcomes the limitation of previous approaches that generate only rectangular floor plans. We define a set of constraints, such as plan size, room orientation and aspect ratio, for specifying the desired floor plans; and present a set of algorithms for placing rectangular or non-rectangular rooms and for generating non-rectangular floor plan boundaries. We demonstrate that our method can generate varied floor plans from user-specified design requirements.", "IdName": "wang2020generating", "Citation": "", "Keywords": ""}, {"Name": "The influence of font scale on semantic expression of word cloud", "Authors": ["Lu Yang", "Jie Li", "Wenhuan Lu", "Yi Chen", "Kang Zhang", "Yan Li"], "Sources": "Journal of Visualization 23", "PublishedYears": "2020", "Doi": "", "Abstracts": " Abstract Word cloud is a common text visualization technique. With the ability of presenting the keywords of a document in a direct way, it has been widely applied in many real-world situations. However, to better represent the main idea of a document, a critical aspect for word cloud design is to set an appropriate font size to facilitate semantic expression. In this paper, we explore the influence of font scale on semantic expression and evaluate font size of word cloud in a more systematic approach. To quantify semantic information of a document, we utilize an LDA ensemble-based method to support interactive selection of topics and obtain the semantics of documents in a scientific way. We conducted two pilot studies to decide important attributes of word clouds for the formal study. Through formal study 1, we find that the scale affects the semantic expression of word cloud, including accuracy, time and confidence in?\u2026", "IdName": "yang2020influence", "Citation": "", "Keywords": ""}, {"Name": "Visual complexity of shapes: a hierarchical perceptual learning model", "Authors": ["Lingchen Dai", "Kang Zhang", "Xianjun Sam Zheng", "Ralph R Martin", "Yina Li", "Jinhui Yu"], "Sources": "The Visual Computer", "PublishedYears": "2022", "Doi": "", "Abstracts": " Understanding how people perceive the visual complexity of shapes has important theoretical as well as practical implications. One school of thought, driven by information theory, focuses on studying the local features that contribute to the perception of visual complexity. Another school, in contrast, emphasizes the impact of global characteristics of shapes on perceived complexity. Inspired by recent discoveries in neuroscience, our model considers both local features of shapes: edge lengths and vertex angles, and global features: concaveness, and is in 92% agreement with human subjective ratings of shape complexity. The model is also consistent with the hierarchical perceptual learning theory, which explains how different layers of neurons in the visual system act together to yield a perception of visual shape complexity. ", "IdName": "dai2022visual", "Citation": "", "Keywords": ""}, {"Name": "Parametric modeling and generation of mandala thangka patterns", "Authors": ["Jiajing Zhang", "Kang Zhang", "Ren Peng", "Jinhui Yu"], "Sources": "Journal of Computer Languages 58", "PublishedYears": "2020", "Doi": "", "Abstracts": "The mandala thangka, as a religious art in Tibetan Buddhism, is an invaluable cultural and artistic heritage. However, drawing a mandala pattern of thangka style is both time- and effort-consuming and requires mastery due to intricate details. Retaining and digitizing this heritage is an unresolved research challenge to date. In this paper, we propose a parametric approach to model and generate mandala thangka patterns to address this issue. Specifically, we construct parameterized models of three stylistic elements used in the interior mandalas of Nyingma school in Tibetan Buddhism according to their geometric features, namely the star, crescent, and lotus flower motifs. Varieties of interior mandala patterns are successfully generated using these parameterized motifs based on the hierarchical structures observed from hand-drawn mandalas. Moreover, we design a user interaction tool which can flexibly generate?\u2026", "IdName": "zhang2020parametric", "Citation": "", "Keywords": ""}, {"Name": "A graph grammar approach to the design and validation of floor plans", "Authors": ["Xiao-Yu Wang", "Yu-Feng Liu", "Kang Zhang"], "Sources": "The Computer Journal", "PublishedYears": "2020", "Doi": "", "Abstracts": " Researchers have proposed many approaches to generate floor plans using shape grammars. None of them, however, testifies the semantic relations among rooms. This paper presents a generic approach for grammar specification, grammar induction, validation, and design generation of house floor plans using their path graphs based on the reserved graph grammar (RGG) formalism. In our approach, the connectivity of a floor plan is analyzed by user-specified graph grammar transformation rules, also known as productions. Floor plans of houses in different styles share common attributes while retaining specific features. By identifying these features, our approach validates floor plans in different styles with user-specified graph productions. A graph grammar induction engine is also introduced to assist designers by automatically inferring graph productions from an input graph set. In addition, the derivation?\u2026", "IdName": "wang2020graph", "Citation": "", "Keywords": ""}, {"Name": "Measuring and evaluating the visual complexity of Chinese ink paintings", "Authors": ["Zhen-Bao Fan", "Yi-Na Li", "Kang Zhang", "Jinhui Yu", "Mao Lin Huang"], "Sources": "The Computer Journal", "PublishedYears": "2022", "Doi": "", "Abstracts": " Painters arrange white space in contrast with chromatic space composed of strokes. This research measures white space, color complexity and stroke density in Chinese ink paintings and examines how these attributes influence the paintings\u2019 perceived complexity. Empirical evidence from 21 well-known modern Chinese artists\u2019 ink paintings shows that white space decreases paintings\u2019 complexity, while chromatic space and stroke density increase complexity. We also reveal that a large rate of white space guides the viewers\u2019 attention on chromatic space and enhances the impacts of color complexity and stroke density on perceived complexity. An eye-tracker measures viewers\u2019 elaboration duration on each painting, which provides consistent evidence to validate our conclusion based on subjective reported visual complexity. Our research provides insights into the rhetorical role of white space in sensory?\u2026", "IdName": "fan2022measuring", "Citation": "", "Keywords": ""}, {"Name": "An end-to-end model for chinese calligraphy generation", "Authors": ["Peichi Zhou", "Zipeng Zhao", "Kang Zhang", "Chen Li", "Changbo Wang"], "Sources": "Multimedia Tools and Applications 80", "PublishedYears": "2021", "Doi": "", "Abstracts": " A Chinese calligraphy copybook usually has a limited number of Chinese characters, far from a whole set of characters needed for typesetting. Therefore, there is a need to develop complete sets of Chinese calligraphy libraries for well-known calligrapher styles. This paper proposes an end-to-end network for character generation based on specific calligraphy styles. Specifically, a style transfer network is designed to transfer the style of characters, and a content supplement network is designed to capture the details of stylish strokes. Our model can generate high-quality calligraphy images without manually annotating data. To verify the generated calligraphy styles, a new dataset is constructed for experimental comparison between our method and two other baseline methods. Moreover, a user study is conducted to evaluate our generated calligraphy from a visual perspective. When the experiment?\u2026", "IdName": "zhou2021end", "Citation": "", "Keywords": ""}, {"Name": "Visual order of Chinese ink paintings", "Authors": ["Zhen-Bao Fan", "Kang Zhang"], "Sources": "Visual Computing for Industry", "PublishedYears": "2020", "Doi": "", "Abstracts": " Visual order is one of the key factors influencing the aesthetic judgment of artworks. This paper reports the results of evaluating the influence of extracted features on visual order in Chinese ink paintings, using a regression model. We use nine contemporary artists\u2019 paintings as examples and extract features related to the visual order of their paintings. A questionnaire survey is conducted to collect people\u2019s rating scores on the visual order. Via regression modeling, our research analyzes the significance of each feature and validates the influences of the features on the visual order.", "IdName": "fan2020visual", "Citation": "", "Keywords": ""}, {"Name": "Ultrahigh energy-dissipation and multifunctional auxetic polymeric foam inspired by balloon art", "Authors": ["Kang Zhang", "Xiyao Zhang", "Qiang Gao", "Meishan Chan", "Shilong Zhang", "Jifan Li", "Wei-Hsin Liao"], "Sources": "Composites Part A: Applied Science and Manufacturing 167", "PublishedYears": "2023", "Doi": "", "Abstracts": "Herein, we report a novel strategy for making ultrahigh energy-dissipation auxetic foam inspired by balloon art. As revealed by finite element analysis of balloon deformation evolution in polymer matrix, spherical balloons will turn to reentrant shape when compressed uniaxially in polymer matrix with large Poisson\u2019s ratio. By utilizing the know-how, auxetic silicone foam (ASF) was successfully developed through a well-designed foaming-compression-curing process. ASF shows ultrahigh energy dissipation capability of \uff5e2000?kJ/m3, which is over 80 times higher than conventional auxetic polyurethane foams. Moreover, ASF has low water absorption and high chemical and temperature resistance, allowing it to be used in harsh circumstances. Additionally, ASF is a thermal-responsive material that can expand at high temperature and return to its initial state when cooling down. Our work provides routes towards?\u2026", "IdName": "zhang2023ultrahigh", "Citation": "", "Keywords": ""}, {"Name": "Interactive influences of color attributes on color perception bias", "Authors": ["Huan Yang", "Yi-Na Li", "Kang Zhang"], "Sources": "The Visual Computer 36", "PublishedYears": "2020", "Doi": "", "Abstracts": " Graphic user interfaces and information visualization use color to represent qualitative or quantitative information. The interaction between adjacent colors leads to perceptual bias, known as simultaneous color contrast, and implicitly distort the understanding of visualized information presentation. To investigate the effect of simultaneous color contrast, we conduct two empirical experiments, in both theoretical and application settings, using a set of random target/proximal combinations of colors in the CIEL*a*b* color space. The perception bias of a target color, induced by its surround, is measured. Linear regression analysis indicates that both a high saturation of the proximal color and a high a*/low b* value of the target color cause a strong simultaneous color contrast (i.e., high perception bias). A moderating effect analysis indicates that a* value/b* value of the target color moderates the influence of the?\u2026", "IdName": "yang2020interactive", "Citation": "", "Keywords": ""}, {"Name": "A comparative study of oil paintings and Chinese ink paintings on composition", "Authors": ["Zhen-Bao Fan", "Yi-Xuan Zhu", "Slobodan Markovi?", "Kang Zhang"], "Sources": "The Visual Computer", "PublishedYears": "2023", "Doi": "", "Abstracts": "In this study, we compare Western oil paintings and Chinese ink paintings on their composition, by extracting and computing 28 composition features of the paintings, including visual balance and relationships between different regions (segments). Among the extracted segments, we compute average distance and rule-based features based on three layout rules, rule of thirds, golden mean and golden triangle. A total of 2253 paintings including 1138 oil paintings and 1115 Chinese ink paintings are collected. By comparing the results of the features on these paintings, our study investigates the difference and similarity between the two types of paintings on composition. Their composition designs are similar in visual balance and their tendency of composing along two diagonal lines, but are fairly different on many other aspects. For example, oil paintings are inclined to place objects on the bottom horizontal dividing?\u2026", "IdName": "fan2023comparative", "Citation": "", "Keywords": ""}, {"Name": "Coordinate graph grammar for the specification of spatial graphs", "Authors": ["Yufeng Liu", "Xiaoqin Zeng", "Kang Zhang", "Yang Zou"], "Sources": "The Computer Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": " As a two-dimensional formal method, graph grammar is widely used in defining various visual programming languages. This paper presents a new graph grammar formalism called coordinate graph grammar (CGG). CGG is extended from the edge-based graph grammar (EGG) by introducing the spatial mechanism into the theoretical framework, which consists of continuous coordinate graph grammar (cCGG) and discrete coordinate graph grammar (dCGG). By combining quantitative and qualitative spatial semantics in one framework, CGG provides strong expressiveness and flexibility for specifying various spatial graphs. This paper focuses on several important issues on the new formalism. First, the theoretical framework of CGG is given. Second, two matching algorithms for cCGG and dCGG are proposed, which use the spatial relationships between nodes to narrow down the search space during parsing?\u2026", "IdName": "liu2021coordinate", "Citation": "", "Keywords": ""}, {"Name": "The computer-based generation of fonts in the style of Kandinsky", "Authors": ["Kang Zhang", "Jinhui Yu"], "Sources": "Leonardo", "PublishedYears": "2021", "Doi": "", "Abstracts": " This article presents a general framework for programmed automatic generation of artistic fonts. By parameterizing various font attributes, such as color and aspect ratio, the authors are able to generate artistically styled fonts in almost unlimited variations to suit any type of design requirement. The authors demonstrate their experiments on generating fonts in an abstract style similar to Kandinsky's, built on a collection of the artist's styled patterns. The approach generates fonts composed of vector strokes and is thus highly scalable, limited only by the computer hardware.", "IdName": "zhang2021computer", "Citation": "", "Keywords": ""}, {"Name": "Transformation of portraits to Picasso\u2019s cubism style", "Authors": ["Guanyu Lian", "Kang Zhang"], "Sources": "The Visual Computer", "PublishedYears": "2020", "Doi": "", "Abstracts": " This paper presents an approach to the transformation of portrait photographs to Picasso\u2019s cubism style using deep learning and image processing techniques. We obtain the side-view face by rotating the face model constructed from a frontal portrait image 90 and then replace the left half of the portrait by the side-view face. Our approach is applicable to online transformation of selfie photographs and potentially extendable to broader categories of images and artistic styles.", "IdName": "lian2020transformation", "Citation": "", "Keywords": ""}, {"Name": "The Contemporary Art of Image Search: Iterative User Intent Expansion via Vision-Language Model", "Authors": ["Yilin Ye", "Qian Zhu", "Shishi Xiao", "Kang Zhang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2312.01656", "PublishedYears": "2023", "Doi": "", "Abstracts": "Image search is an essential and user-friendly method to explore vast galleries of digital images. However, existing image search methods heavily rely on proximity measurements like tag matching or image similarity, requiring precise user inputs for satisfactory results. To meet the growing demand for a contemporary image search engine that enables accurate comprehension of users' search intentions, we introduce an innovative user intent expansion framework. Our framework leverages visual-language models to parse and compose multi-modal user inputs to provide more accurate and satisfying results. It comprises two-stage processes: 1) a parsing stage that incorporates a language parsing module with large language models to enhance the comprehension of textual inputs, along with a visual parsing module that integrates an interactive segmentation module to swiftly identify detailed visual elements within images; and 2) a logic composition stage that combines multiple user search intents into a unified logic expression for more sophisticated operations in complex searching scenarios. Moreover, the intent expansion framework enables users to perform flexible contextualized interactions with the search results to further specify or adjust their detailed search intents iteratively. We implemented the framework into an image search system for NFT (non-fungible token) search and conducted a user study to evaluate its usability and novel properties. The results indicate that the proposed framework significantly improves users' image search experience. Particularly the parsing and contextualized interactions prove useful in allowing users to?\u2026", "IdName": "ye2023contemporary", "Citation": "", "Keywords": ""}, {"Name": "Human Aesthetic Preference-Based Large Text-to-Image Model Personalization: Kandinsky Generation as an Example", "Authors": ["Aven-Le Zhou", "Yu-Ao Wang", "Wei Wu", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2402.06389", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the advancement of neural generative capabilities, the art community has actively embraced GenAI (generative artificial intelligence) for creating painterly content. Large text-to-image models can quickly generate aesthetically pleasing outcomes. However, the process can be non-deterministic and often involves tedious trial-and-error, as users struggle with formulating effective prompts to achieve their desired results. This paper introduces a prompting-free generative approach that empowers users to automatically generate personalized painterly content that incorporates their aesthetic preferences in a customized artistic style. This approach involves utilizing ``semantic injection'' to customize an artist model in a specific artistic style, and further leveraging a genetic algorithm to optimize the prompt generation process through real-time iterative human feedback. By solely relying on the user's aesthetic evaluation and preference for the artist model-generated images, this approach creates the user a personalized model that encompasses their aesthetic preferences and the customized artistic style.", "IdName": "zhou2024human", "Citation": "", "Keywords": ""}, {"Name": "A survey of recent practice of Artificial Life in visual art", "Authors": ["Zi-Wei Wu", "Huamin Qu", "Kang Zhang"], "Sources": "Artificial Life", "PublishedYears": "2024", "Doi": "", "Abstracts": "Nowadays, interdisciplinary fields between Artificial Life, artificial intelligence, computational biology, and synthetic biology are increasingly emerging into public view. It is necessary to reconsider the relations between the material body, identity, the natural world, and the concept of life. Art is known to pave the way to exploring and conveying new possibilities. This survey provides a literature review on recent works of Artificial Life in visual art during the past 40 years, specifically in the computational and software domain. Having proposed a set of criteria and a taxonomy, we briefly analyze representative artworks of different categories. We aim to provide a systematic overview of how artists are understanding nature and creating new life with modern technology.", "IdName": "wu2024survey", "Citation": "", "Keywords": ""}, {"Name": "PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering", "Authors": ["Rong Huang", "Hai-Chuan Lin", "Chuanzhang Chen", "Kang Zhang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2401.17120", "PublishedYears": "2024", "Doi": "", "Abstracts": "Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI) enable automated generation of landscape renderings, the end-to-end methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of GAI models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and second, illustration module converts scene layouts into realistic landscape renderings using a fine-tuned low-rank adaptation diffusion model. PlantoGraphy has undergone a series of performance evaluations and user studies, demonstrating its effectiveness in landscape rendering generation and the high recognition of its interactive functionality.", "IdName": "huang2024plantography", "Citation": "", "Keywords": ""}, {"Name": "Body Cosmos: An Immersive Experience Driven by Real-Time Bio-Data", "Authors": ["Rem RunGu Lin", "Yongen Ke", "Kang Zhang"], "Sources": "2023 IEEE VIS Arts Program (VISAP)", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper presents \u201cBody Cosmos\u201d, an artwork that creates a symbiotic relationship between the human body and a simulated cosmic environment through volumetric rendering and particle system. Drawing from DICOM data to simulate the human body and nebulae, we create an interactive and dynamic virtual environment. The real-time bio-data of users, collected via heart rate sensors and EEG devices, is integrated into the visualization, fostering a personal engagement and unity within this \u2018cosmos.\u2019 Body Cosmos provokes curiosity and expands users\u2019 imagination, and deepens their understanding of life\u2019s macrocosm and microcosm. This exploratory project redefines traditional perceptions of the human body in relation to the universe, creating a unique lens to view selfhood, embodiment, and identity. As we look to the future, the system\u2019s evolution will include incorporation of more bio-data sensors, an?\u2026", "IdName": "lin2023body", "Citation": "", "Keywords": ""}, {"Name": "Shanshui Journey: AI Reproducing the Experience of Chinese \u201cLiterati\u201d Ink Paintings", "Authors": ["Aven Le Zhou", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2023", "Doi": "", "Abstracts": " The authors investigate Chinese \u201cShanshui\u201d (literally meaning mountain and water), a China-origin and East Asian ink paintings of the natural landscape, through an interactive art installation, entitled \u201cShanshui Journey.\u201d By examining Shanshui\u2019s philosophy, multiple-moving perspectives, and creation and appreciation practices, the work emphasizes motion in nature, memories, and interactive appreciation. These concepts are realized in a digitized room, where each participant\u2019s motion is captured as a line \u201csketch\u201d and transformed into an ink painting (i.e., Shanshui) via a custom neural network. Generated paintings are displayed in real-time alongside previous works, collectively termed \u201cShanshui Memories,\u201d mimicking the handscroll interaction. This new Shanshui approach aims to reproduce the Chinese literati art experience, raising awareness of the cultural heritage.", "IdName": "zhou2023shanshui", "Citation": "", "Keywords": ""}, {"Name": "Naturality: A Natural Reflection of Chinese Calligraphy", "Authors": ["Bingyuan Wang", "Kang Zhang", "Zeyu Wang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We present a machine learning-based interactive video installation powered by CLIP and diffusion models and inspired by the concept of naturality in traditional Chinese calligraphy. The artwork explores contemporary interpretations of this traditional concept through practical methods in Artificial Intelligence Generated Content (AIGC). Technically, the algorithms are based on state-of-the-art perceptual and generative models, incorporating multi-dimensional controls over text-to-image and image-to-image translation; conceptually, this real-time art installation extends the discussion brought by Xu Bing\u2019s pieces Book from the Sky and Square Word Calligraphy. The project explores the possibility of AIGC in bridging human creativity and natural randomness, as well as a shifting creative paradigm enhanced by AI knowledge, perception, and association.", "IdName": "wang2023naturality", "Citation": "", "Keywords": ""}, {"Name": "A comparative study of color between abstract paintings, oil paintings and Chinese ink paintings", "Authors": ["Zhenbao Fan", "Yixuan Zhu", "Christine Yan", "Yufan Li", "Kang Zhang"], "Sources": "Proceedings of the 15th International Symposium on Visual Information?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Color is one of the fundamental elements of paintings. This paper proposes a set of measurements for color usage in a painting, including basic color elements, color harmony templates, and spatial distribution, characterizing both global and local features of color. Applying the measurements to over 3000 abstract paintings, oil paintings and Chinese ink paintings, we are able to observe the roles of color in the three genres of paintings. We report our findings in details on the effectiveness of these measurements, which may serve as tools for classification of paintings. The work is the first of this kind and points to further investigation of color usage in other forms of art and design.", "IdName": "fan2022comparative", "Citation": "", "Keywords": ""}, {"Name": "Verification of the Instantiation and Integration of Security Patterns", "Authors": ["Tu Peng", "Shuliang Wang", "Jing Geng", "Qinsi Wang", "Yun Yang", "Kang Zhang"], "Sources": "Journal of Web Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "As software applications suffer from increasing malicious attacks, security becomes a critically important issue for software development. To avoid security problems and increase efficiency, a large software system design may reuse good security solutions for existing security patterns. While security patterns document expert solutions to common security problems and capture well-examined practices on secure software design, implementing them in a particular context (pattern instantiation) and composing them with other related patterns (pattern integration) are prone to flaws and may break expected security properties. In this paper, we present an approach to verify security patterns instantiation and integration automatically. We offer formal definitions for security pattern instantiation and integration, and establish rules to transform sequence diagrams (representing the behaviors of security patterns) to expressions?\u2026", "IdName": "peng2020verification", "Citation": "", "Keywords": ""}, {"Name": "Cursive Calligraphy in 3d and bio-Ink", "Authors": ["Rem RunGu Lin", "You Zhou", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2024", "Doi": "", "Abstracts": " This paper presents a generative approach to creating dynamic 3D cursive calligraphy by integrating motion and bio-data captured by EEG and EMG sensors with particle systems driven by vector fields. The artwork created through this method metaphorically and visually represents a calligrapher\u2019s energy, inspired by the traditional concept of qi. The authors use the term bio-ink to describe the visualization technique of this digital sculpture, which uses bio-data as parameters to control the flow and dynamism of the particles. Utilizing Unreal Engine 5, the authors create a dynamic 3D artwork that inspires further investigation into the therapeutic benefits of calligraphy, highlights the potential use of biofeedback in skill development, and paves the way for combining traditional arts with artists\u2019 life-data.", "IdName": "lin2024cursive", "Citation": "", "Keywords": ""}, {"Name": "Mixed or Misperceived Reality?", "Authors": ["Aven Le Zhou", "Lei Xi", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2405.02338", "PublishedYears": "2024", "Doi": "", "Abstracts": "\"Surrealism Me\" delves into Vil\\'em Flusser's critique of media as mediators that often distort human perception of reality through an interactive virtual-embodying MR experience. It examines the obfuscating nature of media and reveals the constructed nature of media-projected realities, prompting a reevaluation of media's role and influence on our perception.", "IdName": "steinicke2019misperception", "Citation": "", "Keywords": ""}, {"Name": "Another Body in the World: Flusserian Freedom in Mixed Reality", "Authors": ["Aven Le Zhou", "Lei Xi", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2402.10751", "PublishedYears": "2024", "Doi": "", "Abstracts": "In Flusserian view of media history, humans often misperceive the world projected by media to be the world itself, leading to a loss of freedom. This paper examines Flusserian Freedom in the context of Mixed Reality (MR) and explores how humans can recognize the obscuration of the world within the media (i.e., MR) and understand their relationship. The authors investigate the concept of playing against apparatus and deliberately alienating the perception of the projected world through an artwork titled \"Surrealism Me.\" This artwork enables the user to have another body within MR through interactive and immersive experiences based on the definition of Sense of Embodiment. The purpose of this work is to raise awareness of the domination of media and to approach Flusserian freedom within contemporary technical arrangements.", "IdName": "zhou2024another", "Citation": "", "Keywords": ""}, {"Name": "Shanshui Journey: Using AI to Reproduce the Experience of Chinese Literati Ink Paintings", "Authors": ["Aven Le Zhou", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2024", "Doi": "", "Abstracts": "The authors investigate Chinese shanshui (literally, \u201cmountain  and water\u201d), ink paintings of the natural landscape, through an  interactive art installation entitled Shanshui Journey. By examining  shanshui\u2019s philosophy, multiple moving perspectives, and creation  and appreciation practices, the work emphasizes motion in nature,  memories, and interactive appreciation. These concepts are realized  in a digitized room, where each participant\u2019s motion is captured as a  line \u201csketch\u201d and transformed into an ink painting via a custom neural  network. Generated paintings are displayed in real time alongside  previous works, collectively termed Shanshui Memories, mimicking  handscroll interaction. The authors\u2019 approach to shanshui aims to  reproduce the Chinese literati art experience, and to raise awareness of  this cultural heritage.", "IdName": "le2024shanshui", "Citation": "", "Keywords": ""}, {"Name": "Media Interpretation: Revisiting McLuhans' Laws of Media and Ant Farm", "Authors": ["Rem Rungu Lin", "Kang Zhang"], "Sources": "SIGGRAPH Asia 2023 Art Papers", "PublishedYears": "2023", "Doi": "", "Abstracts": " This paper reexamines the work of Marshall McLuhan and Ant Farm, highlighting their enduring relevance for contemporary mediated urbanism and architecture. By exploring their historical context, connections, and influences, the authors provide insights for architects and artists navigating the complex interplay between media, technology, and the built environment. The analysis bridges the gap between historical context and contemporary practice, focusing on the motivations, possibilities, and limitations of media interpretation as a critical and creative practice. The paper addresses the pressing questions concerning the future design of architectural spaces and urban forms, ultimately fostering innovative approaches that challenge conventional design thinking", "IdName": "lin2023media", "Citation": "", "Keywords": ""}, {"Name": "Comparing color usage in abstract, oil, and Chinese ink paintings", "Authors": ["YuFan Li", "ZhenBao Fan", "YiXuan Zhu", "Christine Yan", "Kang Zhang"], "Sources": "Journal of Visualization", "PublishedYears": "2023", "Doi": "", "Abstracts": "Color is one of the fundamental elements of paintings. This paper proposes a set of measurements for color usage in a painting, including basic color elements, global and local color harmony, and color statistical properties, characterizing color features from both the spatial domain and frequency domain. We also collect a painting set including 1059 abstract paintings, 1012 oil paintings, and 1003 Chinese ink paintings. Applying the measurements to this painting set, we are able to observe the roles of color in the three genres of paintings. We report our findings in detail on the effectiveness of these measurements. Chinese ink paintings are significantly different from abstract and oil paintings in color usage, while abstract paintings emphasize color more than the two other genres. The measurements may serve as tools for the classification of paintings. The work is the first of this kind and points to further?\u2026", "IdName": "li2023comparing", "Citation": "", "Keywords": ""}, {"Name": "Archiving Body Movements: Collective Generation of Chinese Calligraphy", "Authors": ["Aven Le Zhou", "Jiayi Ye", "Tianchen Liu", "Kang Zhang"], "Sources": "arXiv preprint arXiv:2311.13770", "PublishedYears": "2023", "Doi": "", "Abstracts": "As a communication channel, body movements have been widely explored in behavioral studies and kinesics. Performing and visual arts share the same interests but focus on documenting and representing human body movements, such as for dance notation and visual work creation. This paper investigates body movements in oriental calligraphy and how to apply calligraphy principles to stimulate and archive body movements. Through an artwork (Wushu), the authors experiment with an interactive and generative approach to engage the audience's bodily participation and archive the body movements as a compendium of generated calligraphy. The audience assumes the role of both writers and readers; creating (\"writing\") and appreciating (\"reading\") the generated calligraphy becomes a cyclical process within this infinite \"Book,\" which can motivate further attention and discussions concerning Chinese characters and calligraphy.", "IdName": "zhou2023archiving", "Citation": "", "Keywords": ""}, {"Name": "Bitter Data: An Exploration into Data Edibilization of Negative Emotion", "Authors": ["Yufan Li", "Kang Zhang", "Yue Huang", "Varvara Guljajeva"], "Sources": "2023 IEEE VIS Arts Program (VISAP)", "PublishedYears": "2023", "Doi": "", "Abstracts": "\u201cBitter Data\u201d transforms 100,000 distress postings from Chinese social media into a multi-sensory experience using data edibilization. We\u2019ve mapped distress data quantity to the bitterness and color of tea through data analysis and experimentation. Participants taste, smell, and observe 11 cups of tea, each embodying a year\u2019s distress data, in our workshop. Their facial expressions, recorded upon tasting, visually indicate emotional states. This project explores benefits and pragmatic solutions to challenges of data edibilization.", "IdName": "li2023bitter", "Citation": "", "Keywords": ""}, {"Name": "Kandinsky's Color-Shape Associations in Chinese Context: Do Personality and Affect Matter?", "Authors": ["Zixu Gong", "Kang Zhang", "Rongrong Chen"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Inspired by Kandinsky's original postulation of specific color-shape association preferences in human beings (i.e., blue circle, red square and yellow triangle), extensive literature from diverse cultural backgrounds has re-examined this issue and achieved a consensus on the existence of such preferences, yet there is disagreement on the specific association patterns. In this study, we investigated the association between color and basic geometric shapes among Chinese college students. Correspondence analysis revealed that both circles and triangles are highly associated with yellow. Circles are also associated with red, while squares exhibit a strong association with blue. Additionally, we confirmed Kandinsky's theory that the angular characteristics of shapes affect the choice of warm and cold colors assigned to them. Interestingly, neither personality traits nor affect states affect the color-shape association?\u2026", "IdName": "gong2023kandinsky", "Citation": "", "Keywords": ""}, {"Name": "Urban Symphony: An AI and Data-Driven Approach to Real-Time Animation for Public Digital Art", "Authors": ["Rem RunGu Lin", "Yongen Ke", "Kang Zhang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Projection mapping is a form of urban public art that uses light and video to transform buildings and structures into dynamic canvases. However, producing high-quality projection mapping content with compelling storytelling requires extensive time and resources, as it involves integrating local culture, urban spatial understanding, and animation production. To address this challenge, this paper proposes a method that combines artistic co-creation with AI, audio-visualization, and data-visualization techniques. The authors present a case study: \u201cUrban Symphony,\u201d an immersive public art installation that showcases our method and leverages AI and data-driven storytelling. This method fosters interdisciplinary research collaboration and explores the potential of projection mapping as a bridge between art, technology, and society. The paper describe the motivation, design, and production of the artwork, the outcomes?\u2026", "IdName": "lin2023urban", "Citation": "", "Keywords": ""}, {"Name": "Metaphor Design of Dockless Bike-sharing Based on Spatio-temporal Geographic Data", "Authors": ["Kelin Li", "Hong Yin", "Dong Li", "Kang Zhang", "Changbo Wang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Dockless Bike-sharing systems can be treated as a typical paradigm of the sharing economy. Due to the indiscriminate use and placement of huge bikes, their scheduling rules are complicated, which poses a challenge to the macro-control of the companies To enhance the information dimension of bike Origin-Destination (OD) data, an algorithm based on grid features is proposed to reconstruct travel trajectories of OD data. This paper starts by analyzing and designing metaphors to describe the scheduling rules and trip characteristics of Dockless Bike-Sharing. The evaluation shows that the proposed metaphors are user-friendly to novice users. We argue that metaphors provide an effective way for users to understand abstract ideas in a visual design with a large dataset.", "IdName": "li2023metaphor", "Citation": "", "Keywords": ""}, {"Name": "BiverWordle: Visualizing Stock Market Sentiment with Financial Text Data and Trends", "Authors": ["Lei Xia", "Yi-Ping Gao", "Le Lin", "Yu-Xi Chen", "Kang Zhang"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " While financial forums are increasingly significant in financial analysis, current visualization tools do not properly exploit their text data. To address this, we present BiverWordle, a novel tool that reveals the relationship between market sentiment and firm trends. BiverWordle integrates candlestick chart, ThemeRiver, and Wordle with text classification and sentiment analysis techniques to decode market dynamics from textual sources, such as shareholder opinions and firm announcements. With the application of a Voting model to the manually labeled data, we achieved an accuracy of approximately 64%. BiverWordle facilitates the extraction of shareholder insights from sparse comments and provides a visual method for historical stock trend analysis, which we validated with three distinct stock trends. Resources are accessible at https://github.com/Brian-Lei-XIA/BiverWordle. ", "IdName": "xia2023biverwordle", "Citation": "", "Keywords": ""}, {"Name": "Interactive moir\u00e9 patterns Reflecting on the traditional nanjing baiju", "Authors": ["Ye Yang", "Guangxi Chen", "Mengqi Li", "Kang Zhang"], "Sources": "Leonardo", "PublishedYears": "2023", "Doi": "", "Abstracts": " This article presents a human-machine design approach to the artistic and metaphorical representation of the traditional weaving scenes featured on Yunjin brocade as interactive moir\u00e9 patterns accompanied by Nanjing Baiju performance. After extracting the basic elements of the eye-shaped moir\u00e9 patterns, the authors systematically recomposed them to mimic the weaving process. They then wrote an algorithm to generate moir\u00e9 patterns that respond dynamically to the unique sounds weavers make while weaving, symbolizing the gazes and eye contacts among the weavers. This became an interactive sonic installation, Sweating Weaving Room, which represents the rhythmic machine sounds, the Nanjing Baiju, and the hard labor and harmonious work hidden behind the glamorous brocade.", "IdName": "yang2023interactive", "Citation": "", "Keywords": ""}, {"Name": "Learning computer graphics via a student-led open source demonstration project", "Authors": ["Pushpa Kumar", "Kang Zhang"], "Sources": "Journal of Computing Sciences in Colleges", "PublishedYears": "2020", "Doi": "", "Abstracts": "Computer Graphics is a computer science subject involving heavy mathematics and many classic graphics algorithms. Providing students hands-on learning experience via programming projects is essential but insufficient. In this paper, we share our experiences in teaching Computer Graphics by letting students build their own algorithm animation and demonstrations open source software. The open source demonstration software, called CGDemo, includes animation and interactive demonstration of various classic graphics algorithms and 3D mathematic transformations. Students first learn the algorithms by developing demonstration projects in Java, following a consistent demonstration framework, and meanwhile by learning and reusing software components built by other students. The gradually built open source project CGDemo has been helping all the subsequent students to learn complex graphics?\u2026", "IdName": "kumar2020learning", "Citation": "", "Keywords": ""}, {"Name": "Practices and Challenges of Using Think-Aloud Protocols in Industry: An International Survey", "Authors": ["Mingming Fan", "Serina Shi", "Khai N Truong"], "Sources": "Journal of Usability Studies", "PublishedYears": "2020", "Doi": "", "Abstracts": "Think-aloud protocols are one of the classic methods often taught in universities for training UX designers and researchers. Although previous research reported how these protocols were used in industry, the findings were typically based on the practices of a small number of professionals in specific geographic regions or on studies conducted years ago. As UX practices continuously evolve to address new challenges emerging in industry, it is important to understand the challenges faced by current UX practitioners around the world when using think-aloud protocols. Such an understanding is beneficial for UX professionals to reflect on and learn from the UX community\u2019s practices. It is also invaluable for academic researchers and educators to understand the challenges faced by professionals when carrying out the protocols in a wide range of practical contexts and to better explore methods to address these challenges. We conducted an international survey study with UX professionals in various sized companies around the world. We found that think-aloud protocols are widely and almost equally used in controlled lab studies and remote usability testing; concurrent protocols are more popular than retrospective protocols. Most UX practitioners probe participants during test sessions, explicitly request them to verbalize particular types of content, and do not administer practice sessions. The findings also offer insights on practices and challenges in analyzing think-aloud sessions. In sum, UX practitioners often deal with the tension between validity and efficiency in their analysis and demand better fast-paced and reliable analysis methods than?\u2026", "IdName": "fan2020practices", "Citation": "", "Keywords": ""}, {"Name": "Chartseer: Interactive steering exploratory visual analysis with machine intelligence", "Authors": ["Jian Zhao", "Mingming Fan", "Mi Feng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "During exploratory visual analysis (EVA), analysts need to continually determine which subsequent activities to perform, such as which data variables to explore or how to present data variables visually. Due to the vast combinations of data variables and visual encodings that are possible, it is often challenging to make such decisions. Further, while performing local explorations, analysts often fail to attend to the holistic picture that is emerging from their analysis, leading them to improperly steer their EVA. These issues become even more impactful in the real world analysis scenarios where EVA occurs in multiple asynchronous sessions that could be completed by one or more analysts. To address these challenges, this work proposes ChartSeer, a system that uses machine intelligence to enable analysts to visually monitor the current state of an EVA and effectively identify future activities to perform. ChartSeer?\u2026", "IdName": "zhao2020chartseer", "Citation": "", "Keywords": ""}, {"Name": "Accessible or not? an empirical investigation of Android app accessibility", "Authors": ["Sen Chen", "Chunyang Chen", "Lingling Fan", "Mingming Fan", "Xian Zhan", "Yang Liu"], "Sources": "IEEE Transactions on Software Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Mobile apps provide new opportunities to people with disabilities to act independently in the world. Following the law of the US, EU, mobile OS vendors such as Google and Apple have included accessibility features in their mobile systems and provide a set of guidelines and toolsets for ensuring mobile app accessibility. Motivated by this trend, researchers have conducted empirical studies by using the inaccessibility issue rate of each page (i.e., screen level) to represent the characteristics of mobile app accessibility. However, there still lacks an empirical investigation directly focusing on the issues themselves (i.e., issue level) to unveil more fine-grained findings, due to the lack of an effective issue detection method and a relatively comprehensive dataset of issues. To fill in this literature gap, we first propose an automated app page exploration tool, named Xbot, to facilitate app accessibility testing and?\u2026", "IdName": "chen2021accessible", "Citation": "", "Keywords": ""}, {"Name": "Human-ai collaboration for ux evaluation: Effects of explanation and synchronization", "Authors": ["Mingming Fan", "Xianyou Yang", "TszTung Yu", "Q Vera Liao", "Jian Zhao"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool-AI Assistant-with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable?\u2026", "IdName": "fan2022human", "Citation": "", "Keywords": ""}, {"Name": "\u201cI Choose Assistive Devices That Save My Face\u201d A Study on Perceptions of Accessibility and Assistive Technology Use Conducted in China", "Authors": ["Franklin Mingzhe Li", "Di Laura Chen", "Mingming Fan", "Khai N Truong"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " Despite the potential benefits of assistive technologies (ATs) for people with various disabilities, only around 7% of Chinese with disabilities have had an opportunity to use ATs. Even for those who have used ATs, the abandonment rate was high. Although China has the world\u2019s largest population with disabilities, prior research exploring how ATs are used and perceived, and why ATs are abandoned have been conducted primarily in North America and Europe. In this paper, we present an interview study conducted in China with 26 people with various disabilities to understand their practices, challenges, perceptions, and misperceptions of using ATs. From the study, we learned about factors that influence AT adoption practices (e.g., misuse of accessible infrastructure, issues with replicating existing commercial ATs), challenges using ATs in social interactions (e.g., Chinese stigma), and misperceptions about ATs?\u2026", "IdName": "li2021choose", "Citation": "", "Keywords": ""}, {"Name": "Automatic Detection of Usability Problem Encounters in Think-Aloud Sessions", "Authors": ["Mingming Fan", "Yue Li", "Khai N Truong"], "Sources": "ACM Transactions on Interactive Intelligent Systems (TiiS)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Think-aloud protocols are a highly valued usability testing method for identifying usability problems. Despite the value of conducting think-aloud usability test sessions, analyzing think-aloud sessions is often time-consuming and labor-intensive. Consequently, previous research has urged the community to develop techniques to support fast-paced analysis. In this work, we took the first step to design and evaluate machine learning (ML) models to automatically detect usability problem encounters based on users\u2019 verbalization and speech features in think-aloud sessions. Inspired by recent research that shows subtle patterns in users\u2019 verbalizations and speech features tend to occur when they encounter problems, we examined whether these patterns can be utilized to improve the automatic detection of usability problems. We first conducted and recorded think-aloud sessions and then examined the effect of different?\u2026", "IdName": "fan2020automatic", "Citation": "", "Keywords": ""}, {"Name": "Eyelid gestures on mobile devices for people with motor impairments", "Authors": ["Mingming Fan", "Zhen Li", "Franklin Mingzhe Li"], "Sources": "Proceedings of the 22nd International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": " Eye-based interactions for people with motor impairments have often used clunky or specialized equipment (e.g., eye-trackers with non-mobile computers) and primarily focused on gaze and blinks. However, two eyelids can open and close for different duration in different orders to form various eyelid gestures. We take a first step to design, detect, and evaluate a set of eyelid gestures for people with motor impairments on mobile devices. We present an algorithm to detect nine eyelid gestures on smartphones in real-time and evaluate it with twelve able-bodied people and four people with severe motor impairments in two studies. The results of the study with people with motor-impairments show that the algorithm can detect the gestures with .76 and .69 overall accuracy in user-dependent and user-independent evaluations. Moreover, we design and evaluate a gesture mapping scheme allowing for navigating mobile?\u2026", "IdName": "fan2020eyelid", "Citation": "", "Keywords": ""}, {"Name": "Older adults\u2019 think-aloud verbalizations and speech features for identifying user experience problems", "Authors": ["Mingming Fan", "Qiwen Zhao", "Vinita Tibdewal"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Subtle patterns in users\u2019 think-aloud (TA) verbalizations and speech features are shown to be telltale signs of User Experience (UX) problems. However, such patterns were uncovered among young adults. Whether such patterns apply for older adults remains unknown. We conducted TA usability testing with older adults using physical and digital products. We analyzed their verbalizations, extracted speech features, identified UX problems, and uncovered the patterns that indicate UX problems. Our results show that when older adults encounter problems, their verbalizations tend to include observations (remarks), negations, question words and words with negative sentiments; and their voices tend to include high loudness, high pitch and high speech rate. We compare these subtle patterns with those of young adults uncovered in recent studies and discuss the implications of these patterns for the design of Human?\u2026", "IdName": "fan2021older", "Citation": "", "Keywords": ""}, {"Name": "Vmirror: Enhancing the interaction with occluded or distant objects in vr with virtual mirrors", "Authors": ["Nianlong Li", "Zhengquan Zhang", "Can Liu", "Zengyao Yang", "Yinan Fu", "Feng Tian", "Teng Han", "Mingming Fan"], "Sources": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Interacting with out of reach or occluded VR objects can be cumbersome. Although users can change their position and orientation, such as via teleporting, to help observe and select, doing so frequently may cause loss of spatial orientation or motion sickness. We present vMirror, an interactive widget leveraging reflection of mirrors to observe and select distant or occluded objects. We first designed interaction techniques for placing mirrors and interacting with objects through mirrors. We then conducted a formative study to explore a semi-automated mirror placement method with manual adjustments. Next, we conducted a target-selection experiment to measure the effect of the mirror\u2019s orientation on users\u2019 performance. Results showed that vMirror can be as efficient as direct target selection for most mirror orientations. We further compared vMirror with teleport technique in a virtual treasure hunt game and?\u2026", "IdName": "li2021vmirror", "Citation": "", "Keywords": ""}, {"Name": "Communication in immersive social virtual reality: A systematic review of 10 years\u2019 studies", "Authors": ["Xiaoying Wei", "Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the Tenth International Symposium of Chinese CHI", "PublishedYears": "2022", "Doi": "", "Abstracts": "As virtual reality (VR) technologies have improved in the past decade, more research has investigated how they could support more effective communication in various contexts to improve collaboration and social connectedness. However, there was no literature to summarize the uniqueness VR provided and put forward guidance for designing social VR applications for better communication. To understand how VR has been designed and used to facilitate communication in different contexts, we conducted a systematic review of the studies investigating communication in social VR in the past ten years by following the PRISMA guidelines. We highlight current practices and challenges and identify research opportunities to improve the design of social VR to better support communication and make social VR more accessible.", "IdName": "wei2022communication", "Citation": "", "Keywords": ""}, {"Name": "CoUX: collaborative visual analysis of think-aloud usability test videos for digital interfaces", "Authors": ["Ehsan Jahangirzadeh Soure", "Emily Kuang", "Mingming Fan", "Jian Zhao"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Reviewing a think-aloud video is both time-consuming and demanding as it requires UX (user experience) professionals to attend to many behavioral signals of the user in the video. Moreover, challenges arise when multiple UX professionals need to collaborate to reduce bias and errors. We propose a collaborative visual analytics tool, CoUX, to facilitate UX evaluators collectively reviewing think-aloud usability test videos of digital interfaces. CoUX seamlessly supports usability problem identification, annotation, and discussion in an integrated environment. To ease the discovery of usability problems, CoUX visualizes a set of problem-indicators based on acoustic, textual, and visual features extracted from the video and audio of a think-aloud session with machine learning. CoUX further enables collaboration amongst UX evaluators for logging, commenting, and consolidating the discovered problems with a?\u2026", "IdName": "soure2021coux", "Citation": "", "Keywords": ""}, {"Name": "Mouill\u00e9: Exploring wetness illusion on fingertips to enhance immersive experience in vr", "Authors": ["Teng Han", "Sirui Wang", "Sijia Wang", "Xiangmin Fan", "Jie Liu", "Feng Tian", "Mingming Fan"], "Sources": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Providing users with rich sensations is beneficial to enhance their immersion in Virtual Reality (VR) environments. Wetness is one such imperative sensation that affects users' sense of comfort and helps users adjust grip force when interacting with objects. Researchers have recently begun to explore ways to create wetness illusions, primarily on a user's face or body skin. In this work, we extended this line of research by creating wetness illusion on users' fingertips. We first conducted a user study to understand the effect of thermal and tactile feedback on users' perceived wetness sensation. Informed by the findings, we designed and evaluated a prototype---Mouill\u00e9---that provides various levels of wetness illusions on fingertips for both hard and soft items when users squeeze, lift, or scratch it. Study results indicated that users were able to feel wetness with different levels of temperature changes and they were able?\u2026", "IdName": "han2020mouille", "Citation": "", "Keywords": ""}, {"Name": "Synapse: interactive guidance by demonstration with trial-and-error support for older adults to use smartphone apps", "Authors": ["Xiaofu Jin", "Xiaozhu Hu", "Xiaoying Wei", "Mingming Fan"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2022", "Doi": "", "Abstracts": "As smartphones are widely adopted, mobile applications (apps) are emerging to provide critical services such as food delivery and telemedicine. While bring convenience to everyday life, this trend may create barriers for older adults who tend to be less tech-savvy than young people. In-person or screen sharing support is helpful but limited by the help-givers' availability. Video tutorials can be useful but require users to switch contexts between watching the tutorial and performing the corresponding actions in the app, which is cumbersome to do on a mobile phone. Although interactive tutorials have been shown to be promising, none was designed for older adults. Furthermore, the trial-and-error approach has been shown to be beneficial for older adults, but they often lack support to use the approach. Inspired by both interactive tutorials and trial-and-error approach, we designed an app-independent mobile service?\u2026", "IdName": "jin2022synapse", "Citation": "", "Keywords": ""}, {"Name": "Douleur: creating pain sensation with chemical stimulant to enhance user experience in virtual reality", "Authors": ["Chutian Jiang", "Yanjun Chen", "Mingming Fan", "Liuping Wang", "Luyao Shen", "Nianlong Li", "Wei Sun", "Yu Zhang", "Feng Tian", "Teng Han"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2021", "Doi": "", "Abstracts": "The imitation of pain sensation in Virtual Reality is considered valuable for safety education and training but has been seldom studied. This paper presents Douleur, a wearable haptic device that renders intensity-adjustable pain sensations with chemical stimulants. Different from mechanical, thermal, or electric stimulation, chemical-induced pain is more close to burning sensations and long-lasting. Douleur consists of a microfluidic platform that precisely emits capsaicin onto the skin and a microneedling component to help the stimulant penetrate the epidermis layer to activate the trigeminal nerve efficiently. Moreover, it embeds a Peltier module to apply the heating or cooling stimulus to the affected area to adjust the level of pain on the skin. To better understand how people would react to the chemical stimulant, we conducted a first study to quantify the enhancement of the sensation by changing the capsaicin?\u2026", "IdName": "jiang2021douleur", "Citation": "", "Keywords": ""}, {"Name": "\" I am the follower, also the boss\": Exploring Different Levels of Autonomy and Machine Forms of Guiding Robots for the Visually Impaired", "Authors": ["Yan Zhang", "Ziang Li", "Haole Guo", "Luyao Wang", "Qihe Chen", "Wenjie Jiang", "Mingming Fan", "Guyue Zhou", "Jiangtao Gong"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Guiding robots, in the form of canes or cars, have recently been explored to assist blind and low vision (BLV) people. Such robots can provide full or partial autonomy when guiding. However, the pros and cons of different forms and autonomy for guiding robots remain unknown. We sought to fill this gap. We designed autonomy-switchable guiding robotic cane and car. We conducted a controlled lab-study (N=12) and a field study (N=9) on BLV. Results showed that full autonomy received better walking performance and subjective ratings in the controlled study, whereas participants used more partial autonomy in the natural environment as demanding more control. Besides, the car robot has demonstrated abilities to provide a higher sense of safety and navigation efficiency compared with the cane robot. Our findings offered empirical evidence about how the BLV community perceived different machine forms and?\u2026", "IdName": "zhang2023follower", "Citation": "", "Keywords": ""}, {"Name": "\"It Feels Like Being Locked in A Cage\": Understanding Blind or Low Vision Streamers' Perceptions of Content Curation Algorithms", "Authors": ["Ethan Z. Rong", "Mo Morgana Zhou", "Zhicong Lu", "Mingming Fan"], "Sources": "Designing Interactive Systems Conference", "PublishedYears": "2022", "Doi": "", "Abstracts": "Blind or low vision (BLV) people were recently reported to be live streamers on the online platforms that employed content curation algorithms. Recent research uncovered perceived algorithmic biases suppressing the content created by marginalized populations (e.g., people of color, the LGBT+ community, and content creators of lower socioeconomic status). However, little is known about how BLV streamers, as a marginalized population, perceive the effects of the algorithms adopted by live streaming platforms. We interviewed BLV streamers (N=19) of Douyin \u2014 a popular live stream platform in China \u2014 to understand their perceptions of algorithms, perceived challenges, and mitigation strategies. Our findings show the perceived factors contributing to disadvantages under algorithmic evaluation of BLV streamers\u2019 content (e.g., issues with filming and timely interaction with viewers) and perceived algorithmic?\u2026", "IdName": "rong2022feels", "Citation": "", "Keywords": ""}, {"Name": "Bridging the generational gap: exploring how virtual reality supports remote communication between grandparents and grandchildren", "Authors": ["Xiaoying Wei", "Yizheng Gu", "Emily Kuang", "Xian Wang", "Beiyan Cao", "Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "When living apart, grandparents and grandchildren often use audio-visual communication approaches to stay connected. However, these approaches seldom provide sufficient companionship and intimacy due to a lack of co-presence and spatial interaction, which can be fulfilled by immersive virtual reality (VR). To understand how grandparents and grandchildren might leverage VR to facilitate their remote communication and better inform future design, we conducted a user-centered participatory design study with twelve pairs of grandparents and grandchildren. Results show that VR affords casual and equal communication by reducing the generational gap, and promotes conversation by offering shared activities as bridges for connection. Participants preferred resemblant appearances on avatars for conveying well-being but created ideal selves for gaining playfulness. Based on the results, we contribute eight?\u2026", "IdName": "wei2023bridging", "Citation": "", "Keywords": ""}, {"Name": "Reducing stress and anxiety in the metaverse: A systematic review of meditation, mindfulness and virtual reality", "Authors": ["Xian Wang", "Xiaoyu Mo", "Mingming Fan", "Lik-Hang Lee", "Bertram Shi", "Pan Hui"], "Sources": "Proceedings of the Tenth International Symposium of Chinese CHI", "PublishedYears": "2022", "Doi": "", "Abstracts": " Meditation, or mindfulness, is widely used to improve mental health. With the emergence of Virtual Reality technology, many studies have provided evidence that meditation with VR can bring health benefits. However, to our knowledge, there are no guidelines and comprehensive reviews in the literature on how to conduct such research in virtual reality. In order to understand the role of VR technology in meditation and future research opportunities, we conducted a systematic literature review in the IEEE and ACM databases. Our process yielded 19 eligible papers and we conducted a structured analysis. We understand the state-of-art of meditation type, design consideration and VR and technology through these papers and conclude research opportunities and challenges for the future.", "IdName": "wang2022reducing", "Citation": "", "Keywords": ""}, {"Name": "\"I Don't Want People to Look At Me Differently\": Designing User-Defined Above-the-Neck Gestures for People with Upper Body Motor Impairments", "Authors": ["Xuan Zhao", "Mingming Fan", "Teng Han"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recent research proposed eyelid gestures for people with upper-body motor impairments (UMI) to interact with smartphones without finger touch. However, such eyelid gestures were designed by researchers. It remains unknown what eyelid gestures people with UMI would want and be able to perform. Moreover, other above-the-neck body parts (e.g., mouth, head) could be used to form more gestures. We conducted a user study in which 17 people with UMI designed above-the-neck gestures for 26 common commands on smartphones. We collected a total of 442 user-defined gestures involving the eyes, the mouth, and the head. Participants were more likely to make gestures with their eyes and preferred gestures that were simple, easy-to-remember, and less likely to draw attention from others. We further conducted a survey (N=24) to validate the usability and acceptance of these user-defined gestures. Results?\u2026", "IdName": "zhao2022don", "Citation": "", "Keywords": ""}, {"Name": "\u201cI need to be professional until my new team uses emoji, GIFs, or memes first\u201d: New Collaborators\u2019 Perspectives on Using Non-Textual Communication in Virtual Workspaces", "Authors": ["Esha Shandilya", "Mingming Fan", "Garreth W Tigwell"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": " Virtual workspaces rapidly increased during the COVID-19 pandemic, and for many new collaborators, working remotely was their first introduction to their colleagues. Building rapport is essential for a healthy work environment, and while this can be achieved through non-textual responses within chat-based systems (e.g., emoji, GIF, stickers, memes), those non-textual responses are typically associated with personal relationships and informal settings. We studied the experiences of new collaborators (questionnaire N=49; interview N=14) in using non-textual responses to communicate with unacquainted teams and the effect of non-textual responses on new collaborators\u2019 interpersonal bonds. We found new collaborators selectively and progressively use non-textual responses to establish interpersonal bonds. Moreover, the use of non-textual responses has exposed several limitations when used on various?\u2026", "IdName": "shandilya2022need", "Citation": "", "Keywords": ""}, {"Name": "Understanding older adults\u2019 perceptions and challenges in using AI-enabled everyday technologies", "Authors": ["Esha Shandilya", "Mingming Fan"], "Sources": "Proceedings of the Tenth International Symposium of Chinese CHI", "PublishedYears": "2022", "Doi": "", "Abstracts": "Artificial intelligence (AI)-enabled everyday technologies could help address age-related challenges like physical impairments and cognitive decline. While recent research studied older adults\u2019 experiences with specific AI-enabled products (e.g., conversational agents and assistive robots), it remains unknown how older adults perceive and experience current AI-enabled everyday technologies in general, which could impact their adoption of future AI-enabled products. We conducted a survey study (N=41) and semi-structured interviews (N=15) with older adults to understand their experiences and perceptions of AI. We found that older adults were enthusiastic about learning and using AI-enabled products, but they lacked learning avenues. Additionally, they worried when AI-enabled products outwitted their expectations, intruded on their privacy, or impacted their decision-making skills. Therefore, they held mixed?\u2026", "IdName": "shandilya2022understanding", "Citation": "", "Keywords": ""}, {"Name": "\" Too old to bank digitally?\": A Survey of Banking Practices and Challenges Among Older Adults in China", "Authors": ["Xiaofu Jin", "Emily Kuang", "Mingming Fan"], "Sources": "ACM SIGCHI Conference on Designing Interactive Systems Conference 2021 (DIS?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " The banking industry has been integrating digital technologies globally. However, accepting new technologies is challenging in particular for older adults. We focus on older adults\u2019 banking experiences in China, where digital transactions have been growing rapidly, to provide a perspective on how they adapt to this trend. We conducted an online survey with 155 older adults who are 60 or above (M = 70, SD = 9) from 18 provinces to explore their banking practices and challenges. Our results show that older adults conduct banking transactions frequently. However, few do so using digital platforms despite long wait times in physical banks. The main concerns reported by them are about security and usability. Nonetheless, they hold a positive attitude towards digital platforms (e.g., apps, virtual banks). Interestingly, age and gender have significant effects on particular banking behaviors. We discuss our findings in the?\u2026", "IdName": "jin2021too", "Citation": "", "Keywords": ""}, {"Name": "Collaboration with conversational AI assistants for UX evaluation: Questions and how to ask them (voice vs. text)", "Authors": ["Emily Kuang", "Ehsan Jahangirzadeh Soure", "Mingming Fan", "Jian Zhao", "Kristen Shinohara"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " AI is promising in assisting UX evaluators with analyzing usability tests, but its judgments are typically presented as non-interactive visualizations. Evaluators may have questions about test recordings, but have no way of asking them. Interactive conversational assistants provide a Q&A dynamic that may improve analysis efficiency and evaluator autonomy. To understand the full range of analysis-related questions, we conducted a Wizard-of-Oz design probe study with 20 participants who interacted with simulated AI assistants via text or voice. We found that participants asked for five categories of information: user actions, user mental model, help from the AI assistant, product and task information, and user demographics. Those who used the text assistant asked more questions, but the question lengths were similar. The text assistant was perceived as significantly more efficient, but both were rated equally in?\u2026", "IdName": "kuang2023collaboration", "Citation": "", "Keywords": ""}, {"Name": "Understanding how older adults comprehend COVID-19 interactive visualizations via think-aloud protocol", "Authors": ["Mingming Fan", "Yiwen Wang", "Yuni Xie", "Franklin Mingzhe Li", "Chunyang Chen"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Older adults have been hit disproportionally hard by the COVID-19 pandemic. One critical way for older adults to minimize the negative impact of COVID-19 and future pandemics is to stay informed about its latest information, which has been increasingly presented through online interactive visualizations (e.g., live dashboards and websites). Thus, it is imperative to understand how older adults interact with and comprehend online COVID-19 interactive visualizations and what challenges they might encounter to make such visualizations more accessible to older adults. We adopted a user-centered approach by inviting older adults to interact with COVID-19 interactive visualizations while at the same time verbalizing their thought processes using a think-aloud protocol. By analyzing their think-aloud verbalizations, we identified four types of thought processes representing how older adults comprehended the?\u2026", "IdName": "fan2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Enabling Voice-Accompanying Hand-to-Face Gesture Recognition with Cross-Device Sensing", "Authors": ["Zisu Li", "Chen Liang", "Yuntao Wang", "Yue Qin", "Chun Yu", "Yukang Yan", "Mingming Fan", "Yuanchun Shi"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Gestures performed accompanying the voice are essential for voice interaction to convey complementary semantics for interaction purposes such as wake-up state and input modality. In this paper, we investigated voice-accompanying hand-to-face (VAHF) gestures for voice interaction. We targeted on hand-to-face gestures because such gestures relate closely to speech and yield significant acoustic features (e.g., impeding voice propagation). We conducted a user study to explore the design space of VAHF gestures, where we first gathered candidate gestures and then applied a structural analysis to them in different dimensions (e.g., contact position and type), outputting a total of 8 VAHF gestures with good usability and least confusion. To facilitate VAHF gesture recognition, we proposed a novel cross-device sensing method that leverages heterogeneous channels (vocal, ultrasound, and IMU) of data from?\u2026", "IdName": "li2023enabling", "Citation": "", "Keywords": ""}, {"Name": "uxSense: Supporting user experience analysis with visualization and computer vision", "Authors": ["Andrea Batch", "Yipeng Ji", "Mingming Fan", "Jian Zhao", "Niklas Elmqvist"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Analyzing user behavior from usability evaluation can be a challenging and time-consuming task, especially as the number of participants and the scale and complexity of the evaluation grows. We propose UXSENSE, a visual analytics system using machine learning methods to extract user behavior from audio and video recordings as parallel time-stamped data streams. Our implementation draws on pattern recognition, computer vision, natural language processing, and machine learning to extract user sentiment, actions, posture, spoken words, and other features from such recordings. These streams are visualized as parallel timelines in a web-based front-end, enabling the researcher to search, filter, and annotate data across time and space. We present the results of a user study involving professional UX researchers evaluating user data using uxSense. In fact, we used uxSense itself to evaluate their sessions.", "IdName": "batch2023uxsense", "Citation": "", "Keywords": ""}, {"Name": "\"Merging Results Is No Easy Task\": An International Survey Study of Collaborative Data Analysis Practices Among UX Practitioners", "Authors": ["Emily Kuang", "Xiaofu Jin", "Mingming Fan"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Analysis is a key part of usability testing where UX practitioners seek to identify usability problems and generate redesign suggestions. Although previous research reported how analysis was conducted, the findings were typically focused on individual analysis or based on a small number of professionals in specific geographic regions. We conducted an online international survey of 279 UX practitioners on their practices and challenges while collaborating during data analysis. We found that UX practitioners were often under time pressure to conduct analysis and adopted three modes of collaboration: independently analyze different portions of the data and then collaborate, collaboratively analyze the session with little or no independent analysis, and independently analyze the same set of data and then collaborate. Moreover, most encountered challenges related to lack of resources, disagreements with?\u2026", "IdName": "kuang2022merging", "Citation": "", "Keywords": ""}, {"Name": "\"I Shake The Package To Check If It's Mine\": A Study of Package Fetching Practices and Challenges of Blind and Low Vision People in China", "Authors": ["Wentao Lei", "Mingming Fan", "Juliann Thang"], "Sources": "In CHI Conference on Human Factors in Computing Systems (CHI'22)", "PublishedYears": "2022", "Doi": "", "Abstracts": "With about 230 million packages delivered per day in 2020, fetching packages has become a routine for many city dwellers in China. When fetching packages, people usually need to go to collection sites of their apartment complexes or a KuaiDiGui, an increasingly popular type of self-service package pickup machine. However, little is known whether such processes are accessible to blind and low vision (BLV) city dwellers. We interviewed BLV people (N=20) living in a large metropolitan area in China to understand their practices and challenges of fetching packages. Our findings show that participants encountered difficulties in finding the collection site and localizing and recognizing their packages. When fetching packages from KuaiDiGuis, they had difficulty in identifying the correct KuaiDiGui, interacting with its touch screen, navigating the complex on-screen workflow, and opening the target compartment. We?\u2026", "IdName": "lei2022shake", "Citation": "", "Keywords": ""}, {"Name": "\u201cI Used To Carry A Wallet, Now I Just Need To Carry My Phone\u201d: Understanding Current Banking Practices and Challenges Among Older Adults in China", "Authors": ["Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the 24th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Managing finances is crucial for older adults who are retired and may rely on savings to ensure their lives\u2019 quality. As digital banking platforms (e.g., mobile apps, electronic payment) gradually replace physical ones, it is critical to understand how they adapt to digital banking and the potential frictions they experience. We conducted semi-structured interviews with 16 older adults in China, where the aging population is the largest and digital banking grows fast. We also interviewed bank employees to gain complementary perspectives of these help givers. Our findings show that older adults used both physical and digital platforms as an ecosystem based on perceived pros and cons. Perceived usefulness, self-confidence, and social influence were key motivators for learning digital banking. They experienced app-related (e.g., insufficient error-recovery support) and user-related challenges (e.g., trust, security and?\u2026", "IdName": "jin2022used", "Citation": "", "Keywords": ""}, {"Name": "iWink: Exploring eyelid gestures on mobile devices", "Authors": ["Zhen Li", "Mingming Fan", "Ying Han", "Khai N Truong"], "Sources": "Proceedings of the 1st International Workshop on Human-Centric Multimedia?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Although gaze has been widely studied for mobile interactions, eyelid-based gestures are relatively understudied and limited to few basic gestures (e.g., blink). In this work, we propose a gesture grammar to construct both basic and compound eyelid gestures. We present an algorithm to detect nine eyelid gestures in real-time on mobile devices and evaluate its performance with 12 participants. Results show that our algorithm is able to recognize nine eyelid gestures with 83% and 78% average accuracy using user-dependent and user-independent models respectively. Further, we design a gesture mapping scheme to allow for navigating between and within mobile apps only using eyelid gestures. Moreover, we show how eyelid gestures can be used to enable cross-application and sensitive interactions. Finally, we highlight future research directions.", "IdName": "li2020iwink", "Citation": "", "Keywords": ""}, {"Name": "Older Adults\u2019 Concurrent and Retrospective Think-Aloud Verbalizations for Identifying User Experience Problems of VR Games", "Authors": ["Mingming Fan", "Vinita Tibdewal", "Qiwen Zhao", "Lizhou Cao", "Chao Peng", "Runxuan Shu", "Yujia Shan"], "Sources": "Interacting with Computers", "PublishedYears": "2022", "Doi": "", "Abstracts": " While virtual reality (VR) games are beneficial for older adults to improve their physical functions and cognitive abilities, VR research often does not include older adults. Our review of the proceedings of major HCI conferences (i.e. ASSETS, CHI, CHI PLAY, CSCW and DIS) between 2016 and 2020 shows that only three out of 352 VR-related papers involved older adults. Consequently, older adults tend to encounter user experience (UX) problems with VR. One common way to identify UX problems is to conduct usability testing with think-aloud (TA) protocols. As VR games tend to be perceptually and physically demanding, older adults might need to allocate more resources to VR content and interaction and thus have fewer resources for thinking aloud. This raises the question of whether TA protocols are still a viable approach to detecting UX problems of VR games for older adult participants. To answer this?\u2026", "IdName": "fan2022older", "Citation": "", "Keywords": ""}, {"Name": "Sparkling silence: Practices and challenges of livestreaming among deaf or hard of hearing streamers", "Authors": ["Beiyan Cao", "Changyang He", "Muzhi Zhou", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Understanding livestream platforms\u2019 accessibility challenges for minority groups, such as people with disabilities, is critical to increasing the diversity and inclusion of those platforms. While prior work investigated the experiences of streamers with vision or motor loss, little is known about the experiences of deaf or hard of hearing (DHH) streamers who must work with livestreaming platforms that heavily depend on audio. We conducted semi-structured interviews with DHH streamers to learn why they livestream, how they navigate livestream platforms and related challenges. Our findings revealed their desire to break the stereotypes towards the DHH groups via livestream and the intense interplay between interaction methods, such as sign language, texts, lip language, background music, and viewer characteristics. Major accessibility challenges include the lack of real-time captioning, the small sign language?\u2026", "IdName": "cao2023sparkling", "Citation": "", "Keywords": ""}, {"Name": "CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming", "Authors": ["Felicia Li Feng", "Ryan Yen", "Yuzhe You", "Mingming Fan", "Jian Zhao", "Zhicong Lu"], "Sources": "arXiv preprint arXiv:2310.09235", "PublishedYears": "2023", "Doi": "", "Abstracts": "Natural language (NL) programming has become more approachable due to the powerful code-generation capability of large language models (LLMs). This shift to using NL to program enhances collaborative programming by reducing communication barriers and context-switching among programmers from varying backgrounds. However, programmers may face challenges during prompt engineering in a collaborative setting as they need to actively keep aware of their collaborators' progress and intents. In this paper, we aim to investigate ways to assist programmers' prompt engineering in a collaborative context. We first conducted a formative study to understand the workflows and challenges of programmers when using NL for collaborative programming. Based on our findings, we implemented a prototype, CoPrompt, to support collaborative prompt engineering by providing referring, requesting, sharing, and linking mechanisms. Our user study indicates that CoPrompt assists programmers in comprehending collaborators' prompts and building on their collaborators' work, reducing repetitive updates and communication costs.", "IdName": "feng2023coprompt", "Citation": "", "Keywords": ""}, {"Name": "Understanding Curators' Practices and Challenge of Making Exhibitions More Accessible for People with Visual Impairments", "Authors": ["Yuru Huang", "Jingling Zhang", "Xiaofu Jin", "Mingming Fan"], "Sources": "Proceedings of the 25th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Assistive technologies are increasingly developed and applied in exhibition environments to help blind and low vision (BLV) people deal with the challenges they face when visiting exhibitions. While studies have examined the experiences of BLV people using such technologies, little is known about the experiences and challenges of curators incorporating assistive technologies into exhibitions to make them more accessible to BLV people. This research focuses on assistive technologies for BLV people in exhibitions from a curatorial perspective. We conducted semi-structured interviews with twenty-two experienced curators to understand their practices and challenges. We also curated a list of assistive technologies from published papers and used them as probes to seek curators\u2019 attitudes and perceptions of such technologies. We uncovered four critical themes related to curators\u2019 challenges of making?\u2026", "IdName": "huang2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Understanding Strategies and Challenges of Conducting Daily Data Analysis (DDA) Among Blind and Low-vision People", "Authors": ["Chutian Jiang", "Wentao Lei", "Emily Kuang", "Teng Han", "Mingming Fan"], "Sources": "Proceedings of the 25th International ACM SIGACCESS Conference on Computers?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Being able to analyze and derive insights from data, which we call Daily Data Analysis (DDA), is an increasingly important skill in everyday life. While the accessibility community has explored ways to make data more accessible to blind and low-vision (BLV) people, little is known about how BLV people perform DDA. Knowing BLV people\u2019s strategies and challenges in DDA would allow the community to make DDA more accessible to them. Toward this goal, we conducted a mixed-methods study of interviews and think-aloud sessions with BLV people (N=16). Our study revealed five key approaches for DDA (i.e., overview obtaining, column comparison, key statistics identification, note-taking, and data validation) and the associated challenges. We discussed the implications of our findings and highlighted potential directions to make DDA more accessible for BLV people.", "IdName": "jiang2023understanding", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Opportunities of AR for Enriching Storytelling with Family Photos between Grandparents and Grandchildren", "Authors": ["Zisu Li", "Li Feng", "Chen Liang", "Yuru Huang", "Mingming Fan"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2023", "Doi": "", "Abstracts": "Storytelling with family photos, as an important mode of reminiscence-based activities, can be instrumental in promoting intergenerational communication between grandparents and grandchildren by strengthening generation bonds and shared family values. Motivated by challenges that existing technology approaches encountered for improving intergenerational storytelling (e.g., the need to hold the tablet, the potential view detachment from the physical world in Virtual Reality (VR)), we sought to find new ways of using Augmented Reality (AR) to support intergenerational storytelling, which offers new capabilities (e.g., 3D models, new interactivity) to enhance the expression for the storyteller. We conducted a two-part exploratory study, where pairs of grandparents and grandchildren 1) participated in an in-person storytelling activity with a semi-structured interview 2) and then a participatory design session with AR?\u2026", "IdName": "li2023exploring", "Citation": "", "Keywords": ""}, {"Name": "CoPracTter: Toward Integrating Personalized Practice Scenarios, Timely Feedback and Social Support into An Online Support Tool for Coping with Stuttering in China", "Authors": ["Li Feng", "Zeyu Xiong", "Xinyi Li", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Stuttering is a speech disorder influencing over 70 million people worldwide, including 13 million in China. It causes low self-esteem among other detrimental effects on people who stutter (PwS). Although prior work has explored approaches to assist PwS, they primarily focused on western contexts. In our formative study, we found unique practices and challenges among Chinese PwS. We then iteratively designed an online tool, CoPracTter, to support Chinese PwS practicing speaking fluency with 1) targeted stress-inducing practice scenarios, 2) real-time speech indicators, and 3) personalized timely feedback from the community. We further conducted a seven-day deployment study (N=11) to understand how participants utilized these key features. To our knowledge, it is the first time such a prototype was designed and tested for a long time with multiple PwS participants online simultaneously. Results indicate?\u2026", "IdName": "feng2023copractter", "Citation": "", "Keywords": ""}, {"Name": "Typist Experiment: an Investigation of Human-to-Human Dictation via Role-play to Inform Voice-based Text Authoring", "Authors": ["Can Liu", "Siying Hu", "Li Feng", "Mingming Fan"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Voice dictation is increasingly used for text entry, especially in mobile scenarios. However, the speech-based experience gets disrupted when users must go back to a screen and keyboard to review and edit the text. While existing dictation systems focus on improving transcription and error correction, little is known about how to support speech input for the entire text creation process, including composition, reviewing and editing. We conducted an experiment in which ten pairs of participants took on the roles of authors and typists to work on a text authoring task. By analysing the natural language patterns of both authors and typists, we identified new challenges and opportunities for the design of future dictation interfaces, including the ambiguity of human dictation, the differences between audio-only and with screen, and various passive and active assistance that can potentially be provided by future systems.", "IdName": "liu2022typist", "Citation": "", "Keywords": ""}, {"Name": "Enhancing UX Evaluation Through Collaboration with Conversational AI Assistants: Effects of Proactive Dialogue and Timing", "Authors": ["Emily Kuang", "Minghao Li", "Mingming Fan", "Kristen Shinohara"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Usability testing is vital for enhancing the user experience (UX) of interactive systems. However, analyzing test videos is complex and resource-intensive. Recent AI advancements have spurred exploration into human-AI collaboration for UX analysis, particularly through natural language. Unlike user-initiated dialogue, our study investigated the potential of proactive conversational assistants to aid UX evaluators through automatic suggestions at three distinct times: before, in sync with, and after potential usability problems. We conducted a hybrid Wizard-of-Oz study involving 24 UX evaluators, using ChatGPT to generate automatic problem suggestions and a human actor to respond to impromptu questions. While timing did not significantly impact analytic performance, suggestions appearing after potential problems were preferred, enhancing trust and efficiency. Participants found the automatic suggestions useful?\u2026", "IdName": "kuang2024enhancing", "Citation": "", "Keywords": ""}, {"Name": "HeadEvolver: Text to Head Avatars via Locally Learnable Mesh Deformation", "Authors": ["Duotun Wang", "Hengyu Meng", "Zeyu Cai", "Zhijing Shao", "Qianxi Liu", "Lin Wang", "Mingming Fan", "Ying Shan", "Xiaohang Zhan", "Zeyu Wang"], "Sources": "arXiv preprint arXiv:2403.09326", "PublishedYears": "2024", "Doi": "", "Abstracts": "We present HeadEvolver, a novel framework to generate stylized head avatars from text guidance. HeadEvolver uses locally learnable mesh deformation from a template head mesh, producing high-quality digital assets for detail-preserving editing and animation. To tackle the challenges of lacking fine-grained and semantic-aware local shape control in global deformation through Jacobians, we introduce a trainable parameter as a weighting factor for the Jacobian at each triangle to adaptively change local shapes while maintaining global correspondences and facial features. Moreover, to ensure the coherence of the resulting shape and appearance from different viewpoints, we use pretrained image diffusion models for differentiable rendering with regularization terms to refine the deformation under text guidance. Extensive experiments demonstrate that our method can generate diverse head avatars with an articulated mesh that can be edited seamlessly in 3D graphics software, facilitating downstream applications such as more efficient animation with inherited blend shapes and semantic consistency.", "IdName": "wang2024headevolver", "Citation": "", "Keywords": ""}, {"Name": "OperARtistry: An AR-based Interactive Application to Assist the Learning of Chinese Traditional Opera (Xiqu) Makeup", "Authors": ["Zeyu Xiong", "Shihan Fu", "Mingming Fan"], "Sources": "Proceedings of the Eleventh International Symposium of Chinese CHI", "PublishedYears": "2023", "Doi": "", "Abstracts": " Chinese Traditional Opera (Xiqu) is an important type of intangible cultural heritage and one key characteristic of Xiqu is its visual effects on face achieved via makeup. However, Xiqu makeup process, especially the eye-area makeup process, is complex and time-consuming, which poses a learning challenge for potential younger inheritors. We introduce OperARtistry, an interactive application based on Augmented Reality (AR) that offers in-situ Xiqu makeup guidance for beginners. Our application provides a step-by-step guide for Xiqu eye-area makeup, incorporating AR effects at each stage. Furthermore, we conducted an initial user study (n=6) to compare our approach with existing video-based tutorials to assess the effectiveness and usefulness of our approach. Our findings show that OperARtisty helped participants achieve high-quality eye-area makeup effects with less learning time.", "IdName": "xiong2023operartistry", "Citation": "", "Keywords": ""}, {"Name": "ShadowTouch: Enabling Free-Form Touch-Based Hand-to-Surface Interaction with Wrist-Mounted Illuminant by Shadow Projection", "Authors": ["Chen Liang", "Xutong Wang", "Zisu Li", "Chi Hsia", "Mingming Fan", "Chun Yu", "Yuanchun Shi"], "Sources": "Proceedings of the 36th Annual ACM Symposium on User Interface Software and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We present ShadowTouch, a novel sensing method to recognize the subtle hand-to-surface touch state for independent fingers based on optical auxiliary. ShadowTouch mounts a forward-facing light source on the user\u2019s wrist to construct shadows on the surface in front of the fingers when the corresponding fingers are close to the surface. With such an optical design, the subtle vertical movements of near-surface fingers are magnified and turned to shadow features cast on the surface, which are recognizable for computer vision algorithms. To efficiently recognize the touch state of each finger, we devised a two-stage CNN-based algorithm that first extracted all the fingertip regions from each frame and then classified the touch state of each region from the cropped consecutive frames. Evaluations showed our touch state detection algorithm achieved a recognition accuracy of 99.1% and an F-1 score of 96.8% in the?\u2026", "IdName": "liang2023shadowtouch", "Citation": "", "Keywords": ""}, {"Name": "Enhancing Older Adults\u2019 Gesture Typing Experience Using the T9 Keyboard on Small Touchscreen Devices", "Authors": ["Emily Kuang", "Ruihuan Chen", "Mingming Fan"], "Sources": "Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Older adults increasingly adopt small-screen devices, but limited motor dexterity hinders their ability to type effectively. While a 9-key (T9) keyboard allocates larger space to each key, it is shared by multiple consecutive letters. Consequently, users must interrupt their gestures when typing consecutive letters, leading to inefficiencies and poor user experience. Thus, we proposed a novel keyboard that leverages the currently unused key 1 to duplicate letters from the previous key, allowing the entry of consecutive letters without interruptions. A user study with 12 older adults showed that it significantly outperformed the T9 with wiggle gesture in typing speed, KSPC, insertion errors, and deletes per word while achieving comparable performance as the conventional T9. Repeating the typing tasks with 12 young adults found that the advantages of the novel T9 were consistent or enhanced. We also provide error analysis?\u2026", "IdName": "kuang2023enhancing", "Citation": "", "Keywords": ""}, {"Name": "SmartRecorder: An IMU-based Video Tutorial Creation by Demonstration System for Smartphone Interaction Tasks", "Authors": ["Xiaozhu Hu", "Yanwen Huang", "Bo Liu", "Ruolan Wu", "Yongquan Hu", "Aaron J Quigley", "Mingming Fan", "Chun Yu", "Yuanchun Shi"], "Sources": "Proceedings of the 28th International Conference on Intelligent User?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " This work focuses on an active topic in the HCI community, namely tutorial creation by demonstration. We present a novel tool named SmartRecorder that facilitates people, without video editing skills, creating video tutorials for smartphone interaction tasks. As automatic interaction trace extraction is a key component to tutorial generation, we seek to tackle the challenges of automatically extracting user interaction traces on smartphones from screencasts. Uniquely, with respect to prior research in this field, we combine computer vision techniques with IMU-based sensing algorithms, and the technical evaluation results show the importance of smartphone IMU data in improving system performance. With the extracted key information of each step, SmartRecorder generates instructional content initially and provides tutorial creators with a tutorial refinement editor designed based on a high recall (99.38%) of key steps?\u2026", "IdName": "hu2023smartrecorder", "Citation": "", "Keywords": ""}, {"Name": "Think-Aloud Verbalizations for Identifying User Experience Problems: Effects of Language Proficiency with Chinese Non-Native English Speakers", "Authors": ["Mingming Fan", "Lingyun Zhu"], "Sources": "Proceedings of the Ninth International Symposium of Chinese CHI", "PublishedYears": "2021", "Doi": "", "Abstracts": "Subtle patterns in users\u2019 think-aloud (TA) verbalizations (i.e., utterances) are shown to be telltale signs of user experience (UX) problems and used to build artificial intelligence (AI) models or AI-assisted tools to help UX evaluators identify UX problems automatically or semi-automatically. Despite the potential of such verbalization patterns, they were uncovered with native English speakers. As most people who speak English are non-native speakers, it is important to investigate whether similar patterns exist in non-native English speakers\u2019 TA verbalizations. As a first step to answer this question, we conducted think-aloud usability testing with Chinese non-native English speakers and native English speakers using three common TA protocols. We compared their verbalizations and UX problems that they encountered to understand the effects of language and TA protocols. Our findings show that both language?\u2026", "IdName": "fan2021think", "Citation": "", "Keywords": ""}, {"Name": "EvoK: Connecting loved ones through Heart Rate sharing", "Authors": ["Esha Shandilya", "Yiwen Wang", "Xuan Zhao", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2102.10685", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this work, we present EvoK, a new way of sharing one's heart rate with feedback from their close contacts to alleviate social isolation and loneliness. EvoK consists of a pair of wearable prototype devices (i.e., sender and receiver). The sender is designed as a headband enabling continuous sensing of heart rate with aesthetic designs to maximize social acceptance. The receiver is designed as a wristwatch enabling unobtrusive receiving of the loved one's continuous heart rate with multi-modal notification systems.", "IdName": "shandilya2021evok", "Citation": "", "Keywords": ""}, {"Name": "Neural Canvas: Supporting Scenic Design Prototyping by Integrating 3D Sketching and Generative AI", "Authors": ["Yulin Shen", "Yifei Shen", "Jiawen Cheng", "Chutian Jiang", "Mingming Fan", "Zeyu Wang"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " We propose Neural Canvas, a lightweight 3D platform that integrates sketching and a collection of generative AI models to facilitate scenic design prototyping. Compared with traditional 3D tools, sketching in a 3D environment helps designers quickly express spatial ideas, but it does not facilitate the rapid prototyping of scene appearance or atmosphere. Neural Canvas integrates generative AI models into a 3D sketching interface and incorporates four types of projection operations to facilitate 2D-to-3D content creation. Our user study shows that Neural Canvas is an effective creativity support tool, enabling users to rapidly explore visual ideas and iterate 3D scenic designs. It also expedites the creative process for both novices and artists who wish to leverage generative AI technology, resulting in attractive and detailed 3D designs created more efficiently than using traditional modeling tools or individual generative?\u2026", "IdName": "shen2024neural", "Citation": "", "Keywords": ""}, {"Name": "AromaBlendz: An Olfactory System for Crafting Personalized Scents", "Authors": ["Shihan Fu", "Jianhao Chen", "Yi Cai", "Mingming Fan"], "Sources": "Extended Abstracts of the CHI Conference on Human Factors in Computing?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": " Although the HCI community has recently begun to explore the usage of scent to enrich interactive system experiences (e.g., making VR more immersive), scent is often preset. In contrast, personalized scents might help trigger emotional responses and memory recall in many application scenarios, ranging from fostering relaxation to managing emotional states. We present AromaBlendz, a novel digital platform that enables users to create and customize their unique scent profiles. AromaBlendz comprises both hardware and software components that collectively deliver a seamless scent customization experience. The hardware includes a blending mechanism for essence oils and a user-friendly control unit, while the software component provides an intuitive interface for users to create, preview, and store their preferred scents. The platform not only allows for the generation of personalized scent profiles using a?\u2026", "IdName": "fu2024aromablendz", "Citation": "", "Keywords": ""}, {"Name": "Designing Unobtrusive Modulated Electrotactile Feedback on Fingertip Edge to Assist Blind and Low Vision (BLV) People in Comprehending Charts", "Authors": ["Chutian Jiang", "Yinan Fan", "Junan Xie", "Emily Kuang", "Kaihao Zhang", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Charts are crucial in conveying information across various fields but are inaccessible to blind and low vision (BLV) people without assistive technology. Chart comprehension tools leveraging haptic feedback have been used widely but are often bulky, expensive, and static, rendering them inefficient for conveying chart data. To increase device portability, enable multitasking, and provide efficient assistance in chart comprehension, we introduce a novel system that delivers unobtrusive modulated electrotactile feedback directly to the fingertip edge. Our three-part study with twelve participants confirmed the effectiveness of this system, demonstrating that electrotactile feedback, when applied for 0.5 seconds with a 0.12-second interval, provides the most accurate position and direction recognition. Furthermore, our electrotactile device has proven valuable in assisting BLV participants in comprehending four commonly?\u2026", "IdName": "jiang2024designing", "Citation": "", "Keywords": ""}, {"Name": "Bridging the Literacy Gap for Adults: Streaming and Engaging in Adult Literacy Education through Livestreaming", "Authors": ["Shihan Fu", "Jianhao Chen", "Emily Kuang", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Literacy\u2014the ability to read, write, and comprehend text\u2014is an important topic addressed by UNESCO. Despite global efforts to promote adult literacy education, rural areas with limited resources still lag behind. As livestreaming has gained popularity in China, many streamers leveraged its accessibility and affordability to reach low-literate adults. To gain a better understanding of the practices and challenges faced by adult literacy education through livestreaming, we conducted a mixed-methods study involving a 7-day observation of livestreaming sessions and an interview study with twelve streamers and ten viewers. We discovered streamers\u2019 altruistic motives and unique interactive approaches. Viewers perceived livestreaming as a more engaging, community-supportive method than traditional approaches. We also identified both shared and unique challenges for streamers and viewers that limit its efficacy as?\u2026", "IdName": "fu2024bridging", "Citation": "", "Keywords": ""}, {"Name": "WieldingCanvas: Interactive Sketch Canvases for Freehand Drawing in VR", "Authors": ["Xiaohui Tan", "Zhenxuan He", "Can Liu", "Mingming Fan", "Tianren Luo", "Zitao Liu", "Mi Tian", "Teng Han", "Feng Tian"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Sketching in Virtual Reality (VR) is challenging mainly due to the absence of physical surface support and virtual depth perception cues, which induce high cognitive and sensorimotor load. This paper presents WieldingCanvas, an interactive VR sketching platform that integrates canvas manipulations to draw lines and curves in 3D. Informed by real-life examples of two-handed creative activities, WieldingCanvas interprets users\u2019 spatial gestures to move, swing, rotate, transform, or fold a virtual canvas, whereby users simply draw primitive strokes on the canvas, which are turned into finer and more sophisticated shapes via the manipulation of the canvas. We evaluated the capability and user experience of WieldingCanvas with two studies where participants were asked to sketch target shapes. A set of freehand sketches of high aesthetic qualities were created, and the results demonstrated that WieldingCanvas can?\u2026", "IdName": "tan2024wieldingcanvas", "Citation": "", "Keywords": ""}, {"Name": "CharacterMeet: Supporting Creative Writers' Entire Story Character Construction Processes Through Conversation with LLM-Powered Chatbot Avatars", "Authors": ["Hua Xuan Qin", "Shan Jin", "Ze Gao", "Mingming Fan", "Pan Hui"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Support for story character construction is as essential as characters are for stories. Building upon past research on early character construction stages, we explore how conversation with chatbot avatars embodying characters powered by more recent technologies could support the entire character construction process for creative writing. Through a user study (N=14) with creative writers, we examine thinking and usage patterns of CharacterMeet, a prototype system allowing writers to progressively manifest characters through conversation while customizing context, character appearance, voice, and background image. We discover that CharacterMeet facilitates iterative character construction. Specifically, participants, including those with more linear usual approaches, alternated between writing and personalized exploration through visualization of ideas on CharacterMeet while visuals and audio enhanced?\u2026", "IdName": "qin2024charactermeet", "Citation": "", "Keywords": ""}, {"Name": "Designing Upper-Body Gesture Interaction with and for People with Spinal Muscular Atrophy in VR", "Authors": ["Jingze Tian", "Yingna Wang", "Keye Yu", "Liyi Xu", "Junan Xie", "Franklin Mingzhe Li", "Yafeng Niu", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent research proposed gaze-assisted gestures to enhance interaction within virtual reality (VR), providing opportunities for people with motor impairments to experience VR. Compared to people with other motor impairments, those with Spinal Muscular Atrophy (SMA) exhibit enhanced distal limb mobility, providing them with more design space. However, it remains unknown what gaze-assisted upper-body gestures people with SMA would want and be able to perform. We conducted an elicitation study in which 12 VR-experienced people with SMA designed upper-body gestures for 26 VR commands, and collected 312 user-defined gestures. Participants predominantly favored creating gestures with their hands. The type of tasks and participants\u2019 abilities influence their choice of body parts for gesture design. Participants tended to enhance their body involvement and preferred gestures that required minimal?\u2026", "IdName": "tian2024designing", "Citation": "", "Keywords": ""}, {"Name": "LightSword: A Customized Virtual Reality Exergame for Long-Term Cognitive Inhibition Training in Older Adults", "Authors": ["Qiuxin Du", "Zhen Song", "Haiyan Jiang", "Xiaoying Wei", "Dongdong Weng", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " The decline of cognitive inhibition significantly impacts older adults\u2019 quality of life and well-being, making it a vital public health problem in today\u2019s aging society. Previous research has demonstrated that Virtual reality (VR) exergames have great potential to enhance cognitive inhibition among older adults. However, existing commercial VR exergames were unsuitable for older adults\u2019 long-term cognitive training due to the inappropriate cognitive activation paradigm, unnecessary complexity, and unbefitting difficulty levels. To bridge these gaps, we developed a customized VR cognitive training exergame (LightSword) based on Dual-task and Stroop paradigms for long-term cognitive inhibition training among healthy older adults. Subsequently, we conducted an eight-month longitudinal user study with 12 older adults aged 60 years and above to demonstrate the effectiveness of LightSword in improving cognitive?\u2026", "IdName": "du2024lightsword", "Citation": "", "Keywords": ""}, {"Name": "\u201cCan It Be Customized According to My Motor Abilities?\u201d: Toward Designing User-Defined Head Gestures for People with Dystonia", "Authors": ["Qin Sun", "Yunqi Hu", "Mingming Fan", "Jingting Li", "Su-Jing Wang"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Recent studies proposed above-the-neck gestures for people with upper-body motor impairments interacting with mobile devices without finger touch, resulting in an appropriate user-defined gesture set. However, many gestures involve sustaining eyelids in closed or open states for a period. This is challenging for people with dystonia, who have difficulty sustaining and intermitting muscle contractions. Meanwhile, other facial parts, such as the tongue and nose, can also be used to alleviate the sustained use of eyes in the interaction. Consequently, we conducted a user study inviting 16 individuals with dystonia to design gestures based on facial muscle movements for 26 common smartphone commands. We collected 416 user-defined head gestures involving facial features and shoulders. Finally, we obtained the preferred gestures set for individuals with dystonia. Participants preferred to make the gestures with?\u2026", "IdName": "sun2024can", "Citation": "", "Keywords": ""}, {"Name": "To Reach the Unreachable: Exploring the Potential of VR Hand Redirection for Upper Limb Rehabilitation", "Authors": ["Peixuan Xiong", "Yukai Zhang", "Nandi Zhang", "Shihan Fu", "Xin Li", "Yadan Zheng", "Jinni Zhou", "Xiquan Hu", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Rehabilitation therapies are widely employed to assist people with motor impairments in regaining control over their affected body parts. Nevertheless, factors such as fatigue and low self-efficacy can hinder patient compliance during extensive rehabilitation processes. Utilizing hand redirection in virtual reality (VR) enables patients to accomplish seemingly more challenging tasks, thereby bolstering their motivation and confidence. While previous research has investigated user experience and hand redirection among able-bodied people, its effects on motor-impaired people remain unexplored. In this paper, we present a VR rehabilitation application that harnesses hand redirection. Through a user study and semi-structured interviews, we examine the impact of hand redirection on the rehabilitation experiences of people with motor impairments and its potential to enhance their motivation for upper limb?\u2026", "IdName": "xiong2024reach", "Citation": "", "Keywords": ""}, {"Name": "Toward Making Virtual Reality (VR) More Inclusive for Older Adults: Investigating Aging Effect on Target Selection and Manipulation Tasks in VR", "Authors": ["Zhiqing Wu", "Duotun Wang", "Shumeng Zhang", "Yuru Huang", "Zeyu Wang", "Mingming Fan"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent studies show the promise of VR in improving physical, cognitive, and emotional health of older adults. However, prior work on optimizing object selection and manipulation performance in VR was mostly conducted among younger adults. It remains unclear how older adults would perform such tasks compared to younger adults and the challenges they might face. To fill in this gap, we conducted two studies with both older and younger adults to understand their performances and user experiences of object selection and manipulation in VR respectively. Based on the results, we delineated interaction difficulties that older adults exhibited in VR and identified multiple factors, such as headset-related neck fatigue, extra head movements from out-of-view interactions, and slow spatial perceptions, that significantly decreased the motor performance of older adults. We further proposed design recommendations for?\u2026", "IdName": "wu2024toward", "Citation": "", "Keywords": ""}, {"Name": "See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles", "Authors": ["Yu Zhang", "Jingwei Sun", "Li Feng", "Cen Yao", "Mingming Fan", "Liuxin Zhang", "Qianying Wang", "Xin Geng", "Yong Rui"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " The proliferation of AI-powered search and recommendation systems has accelerated the formation of \u201cfilter bubbles\u201d that reinforce people\u2019s biases and narrow their perspectives. Previous research has attempted to address this issue by increasing the diversity of information exposure, which is often hindered by a lack of user motivation to engage with. In this study, we took a human-centered approach to explore how Large Language Models (LLMs) could assist users in embracing more diverse perspectives. We developed a prototype featuring LLM-powered multi-agent characters that users could interact with while reading social media content. We conducted a participatory design study with 18 participants and found that multi-agent dialogues with gamification incentives could motivate users to engage with opposing viewpoints. Additionally, progressive interactions with assessment tasks could promote?\u2026", "IdName": "zhang2024see", "Citation": "", "Keywords": ""}, {"Name": "\" It Is Hard to Remove from My Eye\": Design Makeup Residue Visualization System for Chinese Traditional Opera (Xiqu) Performers", "Authors": ["Zeyu Xiong", "Shihan Fu", "Yanying Zhu", "Chenqing Zhu", "Xiaojuan Ma", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2402.15719", "PublishedYears": "2024", "Doi": "", "Abstracts": "Chinese traditional opera (Xiqu) performers often experience skin problems due to the long-term use of heavy-metal-laden face paints. To explore the current skincare challenges encountered by Xiqu performers, we conducted an online survey (N=136) and semi-structured interviews (N=15) as a formative study. We found that incomplete makeup removal is the leading cause of human-induced skin problems, especially the difficulty in removing eye makeup. Therefore, we proposed EyeVis, a prototype that can visualize the residual eye makeup and record the time make-up was worn by Xiqu performers. We conducted a 7-day deployment study (N=12) to evaluate EyeVis. Results indicate that EyeVis helps to increase Xiqu performers' awareness about removing makeup, as well as boosting their confidence and security in skincare. Overall, this work also provides implications for studying the work of people who wear makeup on a daily basis, and helps to promote and preserve the intangible cultural heritage of practitioners.", "IdName": "xiong2024hard", "Citation": "", "Keywords": ""}, {"Name": "FetchAid: Making Parcel Lockers More Accessible to Blind and Low Vision People With Deep-learning Enhanced Touchscreen Guidance, Error-Recovery Mechanism, and AR-based Search?\u2026", "Authors": ["Zhitong Guan", "Zeyu Xiong", "Mingming Fan"], "Sources": "arXiv preprint arXiv:2402.15723", "PublishedYears": "2024", "Doi": "", "Abstracts": "Parcel lockers have become an increasingly prevalent last-mile delivery method. Yet, a recent study revealed its accessibility challenges to blind and low-vision people (BLV). Informed by the study, we designed FetchAid, a standalone intelligent mobile app assisting BLV in using a parcel locker in real-time by integrating computer vision and augmented reality (AR) technologies. FetchAid first uses a deep network to detect the user's fingertip and relevant buttons on the touch screen of the parcel locker to guide the user to reveal and scan the QR code to open the target compartment door and then guide the user to reach the door safely with AR-based context-aware audio feedback. Moreover, FetchAid provides an error-recovery mechanism and real-time feedback to keep the user on track. We show that FetchAid substantially improved task accomplishment and efficiency, and reduced frustration and overall effort in a study with 12 BLV participants, regardless of their vision conditions and previous experience.", "IdName": "guan2024fetchaid", "Citation": "", "Keywords": ""}, {"Name": "Exploring the Impact of Artificial Intelligence-Generated Content (AIGC) Tools on Social Dynamics in UX Collaboration", "Authors": ["Ziyan Wang", "Luyao Shen", "Emily Kuang", "Shumeng Zhang", "Mingming Fan"], "Sources": "None", "PublishedYears": "2024", "Doi": "", "Abstracts": "Artificial Intelligence-Generated Content (AIGC) tools have gradually been integrated into the daily workflow of UX practitioners. While existing research has explored the integration of AIGC tools in daily workflow, little is known about their impact on social dynamics within UX collaboration. We conducted four focus groups and eight semi-structured interviews with 26 UX practitioners to investigate how AIGC tools influence social dynamics in UX collaboration. Our findings indicated that AIGC tools not only mitigated conflicts but also introduced potential new conflicts. AIGC tools expanded the roles of UX practitioners and fostered a team culture characterized by exploring and discussing. Participants have higher expectations for AI-assisted design in user understanding and prototype evaluation, and team-motivated AI tools learning. Based on these findings, we discussed the benefits and concerns of conflict resolution through AIGC and the importance of teams in AI learning. Finally, we proposed several suggestions for future AI design research.", "IdName": "wang2024exploring", "Citation": "", "Keywords": ""}, {"Name": "Toward Leveraging Augmented Reality (AR) for Enhancing Remote Intergenerational Communication in Cooking Scenarios", "Authors": ["Yuru Huang", "Liyi Xu", "You Zhou", "Qiongyan Chen", "Zhiqing Wu", "Li Feng", "Mingming Fan"], "Sources": "Proceedings of the Eleventh International Symposium of Chinese CHI", "PublishedYears": "2023", "Doi": "", "Abstracts": " The close connection between food culture and family relationship has always been regarded as an important link to maintain family harmony and intergenerational(IG) communication. Through cooking and eating together, family members inherit family customs and culture, and enhance mutual feelings and understanding. However, with the development changes in family structure, there is an urgent need to find new approaches for IG communication between the younger and older generations. In this context, this study will explore how modern technological means such as remote home intelligent control and augmented reality (AR) technology, combined with the characteristics of food culture, can be used to innovate and strengthen IG communication between family members. This study explored the challenges inherent in remote integrated circuits in the context of collaborative cooking. Building on this, we use?\u2026", "IdName": "huang2023toward", "Citation": "", "Keywords": ""}, {"Name": "A Multi-modal Toolkit to Support DIY Assistive Technology Creation for Blind and Low Vision People", "Authors": ["Liwen He", "Yifan Li", "Mingming Fan", "Liang He", "Yuhang Zhao"], "Sources": "Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " We design and build A11yBits, a tangible toolkit that empowers blind and low vision (BLV) people to easily create personalized do-it-yourself assistive technologies (DIY-ATs). A11yBits includes (1) a series of Sensing modules to detect both environmental information and user commands, (2) a set of Feedback modules to send multi-modal feedback, and (3) two Base modules (Sensing Base and Feedback Base) to power and connect the sensing and feedback modules. The toolkit enables accessible and easy assembly via a \u201cplug-and-play\u201d mechanism. BLV users can select and assemble their preferred modules to create personalized DIY-ATs. ", "IdName": "he2023multi", "Citation": "", "Keywords": ""}, {"Name": "Designing Loving-Kindness Meditation in Virtual Reality for Long-Distance Romantic Relationships", "Authors": ["Xian Wang", "Xiaoyu Mo", "Lik-Hang Lee", "Xiaoying Wei", "Xiaofu Jin", "Mingming Fan", "Pan Hui"], "Sources": "Proceedings of the 31st ACM International Conference on Multimedia", "PublishedYears": "2023", "Doi": "", "Abstracts": "Loving-kindness meditation (LKM) is used in clinical psychology for couples' relationship therapy, but physical isolation can make the relationship more strained and inaccessible to LKM. Virtual reality (VR) can provide immersive LKM activities for long-distance couples. However, no suitable commercial VR applications for couples exist to engage in LKM activities of long-distance. This paper organized a series of workshops with couples to build a prototype of a couple-preferred LKM app. Through analysis of participants' design works and semi-structured interviews, we derived design considerations for such VR apps and created a prototype for couples to experience. We conducted a study with couples to understand their experiences of performing LKM using the VR prototype and a traditional video conferencing tool. Results show that LKM session utilizing both tools has a positive effect on the intimate?\u2026", "IdName": "wang2023designing", "Citation": "", "Keywords": ""}, {"Name": "OdorV-Art: An Initial Exploration of An Olfactory Intervention for Appreciating Style Information of Artworks in Virtual Museum", "Authors": ["Shumeng Zhang", "Ziyan Wang", "You Zhou", "Hao Cui", "Shihan Fu", "Zeyu Wang", "Mingming Fan"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Style information, such as tone, mood, and genre of artworks, is important for museum visitors to appreciate them better. However, such information can be challenging for non-art specialists to comprehend in the short period that they view artworks. The sense of smell is instrumental for humans to assist their image memory, color, emotion, and shape association. However, it is rarely used in the appreciation of artworks. Taking Western landscape painting as an example, this research explores the following research questions (RQs): 1) How does the intervention of the sense of smell improve the acquisition of style information in paintings? 2) How does the intervention of the sense of smell enhance the immersion in painting appreciation? To answer RQs, we first recruited seven art specialists to participate in a co-design workshop to design a prototype of the virtual museum with olfactory intervention. We then?\u2026", "IdName": "zhang2023odorv", "Citation": "", "Keywords": ""}, {"Name": "All one needs to know about metaverse: A complete survey on technological singularity, virtual ecosystem, and research agenda", "Authors": ["Lik-Hang Lee", "Tristan Braud", "Pengyuan Zhou", "Lin Wang", "Dianlei Xu", "Zijun Lin", "Abhishek Kumar", "Carlos Bermejo", "Pan Hui"], "Sources": "arXiv preprint arXiv:2110.05352", "PublishedYears": "2021", "Doi": "", "Abstracts": "Since the popularisation of the Internet in the 1990s, the cyberspace has kept evolving. We have created various computer-mediated virtual environments including social networks, video conferencing, virtual 3D worlds (e.g., VR Chat), augmented reality applications (e.g., Pokemon Go), and Non-Fungible Token Games (e.g., Upland). Such virtual environments, albeit non-perpetual and unconnected, have bought us various degrees of digital transformation. The term `metaverse' has been coined to further facilitate the digital transformation in every aspect of our physical lives. At the core of the metaverse stands the vision of an immersive Internet as a gigantic, unified, persistent, and shared realm. While the metaverse may seem futuristic, catalysed by emerging technologies such as Extended Reality, 5G, and Artificial Intelligence, the digital `big bang' of our cyberspace is not far away. This survey paper presents the first effort to offer a comprehensive framework that examines the latest metaverse development under the dimensions of state-of-the-art technologies and metaverse ecosystems, and illustrates the possibility of the digital `big bang'. First, technologies are the enablers that drive the transition from the current Internet to the metaverse. We thus examine eight enabling technologies rigorously - Extended Reality, User Interactivity (Human-Computer Interaction), Artificial Intelligence, Blockchain, Computer Vision, IoT and Robotics, Edge and Cloud computing, and Future Mobile Networks. In terms of applications, the metaverse ecosystem allows human users to live and play within a self-sustaining, persistent, and shared realm. Therefore, we?\u2026", "IdName": "lee2021all", "Citation": "", "Keywords": ""}, {"Name": "Edge intelligence: Empowering intelligence to the edge of network", "Authors": ["Dianlei Xu", "Tong Li", "Yong Li", "Xiang Su", "Sasu Tarkoma", "Tao Jiang", "Jon Crowcroft", "Pan Hui"], "Sources": "Proceedings of the IEEE", "PublishedYears": "2021", "Doi": "", "Abstracts": "Edge intelligence refers to a set of connected systems and devices for data collection, caching, processing, and analysis proximity to where data are captured based on artificial intelligence. Edge intelligence aims at enhancing data processing and protects the privacy and security of the data and users. Although recently emerged, spanning the period from 2011 to now, this field of research has shown explosive growth over the past five years. In this article, we present a thorough and comprehensive survey of the literature surrounding edge intelligence. We first identify four fundamental components of edge intelligence, i.e., edge caching, edge training, edge inference, and edge offloading based on theoretical and practical results pertaining to proposed and deployed systems. We then aim for a systematic classification of the state of the solutions by examining research results and observations for each of the four?\u2026", "IdName": "xu2021edge", "Citation": "", "Keywords": ""}, {"Name": "Life, the metaverse and everything: An overview of privacy, ethics, and governance in metaverse", "Authors": ["Carlos Bermejo Fernandez", "Pan Hui"], "Sources": "2022 IEEE 42nd international conference on distributed computing systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The metaverse is expected to be the next major evolution phase of the internet. The metaverse will impact human society, production, and life. In this work, we analyze the current trends and challenges that building such a virtual environment will face. We focus on three major pillars to guide the development of the metaverse: privacy, governance, and ethical design, to guide the development of the metaverse. Finally, we propose a preliminary modular-based framework for an ethical design of the metaverse.", "IdName": "fernandez2022life", "Citation": "", "Keywords": ""}, {"Name": "Privacy-preserving asynchronous federated learning mechanism for edge network computing", "Authors": ["Xiaofeng Lu", "Yuying Liao", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "In the traditional cloud architecture, data needs to be uploaded to the cloud for processing, bringing delays in transmission and response. Edge network emerges as the times require. Data processing on the edge nodes can reduce the delay of data transmission and improve the response speed. In recent years, the need for artificial intelligence of edge network has been proposed. However, the data of a single, individual edge node is limited and does not satisfy the conditions of machine learning. Therefore, performing edge network machine learning under the premise of data confidentiality became a research hotspot. This paper proposes a Privacy-Preserving Asynchronous Federated Learning Mechanism for Edge Network Computing (PAFLM), which can allow multiple edge nodes to achieve more efficient federated learning without sharing their private data. Compared with the traditional distributed learning?\u2026", "IdName": "lu2020privacy", "Citation": "", "Keywords": ""}, {"Name": "A survey on haptic technologies for mobile augmented reality", "Authors": ["Carlos Bermejo", "Pan Hui"], "Sources": "ACM Computing Surveys (CSUR)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Augmented reality (AR) applications have gained much research and industry attention. Moreover, the mobile counterpart\u2014mobile augmented reality (MAR) is one of the most explosive growth areas for AR applications in the mobile environment (e.g., smartphones). The technical improvements in the hardware of smartphones, tablets, and smart-glasses provide an advantage for the wide use of mobile AR in the real world and experience these AR applications anywhere. However, the mobile nature of MAR applications can limit users\u2019 interaction capabilities, such as input and haptic feedback. In this survey, we analyze current research issues in the area of human-computer interaction for haptic technologies in MAR scenarios. The survey first presents human sensing capabilities and their applicability in AR applications. We classify haptic devices into two groups according to the triggered sense: cutaneous/tactile?\u2026", "IdName": "bermejo2021survey", "Citation": "", "Keywords": ""}, {"Name": "One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc era", "Authors": ["Chaoning Zhang", "Chenshuang Zhang", "Chenghao Li", "Yu Qiao", "Sheng Zheng", "Sumit Kumar Dam", "Mengchun Zhang", "Jung Uk Kim", "Seong Tae Kim", "Jinwoo Choi", "Gyeong-Moon Park", "Sung-Ho Bae", "Lik-Hang Lee", "Pan Hui", "In So Kweon", "Choong Seon Hong"], "Sources": "arXiv preprint arXiv:2304.06488", "PublishedYears": "2023", "Doi": "", "Abstracts": "OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is demonstrated to be one small step for generative AI (GAI), but one giant leap for artificial general intelligence (AGI). Since its official release in November 2022, ChatGPT has quickly attracted numerous users with extensive media coverage. Such unprecedented attention has also motivated numerous researchers to investigate ChatGPT from various aspects. According to Google scholar, there are more than 500 articles with ChatGPT in their titles or mentioning it in their abstracts. Considering this, a review is urgently needed, and our work fills this gap. Overall, this work is the first to survey ChatGPT with a comprehensive review of its underlying technology, applications, and challenges. Moreover, we present an outlook on how ChatGPT might evolve to realize general-purpose AIGC (a.k.a. AI-generated content), which will be a significant milestone for the development of AGI.", "IdName": "zhang2023one", "Citation": "", "Keywords": ""}, {"Name": "Automatic mandibular canal detection using a deep convolutional neural network", "Authors": ["Gloria Hyunjung Kwak", "Eun-Jung Kwak", "Jae Min Song", "Hae Ryoun Park", "Yun-Hoa Jung", "Bong-Hae Cho", "Pan Hui", "Jae Joon Hwang"], "Sources": "Scientific Reports", "PublishedYears": "2020", "Doi": "", "Abstracts": "The practicability of deep learning techniques has been demonstrated by their successful implementation in varied fields, including diagnostic imaging for clinicians. In accordance with the increasing demands in the healthcare industry, techniques for automatic prediction and detection are being widely researched. Particularly in dentistry, for various reasons, automated mandibular canal detection has become highly desirable. The positioning of the inferior alveolar nerve (IAN), which is one of the major structures in the mandible, is crucial to prevent nerve injury during surgical procedures. However, automatic segmentation using Cone beam computed tomography (CBCT) poses certain difficulties, such as the complex appearance of the human skull, limited number of datasets, unclear edges, and noisy images. Using work-in-progress automation software, experiments were conducted with models based on 2D?\u2026", "IdName": "kwak2020automatic", "Citation": "", "Keywords": ""}, {"Name": "When creators meet the metaverse: A survey on computational arts", "Authors": ["Lik-Hang Lee", "Zijun Lin", "Rui Hu", "Zhengya Gong", "Abhishek Kumar", "Tangyao Li", "Sijia Li", "Pan Hui"], "Sources": "arXiv preprint arXiv:2111.13486", "PublishedYears": "2021", "Doi": "", "Abstracts": "The metaverse, enormous virtual-physical cyberspace, has brought unprecedented opportunities for artists to blend every corner of our physical surroundings with digital creativity. This article conducts a comprehensive survey on computational arts, in which seven critical topics are relevant to the metaverse, describing novel artworks in blended virtual-physical realities. The topics first cover the building elements for the metaverse, e.g., virtual scenes and characters, auditory, textual elements. Next, several remarkable types of novel creations in the expanded horizons of metaverse cyberspace have been reflected, such as immersive arts, robotic arts, and other user-centric approaches fuelling contemporary creative outputs. Finally, we propose several research agendas: democratising computational arts, digital privacy, and safety for metaverse artists, ownership recognition for digital artworks, technological challenges, and so on. The survey also serves as introductory material for artists and metaverse technologists to begin creations in the realm of surrealistic cyberspace.", "IdName": "lee2021creators", "Citation": "", "Keywords": ""}, {"Name": "ChatGPT in education: A blessing or a curse? A qualitative study exploring early adopters\u2019 utilization and perceptions", "Authors": ["Reza Hadi Mogavi", "Chao Deng", "Justin Juho Kim", "Pengyuan Zhou", "Young D Kwon", "Ahmed Hosny Saleh Metwally", "Ahmed Tlili", "Simone Bassanelli", "Antonio Bucchiarone", "Sujit Gujar", "Lennart E Nacke", "Pan Hui"], "Sources": "Computers in Human Behavior: Artificial Humans", "PublishedYears": "2024", "Doi": "", "Abstracts": "To foster the development of pedagogically potent and ethically sound AI-integrated learning landscapes, it is pivotal to critically explore the perceptions and experiences of the users immersed in these contexts. In this study, we perform a thorough qualitative content analysis across four key social media platforms. Our goal is to understand the user experience (UX) and views of early adopters of ChatGPT across different educational sectors. The results of our research show that ChatGPT is most commonly used in the domains of higher education, K-12 education, and practical skills training. In social media dialogues, the topics most frequently associated with ChatGPT are productivity, efficiency, and ethics. Early adopters' attitudes towards ChatGPT are multifaceted. On one hand, some users view it as a transformative tool capable of amplifying student self-efficacy and learning motivation. On the other hand, there?\u2026", "IdName": "mogavi2024chatgpt", "Citation": "", "Keywords": ""}, {"Name": "Trustworthy AI in the age of pervasive computing and big data", "Authors": ["Abhishek Kumar", "Tristan Braud", "Sasu Tarkoma", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "The era of pervasive computing has resulted in countless devices that continuously monitor users and their environment, generating an abundance of user behavioural data. Such data may support improving the quality of service, but may also lead to adverse usages such as surveillance and advertisement. In parallel, Artificial Intelligence (AI) systems are being applied to sensitive fields such as healthcare, justice, or human resources, raising multiple concerns on the trustworthiness of such systems. Trust in AI systems is thus intrinsically linked to ethics, including the ethics of algorithms, the ethics of data, or the ethics of practice. In this paper, we formalise the requirements of trustworthy AI systems through an ethics perspective. We specifically focus on the aspects that can be integrated into the design and development of AI systems. After discussing the state of research and the remaining challenges, we show how?\u2026", "IdName": "kumar2020trustworthy", "Citation": "", "Keywords": ""}, {"Name": "Smartphone app usage analysis: datasets, methods, and applications", "Authors": ["Tong Li", "Tong Xia", "Huandong Wang", "Zhen Tu", "Sasu Tarkoma", "Zhu Han", "Pan Hui"], "Sources": "IEEE Communications Surveys & Tutorials", "PublishedYears": "2022", "Doi": "", "Abstracts": "As smartphones have become indispensable personal devices, the number of smartphone users has increased dramatically over the last decade. These personal devices, which are supported by a variety of smartphone apps, allow people to access Internet services in a convenient and ubiquitous manner. App developers and service providers can collect fine-grained app usage traces, revealing connections between users, apps, and smartphones. We present a comprehensive review of the most recent research on smartphone app usage analysis in this survey. Our survey summarizes advanced technologies and key patterns in smartphone app usage behaviors, all of which have significant implications for all relevant stakeholders, including academia and industry. We begin by describing four data collection methods: surveys, monitoring apps, network operators, and app stores, as well as nine publicly available?\u2026", "IdName": "li2022smartphone", "Citation": "", "Keywords": ""}, {"Name": "Urban anomaly analytics: Description, detection, and prediction", "Authors": ["Mingyang Zhang", "Tong Li", "Yue Yu", "Yong Li", "Pan Hui", "Yu Zheng"], "Sources": "IEEE Transactions on Big Data", "PublishedYears": "2020", "Doi": "", "Abstracts": "Urban anomalies may result in loss of life or property if not handled properly. Automatically alerting anomalies in their early stage or even predicting anomalies before happening is of great value for populations. Recently, data-driven urban anomaly analysis frameworks have been forming, which utilize urban big data and machine learning algorithms to detect and predict urban anomalies automatically. In this survey, we make a comprehensive review of the state-of-the-art research on urban anomaly analytics. We first give an overview of four main types of urban anomalies, traffic anomaly, unexpected crowds, environment anomaly, and individual anomaly. Next, we summarize various types of urban datasets obtained from diverse devices, i.e., trajectory, trip records, CDRs, urban sensors, event records, environment data, social media and surveillance cameras. Subsequently, a comprehensive survey of issues on?\u2026", "IdName": "zhang2020urban", "Citation": "", "Keywords": ""}, {"Name": "A multi-stream feature fusion approach for traffic prediction", "Authors": ["Zhishuai Li", "Gang Xiong", "Yonglin Tian", "Yisheng Lv", "Yuanyuan Chen", "Pan Hui", "Xiang Su"], "Sources": "IEEE transactions on intelligent transportation systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Accurate and timely traffic flow prediction is crucial for intelligent transportation systems (ITS). Recent advances in graph-based neural networks have achieved promising prediction results. However, some challenges remain, especially regarding graph construction and the time complexity of models. In this paper, we propose a multi-stream feature fusion approach to extract and integrate rich features from traffic data and leverage a data-driven adjacent matrix instead of the distance-based matrix to construct graphs. We calculate the Spearman rank correlation coefficient between monitor stations to obtain the initial adjacent matrix and fine-tune it while training. As to the model, we construct a multi-stream feature fusion block (MFFB) module, which includes a three-channel network and the soft-attention mechanism. The three-channel networks are graph convolutional neural network (GCN), gated recurrent unit?\u2026", "IdName": "li2020multi", "Citation": "", "Keywords": ""}, {"Name": "Can chatgpt reproduce human-generated labels? a study of social computing tasks", "Authors": ["Yiming Zhu", "Peixian Zhang", "Ehsan-Ul Haq", "Pan Hui", "Gareth Tyson"], "Sources": "arXiv preprint arXiv:2304.10145", "PublishedYears": "2023", "Doi": "", "Abstracts": "The release of ChatGPT has uncovered a range of possibilities whereby large language models (LLMs) can substitute human intelligence. In this paper, we seek to understand whether ChatGPT has the potential to reproduce human-generated label annotations in social computing tasks. Such an achievement could significantly reduce the cost and complexity of social computing research. As such, we use ChatGPT to re-label five seminal datasets covering stance detection (2x), sentiment analysis, hate speech, and bot detection. Our results highlight that ChatGPT does have the potential to handle these data annotation tasks, although a number of challenges remain. ChatGPT obtains an average precision 0.609. Performance is highest for the sentiment analysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we show that performance varies substantially across individual labels. We believe this work can open up new lines of analysis and act as a basis for future research into the exploitation of ChatGPT for human annotation tasks.", "IdName": "zhu2023can", "Citation": "", "Keywords": ""}, {"Name": "Re-shaping Post-COVID-19 teaching and learning: A blueprint of virtual-physical blended classrooms in the metaverse era", "Authors": ["Yuyang Wang", "Lik-Hang Lee", "Tristan Braud", "Pan Hui"], "Sources": "2022 IEEE 42nd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "During the COVID-19 pandemic, most countries have experienced some form of remote education through video conferencing software platforms. However, these software platforms fail to reduce immersion and replicate the classroom experience. The currently emerging Metaverse addresses many of such limitations by offering blended physical-digital environments. This paper aims to assess how the Metaverse can support and improve e-learning. We first survey the latest applications of blended environments in education and highlight the primary challenges and opportunities. Accordingly, we derive our proposal for a virtual-physical blended classroom configuration that brings students and teachers into a shared educational Metaverse. We focus on the system architecture of the Metaverse classroom to achieve real-time synchronization of a large number of participants and activities across physical (mixed?\u2026", "IdName": "wang2022re", "Citation": "", "Keywords": ""}, {"Name": "To what extent we repeat ourselves? Discovering daily activity patterns across mobile app usage", "Authors": ["Tong Li", "Yong Li", "Mohammad Ashraful Hoque", "Tong Xia", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "With the prevalence of smartphones, people have left abundant behavior records in cyberspace. Discovering and understanding individuals\u2019 cyber activities can provide useful implications for policymakers, service providers, and app developers. In this paper, we propose a framework to discover daily cyber activity patterns across people's mobile app usage. The framework first segments app usage traces into short time windows and then applies a probabilistic topic model to infer users\u2019 cyber activities in each window. By constructing and exploring the coherence of users\u2019 activity sequences, the framework can identify individuals\u2019 daily patterns. Next, the framework uses a hierarchical clustering algorithm to recognize the common patterns across diverse groups of individuals. We apply the framework on a large-scale and real-world dataset, consisting of 653,092 users with 971,818,946 usage records of 2,000?\u2026", "IdName": "li2020extent", "Citation": "", "Keywords": ""}, {"Name": "Multi-view joint graph representation learning for urban region embedding", "Authors": ["Mingyang Zhang", "Tong Li", "Yong Li", "Pan Hui"], "Sources": "Proceedings of the Twenty-Ninth International Conference on International?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "The increasing amount of urban data enables us to investigate urban dynamics, assist urban planning, and, eventually, make our cities more livable and sustainable. In this paper, we focus on learning an embedding space from urban data for urban regions. For the first time, we propose a multi-view joint learning model to learn comprehensive and representative urban region embeddings. We first model different types of region correlations based on both human mobility and inherent region properties. Then, we apply a graph attention mechanism in learning region representations from each view of the built correlations. Moreover, we introduce a joint learning module that boosts the region embedding learning by sharing cross-view information and fuses multi-view embeddings by learning adaptive weights. Finally, we exploit the learned embeddings in the downstream applications of land usage classification and crime prediction in urban areas with real-world data. Extensive experiment results demonstrate that by exploiting our proposed joint learning model, the performance is improved by a large margin on both tasks compared with the state-of-the-art methods.", "IdName": "zhang2021multi", "Citation": "", "Keywords": ""}, {"Name": "Continuous authentication by free-text keystroke based on CNN and RNN", "Authors": ["Xiaofeng Lu", "Shengfei Zhang", "Pan Hui", "Pietro Lio"], "Sources": "Computers & Security 96", "PublishedYears": "2020", "Doi": "", "Abstracts": "Personal keystroke modes are difficult to imitate and can therefore be used for identity authentication. The keystroke habits of a person can be learned according to the keystroke data generated when the person inputs free text. Detecting a user's keystroke habits as the user enters text can continuously verify the user's identity without affecting user input. The method proposed in this paper authenticates users via their keystrokes when they type free text. The user keystroke data is divided into a fixed-length keystroke sequence, which is then converted into a keystroke vector sequence according to the time feature of the keystroke. A model that combines a convolutional neural network and a recursive neural network is used to learn a sequence of individual keystroke vectors to obtain individual keystroke features for identity authentication. The model is tested using two open datasets, and the best false rejection rate?\u2026", "IdName": "lu2020continuous", "Citation": "", "Keywords": ""}, {"Name": "Agora: A privacy-aware data marketplace", "Authors": ["Vlasis Koutsos", "Dimitrios Papadopoulos", "Dimitris Chatzopoulos", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Dependable and Secure Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "We propose Agora, the first blockchain-based data marketplace that enables multiple privacy-concerned parties to get compensated for contributing and exchanging data, without relying on a trusted third party during the exchange. Agora achieves  data privacy ,  output verifiability , and  atomicity of payments  by leveraging cryptographic techniques, and is designed as a decentralized application via smart contracts. Particularly, data generators provide encrypted data to data brokers who use a  functional secret key  to learn nothing but the output of a specific, agreed upon, function over the raw data. Data consumers can purchase decrypted outputs from the brokers, accompanied by corresponding  proofs of correctness . We implement a working prototype of Agora on Ethereum and experimentally evaluate its performance and deployment costs. As a core building block of Agora, we propose a new  functional?\u2026", "IdName": "koutsos2021agora", "Citation": "", "Keywords": ""}, {"Name": "Mobile augmented reality: User interfaces, frameworks, and intelligence", "Authors": ["Jacky Cao", "Kit-Yung Lam", "Lik-Hang Lee", "Xiaoli Liu", "Pan Hui", "Xiang Su"], "Sources": "ACM Computing Surveys", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) integrates computer-generated virtual objects with physical environments for mobile devices. MAR systems enable users to interact with MAR devices, such as smartphones and head-worn wearables, and perform seamless transitions from the physical world to a mixed world with digital entities. These MAR systems support user experiences using MAR devices to provide universal access to digital content. Over the past 20 years, several MAR systems have been developed, however, the studies and design of MAR frameworks have not yet been systematically reviewed from the perspective of user-centric design. This article presents the first effort of surveying existing MAR frameworks (count: 37) and further discusses the latest studies on MAR through a top-down approach: (1) MAR applications; (2) MAR visualisation techniques adaptive to user mobility and contexts; (3) systematic?\u2026", "IdName": "cao2023mobile", "Citation": "", "Keywords": ""}, {"Name": "Multipath computation offloading for mobile augmented reality", "Authors": ["Tristan Braud", "ZHOU Pengyuan", "Jussi Kangasharju", "HUI Pan"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) applications employ computationally demanding vision algorithms on resource-limited devices. In parallel, communication networks are becoming more ubiquitous. Offloading to distant servers can thus overcome the device limitations at the cost of network delays. Multipath networking has been proposed to overcome network limitations but it is not easily adaptable to edge computing due to the server proximity and networking differences. In this article, we extend the current mobile edge offloading models and present a model for multi-server device-to-device, edge, and cloud offloading. We then introduce a new task allocation algorithm exploiting this model for MAR offloading. Finally, we evaluate the allocation algorithm against naive multipath scheduling and single path models through both a real-life experiment and extensive simulations. In case of sub-optimal network?\u2026", "IdName": "braud2020multipath", "Citation": "", "Keywords": ""}, {"Name": "\u201d what apps did you use?\u201d: Understanding the long-term evolution of mobile app usage", "Authors": ["Tong Li", "Mingyang Zhang", "Hancheng Cao", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the web conference 2020", "PublishedYears": "2020", "Doi": "", "Abstracts": "The prevalence of smartphones has promoted the popularity of mobile apps in recent years. Although significant effort has been made to understand mobile app usage, existing studies are based primarily on short-term datasets with limited time span, e.g., a few months. Therefore, many basic facts about the long-term evolution of mobile app usage are unknown. In this paper, we study how mobile app usage evolves over a long-term period. We first introduce an app usage collection platform named carat, from which we have gathered app usage records of 1,465 users from 2012 to 2017. We then conduct the first study on the long-term evolution processes on a macro-level, i.e., app-category, and micro-level, i.e., individual app. We discover that, on both levels, there is a growth stage enabled by the introduction of new technologies. Then there is a plateau stage caused by high correlations between app categories?\u2026", "IdName": "li2020apps", "Citation": "", "Keywords": ""}, {"Name": "DRLE: Decentralized reinforcement learning at the edge for traffic light control in the IoV", "Authors": ["Pengyuan Zhou", "Xianfu Chen", "Zhi Liu", "Tristan Braud", "Pan Hui", "Jussi Kangasharju"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "The Internet of Vehicles (IoV) enables real-time data exchange among vehicles and roadside units and thus provides a promising solution to alleviate traffic jams in the urban area. Meanwhile, better traffic management via efficient traffic light control can benefit the IoV as well by enabling a better communication environment and decreasing the network load. As such, IoV and efficient traffic light control can formulate a virtuous cycle. Edge computing, an emerging technology to provide low-latency computation capabilities at the edge of the network, can further improve the performance of this cycle. However, while the collected information is valuable, an efficient solution for better utilization and faster feedback has yet to be developed for edge-empowered IoV. To this end, we propose a Decentralized Reinforcement Learning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits the ubiquity of the IoV to?\u2026", "IdName": "zhou2020drle", "Citation": "", "Keywords": ""}, {"Name": "Understanding the long-term evolution of mobile app usage", "Authors": ["Tong Li", "Yali Fan", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "The prevalence of smartphones has promoted the popularity of mobile apps in recent years. Although significant effort has been made to understand mobile app usage, existing studies are based primarily on short-term datasets with a limited time span, e.g., a few months. Therefore, many basic facts about the long-term evolution of mobile app usage are unknown. In this paper, we study how mobile app usage evolves over a long-term period. We first introduce an app usage collection platform named carat, from which we have gathered app usage records of 1,465 users from 2012 to 2017. We then conduct the first study on the long-term evolution processes on a macro-level, i.e., app-category, and micro-level, i.e., individual app. We discover that, on both levels, there is a growth stage enabled by the introduction of new technologies. Then there is a plateau stage caused by high correlations between app categories?\u2026", "IdName": "li2021understanding", "Citation": "", "Keywords": ""}, {"Name": "This website uses nudging: Mturk workers' behaviour on cookie consent notices", "Authors": ["Carlos Bermejo Fernandez", "Dimitris Chatzopoulos", "Dimitrios Papadopoulos", "Pan Hui"], "Sources": "Proceedings of the ACM on human-computer interaction", "PublishedYears": "2021", "Doi": "", "Abstracts": "Data protection regulatory policies, such as the European Union's General Data Protection Regulation (GDPR), force website operators to request users' consent before collecting any personal information revealed through their web browsing. Website operators, motivated by the potential value of the collected personal data, employ various methods when designing consent notices (e.g., dark patterns) in order to convince users to allow the collection of as much of their personal data as possible. In this paper, we design and conduct a user study where 1100 MTurk workers interact with eight different designs of cookie consent notices. We show that the nudging designs used in the different cookie consent notices have a large effect on the choices user make. Our results show that color-based nudging bars can significantly impact the participants' decisions to change the default cookie settings, despite using dark?\u2026", "IdName": "bermejo2021website", "Citation": "", "Keywords": ""}, {"Name": "Towards augmented reality driven human-city interaction: Current research on mobile headsets and future challenges", "Authors": ["Lik-Hang Lee", "Tristan Braud", "Simo Hosio", "Pan Hui"], "Sources": "ACM Computing Surveys (CSUR)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Interaction design for Augmented Reality (AR) is gaining attention from both academia and industry. This survey discusses 260 articles (68.8% of articles published between 2015\u20132019) to review the field of human interaction in connected cities with emphasis on augmented reality-driven interaction. We provide an overview of Human-City Interaction and related technological approaches, followed by reviewing the latest trends of information visualization, constrained interfaces, and embodied interaction for AR headsets. We highlight under-explored issues in interface design and input techniques that warrant further research and conjecture that AR with complementary Conversational User Interfaces (CUIs) is a crucial enabler for ubiquitous interaction with immersive systems in smart cities. Our work helps researchers understand the current potential and future needs of AR in Human-City Interaction.", "IdName": "lee2021towards", "Citation": "", "Keywords": ""}, {"Name": "Identity, crimes, and law enforcement in the metaverse", "Authors": ["Hua Xuan Qin", "Yuyang Wang", "Pan Hui"], "Sources": "arXiv preprint arXiv:2210.06134", "PublishedYears": "2022", "Doi": "", "Abstracts": "With the boom in metaverse-related projects in major areas of the public's life, the safety of users becomes a pressing concern. We believe that an international legal framework should be established to promote collaboration among nations, facilitate crime investigation, and support democratic governance. In this paper, we discuss the legal concerns of identity, crimes that could occur based on incidents in existing virtual worlds, and challenges to unified law enforcement in the metaverse.", "IdName": "qin2022identity", "Citation": "", "Keywords": ""}, {"Name": "Enhancing the internet of things with knowledge-driven software-defined networking technology: Future perspectives", "Authors": ["Yuhong Li", "Xiang Su", "Aaron Yi Ding", "Anders Lindgren", "Xiaoli Liu", "Christian Prehofer", "Jukka Riekki", "Rahim Rahmani", "Sasu Tarkoma", "Pan Hui"], "Sources": "Sensors", "PublishedYears": "2020", "Doi": "", "Abstracts": "The Internet of Things (IoT) connects smart devices to enable various intelligent services. The deployment of IoT encounters several challenges, such as difficulties in controlling and managing IoT applications and networks, problems in programming existing IoT devices, long service provisioning time, underused resources, as well as complexity, isolation and scalability, among others. One fundamental concern is that current IoT networks lack flexibility and intelligence. A network-wide flexible control and management are missing in IoT networks. In addition, huge numbers of devices and large amounts of data are involved in IoT, but none of them have been tuned for supporting network management and control. In this paper, we argue that Software-defined Networking (SDN) together with the data generated by IoT applications can enhance the control and management of IoT in terms of flexibility and intelligence. We present a review for the evolution of SDN and IoT and analyze the benefits and challenges brought by the integration of SDN and IoT with the help of IoT data. We discuss the perspectives of knowledge-driven SDN for IoT through a new IoT architecture and illustrate how to realize Industry IoT by using the architecture. We also highlight the challenges and future research works toward realizing IoT with the knowledge-driven SDN.", "IdName": "li2020enhancing", "Citation": "", "Keywords": ""}, {"Name": "A survey on edge intelligence", "Authors": ["Dianlei Xu", "Tong Li", "Yong Li", "Xiang Su", "Sasu Tarkoma", "Pan Hui"], "Sources": "arXiv preprint arXiv:2003.12172", "PublishedYears": "2020", "Doi": "", "Abstracts": "Edge intelligence refers to a set of connected systems and devices for data collection, caching, processing, and analysis in locations close to where data is captured based on artificial intelligence. The aim of edge intelligence is to enhance the quality and speed of data processing and protect the privacy and security of the data. Although recently emerged, spanning the period from 2011 to now, this field of research has shown explosive growth over the past five years. In this paper, we present a thorough and comprehensive survey on the literature surrounding edge intelligence. We first identify four fundamental components of edge intelligence, namely edge caching, edge training, edge inference, and edge offloading, based on theoretical and practical results pertaining to proposed and deployed systems. We then aim for a systematic classification of the state of the solutions by examining research results and observations for each of the four components and present a taxonomy that includes practical problems, adopted techniques, and application goals. For each category, we elaborate, compare and analyse the literature from the perspectives of adopted techniques, objectives, performance, advantages and drawbacks, etc. This survey article provides a comprehensive introduction to edge intelligence and its application areas. In addition, we summarise the development of the emerging research field and the current state-of-the-art and discuss the important open issues and possible theoretical and technical solutions.", "IdName": "xu2020survey", "Citation": "", "Keywords": ""}, {"Name": "A deep learning method for improving the classification accuracy of SSMVEP-based BCI", "Authors": ["Zhongke Gao", "Tao Yuan", "Xinjun Zhou", "Chao Ma", "Kai Ma", "Pan Hui"], "Sources": "IEEE Transactions on Circuits and Systems II: Express Briefs", "PublishedYears": "2020", "Doi": "", "Abstracts": "Steady State Motion Visual Evoked Potential (SSMVEP)-based Brain Computer Interface (BCI) is widely studied and has been used to varies of occasions on account of its good performance, mild stimulation, and free of additional training. We design a trolley control system based on SSMVEP signals and observe a phenomenon named \u201cBCI Illiterate,\u201d in which case some subjects present unsatisfactory performance with low classification accuracies. In order to cope with this challenging problem in real-world contexts, we introduce a deep learning (DL) method. The method allows improving the accuracies for both EEG literate and EEG illiterate. In particular, we firstly conduct SSMVEP experiments to obtain EEG signals from 10 subjects, including 5 EEG literates and 5 EEG illiterates. Then we construct a convolutional neural network with long short-term memory (CNN-LSTM) framework, which allows extracting the?\u2026", "IdName": "gao2020deep", "Citation": "", "Keywords": ""}, {"Name": "Scaling-up ar: University campus as a physical-digital metaverse", "Authors": ["Tristan Braud", "Carlos Bermejo Fern\u00e1ndez", "Pan Hui"], "Sources": "2022 ieee conference on virtual reality and 3d user interfaces abstracts and?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The metaverse promises large-scale and persistent environments for users to share experiences at the intersection between physical and digital. Augmented reality (AR) is one of the primary technologies that supports blending digital content with physical environments. However, most AR applications are currently single-user and present significant constraints in terms of time and location. Scaling up the technology to large-sized environments and massively multi-user experiences thus represents one of the primary challenges to achieving such a vision. Due to these constraints, current proposals for the metaverse primarily consist of virtual worlds with little duality between physical and digital. This paper studies the feasibility of a large-scale and persistent AR experience shared among all visitors on our university campus. We define an integrated framework to enable the first AR campus metaverse by considering?\u2026", "IdName": "braud2022scaling", "Citation": "", "Keywords": ""}, {"Name": "Contauth: Continual learning framework for behavioral-based user authentication", "Authors": ["Jagmohan Chauhan", "Young D Kwon", "Pan Hui", "Cecilia Mascolo"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "User authentication is key in user authorization on smart and personal devices. Over the years, several authentication mechanisms have been proposed: these also include behavioral-based biometrics. However, behavioral-based biometrics suffer from two issues: they are prone to degradation in performance (accuracy) over time (e.g., due to data distribution changes arising from user behavior) and the need to learn the machine learning model from scratch, when adding new users. In this paper, we propose ContAuth, a system that can enhance the robustness of behavioral-based authentication. ContAuth continuously adapts to new incoming data (data incremental learning) and is able to add new users without retraining (class incremental learning). Specifically, ContAuth combines deep learning models with online learning models to achieve learning on the fly, thereby preventing a severe drop in the accuracy?\u2026", "IdName": "chauhan2020contauth", "Citation": "", "Keywords": ""}, {"Name": "Twitter dataset for 2022 russo-ukrainian crisis", "Authors": ["Ehsan-Ul Haq", "Gareth Tyson", "Lik-Hang Lee", "Tristan Braud", "Pan Hui"], "Sources": "arXiv preprint arXiv:2203.02955", "PublishedYears": "2022", "Doi": "", "Abstracts": "Online Social Networks (OSNs) play a significant role in information sharing during a crisis. The data collected during such a crisis can reflect the large scale public opinions and sentiment. In addition, OSN data can also be used to study different campaigns that are employed by various entities to engineer public opinions. Such information sharing campaigns can range from spreading factual information to propaganda and misinformation. We provide a Twitter dataset of the 2022 Russo-Ukrainian conflict. In the first release, we share over 1.6 million tweets shared during the 1st week of the crisis.", "IdName": "haq2022twitter", "Citation": "", "Keywords": ""}, {"Name": "3dgcn: 3-dimensional dynamic graph convolutional network for citywide crowd flow prediction", "Authors": ["Tong Xia", "Junjie Lin", "Yong Li", "Jie Feng", "Pan Hui", "Funing Sun", "Diansheng Guo", "Depeng Jin"], "Sources": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Crowd flow prediction is an essential task benefiting a wide range of applications for the transportation system and public safety. However, it is a challenging problem due to the complex spatio-temporal dependence and the complicated impact of urban structure on the crowd flow patterns. In this article, we propose a novel framework, 3-Dimensional Graph Convolution Network (3DGCN), to predict citywide crowd flow. We first model it as a dynamic spatio-temporal graph prediction problem, where each node represents a region with time-varying flows, and each edge represents the origin\u2013destination (OD) flow between its corresponding regions. As such, OD flows among regions are treated as a proxy for the spatial interactions among regions. To tackle the complex spatio-temporal dependence, our proposed 3DGCN can model the correlation among graph spatial and temporal neighbors simultaneously. To learn?\u2026", "IdName": "xia20213dgcn", "Citation": "", "Keywords": ""}, {"Name": "A survey on computational politics", "Authors": ["Ehsan Ul Haq", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "Computational Politics is the study of computational methods to analyze and moderate users' behaviors related to political activities such as election campaign persuasion, political affiliation, and opinion mining. With the rapid development and ease of access to the Internet, Information Communication Technologies (ICT) have given rise to massive numbers of users joining online communities and the digitization of political practices such as debates. These communities and digitized data contain both explicit and latent information about users and their behaviors related to politics and social movements. For researchers, it is essential to utilize data from these sources to develop and design systems that not only provide solutions to computational politics but also help other businesses, such as marketers, to increase users' participation and interactions. In this survey, we attempt to categorize main areas in?\u2026", "IdName": "haq2020survey", "Citation": "", "Keywords": ""}, {"Name": "Edge-facilitated augmented vision in vehicle-to-everything networks", "Authors": ["Pengyuan Zhou", "Tristan Braud", "Aleksandr Zavodovski", "Zhi Liu", "Xianfu Chen", "Pan Hui", "Jussi Kangasharju"], "Sources": "IEEE Transactions on Vehicular Technology", "PublishedYears": "2020", "Doi": "", "Abstracts": "Vehicular communication applications require an efficient communication architecture for timely information delivery. Centralized, cloud-based infrastructures present latencies too high to satisfy the requirements of emergency information processing and transmission, while Vehicle-to-Vehicle communication is too variable for reliable in-time information transmission. In this paper, we present EAVVE, a novel Vehicle-to-Everything system, consisting of vehicles with and without comprehensive data processing capabilities, facilitated by edge servers co-located with roadside units. Adding computation capabilities at the edge of the network allows reducing the overall latency compared to vehicle-to-cloud and makes up for scenarios in which in-vehicle computational power is not sufficient to satisfy the service demand. To improve the offloading efficiency, we propose a decentralized algorithm for real-time task?\u2026", "IdName": "zhou2020edge", "Citation": "", "Keywords": ""}, {"Name": "Deep reinforcement learning approaches for global public health strategies for COVID-19 pandemic", "Authors": ["Gloria Hyunjung Kwak", "Lowell Ling", "Pan Hui"], "Sources": "PloS one", "PublishedYears": "2021", "Doi": "", "Abstracts": " Background Unprecedented public health measures have been used during this coronavirus 2019 (COVID-19) pandemic to control the spread of SARS-CoV-2 virus. It is a challenge to implement timely and appropriate public health interventions. Methods and findings Population and COVID-19 epidemiological data between 21st January 2020 to 15th November 2020 from 216 countries and territories were included with the implemented public health interventions. We used deep reinforcement learning, and the algorithm was trained to enable agents to try to find optimal public health strategies that maximized total reward on controlling the spread of COVID-19. The results suggested by the algorithm were analyzed against the actual timing and intensity of lockdown and travel restrictions. Early implementations of the actual lockdown and travel restriction policies, usually at the time of local index case were associated with less burden of COVID-19. In contrast, our agent suggested to initiate at least minimal intensity of lockdown or travel restriction even before or on the day of the index case in each country and territory. In addition, the agent mostly recommended a combination of lockdown and travel restrictions and higher intensity policies than the policies implemented by governments, but did not always encourage rapid full lockdown and full border closures. The limitation of this study was that it was done with incomplete data due to the emerging COVID-19 epidemic, inconsistent testing and reporting. In addition, our research focuses only on population health benefits by controlling the spread of COVID-19 without balancing the negative?\u2026", "IdName": "kwak2021deep", "Citation": "", "Keywords": ""}, {"Name": "Distributed vehicular computing at the dawn of 5G: A survey", "Authors": ["Ahmad Alhilal", "Benjamin Finley", "Tristan Braud", "Dongzhe Su", "Pan Hui"], "Sources": "arXiv preprint arXiv:2001.07077", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent advances in information technology have revolutionized the automotive industry, paving the way for next-generation smart vehicular mobility. Vehicles, roadside units, and other road users can collaborate to deliver novel services and applications. These services and applications require 1) massive volumes of heterogeneous and continuous data to perceive the environment, 2) reliable and low-latency communication networks, 3) real-time data processing that provides decision support under application-specific constraints. Addressing such constraints introduces significant challenges for current communication and computing technologies. Relatedly, the fifth generation of cellular networks (5G) was developed to respond to communication challenges by providing for low-latency, high-reliability, and high bandwidth communications. As a major part of 5G, edge computing allows data offloading and computation at the edge of the network, ensuring low-latency and context-awareness, and 5G efficiency. In this work, we aim at providing a comprehensive overview of the state of research on vehicular computing in the emerging age of 5G and big data.", "IdName": "alhilal2020distributed", "Citation": "", "Keywords": ""}, {"Name": "6G mobile-edge empowered metaverse: Requirements, technologies, challenges and research directions", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Pan Hui", "Danny HK Tsang"], "Sources": "arXiv preprint arXiv:2211.04854", "PublishedYears": "2022", "Doi": "", "Abstracts": "The Metaverse has emerged as the successor of the conventional mobile internet to change people's lifestyles. It has strict visual and physical requirements to ensure an immersive experience (i.e., high visual quality, low motion-to-photon latency, and real-time tactile and control experience). However, the current technologies fall short to satisfy these requirements. Mobile edge computing (MEC) has been indispensable to enable low latency and powerful computing. Moreover, the sixth generation (6G) networks promise to provide end users with seamless communications. In this paper, we explore and demonstrate the synergistic relationship between 6G and mobile-edge technologies in empowering the Metaverse with ubiquitous communications and computation. This includes the usage of heterogeneous radios, intelligent reflecting surfaces (IRS), non-orthogonal multiple access (NOMA), and digital twins (DTs) - assisted MEC. We also discuss emerging communication paradigms (i.e., semantic communication, holographic-type communication, and haptic communication) to further satisfy the demand for human-type communications and fulfill user preferences and immersive experiences in the Metaverse.", "IdName": "yu20226g", "Citation": "", "Keywords": ""}, {"Name": "Para: Privacy management and control in emerging iot ecosystems using augmented reality", "Authors": ["Carlos Bermejo Fernandez", "Lik Hang Lee", "Petteri Nurmi", "Pan Hui"], "Sources": "Proceedings of the 2021 International Conference on Multimodal Interaction?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " The ubiquity of smart devices, combined with a lack of information about data garnered by them, make privacy a significant challenge for adopting smart devices. Ensuring users can safeguard their privacy without compromising the devices\u2019 functionality requires effective yet intuitive ways to manage personal privacy preferences. Current solutions for privacy management are severely lacking as they are ineffective in making users aware of potential privacy risks or how to mitigate them and as they offer limited support for interaction. As our first contribution, we develop a novel AR privacy management interface (PARA) that uses AR visualization to contextualize data disclosure and improve user\u2019s perceptions of privacy threats. Besides offering support for enhancing user\u2019s privacy perceptions, our interface supports privacy control on compatible devices through privacy-enhancing technologies. As our second?\u2026", "IdName": "bermejo2021privacy", "Citation": "", "Keywords": ""}, {"Name": "A2w: Context-aware recommendation system for mobile augmented reality web browser", "Authors": ["Kit Yung Lam", "Lik Hang Lee", "Pan Hui"], "Sources": "Proceedings of the 29th ACM international conference on multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Augmented Reality (AR) offers new capabilities for blurring the boundaries between physical reality and digital media. However, the capabilities of integrating web contents and AR remain underexplored. This paper presents an AR web browser with an integrated context-aware AR-to-Web content recommendation service named as A2W browser, to provide continuously user-centric web browsing experiences driven by AR headsets. We implement the A2W browser on an AR headset as our demonstration application, demonstrating the features and performance of A2W framework. The A2W browser visualizes the AR-driven web contents to the user, which is suggested by the content-based filtering model in our recommendation system. In our experiments, 20 participants with the adaptive UIs and recommendation system in A2W browser achieve up to 30.69% time saving compared to smartphone conditions?\u2026", "IdName": "lam2021a2w", "Citation": "", "Keywords": ""}, {"Name": "Intelligent and scalable air quality monitoring with 5G edge", "Authors": ["Xiang Su", "Xiaoli Liu", "Naser Hossein Motlagh", "Jacky Cao", "Peifeng Su", "Petri Pellikka", "Yongchun Liu", "Tuukka Pet?j?", "Markku Kulmala", "Pan Hui", "Sasu Tarkoma"], "Sources": "IEEE Internet Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "Air pollution introduces a major challenge for societies, where it leads to the premature deaths of millions of people each year globally. Massive deployment of air quality sensing devices and data analysis for the resultant data will pave the way for the development of real-time intelligent applications and services, e.g., minimization of exposure to poor air quality either on an individual or city scale. 5G and edge computing supports dense deployments of sensors at high resolution with ubiquitous connectivity, high bandwidth, high-speed gigabit connections, and ultralow latency analysis. This article conceptualizes AI-powered scalable air quality monitoring and presents two systems of calibrating low-cost air quality sensors and the image processing of pictures captured by hyperspectral cameras to better detect air quality. We develop and deploy different AI algorithms in these two systems on a 5G edge testbed and?\u2026", "IdName": "su2021intelligent", "Citation": "", "Keywords": ""}, {"Name": "Emgauth: An emg-based smartphone unlocking system using siamese network", "Authors": ["Boyu Fan", "Xuefeng Liu", "Xiang Su", "Pan Hui", "Jianwei Niu"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Screen lock is a critical security feature for smart-phones to prevent unauthorized access. Although various screen unlocking technologies including fingerprint and facial recognition have been widely adopted, they still have some limitations. For example, fingerprints can be stolen by special material stickers and facial recognition systems can be cheated by 3D-printed head models. In this paper, we propose EmgAuth, a novel electromyography(EMG)-based smartphone unlocking system based on the Siamese network. EmgAuth leverages the Myo armband to collect the EMG data of smartphone users and enables users to unlock their smartphones when picking up and watching their smartphones. In particular, when training the Siamese network, we design a special data augmentation technique to make the system resilient to the rotation of the armband. We conduct experiments including 40 participants and the?\u2026", "IdName": "fan2020emgauth", "Citation": "", "Keywords": ""}, {"Name": "Dios-an extended reality operating system for the metaverse", "Authors": ["Tristan Braud", "Lik-Hang Lee", "Ahmad Alhilal", "Carlos Bermejo Fern\u00e1ndez", "Pan Hui"], "Sources": "IEEE multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Driven by the recent improvements in device and networks capabilities, extended reality (XR) is becoming more pervasive; industry and academia alike envision ambitious projects, such as the metaverse. However, XR is still limited by the current architecture of mobile systems. This article makes the case for an XR-specific operating system (XROS). An XROS integrates hardware-support, computer vision algorithms, and XR-specific networking as the primitives supporting XR technology. These primitives represent the physical\u2013digital world as a single shared resource among applications. Such an XROS allows for the development of coherent and system-wide interaction and display methods, systematic privacy preservation on sensor data, and performance improvement while simplifying application development.", "IdName": "braud2022dios", "Citation": "", "Keywords": ""}, {"Name": "What is the metaverse? an immersive cyberspace and open challenges", "Authors": ["Lik-Hang Lee", "Pengyuan Zhou", "Tristan Braud", "Pan Hui"], "Sources": "arXiv preprint arXiv:2206.03018", "PublishedYears": "2022", "Doi": "", "Abstracts": "The Metaverse refers to a virtual-physical blended space in which multiple users can concurrently interact with a unified computer-generated environment and other users, which can be regarded as the next significant milestone of the current cyberspace. This article primarily discusses the development and challenges of the Metaverse. We first briefly describe the development of cyberspace and the necessity of technology enablers. Accordingly, our bottom-up approach highlights three critical technology enablers for the Metaverse: networks, systems, and users. Also, we highlight a number of indispensable issues, under technological and ecosystem perspectives, that build and sustain the Metaverse.", "IdName": "lee2022metaverse", "Citation": "", "Keywords": ""}, {"Name": "Exploring button designs for mid-air interaction in virtual reality: A hexa-metric evaluation of key representations and multi-modal cues", "Authors": ["Carlos Bermejo", "Lik Hang Lee", "Paul Chojecki", "David Przewozny", "Pan Hui"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2021", "Doi": "", "Abstracts": "The continued advancement in user interfaces comes to the era of virtual reality that requires a better understanding of how users will interact with 3D buttons in mid-air. Although virtual reality owns high levels of expressiveness and demonstrates the ability to simulate the daily objects in the physical environment, the most fundamental issue of designing virtual buttons is surprisingly ignored. To this end, this paper presents four variants of virtual buttons, considering two design dimensions of key representations and multi-modal cues (audio, visual, haptic). We conduct two multi-metric assessments to evaluate the four virtual variants and the baselines of physical variants. Our results indicate that the 3D-lookalike buttons help users with more refined and subtle mid-air interactions (i.e. lesser press depth) when haptic cues are available; while the users with 2D-lookalike buttons unintuitively achieve better keystroke?\u2026", "IdName": "bermejo2021exploring", "Citation": "", "Keywords": ""}, {"Name": "The impact of COVID-19 on smartphone usage", "Authors": ["Tong Li", "Mingyang Zhang", "Yong Li", "Eemil Lagerspetz", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": "The outbreak of Covid-19 changed the world as well as human behavior. In this article, we study the impact of Covid-19 on smartphone usage. We gather smartphone usage records from a global data collection platform called Carat, including the usage of mobile users in North America from November 2019 to April 2020. We then conduct the first study on the differences in smartphone usage across the outbreak of Covid-19. We discover that Covid-19 leads to a decrease in users\u2019 smartphone engagement and network switches, but an increase in WiFi usage. Also, its outbreak causes new typical diurnal patterns of both memory usage and WiFi usage. Additionally, we investigate the correlations between smartphone usage and daily confirmed cases of Covid-19. The results reveal that memory usage, WiFi usage, and network switches of smartphones have significant correlations, whose absolute values of Pearson?\u2026", "IdName": "li2021impact", "Citation": "", "Keywords": ""}, {"Name": "Sketching an ai marketplace: Tech, economic, and regulatory aspects", "Authors": ["Abhishek Kumar", "Benjamin Finley", "Tristan Braud", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Access 9", "PublishedYears": "2021", "Doi": "", "Abstracts": "Artificial intelligence shows promise for solving many practical societal problems in areas such as healthcare and transportation. However, the current mechanisms for AI model diffusion such as Github code repositories, academic project webpages, and commercial AI marketplaces have some limitations; for example, a lack of monetization methods, model traceability, and model auditabilty. In this work, we sketch guidelines for a new AI diffusion method based on a decentralized online marketplace. We consider the technical, economic, and regulatory aspects of such a marketplace including a discussion of solutions for problems in these areas. Finally, we include a comparative analysis of several current AI marketplaces that are already available or in development. We find that most of these marketplaces are centralized commercial marketplaces with relatively few models.", "IdName": "kumar2021sketching", "Citation": "", "Keywords": ""}, {"Name": "Predicting the need for intubation in the first 24 h after critical care admission using machine learning approaches", "Authors": ["Benjamin Ming Kit Siu", "Gloria Hyunjung Kwak", "Lowell Ling", "Pan Hui"], "Sources": "Scientific reports", "PublishedYears": "2020", "Doi": "", "Abstracts": "Early and accurate prediction of the need for intubation may provide more time for preparation and increase safety margins by avoiding high risk late intubation. This study evaluates whether machine learning can predict the need for intubation within 24?h using commonly available bedside and laboratory parameters taken at critical care admission. We extracted data from 2 large critical care databases (MIMIC-III and eICU-CRD). Missing variables were imputed using autoencoder. Machine learning classifiers using logistic regression and random forest were trained using 60% of the data and tested using the remaining 40% of the?data. We compared the performance of logistic regression and random forest models to predict intubation in critically ill patients. After excluding patients with limitations of therapy and missing data, we included 17,616 critically ill patients in this retrospective cohort. Within 24?h of admission?\u2026", "IdName": "siu2020predicting", "Citation": "", "Keywords": ""}, {"Name": "Genetic meta-structure search for recommendation on heterogeneous information network", "Authors": ["Zhenyu Han", "Fengli Xu", "Jinghan Shi", "Yu Shang", "Haorui Ma", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the 29th ACM international conference on information?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "In the past decade, the heterogeneous information network (HIN) has become an important methodology for modern recommender systems. To fully leverage its power, manually designed network templates, i.e., meta-structures, are introduced to filter out semantic-aware information. The hand-crafted meta-structure rely on intense expert knowledge, which is both laborious and data-dependent. On the other hand, the number of meta-structures grows exponentially with its size and the number of node types, which prohibits brute-force search. To address these challenges, we propose Genetic Meta-Structure Search (GEMS) to automatically optimize meta-structure designs for recommendation on HINs. Specifically, GEMS adopts a parallel genetic algorithm to search meaningful meta-structures for recommendation, and designs dedicated rules and a meta-structure predictor to efficiently explore the search space?\u2026", "IdName": "han2020genetic", "Citation": "", "Keywords": ""}, {"Name": "Vetaverse: A survey on the intersection of Metaverse, vehicles, and transportation systems", "Authors": ["Pengyuan Zhou", "Jinjing Zhu", "Yiting Wang", "Yunfan Lu", "Zixiang Wei", "Haolin Shi", "Yuchen Ding", "Yu Gao", "Qinglong Huang", "Yan Shi", "Ahmad Alhilal", "Lik-Hang Lee", "Tristan Braud", "Pan Hui", "Lin Wang"], "Sources": "arXiv preprint arXiv:2210.15109", "PublishedYears": "2022", "Doi": "", "Abstracts": "Since 2021, the term \"Metaverse\" has been the most popular one, garnering a lot of interest. Because of its contained environment and built-in computing and networking capabilities, a modern car makes an intriguing location to host its own little metaverse. Additionally, the travellers don't have much to do to pass the time while traveling, making them ideal customers for immersive services. Vetaverse (Vehicular-Metaverse), which we define as the future continuum between vehicular industries and Metaverse, is envisioned as a blended immersive realm that scales up to cities and countries, as digital twins of the intelligent Transportation Systems, referred to as \"TS-Metaverse\", as well as customized XR services inside each Individual Vehicle, referred to as \"IV-Metaverse\". The two subcategories serve fundamentally different purposes, namely long-term interconnection, maintenance, monitoring, and management on scale for large transportation systems (TS), and personalized, private, and immersive infotainment services (IV). By outlining the framework of Vetaverse and examining important enabler technologies, we reveal this impending trend. Additionally, we examine unresolved issues and potential routes for future study while highlighting some intriguing Vetaverse services.", "IdName": "zhou2022vetaverse", "Citation": "", "Keywords": ""}, {"Name": "Aicp: Augmented informative cooperative perception", "Authors": ["Pengyuan Zhou", "Pranvera Korto?i", "Yui-Pan Yau", "Benjamin Finley", "Xiujun Wang", "Tristan Braud", "Lik-Hang Lee", "Sasu Tarkoma", "Jussi Kangasharju", "Pan Hui"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": "Connected vehicles, whether equipped with advanced driver-assistance systems or fully autonomous, require human driver supervision and are currently constrained to visual information in their line-of-sight. A cooperative perception system among vehicles increases their situational awareness by extending their perception range. Existing solutions focus on improving perspective transformation and fast information collection. However, such solutions fail to filter out large amounts of less relevant data and thus impose significant network and computation load. Moreover, presenting all this less relevant data can overwhelm the driver and thus actually hinder them. To address such issues, we present Augmented Informative Cooperative Perception (AICP), the first fast-filtering system which optimizes the informativeness of shared data at vehicles to improve the fused presentation. To this end, an informativeness?\u2026", "IdName": "zhou2022aicp", "Citation": "", "Keywords": ""}, {"Name": "Sear: Scaling experiences in multi-user augmented reality", "Authors": ["Wenxiao Zhang", "Bo Han", "Pan Hui"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In this paper, we present the design, implementation, and evaluation of SEAR, a collaborative framework for Scaling Experiences in multi-user Augmented Reality (AR). Most AR systems benefit from computer vision (CV) algorithms to detect, classify, or recognize physical objects for augmentation. A widely used acceleration method for mobile AR is to offload the compute-intensive tasks ( e.g. , CV algorithms) to the network edge. However, we show that the end-to-end latency, an important metric of mobile AR, may dramatically increase when offloading AR tasks from a large number of concurrent users to the edge. SEAR tackles this scalability issue through the innovation of a lightweight collaborative local caching scheme. Our key observation is that nearby AR users may share some common interests, and may even have overlapped views to augment ( e.g. , when playing a multi-user AR game). Thus, SEAR?\u2026", "IdName": "zhang2022sear", "Citation": "", "Keywords": ""}, {"Name": "Student barriers to active learning in Synchronous online classes: Characterization, reflections, and suggestions", "Authors": ["Reza Hadi Mogavi", "Yankun Zhao", "Ehsan Ul Haq", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the Eighth ACM Conference on Learning@ Scale", "PublishedYears": "2021", "Doi": "", "Abstracts": "As more and more face-to-face classes move to online environments, it becomes increasingly important to explore any emerging barriers to students' learning. This work focuses on characterizing student barriers to active learning in synchronous online environments. The aim is to help novice educators develop a better understanding of those barriers and prepare more student-centered course plans for their active online classes. Towards this end, we adopt a qualitative research approach and study information from different sources: social media content, interviews, and surveys from students and expert educators. Through a thematic analysis, we craft a nuanced list of students' online active learning barriers within the themes of human-side, technological, and environmental barriers. Each barrier is explored from the three aspects of frequency, importance, and exclusiveness to active online classes. Finally, we?\u2026", "IdName": "hadi2021student", "Citation": "", "Keywords": ""}, {"Name": "Strategic COVID-19 vaccine distribution can simultaneously elevate social utility and equity", "Authors": ["Lin Chen", "Fengli Xu", "Zhenyu Han", "Kun Tang", "Pan Hui", "James Evans", "Yong Li"], "Sources": "Nature Human Behaviour", "PublishedYears": "2022", "Doi": "", "Abstracts": "Balancing social utility and equity in distributing limited vaccines is a critical policy concern for protecting against the prolonged COVID-19 pandemic and future health emergencies. What is the nature of the trade-off between maximizing collective welfare and minimizing disparities between more and less privileged communities? To evaluate vaccination strategies, we propose an epidemic model that explicitly accounts for both demographic and mobility differences among communities and their associations with heterogeneous COVID-19 risks, then calibrate it with large-scale data. Using this model, we find that social utility and equity can be simultaneously improved when vaccine access is prioritized for the most disadvantaged communities, which holds even when such communities manifest considerable vaccine reluctance. Nevertheless, equity among distinct demographic features may conflict; for example, low?\u2026", "IdName": "chen2022strategic", "Citation": "", "Keywords": ""}, {"Name": "Exploring system performance of continual learning for mobile and embedded sensing applications", "Authors": ["Young D Kwon", "Jagmohan Chauhan", "Abhishek Kumar", "Pan Hui HKUST", "Cecilia Mascolo"], "Sources": "2021 IEEE/ACM Symposium on Edge Computing (SEC)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Continual learning approaches help deep neural network models adapt and learn incrementally by trying to solve catastrophic forgetting. However, whether these existing approaches, applied traditionally to image-based tasks, work with the same efficacy to the sequential time series data generated by mobile or embedded sensing systems remains an unanswered question. To address this void, we conduct the first comprehensive empirical study that quantifies the performance of three predominant continual learning schemes (i.e., regularization, replay, and replay with examples) on six datasets from three mobile and embedded sensing applications in a range of scenarios having different learning complexities. More specifically, we implement an end-to-end continual learning framework on edge devices. Then we investigate the generalizability, trade-offs between performance, storage, computational costs, and?\u2026", "IdName": "kwon2021exploring", "Citation": "", "Keywords": ""}, {"Name": "One-thumb text acquisition on force-assisted miniature interfaces for mobile headsets", "Authors": ["LEE Lik-Hang", "ZHU Yiming", "YAU Yui-Pan", "Tristan Braud", "SU Xiang", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Touchscreen interfaces are shrinking and even dis-appearing on mobile headsets. The existing approaches for text acquisition on mobile headsets, for instance, speech commands and hand gestures, are cumbersome and coarse. In this paper, we show the feasibility of interaction on a miniature area as small as 12 * 13 mm 2  that offers an input alternative on small form-factor devices such as smartwatches, smart rings, or the spectacles frames of mobile headsets. To this end, we propose and implement two interaction approaches, namely FRS and DupleFR, for acquiring textual contents on mobile headsets. Both approaches leverage force-assisted interaction on a miniature-size interface. They enable the user to acquire textual content with various granularities such as characters, words, sentences, paragraphs, and the entire text. After 8 sessions, 22 participants with FRS and DupleFR achieve the peak?\u2026", "IdName": "lik2020one", "Citation": "", "Keywords": ""}, {"Name": "Are you left out? an efficient and fair federated learning for personalized profiles on wearable devices of inferior networking conditions", "Authors": ["Pengyuan Zhou", "Hengwei Xu", "Lik Hang Lee", "Pei Fang", "Pan Hui"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2022", "Doi": "", "Abstracts": "Wearable computers engage in percutaneous interactions with human users and revolutionize the way of learning human activities. Due to rising privacy concerns, federated learning has been recently proposed to train wearable data with privacy preservation collaboratively. However, under the state-of-the-art (SOTA) schemes, user profiles on wearable devices of inferior networking conditions are regarded as 'left out'. Such schemes suffer from three fundamental limitations: (1) the widely adopted network-capacity-based client selection leads to biased training; (2) the aggregation has low communication efficiency; (3) users lack convenient channels for providing feedback on wearable devices. Therefore, this paper proposes a Fair and Communication-efficient Federated Learning scheme, namely FCFL. FCFL is a full-stack learning system specifically designed for wearable computers, improving the SOTA?\u2026", "IdName": "zhou2022you", "Citation": "", "Keywords": ""}, {"Name": "Analyzing smart contract interactions and contract level state consensus", "Authors": ["Yao\u2010Chieh Hu", "Ting\u2010Ting Lee", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "Concurrency and Computation: Practice and Experience", "PublishedYears": "2020", "Doi": "", "Abstracts": " Although the primary function of distributed ledgers is to store data related to users' interactions, their capabilities allow them to offer more sophisticated functionalities. Advances in blockchain technologies introduced smart contracts, software programs that define immutable rules as functions stored on the blockchain and can be executed on demand. Smart contracts can interact not only with users but also with each other via message exchange. We compare existing smart contract interactions, and develop an architecture for asynchronous state consensus, a novel type of smart contract interaction required in applications but had rarely been addressed. The proposed architecture is composed of two types of smart contracts, ie, Custodian and Client. Client smart contracts serve as network participants reaching a particular consensus collectively by forming a cluster and issuing votes towards a final state agreement?\u2026", "IdName": "hu2020analyzing", "Citation": "", "Keywords": ""}, {"Name": "When gamification spoils your learning: A qualitative case study of gamification misuse in a language-learning app", "Authors": ["Reza Hadi Mogavi", "Bingcan Guo", "Yuanhao Zhang", "Ehsan-Ul Haq", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the Ninth ACM Conference on Learning@ Scale", "PublishedYears": "2022", "Doi": "", "Abstracts": "More and more learning apps like Duolingo are using some form of gamification (e.g., badges, points, and leaderboards) to enhance user learning. However, they are not always successful. Gamification misuse is a phenomenon that occurs when users become too fixated on gamification and get distracted from learning. This undesirable phenomenon wastes users' precious time and negatively impacts their learning performance. However, there has been little research in the literature to understand gamification misuse and inform future gamification designs. Therefore, this paper aims to fill this knowledge gap by conducting the first extensive qualitative research on gamification misuse in a popular learning app called Duolingo. Duolingo is currently the world's most downloaded learning app used to learn languages. This study consists of two phases: (I)a content analysis of data from Duolingo forums (from the past?\u2026", "IdName": "hadi2022gamification", "Citation": "", "Keywords": ""}, {"Name": "Beyond the first law of geography: Learning representations of satellite imagery by leveraging point-of-interests", "Authors": ["Yanxin Xi", "Tong Li", "Huandong Wang", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the ACM Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": " Satellite imagery depicts the earth\u2019s surface remotely and provides comprehensive information for many applications, such as land use monitoring and urban planning. Existing studies on unsupervised representation learning for satellite images only take into account the images\u2019 geographic information, ignoring human activity factors. To bridge this gap, we propose using Point-of-Interest (POI) data to capture human factors and design a contrastive learning-based framework to consolidate the representation of satellite imagery with POI information. Also, we design an attention model that merges the representations from the geographic and POI perspectives adaptively. On the basis of real-world datasets collected from Beijing, we evaluate our method for predicting socioeconomic indicators. The results show that the representation containing POI information outperforms the geographic representation in estimating?\u2026", "IdName": "xi2022beyond", "Citation": "", "Keywords": ""}, {"Name": "5G MEC computation handoff for mobile augmented reality", "Authors": ["Pengyuan Zhou", "Shuhao Fu", "Benjamin Finley", "Xuebing Li", "Sasu Tarkoma", "Jussi Kangasharju", "Mostafa Ammar", "Pan Hui"], "Sources": "arXiv preprint arXiv:2101.00256", "PublishedYears": "2021", "Doi": "", "Abstracts": "The combination of 5G and Multi-access Edge Computing (MEC) can significantly reduce application delay by lowering transmission delay and bringing computational capabilities closer to the end user. Therefore, 5G MEC could enable excellent user experience in applications like Mobile Augmented Reality (MAR), which are computation-intensive, and delay and jitter-sensitive. However, existing 5G handoff algorithms often do not consider the computational load of MEC servers, are too complex for real-time execution, or do not integrate easily with the standard protocol stack. Thus they can impair the performance of 5G MEC. To address this gap, we propose Comp-HO, a handoff algorithm that finds a local solution to the joint problem of optimizing signal strength and computational load. Additionally, Comp-HO can easily be integrated into current LTE and 5G base stations thanks to its simplicity and standard-friendly deployability. Specifically, we evaluate Comp-HO through a custom NS-3 simulator which we calibrate via MAR prototype measurements from a real-world 5G testbed. We simulate both Comp-HO and several classic handoff algorithms. The results show that, even without a global optimum, the proposed algorithm still significantly reduces the number of large delays, caused by congestion at MECs, at the expense of a small increase in transmission delay.", "IdName": "zhou20215g", "Citation": "", "Keywords": ""}, {"Name": "Eyeshopper: Estimating shoppers' gaze using cctv cameras", "Authors": ["Carlos Bermejo", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "Proceedings of the 28th ACM international conference on multimedia", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent advances in machine and deep learning allow for enhanced retail analytics by applying object detection techniques. However, existing approaches either require laborious installation processes to function or lack precision when the customers turn their back in the installed cameras. In this paper, we present EyeShopper, an innovative system that tracks the gaze of shoppers when facing away from the camera and provides insights about their behavior in physical stores. EyeShopper is readily deployable in existing surveillance systems and robust against low-resolution video inputs. At the same time, its accuracy is comparable to state-of-the-art gaze estimation frameworks that require high-resolution and continuous video inputs to function. Furthermore, EyeShopper is more robust than state-of-the-art gaze tracking techniques for back head images. Extensive evaluation with different real video datasets and?\u2026", "IdName": "bermejo2020eyeshopper", "Citation": "", "Keywords": ""}, {"Name": "How subtle can it get? a trimodal study of ring-sized interfaces for one-handed drone control", "Authors": ["Yui-Pan Yau", "Lik Hang Lee", "Zheng Li", "Tristan Braud", "Yi-Hsuan Ho", "Pan Hui"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "Flying drones have become common objects in our daily lives, serving a multitude of purposes. Many of these purposes involve outdoor scenarios where the user combines drone control with another activity. Traditional interaction methods rely on physical or virtual joysticks that occupy both hands, thus restricting drone usability. In this paper, we investigate one-handed human-to-drone-interaction by leveraging three modalities: force, touch, and IMU. After prototyping three different combinations of these modalities on a smartphone, we evaluate them against the current commercial standard through two user experiments. These experiments help us to find the combination of modalities that strikes a compromise between user performance, perceived task load, wrist rotation, and interaction area size. Accordingly, we select a method that achieves faster task completion times than the two-handed commercial baseline?\u2026", "IdName": "yau2020subtle", "Citation": "", "Keywords": ""}, {"Name": "Nebula: Reliable low-latency video transmission for mobile cloud gaming", "Authors": ["Ahmad Alhilal", "Tristan Braud", "Bo Han", "Pan Hui"], "Sources": "Proceedings of the ACM Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": " Mobile cloud gaming enables high-end games on constrained devices by streaming the game content from powerful servers through mobile networks. Mobile networks suffer from highly variable bandwidth, latency, and losses that affect the gaming experience. This paper introduces , an end-to-end cloud gaming framework to minimize the impact of network conditions on the user experience. relies on an end-to-end distortion model adapting the video source rate and the amount of frame-level redundancy based on the measured network conditions. As a result, it minimizes the motion-to-photon (MTP) latency while protecting the frames from losses. We fully implement and evaluate its performance against the state-of-the-art techniques and latest research in real-time mobile cloud gaming transmission on a physical testbed over emulated and real wireless networks. consistently balances MTP latency (<140?ms) and?\u2026", "IdName": "alhilal2022nebula", "Citation": "", "Keywords": ""}, {"Name": "Vibroweight: Simulating weight and center of gravity changes of objects in virtual reality for enhanced realism", "Authors": ["Xian Wang", "Diego Monteiro", "Lik-Hang Lee", "Pan Hui", "Hai-Ning Liang"], "Sources": "2022 IEEE haptics symposium (HAPTICS)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Haptic feedback in virtual reality (VR) allows users to perceive the physical properties of virtual objects (e.g., their weight and motion patterns). However, the lack of haptic sensations deteriorates users' immersion and overall experience. In this work, we designed and implemented a low-cost hardware prototype with liquid metal, VibroWeight, which can work in complementarity with commercial VR handheld controllers. VibroWeight is characterized by bimodal feedback cues in VR, driven by adaptive absolute mass (weights) and gravity shift. To our knowledge, liquid metal is used in a VR haptic device for the first time. Our 29 participants show that VibroWeight delivers significantly better VR experiences in realism and comfort.", "IdName": "wang2022vibroweight", "Citation": "", "Keywords": ""}, {"Name": "Heterogeneous model fusion federated learning mechanism based on model mapping", "Authors": ["Xiaofeng Lu", "Yuying Liao", "Chao Liu", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": "The computing power of various Internet of Things (IoT) devices is quite different. To enable IoT devices with lower computing power to perform machine learning, all nodes can only train smaller models, which results in the waste of computing power for high-performance devices. In this article, a heterogeneous model fusion federated learning (HFL) mechanism is proposed. Each node trains learning models of different scales according to its own computing capabilities. After receiving the gradient trained by each node, the parameter server (PS) corrects the received gradient with the repeat matrix, and then update the corresponding region of the global model according to the mapping matrix. After all update operations are over, the PS assigns the compressed model to the corresponding node. This article uses a variety of experimental schemes to evaluate the proposed method, including three data sets, two model?\u2026", "IdName": "lu2021heterogeneous", "Citation": "", "Keywords": ""}, {"Name": "Deepvista: 16k panoramic cinema on your mobile device", "Authors": ["Wenxiao Zhang", "Feng Qian", "Bo Han", "Pan Hui"], "Sources": "Proceedings of the Web Conference 2021", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, we design, implement, and evaluate , which is to our knowledge the first consumer-class system that streams panoramic videos far beyond the ultra high-definition resolution (up to 16K) to mobile devices, offering truly immersive experiences. Such an immense resolution makes streaming video-on-demand (VoD) content extremely resource-demanding. To tackle this challenge, introduces a novel framework that leverages an edge server to perform efficient, intelligent, and quality-guaranteed content transcoding, by extracting from panoramic frames the viewport stream that will be delivered to the client. To support real-time transcoding of 16K content, employs several key mechanisms such as dual-GPU acceleration, lossless viewport extraction, deep viewport prediction, and a two-layer streaming design. Our extensive evaluations using real users\u2019 viewport movement data indicate that outperforms?\u2026", "IdName": "zhang2021deepvista", "Citation": "", "Keywords": ""}, {"Name": "Understanding the user behavior of foursquare: A data-driven study on a global scale", "Authors": ["Yang Chen", "Jiyao Hu", "Yu Xiao", "Xiang Li", "Pan Hui"], "Sources": "IEEE Transactions on Computational Social Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Being a leading online service providing both local search and social networking functions, Foursquare has attracted tens of millions of users all over the world. Understanding the user behavior of Foursquare is helpful to gain insights for location-based social networks (LBSNs). Most of the existing studies focus on a biased subset of users, which cannot give a representative view of the global user base. Meanwhile, although the user-generated content (UGC) is very important to reflect user behavior, most of the existing UGC studies of Foursquare are based on the check-ins. There is a lack of a thorough study on tips, the primary type of UGC on Foursquare. In this article, by crawling and analyzing the global social graph and all published tips, we conduct the first comprehensive user behavior study of all 60+ million Foursquare users around the world. We have made the following three main contributions. First, we?\u2026", "IdName": "chen2020understanding", "Citation": "", "Keywords": ""}, {"Name": "From seen to unseen: Designing keyboard-less interfaces for text entry on the constrained screen real estate of Augmented Reality headsets", "Authors": ["Lik Hang Lee", "Tristan Braud", "Kit Yung Lam", "Yui Pan Yau", "Pan Hui"], "Sources": "Pervasive and Mobile Computing 64", "PublishedYears": "2020", "Doi": "", "Abstracts": "Text input is a very challenging task in the constrained screen real-estate of Augmented Reality headsets. Typical keyboards spread over multiple lines and occupy a significant portion of the screen. In this article, we explore the feasibility of single-line text entry systems for smartglasses. We first design FITE, a dynamic keyboard where the characters are positioned depending on their probability within the current input. However, the dynamic layout leads to mediocre text input and low accuracy. We then introduce HIBEY, a fixed 1-line solution that further decreases the screen real-estate usage by hiding the layout. Despite its hidden layout, HIBEY surprisingly performs much better than FITE, and achieves a mean text entry rate of 9.95 words per minute (WPM) with 96.06% accuracy, which is comparable to other state-of-the-art approaches. After 8 days, participants achieve an average of 13.19 WPM. In addition?\u2026", "IdName": "lee2020seen", "Citation": "", "Keywords": ""}, {"Name": "Collaborative augmented reality system", "Authors": ["Bo Han", "Vijay Gopalakrishnan", "Eric Zavesky", "Wenxiao Zhang", "Pan Hui"], "Sources": "US Patent 10", "PublishedYears": "2020", "Doi": "", "Abstracts": "An augmented reality device computationally processes an image frame against a first augmented reality profile stored in a local database. The first augmented reality profile includes first annotation content associated with a first object and is obtained from a second user device. In response to an object computationally processed from the first image frame satisfying a predetermined threshold of similarity with the first object in the first augmented reality profile, the first annotation content is rendered, on a display of the first user device, relative to the first object according to rendering instructions for the first annotation content.", "IdName": "han2020collaborative", "Citation": "", "Keywords": ""}, {"Name": "Cross-site prediction on social influence for cold-start users in online social networks", "Authors": ["Qingyuan Gong", "Yang Chen", "Xinlei He", "Yu Xiao", "Pan Hui", "Xin Wang", "Xiaoming Fu"], "Sources": "ACM Transactions on the Web (TWEB)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Online social networks (OSNs) have become a commodity in our daily life. As an important concept in sociology and viral marketing, the study of social influence has received a lot of attentions in academia. Most of the existing proposals work well on dominant OSNs, such as Twitter, since these sites are mature and many users have generated a large amount of data for the calculation of social influence. Unfortunately, cold-start users on emerging OSNs generate much less activity data, which makes it challenging to identify potential influential users among them. In this work, we propose a practical solution to predict whether a cold-start user will become an influential user on an emerging OSN, by opportunistically leveraging the user\u2019s information on dominant OSNs. A supervised machine learning-based approach is adopted, transferring the knowledge of both the descriptive information and dynamic activities on?\u2026", "IdName": "gong2021cross", "Citation": "", "Keywords": ""}, {"Name": "Characterizing student engagement moods for dropout prediction in question pool websites", "Authors": ["Reza Hadi Mogavi", "Xiaojuan Ma", "Pan Hui"], "Sources": "arXiv preprint arXiv:2102.00423", "PublishedYears": "2021", "Doi": "", "Abstracts": "Problem-Based Learning (PBL) is a popular approach to instruction that supports students to get hands-on training by solving problems. Question Pool websites (QPs) such as LeetCode, Code Chef, and Math Playground help PBL by supplying authentic, diverse, and contextualized questions to students. Nonetheless, empirical findings suggest that 40% to 80% of students registered in QPs drop out in less than two months. This research is the first attempt to understand and predict student dropouts from QPs via exploiting students' engagement moods. Adopting a data-driven approach, we identify five different engagement moods for QP students, which are namely challenge-seeker, subject-seeker, interest-seeker, joy-seeker, and non-seeker. We find that students have collective preferences for answering questions in each engagement mood, and deviation from those preferences increases their probability of dropping out significantly. Last but not least, this paper contributes by introducing a new hybrid machine learning model (we call Dropout-Plus) for predicting student dropouts in QPs. The test results on a popular QP in China, with nearly 10K students, show that Dropout-Plus can exceed the rival algorithms' dropout prediction performance in terms of accuracy, F1-measure, and AUC. We wrap up our work by giving some design suggestions to QP managers and online learning professionals to reduce their student dropouts.", "IdName": "mogavi2021characterizing", "Citation": "", "Keywords": ""}, {"Name": "Notice of Retraction: Steal Your Life Using 5 Cents: Hacking Android Smartphones with NFC Tags", "Authors": ["Carlos Bermejo", "Huber Flores", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Retracted.", "IdName": "bermejo2020notice", "Citation": "", "Keywords": ""}, {"Name": "Decentralized, not dehumanized in the metaverse: Bringing utility to NFTs through multimodal interaction", "Authors": ["Anqi Wang", "Ze Gao", "Lik Hang Lee", "Tristan Braud", "Pan Hui"], "Sources": "Proceedings of the 2022 international conference on multimodal interaction?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "User Interaction for NFTs (Non-fungible Tokens) is gaining increasing attention. Although NFTs have been traditionally single-use and monolithic, recent applications aim to connect multimodal interaction with human behavior. This paper reviews the related technological approaches and business practices in NFT art. We highlight that multimodal interaction is a currently under-studied issue in mainstream NFT art, and conjecture that multimodal interaction is a crucial enabler for decentralization in the NFT community. We present a continuum theory and propose a framework combining a bottom-up approach with AI multimodal process. Through this framework, we put forward integrating human behavior data into generative NFT units, as \"multimodal interactive NFT.\" Our work displays the possibilities of NFTs in the art world, beyond the traditional 2D and 3D static content. ", "IdName": "wang2022decentralized", "Citation": "", "Keywords": ""}, {"Name": "Passive health monitoring using large scale mobility data", "Authors": ["Yunke Zhang", "Fengli Xu", "Tong Li", "Vassilis Kostakos", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, we investigate the feasibility of using mobility patterns and demographic data to predict hospital visits. We collect mobility traces from two thousand users for around two months. We extract 16 mobility features from these passively collected mobility traces and train an XGBoost model to predict users' hospital visits. We demonstrate that the designed mobility features can significantly improve prediction accuracy (p < 0.01, AUC = 0.79). We further analyze how these mobility features affect the prediction results and measure their importance by using Shapley additive explanation values. We discover that users with less mobility activity, less visit diversity, and few sports facilities, bountiful entertainment around their visited locations are more likely to visit hospitals. Moreover, we conduct predictions on the populations with different demographic features, which achieves meaningful and insightful results, i.e?\u2026", "IdName": "zhang2021passive", "Citation": "", "Keywords": ""}, {"Name": "UbiPoint: towards non-intrusive mid-air interaction for hardware constrained smart glasses", "Authors": ["Lik Hang Lee", "Tristan Braud", "Farshid Hassani Bijarbooneh", "Pan Hui"], "Sources": "Proceedings of the 11th ACM Multimedia Systems Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": "Throughout the past decade, numerous interaction techniques have been designed for mobile and wearable devices. Among these devices, smartglasses mostly rely on hardware interfaces such as touchpad and buttons, which are often cumbersome and counterintuitive to use. Furthermore, smartglasses feature cheap and low-power hardware preventing the use of advanced pointing techniques. To overcome these issues, we introduce UbiPoint, a freehand mid-air interaction technique. UbiPoint uses the monocular camera embedded in smartglasses to detect the user's hand without relying on gloves, markers, or sensors, enabling intuitive and non-intrusive interaction. We introduce a computationally fast and light-weight algorithm for fingertip detection, which is especially suited for the limited hardware specifications and the short battery life of smartglasses. UbiPoint processes pictures at a rate of 20 frames per?\u2026", "IdName": "lee2020ubipoint", "Citation": "", "Keywords": ""}, {"Name": "Street smart in 5G: Vehicular applications, communication, and computing", "Authors": ["Ahmad Yousef Alhilal", "Benjamin Finley", "Tristan Braud", "Dongzhe Su", "Pan Hui"], "Sources": "IEEE Access 10", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recent advances in information technology have revolutionized the automotive industry, paving the way for next-generation smart vehicular mobility. Specifically, vehicles, roadside units, and other road users can collaborate to deliver novel services and applications that leverage, for example, big vehicular data and machine learning. Relatedly, fifth-generation cellular networks (5G) are being developed and deployed for low-latency, high-reliability, and high bandwidth communications. While 5G adjacent technologies such as edge computing allow for data offloading and computation at the edge of the network thus ensuring even lower latency and context-awareness. Overall, these developments provide a rich ecosystem for the evolution of vehicular applications, communications, and computing. Therefore in this work, we aim at providing a comprehensive overview of the state of research on vehicular computing?\u2026", "IdName": "alhilal2022street", "Citation": "", "Keywords": ""}, {"Name": "Human-avatar interaction in metaverse: Framework for full-body interaction", "Authors": ["Kit Yung Lam", "Liang Yang", "Ahmad Alhilal", "Lik-Hang Lee", "Gareth Tyson", "Pan Hui"], "Sources": "Proceedings of the 4th ACM International Conference on Multimedia in Asia", "PublishedYears": "2022", "Doi": "", "Abstracts": "The metaverse is a network of shared virtual environments where people can interact synchronously through their avatars. To enable this, it is necessary to accurately capture and recreate (physical) human motion. This is used to render avatars correctly, reflecting the motion of their corresponding users. In large-scale environments this must be done in real-time. This paper proposes a human-avatar framework with full-body motion capture. Its goal is to deliver high-accuracy capture with low computational and network overheads. It relies on a lightweight Octree data structure to record and transmit motion to other users. We conduct a user study with 22 participants and perform a preliminary evaluation of its scalability. Our user study shows that Octree with Inverse Kinematic achieves the best trade-off, achieving low delay and high accuracy. Our proposed solution delivers the lowest delay, with an average of 67ms in?\u2026", "IdName": "lam2022human", "Citation": "", "Keywords": ""}, {"Name": "Loss tolerant federated learning", "Authors": ["Pengyuan Zhou", "Pei Fang", "Pan Hui"], "Sources": "arXiv preprint arXiv:2105.03591", "PublishedYears": "2021", "Doi": "", "Abstracts": "Federated learning has attracted attention in recent years for collaboratively training data on distributed devices with privacy-preservation. The limited network capacity of mobile and IoT devices has been seen as one of the major challenges for cross-device federated learning. Recent solutions have been focusing on threshold-based client selection schemes to guarantee the communication efficiency. However, we find this approach can cause biased client selection and results in deteriorated performance. Moreover, we find that the challenge of network limit may be overstated in some cases and the packet loss is not always harmful. In this paper, we explore the loss tolerant federated learning (LT-FL) in terms of aggregation, fairness, and personalization. We use ThrowRightAway (TRA) to accelerate the data uploading for low-bandwidth-devices by intentionally ignoring some packet losses. The results suggest that, with proper integration, TRA and other algorithms can together guarantee the personalization and fairness performance in the face of packet loss below a certain fraction (10%-30%).", "IdName": "zhou2021loss", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical reinforcement learning for scarce medical resource allocation with imperfect information", "Authors": ["Qianyue Hao", "Fengli Xu", "Lin Chen", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Facing the outbreak of COVID-19, shortage in medical resources becomes increasingly outstanding. Therefore, efficient strategies for medical resource allocation are urgently called for. Reinforcement learning (RL) is powerful for decision making, but three key challenges exist in solving this problem via RL: (1) complex situation and countless choices for decision making in the real world; (2) only imperfect information are available due to the latency of pandemic spreading; (3) limitations on conducting experiments in real world since we cannot set pandemic outbreaks arbitrarily. In this paper, we propose a hierarchical reinforcement learning method with a corresponding training algorithm. We design a decomposed action space to deal with the countless choices to ensure efficient and real time strategies. We also design a recurrent neural network based framework to utilize the imperfect information obtained from?\u2026", "IdName": "hao2021hierarchical", "Citation": "", "Keywords": ""}, {"Name": "Bayesian inference federated learning for heart rate prediction", "Authors": ["Lei Fang", "Xiaoli Liu", "Xiang Su", "Juan Ye", "Simon Dobson", "Pan Hui", "Sasu Tarkoma"], "Sources": "Wireless Mobile Communication and Healthcare: 9th EAI International?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " The advances of sensing and computing technologies pave the way to develop novel applications and services for wearable devices. For example, wearable devices measure heart rate, which accurately reflects the intensity of physical exercise. Therefore, heart rate prediction from wearable devices benefits users with optimization of the training process. Conventionally, Cloud collects user data from wearable devices and conducts inference. However, this paradigm introduces significant privacy concerns. Federated learning is an emerging paradigm that enhances user privacy by remaining the majority of personal data on users\u2019 devices. In this paper, we propose a statistically sound, Bayesian inference federated learning for heart rate prediction with autoregression with exogenous variable (ARX) model. The proposed privacy-preserving method achieves accurate and robust heart rate prediction. To?\u2026", "IdName": "fang2021bayesian", "Citation": "", "Keywords": ""}, {"Name": "Lifecycle-aware online video caching", "Authors": ["Tong Li", "Tristan Braud", "Yong Li", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "The current explosion of video traffic compels service providers to deploy caches at edge networks. Nowadays, most caching systems store data with a high programming voltage corresponding to the largest possible \u2018expiry date\u2019, typically on the order of years, which maximizes the cache damage. However, popular videos rarely exhibit lifecycles longer than a couple of months. Consequently, the programming voltage can instead be adapted to fit the lifecycle and mitigate the cache damage accordingly. In this paper, we propose LiA-cache, a Lifecycle-Aware caching policy for online videos. LiA-cache finds both near-optimal caching retention times and cache eviction policies by optimizing traffic delivery cost and cache damage cost conjointly. We first investigate temporal patterns of video access from a real-world dataset covering 10 million online videos collected by one of the largest mobile network operators in?\u2026", "IdName": "li2020lifecycle", "Citation": "", "Keywords": ""}, {"Name": "Bi-directional digital twin and edge computing in the metaverse", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Pan Hui", "Danny HK Tsang"], "Sources": "IEEE Internet of Things Magazine", "PublishedYears": "2024", "Doi": "", "Abstracts": "The Metaverse has emerged to extend our lifestyle beyond physical limitations. As essential components in the Metaverse, digital twins (DTs) are the real-time digital replicas of physical items. Multi-access edge computing (MEC) provides responsive services to the end users, ensuring an immersive and interactive Metaverse experience. While the digital representation (DT) of physical objects, end users, and edge computing systems is crucial in the Metaverse, the construction of these DTs and the interplay between them have not been well-investigated. In this article, we discuss the bidirectional reliance between the DT and the MEC system and investigate the creation of DTs of objects and users on the MEC servers and DT-assisted edge computing (DTEC). To ensure seamless handover among MEC servers and to avoid intermittent Metaverse services, we also explore the interaction between local DTECs on?\u2026", "IdName": "yu2024bi", "Citation": "", "Keywords": ""}, {"Name": "Weaponising social media for information divide and warfare", "Authors": ["Ehsan-Ul Haq", "Gareth Tyson", "Tristan Braud", "Pan Hui"], "Sources": "Proceedings of the 33rd ACM Conference on Hypertext and Social Media", "PublishedYears": "2022", "Doi": "", "Abstracts": "Social media is often used to disseminate information during crises, including wars, natural disasters and pandemics. This paper discusses the challenges faced during crisis situations, which social media can both contribute to and ameliorate. We discuss the role that information polarisation plays in exacerbating problems. We then discuss how certain mal-actors exploit these divides. We conclude by detailing future avenues of work that can help mitigate these issues. ", "IdName": "haq2022weaponising", "Citation": "", "Keywords": ""}, {"Name": "Theophany: Multimodal speech augmentation in instantaneous privacy channels", "Authors": ["Abhishek Kumar", "Tristan Braud", "Lik Hang Lee", "Pan Hui"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Many factors affect speech intelligibility in face-to-face conversations. These factors lead conversation participants to speak louder and more distinctively, exposing the content to potential eavesdroppers. To address these issues, we introduce Theophany, a privacy-preserving framework for augmenting speech. Theophany establishes ad-hoc social networks between conversation participants to exchange contextual information, improving speech intelligibility in real-time. At the core of Theophany, we develop the first privacy perception model that assesses the privacy risk of a face-to-face conversation based on its topic, location, and participants. This framework allows to develop any privacy-preserving application for face-to-face conversation. We implement the framework within a prototype system that augments the speaker's speech with real-life subtitles to overcome the loss of contextual cues brought by mask?\u2026", "IdName": "kumar2021theophany", "Citation": "", "Keywords": ""}, {"Name": "A roadmap toward a unified space communication architecture", "Authors": ["Ahmad Yousef Alhilal", "Tristan Braud", "Pan Hui"], "Sources": "IEEE Access 9", "PublishedYears": "2021", "Doi": "", "Abstracts": "In recent years, the number of space exploration missions has multiplied. Such an increase raises the question of effective communication between the multitude of human-made objects spread across our solar system. An efficient and scalable communication architecture presents multiple challenges, including the distance between planetary entities, their motion and potential obstruction, the limited available payload on satellites, and the high mission cost. This paper brings together recent relevant specifications, standards, mission demonstrations, and the most recent proposals to develop a unified architecture for deep-space internetworked communication. After characterizing the transmission medium and its unique challenges, we explore the available communication technologies and frameworks to establish a reliable communication architecture across the solar system. We then draw an evolutive roadmap for?\u2026", "IdName": "alhilal2021roadmap", "Citation": "", "Keywords": ""}, {"Name": "Cosine: Collaborator selector for cooperative multi-device sensing and computing", "Authors": ["Huber Flores", "Agustin Zuniga", "Farbod Faghihi", "Xin Li", "Samuli Hemminki", "Sasu Tarkoma", "Pan Hui", "Petteri Nurmi"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Pervasive availability of programmable smart de-vices is giving rise to sensing and computing scenarios that involve collaboration between multiple devices. Maximizing the benefits of collaboration requires careful selection of devices with whom to collaborate as otherwise collaboration may be interrupted prematurely or be sub-optimal for the characteristics of the task at hand. Existing research on collaborative scenarios has mostly focused on providing mechanisms that can establish and harness collaboration, without considering how to maximally benefit from it. In this paper, we contribute by developing COSINE as a novel approach for selecting collaborators in multi-device computing scenarios. COSINE identifies and recommends collaborators based on a novel information theoretic measure based on Markov trajectory entropy. Rigorous experimental benchmarks carried out using a large-scale dataset of?\u2026", "IdName": "flores2020cosine", "Citation": "", "Keywords": ""}, {"Name": "Marketplace for AI models", "Authors": ["Abhishek Kumar", "Benjamin Finley", "Tristan Braud", "Sasu Tarkoma", "Pan Hui"], "Sources": "arXiv preprint arXiv:2003.01593", "PublishedYears": "2020", "Doi": "", "Abstracts": "Artificial intelligence shows promise for solving many practical societal problems in areas such as healthcare and transportation. However, the current mechanisms for AI model diffusion such as Github code repositories, academic project webpages, and commercial AI marketplaces have some limitations; for example, a lack of monetization methods, model traceability, and model auditabilty. In this work, we sketch guidelines for a new AI diffusion method based on a decentralized online marketplace. We consider the technical, economic, and regulatory aspects of such a marketplace including a discussion of solutions for problems in these areas. Finally, we include a comparative analysis of several current AI marketplaces that are already available or in development. We find that most of these marketplaces are centralized commercial marketplaces with relatively few models.", "IdName": "kumar2020marketplace", "Citation": "", "Keywords": ""}, {"Name": "The dark side of augmented reality: Exploring manipulative designs in ar", "Authors": ["Xian Wang", "Lik-Hang Lee", "Carlos Bermejo Fernandez", "Pan Hui"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Augmented Reality (AR) applications are becoming more mainstream, with successful examples in the mobile environment like Pokemon GO. Current malicious techniques can exploit these environments\u2019 immersive and mixed nature (physical-virtual) to trick users into providing more personal information, i.e., dark patterns. Dark patterns are deceiving techniques (e.g., interface tricks) designed to influence individuals\u2019 behavioural decisions. However, there are few studies regarding dark patterns\u2019 potential issues in AR environments. In this work, using scenario construction to build our prototypes, we investigate the potential future approaches that dark patterns can have. We use VR mockups in our user study to analyze the effects of dark patterns in AR. Our study indicates that dark patterns are effective in immersive scenarios, and the use of novel techniques, such as \u201chaptic grabbing\u201d to draw participants\u2019 attention?\u2026", "IdName": "wang2023dark", "Citation": "", "Keywords": ""}, {"Name": "Predicting multi-level socioeconomic indicators from structural urban imagery", "Authors": ["Tong Li", "Shiduo Xin", "Yanxin Xi", "Sasu Tarkoma", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the 31st ACM International Conference on Information?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Understanding economic development and designing government policies requires accurate and timely measurements of socioeconomic activities. In this paper, we show how to leverage city structural information and urban imagery like satellite images and street view images to accurately predict multi-level socioeconomic indicators. Our framework consists of four steps. First, we extract structural information from cities by transforming real-world street networks into city graphs (GeoStruct). Second, we design a contrastive learning-based model to refine urban image features by looking at geographic similarity between images, with images that are geographically close together having similar features (GeoCLR). Third, we propose using street segments as containers to adaptively fuse the features of multi-view urban images, including satellite images and street view images (GeoFuse). Finally, given the city graph?\u2026", "IdName": "li2022predicting", "Citation": "", "Keywords": ""}, {"Name": "Fras: Federated reinforcement learning empowered adaptive point cloud video streaming", "Authors": ["Yu Gao", "Pengyuan Zhou", "Zhi Liu", "Bo Han", "Pan Hui"], "Sources": "arXiv preprint arXiv:2207.07394", "PublishedYears": "2022", "Doi": "", "Abstracts": "Point cloud video transmission is challenging due to high encoding/decoding complexity, high video bitrate, and low latency requirement. Consequently, conventional adaptive streaming methodologies often find themselves unsatisfactory to meet the requirements in threefold: 1) current algorithms reuse existing quality of experience (QoE) definitions while overlooking the unique features of point cloud video thus failing to provide optimal user experience, 2) most deep learning approaches require long-span data collections to learn sufficiently varied network conditions and result in long training periods and capacity occupation, 3) cloud training approaches pose privacy risks caused by leakage of user reported service usage and networking conditions. To overcome the limitations, we present FRAS, the first federated reinforcement learning framework, to the best of our knowledge, for adaptive point cloud video streaming. We define a new QoE model which takes the unique features of point cloud video into account. Each client uses reinforcement learning (RL) to train video quality selection with the objective of optimizing the user's QoE under multiple constraints. Then, a federated learning framework is integrated with the RL algorithm to enhance training performance with privacy preservation. Extensive simulations using real point cloud videos and network traces reveal the superiority of the proposed scheme over baseline schemes. We also implement a prototype that demonstrates the performance of FRAS via real-world tests.", "IdName": "gao2022fras", "Citation": "", "Keywords": ""}, {"Name": "Edgexar: A 6-dof camera multi-target interaction framework for mar with user-friendly latency compensation", "Authors": ["Wenxiao Zhang", "Sikun Lin", "Farshid Hassani Bijarbooneh", "Hao-Fei Cheng", "Tristan Braud", "Pengyuan Zhou", "Lik-Hang Lee", "Pan Hui"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "The computational capabilities of recent mobile devices enable the processing of natural features for Augmented Reality (AR), but the scalability is still limited by the devices' computation power and available resources. In this paper, we propose EdgeXAR, a mobile AR framework that utilizes the advantages of edge computing through task offloading to support flexible camera-based AR interaction. We propose a hybrid tracking system for mobile devices that provides lightweight tracking with 6 Degrees of Freedom and hides the offloading latency from users' perception. A practical, reliable and unreliable communication mechanism is used to achieve fast response and consistency of crucial information. We also propose a multi-object image retrieval pipeline that executes fast and accurate image recognition tasks on the cloud and edge servers. Extensive experiments are carried out to evaluate the performance of?\u2026", "IdName": "zhang2022edgexar", "Citation": "", "Keywords": ""}, {"Name": "A reddit dataset for the russo-ukrainian conflict in 2022", "Authors": ["Yiming Zhu", "Ehsan-ul Haq", "Lik-Hang Lee", "Gareth Tyson", "Pan Hui"], "Sources": "arXiv preprint arXiv:2206.05107", "PublishedYears": "2022", "Doi": "", "Abstracts": "Reddit consists of sub-communities that cover a focused topic. This paper provides a list of relevant subreddits for the ongoing Russo-Ukrainian crisis. We perform an exhaustive subreddit exploration using keyword search and shortlist 12 subreddits as potential candidates that contain nominal discourse related to the crisis. These subreddits contain over 300,000 posts and 8 million comments collectively. We provide an additional categorization of content into two categories, \"R-U Conflict\", and \"Military Related\", based on their primary focus. We further perform content characterization of those subreddits. The results show a surge of posts and comments soon after Russia launched the invasion. \"Military Related\" posts are more likely to receive more replies than \"R-U Conflict\" posts. Our textual analysis shows an apparent preference for the Pro-Ukraine stance in \"R-U Conflict\", while \"Military Related\" retain a neutral stance.", "IdName": "zhu2022reddit", "Citation": "", "Keywords": ""}, {"Name": "Myokey: Surface electromyography and inertial motion sensing-based text entry in ar", "Authors": ["Young D Kwon", "Kirill A Shatilov", "Lik-Hang Lee", "Serkan Kumyol", "Kit-Yung Lam", "Yui-Pan Yau", "Pan Hui"], "Sources": "2020 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "The seamless textual input in Augmented Reality (AR) is very challenging and essential for enabling user-friendly AR applications. Existing approaches such as speech input and vision-based gesture recognition suffer from environmental obstacles and the large default keyboard size, sacrificing the majority of the screen's real estate in AR. In this paper, we propose MyoKey, a system that enables users to effectively and unobtrusively input text in a constrained environment of AR by jointly leveraging surface Electromyography (sEMG) and Inertial Motion Unit (IMU) signals transmitted by wearable sensors on a user's forearm. MyoKey adopts a deep learning-based classifier to infer hand gestures using sEMG. In order to show the feasibility of our approach, we implement a mobile AR application using the Unity application building framework. We present novel interaction and system designs to incorporate information?\u2026", "IdName": "kwon2020myokey", "Citation": "", "Keywords": ""}, {"Name": "Short, colorful, and irreverent! a comparative analysis of new users on wallstreetbets during the gamestop short-squeeze", "Authors": ["Ehsan-Ul Haq", "Tristan Braud", "Lik-Hang Lee", "Anish K Vallapuram", "Yue Yu", "Gareth Tyson", "Pan Hui"], "Sources": "Companion Proceedings of the Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": " WallStreetBets (WSB) is a Reddit community that primarily discusses high-risk options and stock trading. In January 2021, it attracted worldwide attention as one of the epicentres of a significant short squeeze on US markets. Following this event, the number of users and their activity increased exponentially. In this paper, we study the changes caused in the WSB community by such an increase in activity. We perform a comparative analysis between long-term users and newcomers and examine their respective writing styles, topics, and susceptibility to community feedback. We report a significant difference in the post length and the number of emojis between the regular and new users joining WSB. Newer users\u2019 activity also closely follows the affected companies\u2019 stock prices. Finally, although community feedback affects the choices of topics for all users, new users are less prone to select their subsequent?\u2026", "IdName": "haq2022short", "Citation": "", "Keywords": ""}, {"Name": "Predicting the need for vasopressors in the intensive care unit using an attention based deep learning model", "Authors": ["Gloria Hyunjung Kwak", "Lowell Ling", "Pan Hui"], "Sources": "Shock", "PublishedYears": "2021", "Doi": "", "Abstracts": "Background:Previous models on prediction of shock mostly focused on septic shock and often required laboratory results in their models. The purpose of this study was to use deep learning approaches to predict vasopressor requirement for critically ill patients within 24 h of intensive care unit (ICU) admission using only vital signs.Methods:We used data from the Medical Information Mart for Intensive Care III database and the eICU Collaborative Research Database to develop a vasopressor prediction model. We performed systematic data preprocessing using matching of cohorts, oversampling, and imputation to control for bias, class imbalance, and missing data. Bidirectional long short-term memory (Bi-LSTM), a multivariate time series model, was used to predict the need for vasopressor therapy using serial physiological data collected 21 h prior to prediction time.Results:Using data from 10,941 critically ill?\u2026", "IdName": "kwak2021predicting", "Citation": "", "Keywords": ""}, {"Name": "Community matters more than anonymity: analysis of user interactions on the Quora Q&A platform", "Authors": ["Ehsan ul Haq", "Tristan Braud", "Pan Hui"], "Sources": "2020 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Question-and-answer (Q&A) websites are one of the latest evolutions in crowdsourced knowledge aggregation. Q&A websites provide more diverse opinions, as they involve the entire community. Quora made its reputation out of enhancing the traditional Q&A model with popular aspects of social media and incites its users to provide their names, locations, and references. This model allows higher quality control - including anonymous content, but more importantly, it leads users to form communities based on other criteria (e.g. profession, city) than similar interests. In this paper, we study the interactions among Quorans to unveil how such communities emerge. We perform both quantitative and qualitative analysis on the user-generated content and relate this content to social and demographic features. We show that being anonymous significantly affects the answers' length and subjectivity. On the other hand, most?\u2026", "IdName": "ul2020community", "Citation": "", "Keywords": ""}, {"Name": "Empowering the metaverse with generative ai: Survey and future directions", "Authors": ["Hua Xuan Qin", "Pan Hui"], "Sources": "2023 IEEE 43rd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper aims to motivate the development of the metaverse by highlighting the potential of artificial-intelligence-generated content (AIGC) for the metaverse. We present the first literature review on AIGC in the metaverse with state-of-the-art research classified into 5 key application areas (avatars and Non-player Characters (NPCs), content creation, virtual world generation, automatic digital twin, and personalization). Having noticed a notable gap in research through our review, we propose ways in which state-of-the-art generative AI can be applied to the metaverse. Additionally, we offer a roadmap for future research with related ethical implications.", "IdName": "qin2023empowering", "Citation": "", "Keywords": ""}, {"Name": "Aquilis: Using contextual integrity for privacy protection on mobile devices", "Authors": ["Abhishek Kumar", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "Smartphones are nowadays the dominant end-user device. As a result, they have become gateways to all users' communications, including sensitive personal data. In this paper, we present Aquilis, a privacy-preserving system for mobile platforms following the principles of contextual integrity to define the appropriateness of an information flow. Aquilis takes the form of a keyboard that reminds users of potential privacy leakages through a simple three-colour code. Aquilis considers the instantaneous privacy risk related to posting information (Local Sensitivity), the risk induced by repeating information over time (Longitudinal Sensitivity) and on different platforms (Cross-platform Sensitivity). Considering 50% of Aquilis warnings decreases the proportion of inappropriate information by up to 30%. Repeating information over time or in a broader exposure context increases the risk by 340% in a one-to-one context. We?\u2026", "IdName": "kumar2020aquilis", "Citation": "", "Keywords": ""}, {"Name": "VIMES: A wearable memory assistance system for automatic information retrieval", "Authors": ["Carlos Bermejo", "Tristan Braud", "Ji Yang", "Shayan Mirjafari", "Bowen Shi", "Yu Xiao", "Pan Hui"], "Sources": "Proceedings of the 28th ACM International Conference on Multimedia", "PublishedYears": "2020", "Doi": "", "Abstracts": "The advancement of artificial intelligence and wearable computing triggers the radical innovation of cognitive applications. In this work, we propose VIMES, an augmented reality-based memory assistance system that helps recall declarative memory, such as whom the user meets and what they chat. Through a collaborative method with 20 participants, we design VIMES, a system that runs on smartglasses, takes the first-person audio and video as input, and extracts personal profiles and event information to display on the embedded display or a smartphone. We perform an extensive evaluation with 50 participants to show the effectiveness of VIMES for memory recall. VIMES outperforms (90% memory accuracy) other traditional methods such as self-recall (34%) while offering the best memory experience (Vividness, Coherence, and Visual Perspective all score over 4/5). The user study results show that most?\u2026", "IdName": "bermejo2020vimes", "Citation": "", "Keywords": ""}, {"Name": "What do users think of promotional gamification schemes? a qualitative case study in a question answering website", "Authors": ["Reza Hadi Mogavi", "Yuanhao Zhang", "Ehsan-Ul Haq", "Yongjin Wu", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "In recent years, studies on the user experience have emerged as an indispensable part of any gamification research. The study of user experience enables gamification designers and practitioners to design or adapt their gamification schemes in a more knowledgeable and efficacious manner. However, one popular gamification scheme that has largely remained under-researched in terms of user experience is promotional gamification, which refers to an optional and time-limited gamification program that usually mounts an already gamified platform to increase user incentive and engagement for a short span of time (e.g., during the holiday season). The current study undertakes the first steps necessary to explore users' experiences of working with a promotional gamification scheme in a large-scale online community. To this end, we conduct an extensive qualitative case study of users' experiences with a?\u2026", "IdName": "hadi2022users", "Citation": "", "Keywords": ""}, {"Name": "Automorphic equivalence-aware graph neural network", "Authors": ["Fengli Xu", "Quanming Yao", "Pan Hui", "Yong Li"], "Sources": "Advances in Neural Information Processing Systems 34", "PublishedYears": "2021", "Doi": "", "Abstracts": "Distinguishing the automorphic equivalence of nodes in a graph plays an essential role in many scientific domains, eg, computational biologist and social network analysis. However, existing graph neural networks (GNNs) fail to capture such an important property. To make GNN aware of automorphic equivalence, we first introduce a localized variant of this concept---ego-centered automorphic equivalence (Ego-AE). Then, we design a novel variant of GNN, ie, GRAPE, that uses learnable AE-aware aggregators to explicitly differentiate the Ego-AE of each node's neighbors with the aids of various subgraph templates. While the design of subgraph templates can be hard, we further propose a genetic algorithm to automatically search them from graph data. Moreover, we theoretically prove that GRAPE is expressive in terms of generating distinct representations for nodes with different Ego-AE features, which fills in a fundamental gap of existing GNN variants. Finally, we empirically validate our model on eight real-world graph data, including social network, e-commerce co-purchase network, and citation network, and show that it consistently outperforms existing GNNs. The source code is public available at https://github. com/tsinghua-fib-lab/GRAPE.", "IdName": "xu2021automorphic", "Citation": "", "Keywords": ""}, {"Name": "Redundancy removing aggregation network with distance calibration for video face recognition", "Authors": ["Zhonghong Ou", "Yucheng Hu", "Meina Song", "Zheng Yan", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2020", "Doi": "", "Abstracts": "Attention-based techniques have been successfully used for rating image quality, and have been widely employed for set-based face recognition. Nevertheless, for video face recognition, where the base convolutional neural network (CNN) trained on large-scale data already provides discriminative features, fusing features with only predicted quality scores to generate representation are likely to cause duplicate sample dominant problem, and degrade performance correspondingly. To resolve the problem mentioned above, we propose a redundancy removing aggregation network (RRAN) for video face recognition. Compared with other quality-aware aggregation schemes, RRAN can take advantage of similarity information to tackle the noise introduced by redundant video frames. By leveraging metric learning, RRAN introduces a distance calibration scheme to align distance distributions of negative pairs of?\u2026", "IdName": "ou2020redundancy", "Citation": "", "Keywords": ""}, {"Name": "Preference-based privacy markets", "Authors": ["Ranjan Pal", "Jon Crowcroft", "Yixuan Wang", "Yong Li", "Swades De", "Sasu Tarkoma", "Mingyan Liu", "Bodhibrata Nag", "Abhishek Kumar", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "In the modern era of the mobile apps (the era of surveillance capitalism - as termed by Shoshana Zuboff) huge quantities of surveillance data about consumers and their activities offer a wave of opportunities for economic and societal value creation. ln-app advertising - a multi-billion dollar industry, is an essential part of the current digital ecosystem driven by free mobile applications, where the ecosystem entities usually comprise consumer apps, their clients (consumers), ad-networks, and advertisers. Sensitive consumer information is often being sold downstream in this ecosystem without the knowledge of consumers, and in many cases to their annoyance. While this practice, in cases, may result in long-term benefits for the consumers, it can result in serious information privacy breaches of very significant impact (e.g., breach of genetic data) in the short term. The question we raise through this paper is: Is it?\u2026", "IdName": "pal2020preference", "Citation": "", "Keywords": ""}, {"Name": "(m) ad to see me? intelligent advertisement placement: Balancing user annoyance and advertising effectiveness", "Authors": ["Ngoc Thi Nguyen", "Agustin Zuniga", "Hyowon Lee", "Pan Hui", "Huber Flores", "Petteri Nurmi"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2020", "Doi": "", "Abstracts": "Advertising is an unavoidable albeit a frustrating part of mobile interactions. Due to limited form factor, mobile advertisements often resort to intrusive strategies where they temporarily block the user's view in an attempt to increase effectiveness by forcing the user's attention. While such strategies contribute to advertising awareness and effectiveness, they do so at the cost of degrading the user's overall experience and can lead to frustration and annoyance. In this paper, we contribute by developing Perceptive Ads as an intelligent advertisement placement strategy that minimizes disruptions caused by ads while preserving their effectiveness. Our work is the first to simultaneously consider the needs of users, app developers, and advertisers. Ensuring the needs of all stakeholders are taken into account is essential for the adoption of advertising strategies as users (and indirectly developers) would reject strategies?\u2026", "IdName": "nguyen2020m", "Citation": "", "Keywords": ""}, {"Name": "Edge Intelligence: Architectures, Challenges, and\nApplications", "Authors": ["Dianlei Xu", "Tong Li", "Yong Li", "Xiang Su", "Sasu Tarkoma", "Tao Jiang", "Jon Crowcroft", "Pan Hui"], "Sources": "Challenges", "PublishedYears": "2020", "Doi": "", "Abstracts": "None", "IdName": "xu2020edge", "Citation": "", "Keywords": ""}, {"Name": "An asynchronous federated learning mechanism for edge network computing", "Authors": ["X Lu", "Y Liao", "Pietro Lio", "H Pan"], "Sources": "Journal of Computer Research and Development", "PublishedYears": "2020", "Doi": "", "Abstracts": "None", "IdName": "lu2020asynchronous", "Citation": "", "Keywords": ""}, {"Name": "Exploring gaze-assisted and hand-based region selection in augmented reality", "Authors": ["Rongkai Shi", "Yushi Wei", "Xueying Qin", "Pan Hui", "Hai-Ning Liang"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Region selection is a fundamental task in interactive systems. In 2D user interfaces, users typically use a rectangle selection tool to formulate a region using a mouse or touchpad. Region selection in 3D spaces, especially in Augmented Reality (AR) Head-Mounted Displays (HMDs) is different and challenging because users need to select an intended region via freehand mid-air gestures or eye-based actions that are touchless interactions. In this work, we aim to fill in the gap in the design of region selection techniques in AR HMDs. We first analyzed and discretized the interaction procedure of region selection and explored design possibilities for each step. We then developed four techniques for region selection in AR HMDs, which leveraged users' hand and gaze for unimodal or multimodal interaction. The techniques were evaluated via a user study with a controlled region selection task. The findings led to three?\u2026", "IdName": "shi2023exploring", "Citation": "", "Keywords": ""}, {"Name": "More gamification is not always better: A case study of promotional gamification in a question answering website", "Authors": ["Reza Hadi Mogavi", "Ehsan-Ul Haq", "Sujit Gujar", "Pan Hui", "Xiaojuan Ma"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Community Question Answering Websites (CQAs) like Stack Overflow rely on continuous user contributions to keep their services active. Nevertheless, they often undergo a sharp decline in their user participation during the holiday season, undermining their performance. To address this issue, some CQAs have developed their own special promotional gamification schemes to incentivize users to maintain their contributions throughout the holiday season. These promotional gamification schemes are often time-limited, optional, and run alongside the default gamification schemes of their websites. However, the impact of such promotional gamification schemes on user behavior remains largely unexplored in the existing literature. This paper takes the first steps toward filling this knowledge gap by conducting a large-scale empirical study of a particular promotional gamification scheme called Winter Bash (WB) on the?\u2026", "IdName": "hadi2022more", "Citation": "", "Keywords": ""}, {"Name": "PassWalk: spatial authentication leveraging lateral shift and gaze on mobile headsets", "Authors": ["Abhishek Kumar", "Lik-Hang Lee", "Jagmohan Chauhan", "Xiang Su", "Mohammad A Hoque", "Susanna Pirttikangas", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the 30th ACM International Conference on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Secure and usable user authentication on mobile headsets is a challenging problem. The miniature-sized touchpad on such devices becomes a hurdle to user interactions that impact usability. However, the most common authentication methods, i.e., the standard QWERTY virtual keyboard or mid-air inputs to enter passwords are highly vulnerable to shoulder surfing attacks. In this paper, we present PassWalk, a keyboard-less authentication system leveraging multi-modal inputs on mobile headsets. PassWalk demonstrates the feasibility of user authentication driven by the user's gaze and lateral shifts (i.e., footsteps) simultaneously. The keyboard-less authentication interface in PassWalk enables users to accomplish highly mobile inputs of graphical passwords, containing digital overlays and physical objects. We conduct an evaluation with 22 recruited participants (15 legitimate users and 7 attackers). Our results?\u2026", "IdName": "kumar2022passwalk", "Citation": "", "Keywords": ""}, {"Name": "Hidenseek: Federated lottery ticket via server-side pruning and sign supermask", "Authors": ["Anish K Vallapuram", "Pengyuan Zhou", "Young D Kwon", "Lik Hang Lee", "Hengwei Xu", "Pan Hui"], "Sources": "arXiv preprint arXiv:2206.04385", "PublishedYears": "2022", "Doi": "", "Abstracts": "Federated learning alleviates the privacy risk in distributed learning by transmitting only the local model updates to the central server. However, it faces challenges including statistical heterogeneity of clients' datasets and resource constraints of client devices, which severely impact the training performance and user experience. Prior works have tackled these challenges by combining personalization with model compression schemes including quantization and pruning. However, the pruning is data-dependent and thus must be done on the client side which requires considerable computation cost. Moreover, the pruning normally trains a binary supermask  which significantly limits the model capacity yet with no computation benefit. Consequently, the training requires high computation cost and a long time to converge while the model performance does not pay off. In this work, we propose HideNseek which employs one-shot data-agnostic pruning at initialization to get a subnetwork based on weights' synaptic saliency. Each client then optimizes a sign supermask  multiplied by the unpruned weights to allow faster convergence with the same compression rates as state-of-the-art. Empirical results from three datasets demonstrate that compared to state-of-the-art, HideNseek improves inferences accuracies by up to 40.6\\% while reducing the communication cost and training time by up to 39.7\\% and 46.8\\% respectively.", "IdName": "vallapuram2022hidenseek", "Citation": "", "Keywords": ""}, {"Name": "Screenshots, symbols, and personal thoughts: The role of instagram for social activism", "Authors": ["Ehsan-Ul Haq", "Tristan Braud", "Yui-Pan Yau", "Lik-Hang Lee", "Franziska B Keller", "Pan Hui"], "Sources": "Proceedings of the ACM Web Conference 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "In this paper, we highlight the use of Instagram for social activism, taking 2019 Hong Kong protests as a case study. Instagram focuses on image content and provides users with few features to share or repost, limiting information propagation. Nevertheless, users who are politically active offline also share their activism on Instagram. We first evaluate the effect of protests on social media activity for protesters and non-protesters over two significant protests. Protesters\u2019 exposure to protest-related posts is much higher than non-protesters, and their network activity follows the protest schedule. They are also much more active on posts related to the protest that they participate in than the other protest. We then analyze the images posted by the users. Users predominantly use symbols related to protests and share personal thoughts on its primary actors. Users primarily share content to raise their network\u2019s awareness, and?\u2026", "IdName": "haq2022screenshots", "Citation": "", "Keywords": ""}, {"Name": "Seeing is believing? Effects of visualization on smart device privacy perceptions", "Authors": ["Carlos Bermejo Fernandez", "Petteri Nurmi", "Pan Hui"], "Sources": "Proceedings of the 29th ACM International Conference on Multimedia", "PublishedYears": "2021", "Doi": "", "Abstracts": "Research on smart device privacy has consistently highlighted how privacy is an important concern for users, but they fail to act on their concerns. While this discrepancy between user perceptions and actions has been consistently reported, currently there is a limited understanding of why this is the case or how the situation can be ameliorated. This paper systematically studies how visualizations in privacy assistants can improve the situation, reporting on two studies that explore the users' privacy perceptions in smart device ecosystems. The first study shows that displaying device location and data type reduces the users' privacy perceptions. Participants also weigh the use of media such as online news as a source to inform users about the possible inferences. The second study analyzes participants' preferences to visualize smart device information and privacy policies using augmented reality. Through these two?\u2026", "IdName": "bermejo2021seeing", "Citation": "", "Keywords": ""}, {"Name": "Persuade to click: Context-aware persuasion model for online textual advertisement", "Authors": ["Yuan Yuan", "Fengli Xu", "Hancheng Cao", "Guozhen Zhang", "Pan Hui", "Yong Li", "Depeng Jin"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "In recent years, due to the prevalence of online textual advertisements, increasing businesses recognize their huge potential in product promotion. The high-quality textual content has been empirically shown to have a substantial impact on consumers\u2019 attitudes and decisions. As a result, persuasive tactics play an essential role in online textual advertisements, which are employed to increase the attractiveness, and sequentially increase the conversion rate and sales volume. As the context of persuasion, product attributes, e.g., category and price, also greatly influence the persuasion outcomes. However, they are largely overlooked by existing works. In this paper, we propose a novel framework to study context-aware persuasion by designing a multi-task learning model and performing extensive causal analysis. First, the prediction model recognizes the persuasive tactics employed in an advertising text and?\u2026", "IdName": "yuan2021persuade", "Citation": "", "Keywords": ""}, {"Name": "Emerging exg-based nui inputs in extended realities: A bottom-up survey", "Authors": ["Kirill A Shatilov", "Dimitris Chatzopoulos", "Lik-Hang Lee", "Pan Hui"], "Sources": "ACM Transactions on Interactive Intelligent Systems (TiiS)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Incremental and quantitative improvements of two-way interactions with extended realities (XR) are contributing toward a qualitative leap into a state of XR ecosystems being efficient, user-friendly, and widely adopted. However, there are multiple barriers on the way toward the omnipresence of XR; among them are the following: computational and power limitations of portable hardware, social acceptance of novel interaction protocols, and usability and efficiency of interfaces. In this article, we overview and analyse novel natural user interfaces based on sensing electrical bio-signals that can be leveraged to tackle the challenges of XR input interactions. Electroencephalography-based brain-machine interfaces that enable thought-only hands-free interaction, myoelectric input methods that track body gestures employing electromyography, and gaze-tracking electrooculography input interfaces are the examples of?\u2026", "IdName": "shatilov2021emerging", "Citation": "", "Keywords": ""}, {"Name": "Who will survive and revive undergoing the epidemic: Analyses about poi visit behavior in Wuhan via check-in records", "Authors": ["Zhenyu Han", "Haohao Fu", "Fengli Xu", "Zhen Tu", "Yang Yu", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the ACM on Interactive", "PublishedYears": "2021", "Doi": "", "Abstracts": "A rapid-spreading epidemic of COVID-19 hit China at the end of 2019, resulting in unignorable social and economic damage in the epicenter, Wuhan. POIs capture the microscopic behavior of citizens, providing valuable information to understand city reactions toward the epidemic. Leveraging large-scale check-in records, we analyze the POI visit trends over the epidemic period and normal times. We demonstrate that COVID-19 greatly influences the society, where most POIs demonstrate more than 60% of visit drops during the city lockdown period. Among them, Tourist Attractions received greatest impact with a 78.8% drop. Entertainment, Food, Medical and Shopping are sensible to the disease before lockdown, and we identify these \"early birds\" to investigate the public reaction in the early stage of the epidemic. We further analyze the revival trends, generating four different revival patterns that correlated with the?\u2026", "IdName": "han2021will", "Citation": "", "Keywords": ""}, {"Name": "DeepPredict: A zone preference prediction system for online lodging platforms", "Authors": ["Yihan Ma", "Hua Sun", "Yang Chen", "Jiayun Zhang", "Yang Xu", "Xin Wang", "Pan Hui"], "Sources": "Journal of Social Computing", "PublishedYears": "2021", "Doi": "", "Abstracts": "Online lodging platforms have become more and more popular around the world. To make a booking in these platforms, a user usually needs to select a city first, then browses among all the prospective options. To improve the user experience, understanding the zone preferences of a user's booking behavior will be helpful. In this work, we aim to predict the zone preferences of users when booking accommodations for the next travel. We have two main challenges: (1) The previous works about next information of Points Of Interest (POIs) recommendation are mainly focused on users' historical records in the same city, while in practice, the historical records of a user in the same city would be very sparse. (2) Since each city has its own specific geographical entities, it is hard to extract the structured geographical features of accommodation in different cities. Towards the difficulties, we propose DeepPredict, a zone?\u2026", "IdName": "ma2021deeppredict", "Citation": "", "Keywords": ""}, {"Name": "5G edge enhanced mobile augmented reality", "Authors": ["Xiang Su", "Jacky Cao", "Pan Hui"], "Sources": "Proceedings of the 26th Annual International Conference on Mobile Computing?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) provides a unique experience where the physical world is augmented with virtual annotations. MAR involves computation-heavy algorithms that could potentially be offloaded to edge servers on 5G networks, which significantly enhances MAR with reduced communication latency and more stable network connections, therefore leading to seamless MAR user experiences. In this demo, we show a running MAR system deployed on a 5G edge test bed and present latency results.", "IdName": "su20205g", "Citation": "", "Keywords": ""}, {"Name": "Guest editorial special issue on advances in artificial intelligence and machine learning for networking", "Authors": ["Prosper Chemouil", "Pan Hui", "Wolfgang Kellerer", "Noura Limam", "Rolf Stadler", "Yonggang Wen"], "Sources": "IEEE Journal on Selected Areas in Communications", "PublishedYears": "2020", "Doi": "", "Abstracts": "I. INTRODUCTION ARTIFICIAL Intelligence (AI) and Machine Learn-ing (ML) approaches have emerged in the networking domain with great expectation. They can be broadly divided into AI/ML techniques for network engineering and management, network designs for AI/ML applications, and system concepts. AI/ML techniques for networking and management improve the way we address networking. They support efficient, rapid, and trustworthy engineering, operations, and management. As such, they meet the current interest in softwarization and network programmability that fuels the need for improved network automation in agile infrastructures, including edge and fog environments. Network design and optimization for AI/ML applications addresses the complementary topic of supporting AI/ML-based systems through novel networking techniques, including new architectures and algorithms. The third topic area is system implementation and open-source software development. This evolution draws particular attention to interdisciplinary approaches. Researchers in communication networks apply ML and AI concepts to optimize and automate network architecture, control, and management. Similarly, AI experts collaborate with networking researchers to optimize network support for architecture and design of data communication and processing for AI purposes. This special issue is a follow-up to the JSAC\u2019s Special Issue on Artificial Intelligence and Machine Learning for Networking and Communications published in June 2019 [1]. It has been organized by the same core team of researchers.", "IdName": "chemouil2020guest", "Citation": "", "Keywords": ""}, {"Name": "Domain-oriented topic discovery based on features extraction and topic clustering", "Authors": ["Xiaofeng Lu", "Xiao Zhou", "Wenting Wang", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "Topic detection technology can automatically discover new topics on the Internet. This paper investigates domain-oriented feature extraction methods, and proposes a keyword feature extraction method ITFIDF-LP, a subject word feature extraction method LDA-SLP and a topic clustering model based on vector product similarity. A novel Domain-oriented Topic Discovery based on Features Extraction and Topic Clustering (DTD-FETC) model is proposed to analyze open source web of a domain and identify emerging topics in the domain in real time. This article describes a DTD-FETC system built for cyber security domain. It filters and aggregates web for specical security threat topics such as vulnerability and malware, and helps security staff respond quickly and defends against the emerging cyber threats as early as possible. The recall rate, accuracy and F1 value results of the DTD-FETC method applied to the?\u2026", "IdName": "lu2020domain", "Citation": "", "Keywords": ""}, {"Name": "Mneme: A mobile distributed ledger", "Authors": ["Dimitris Chatzopoulos", "Sujit Gujar", "Boi Faltings", "Pan Hui"], "Sources": "Ieee Infocom 2020-Ieee Conference On Computer Communications", "PublishedYears": "2020", "Doi": "", "Abstracts": "Advances in mobile computing have paved the way for new types of distributed applications that can be executed solely by mobile devices on device-to-device (D2D) ecosystems (e.g., crowdsensing). More sophisticated applications, like cryptocurrencies, need distributed ledgers to function. Distributed ledgers, such as blockchains and directed acyclic graphs (DAGs), employ consensus protocols to add data in the form of blocks. However such protocols are designed for resourceful devices that are interconnected via the Internet. Moreover, existing distributed ledgers are not deployable to D2D ecosystems since their storage needs are continuously increasing. In this work, we introduce Mneme, a DAG-based distributed ledger that can be maintained solely by mobile devices and operates via two consensus protocols: Proof-of-Context (PoC) and Proof-of-Equivalence (PoE). PoC employs users' context to add data?\u2026", "IdName": "chatzopoulos2020mneme", "Citation": "", "Keywords": ""}, {"Name": "Towards augmented reality-driven human-city interaction: Current research and future challenges", "Authors": ["Lik-Hang Lee", "Tristan Braud", "Simo Hosio", "Pan Hui"], "Sources": "ArXiv", "PublishedYears": "2020", "Doi": "", "Abstracts": "Authors\u2019 addresses: Lik-Hang Lee Center for Ubiquitous Computing, The University of Oulu, Finland; Tristan Braud Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong; Simo Hosio Center for Ubiquitous Computing, The University of Oulu, Finland; Pan Hui Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong Department of Computer Science, The University of Helsinki, Finland.", "IdName": "lee2020towards", "Citation": "", "Keywords": ""}, {"Name": "A survey on generative ai and llm for video generation, understanding, and streaming", "Authors": ["Pengyuan Zhou", "Lin Wang", "Zhi Liu", "Yanbin Hao", "Pan Hui", "Sasu Tarkoma", "Jussi Kangasharju"], "Sources": "arXiv preprint arXiv:2404.16038", "PublishedYears": "2024", "Doi": "", "Abstracts": "This paper offers an insightful examination of how currently top-trending AI technologies, i.e., generative artificial intelligence (Generative AI) and large language models (LLMs), are reshaping the field of video technology, including video generation, understanding, and streaming. It highlights the innovative use of these technologies in producing highly realistic videos, a significant leap in bridging the gap between real-world dynamics and digital creation. The study also delves into the advanced capabilities of LLMs in video understanding, demonstrating their effectiveness in extracting meaningful information from visual content, thereby enhancing our interaction with videos. In the realm of video streaming, the paper discusses how LLMs contribute to more efficient and user-centric streaming experiences, adapting content delivery to individual viewer preferences. This comprehensive review navigates through the current achievements, ongoing challenges, and future possibilities of applying Generative AI and LLMs to video-related tasks, underscoring the immense potential these technologies hold for advancing the field of video technology related to multimedia, networking, and AI communities.", "IdName": "zhou2024survey", "Citation": "", "Keywords": ""}, {"Name": "Large-scale urban cellular traffic generation via knowledge-enhanced gans with multi-periodic patterns", "Authors": ["Shuodi Hui", "Huandong Wang", "Tong Li", "Xinghao Yang", "Xing Wang", "Junlan Feng", "Lin Zhu", "Chao Deng", "Pan Hui", "Depeng Jin", "Yong Li"], "Sources": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "With the rapid development of the cellular network, network planning is increasingly important. Generating large-scale urban cellular traffic contributes to network planning via simulating the behaviors of the planned network. Existing methods fail in simulating the long-term temporal behaviors of cellular traffic while cannot model the influences of the urban environment on the cellular networks. We propose a knowledge-enhanced GAN with multi-periodic patterns to generate large-scale cellular traffic based on the urban environment. First, we design a GAN model to simulate the multi-periodic patterns and long-term aperiodic temporal dynamics of cellular traffic via learning the daily patterns, weekly patterns, and residual traffic between long-term traffic and periodic patterns step by step. Then, we leverage urban knowledge to enhance traffic generation via constructing a knowledge graph containing multiple factors?\u2026", "IdName": "hui2023large", "Citation": "", "Keywords": ""}, {"Name": "Envisioning an Inclusive Metaverse: Student Perspectives on Accessible and Empowering Metaverse-Enabled Learning", "Authors": ["Reza Hadi Mogavi", "Jennifer Hoffman", "Chao Deng", "Yiwei Du", "Ehsan-Ul Haq", "Pan Hui"], "Sources": "Proceedings of the Tenth ACM Conference on Learning@ Scale", "PublishedYears": "2023", "Doi": "", "Abstracts": "The emergence of the metaverse is being widely viewed as a revolutionary technology owing to a myriad of factors, particularly the potential to increase the accessibility of learning for students with disabilities. However, not much is yet known about the views and expectations of disabled students in this regard. The fact that the metaverse is still in its nascent stage exemplifies the need for such timely discourse. To bridge this important gap, we conducted a series of semi-structured interviews with 56 university students with disabilities in the United States and Hong Kong to understand their views and expectations concerning the future of metaverse-driven education. We have distilled student expectations into five thematic categories, referred to as the REEPS framework: Recognition, Empowerment, Engagement, Privacy, and Safety. Additionally, we have summarized the main design considerations in eight concise?\u2026", "IdName": "hadi2023envisioning", "Citation": "", "Keywords": ""}, {"Name": "Ad-rcnn: Adaptive dynamic neural network for small object detection", "Authors": ["Zhonghong Ou", "Zhaofengnian Wang", "Fenrui Xiao", "Baiqiao Xiong", "Hongxing Zhang", "Meina Song", "Yan Zheng", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2022", "Doi": "", "Abstracts": "With the large-scale commercialization of 5G networks, Internet of Things (IoT) applications keep on emerging in recent years. Real-time environmental awareness is an essential part of various IoT applications, e.g., self-driving vehicles. Object detection plays a fundamental role in real-time environmental awareness, which is responsible for acquiring valuable object information from the environment automatically. Despite of the fast progress for object detection in general, small object detection still faces challenges. Because of the restricted scales, small objects are only capable of generating relatively week features after multiple convolutional layers, thus causing low detection accuracy. Existing schemes mostly focus on extracting rich multiscale features, e.g., generating high-resolution features through generative adversarial networks (GANs), or generating multiscale features through feature combination?\u2026", "IdName": "ou2022ad", "Citation": "", "Keywords": ""}, {"Name": "Talaria: In-engine synchronisation for seamless migration of mobile edge gaming instances", "Authors": ["Tristan Braud", "Ahmad Alhilal", "Pan Hui"], "Sources": "Proceedings of the 17th International Conference on emerging Networking?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Mobile cloud gaming requires a very low end-to-end latency. Edge computing significantly reduces network latency. However, in mobility scenarios, the user will frequently move out of the edge server's coverage area, requiring frequent migration of the game instance. This paper presents Talaria, an in-engine content synchronisation solution for unnoticeable game instance migration between edge servers. Talaria creates a minimal instance with content immediately relevant to the game experience, allowing the client to switch servers in a minimal amount of time. The remaining content is then synchronised according to priority until the game's state is coherent between both instances. Our implementation of Talaria as a Unity engine plugin reduces the game's downtime by 61% compared to one-off server migration, with an average latency below 25 ms for the server migration, and 87 ms for the entire game?\u2026", "IdName": "braud2021talaria", "Citation": "", "Keywords": ""}, {"Name": "Enemy at the gate: evolution of Twitter user's polarization during national crisis", "Authors": ["Ehsan ul Haq", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "Proceedings of the 12th IEEE/ACM International Conference on Advances in?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Social networks are effective platforms to study the real-life behavior of users. In this paper, we study users' political polarization during the times of crisis and its relation to nationalism. To this purpose, we focus on the reaction of Indian and Pakistani Twitter users during February 2019 crisis and the ensuing Indian General Elections in 2019. We show that a national crisis affects the polarization and discourse in both countries. Also, we show that user activities increase during a national crisis, and political discourse strengthens while polarization decreases on critical days. Finally, we highlight the links between this crisis and the Indian elections and show how the political parties discussed the crisis in their campaigns.", "IdName": "haq2020enemy", "Citation": "", "Keywords": ""}, {"Name": "Demo Abstract: Federated Learning on Wearable Devices", "Authors": ["Xiaoxin He", "Xiang Su", "Yang Chen", "Pan Hui"], "Sources": "Proceedings of the 18th Conference on Embedded Networked Sensor Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Wearable devices collect user information about their activities and provide insights to improve their daily lifestyles. Smart health applications have achieved great success by training Machine Learning (ML) models on a large quantity of user data from wearables. However, user privacy and scalability are becoming critical challenges for training ML models in a centralized way. Federated learning (FL) is a novel ML paradigm with the goal of training high quality models while distributing training data over a large number of devices. In this demo, we present FL4W, a FL system with wearable devices enabling training a human activity recognition classifier. We also perform preliminary analytics to investigate the model performance with increasing computation of clients.", "IdName": "he2020federated", "Citation": "", "Keywords": ""}, {"Name": "IoT vs. human: A comparison of mobility", "Authors": ["Dianlei Xu", "Huandong Wang", "Yong Li", "Sasu Tarkoma", "Depeng Jin", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "Internet of Thing (IoT) devices are rapidly becoming an indispensable part of our life with their increasing deployment in many promising areas, including tele-health, smart city, intelligent agriculture. Understanding the mobility of IoT devices is essential to improve quality of service in IoT applications, such as route planning in logistic management, infrastructure deployment, cellular network update and congestion detection in intelligent traffic. Despite its importance, there are not many results pertaining to the mobility of IoT devices. In this article, we aim to answer three research questions: (i) what are the mobility patterns of IoT device? (ii) what are the differences between IoT device and smartphone mobility patterns? (iii) how the IoT device mobility patterns differ among device types and usage scenarios? We present a comprehensive characterization of IoT device mobility patterns from the perspective of cellular?\u2026", "IdName": "xu2020iot", "Citation": "", "Keywords": ""}, {"Name": "Understanding the working time of developers in it companies in China and the United States", "Authors": ["Jiayun Zhang", "Yang Chen", "Qingyuan Gong", "Xin Wang", "Aaron Yi Ding", "Yu Xiao", "Pan Hui"], "Sources": "IEEE Software", "PublishedYears": "2020", "Doi": "", "Abstracts": "We identified three temporal patterns shown in commit activities among Chinese and American companies and found that Chinese businesses are more likely to follow long work hours than American ones. We also conducted a survey on the trends of, reasons for, and results of overtime work. Our study could provide references for developers to choose workplaces and for companies to make regulations.", "IdName": "zhang2020understanding", "Citation": "", "Keywords": ""}, {"Name": "You are how you use apps: user profiling based on spatiotemporal app usage behavior", "Authors": ["Tong Li", "Yong Li", "Mingyang Zhang", "Sasu Tarkoma", "Pan Hui"], "Sources": "ACM Transactions on Intelligent Systems and Technology", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile apps have become an indispensable part of people\u2019s daily lives. Users determine what apps to use and when and where to use them based on their tastes, interests, and personal demands, depending on their personality traits. This article aims to infer user profiles from their spatiotemporal mobile app usage behavior. Specifically, we first transform mobile app usage records into a heterogeneous graph. On the graph, nodes represent users, apps, locations, and time slots. Edges describe the co-occurrence of entities in usage records. We then develop a multi-relational heterogeneous graph attention network (MRel-HGAN), an end-to-end system for user profiling. MRel-HGAN first adopts a neighbor sampling strategy based on bootstrapping to sample heavily connected neighbors of a fixed size for each node. Next, we design a relational graph convolutional operation and a multi-relational attention operation?\u2026", "IdName": "li2023you", "Citation": "", "Keywords": ""}, {"Name": "Network Traffic in the Metaverse: The Case of Social VR", "Authors": ["Ahmad Alhilal", "Kirill Shatilov", "Gareth Tyson", "Tristan Braud", "Pan Hui"], "Sources": "2023 IEEE 43rd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The Metaverse connects our physical reality with virtual worlds. Social VR platforms facilitate the creation of such virtual worlds, enabling activities such as interactive teaching, conferences, and community gatherings. These activities can be performed in mixed mode, with some participants physically present in the same location. In this paper, we evaluate the feasibility of such mixed-mode events by studying three leading social VR platforms. We uncover the network traffic patterns generated by these platforms, which affect the user experience when multiple users share the same network. We explore the traffic patterns to show that model loading creates a significant overhead and impacts user quality of experience. When the number of simultaneously connected users increases, some operations lead to network congestion that degrades or even interrupts service for most users. From these observations, we derive?\u2026", "IdName": "alhilal2023network", "Citation": "", "Keywords": ""}, {"Name": "Your favorite gameplay speaks volumes about you: Predicting user behavior and hexad type", "Authors": ["Reza Hadi Mogavi", "Chao Deng", "Jennifer Hoffman", "Ehsan-Ul Haq", "Sujit Gujar", "Antonio Bucchiarone", "Pan Hui"], "Sources": "International Conference on Human-Computer Interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "In recent years, the gamification research community has widely and frequently questioned the effectiveness of one-size-fits-all gamification schemes. In consequence, personalization seems to be an important part of any successful gamification design. Personalization can be improved by understanding user behavior and Hexad player/user type. This paper comes with an original research idea: It investigates whether users\u2019 game-related data (collected via various gamer-archetype surveys) can be used to predict their behavioral characteristics and Hexad user types in non-game (but gamified) contexts. The affinity that exists between the concepts of gamification and gaming provided us with the impetus for running this exploratory research.We conducted an initial survey study with 67 Stack Exchange users (as a case study). We discovered that users\u2019 gameplay information could reveal valuable and helpful?\u2026", "IdName": "hadi2023your", "Citation": "", "Keywords": ""}, {"Name": "Deepfake in the Metaverse: An Outlook Survey", "Authors": ["Haojie Wu", "Pan Hui", "Pengyuan Zhou"], "Sources": "arXiv preprint arXiv:2306.07011", "PublishedYears": "2023", "Doi": "", "Abstracts": "We envision deepfake technologies, which synthesize realistic fake images and videos, will play an important role in the future metaverse. While enhancing users' immersion and experience with synthesized virtual characters and scenes, deepfake can cause serious consequences if used for fraud, impersonation, and dissemination of fake information. In this paper, we introduce the principles, applications, and risks of deepfake technology, and propose some countermeasures to help users and developers in the metaverse deal with the challenges brought by deepfake technologies. Further, we provide an outlook on the future development of deepfake in the metaverse.", "IdName": "wu2023deepfake", "Citation": "", "Keywords": ""}, {"Name": "Tangible web: An interactive immersion virtual reality creativity system that travels across reality", "Authors": ["Simin Yang", "Ze Gao", "Reza Hadi Mogavi", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the ACM Web Conference 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": " With the advancement of virtual reality (VR) technology, virtual displays have become integral to how museums, galleries, and other tourist destinations present their collections to the public. However, the current lack of immersion in virtual reality displays limits the user\u2019s ability to experience and appreciate its aesthetics. This paper presents a case study of a creative approach taken by a tourist attraction venue in developing a physical network system that allows visitors to enhance VR\u2019s aesthetic aspects based on environmental parameters gathered by external sensors. Our system was collaboratively developed through interviews and sessions with twelve stakeholder groups interested in art and exhibitions. This paper demonstrates how our technological advancements in interaction, immersion and visual attractiveness surpass those of earlier virtual display generations. Through multimodal interaction, we aim to?\u2026", "IdName": "yang2023tangible", "Citation": "", "Keywords": ""}, {"Name": "Fedclean: A defense mechanism against parameter poisoning attacks in federated learning", "Authors": ["Abhishek Kumar", "Vivek Khimani", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "ICASSP 2022-2022 IEEE International Conference on Acoustics", "PublishedYears": "2022", "Doi": "", "Abstracts": "In Federated learning (FL) systems, a centralized entity (server), instead of access to the training data, has access to model parameter updates computed by each participant independently and based solely on their samples. Unfortunately, FL is susceptible to model poisoning attacks, in which malicious or malfunctioning entities share polluted updates that can compromise the model\u2019s accuracy. In this study, we propose FedClean, an FL mechanism that is robust to model poisoning attacks. The accuracy of the models trained with the assistance of FedClean is close to the one where malicious entities do not participate.", "IdName": "kumar2022fedclean", "Citation": "", "Keywords": ""}, {"Name": "Implementing GDPR for mobile and ubiquitous computing", "Authors": ["Carlos Bermejo Fernandez", "Tristan Braud", "Pan Hui"], "Sources": "Proceedings of the 23rd Annual International Workshop on Mobile Computing?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The General Data Protection Regulation (GDPR) presents directives to give data subjects control over their personal data. These directives impose data-collecting and processing organizations to take concrete actions for privacy preservation of users and non-users alike. Significant challenges arise when applying these directives to mobile and ubiquitous computing. Mobile and ubiquitous computing aim for computer use to be as transparent and seamless as possible. Inconspicuous devices continually sense their environment, often without the data subject's knowledge. This context significantly complicates the implementation of core GDPR directives, such as informing the user and collecting consent. In this paper, we challenge the mobile computing research community on how to address such issues in practical implementations that combine the philosophy of mobile and ubiquitous computing with often?\u2026", "IdName": "fernandez2022implementing", "Citation": "", "Keywords": ""}, {"Name": "Evaluating multimedia protocols on 5g edge for mobile augmented reality", "Authors": ["Jacky Cao", "Xiang Su", "Benjamin Finley", "Antti Pauanne", "Mostafa Ammar", "Pan Hui"], "Sources": "2021 17th International Conference on Mobility", "PublishedYears": "2021", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) mixes physical environments with user-interactive virtual annotations. Immersive MAR experiences are supported by computation-intensive tasks, which are typically offloaded to cloud or edge servers. Such offloading introduces additional network traffic and influences the motion-to-photon latency (a determinant of user-perceived quality of experience). Therefore, proper multimedia protocols are crucial to minimise transmission latency and ensure sufficient throughput to support MAR performance. Relatedly, 5G is a potential MAR supporting technology and is widely believed to be faster and more efficient than its predecessors. However, the suitability and performance of existing multimedia protocols for MAR in the 5G edge context have not been explored. In this work, we present a detailed evaluation of several popular multimedia protocols (HLS, MPEG-DASH, RTP, RTMP, RTMFP?\u2026", "IdName": "cao2021evaluating", "Citation": "", "Keywords": ""}, {"Name": "CAD3: Edge-facilitated real-time collaborative abnormal driving distributed detection", "Authors": ["Ahmad Alhilal", "Tristan Braud", "Xiang Su", "Luay Al Asadi", "Pan Hui"], "Sources": "2021 IEEE 41st International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Speeding, slowing down, and sudden acceleration are the leading causes of fatal accidents on highways. Anomalous driving behavior detection can improve road safety by informing drivers who are in the vicinity of dangerous vehicles. However, detecting abnormal driving behavior at the city-scale in a centralized fashion results in considerable network and computation load, that would significantly restrict the scalability of the system. In this paper, we propose CAD3, a distributed collaborative system for road-aware and driver-aware anomaly driving detection. CAD3 considers a decentralized deployment of edge computation nodes on the roadside and combines collaborative and context-aware computation with low-latency communication to detect and inform nearby drivers of unsafe behaviors of other vehicles in real-time. Adjacent edge nodes collaborate to improve the detection of abnormal driving behavior at?\u2026", "IdName": "alhilal2021cad3", "Citation": "", "Keywords": ""}, {"Name": "Enemy at the Gate: Evolution of Twitter User's Polarization During National Crisis", "Authors": ["Ehsan ul Haq", "Tristan Braud", "Young D Kwon", "Pan Hui"], "Sources": "2020 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Social networks are effective platforms to study the real-life behavior of users. In this paper, we study users' political polarization during the times of crisis and its relation to nationalism. To this purpose, we focus on the reaction of Indian and Pakistani Twitter users during February 2019 crisis and the ensuing Indian General Elections in 2019. We show that a national crisis affects the polarization and discourse in both countries. Also, we show that user activities increase during a national crisis, and political discourse strengthens while polarization decreases on critical days. Finally, we highlight the links between this crisis and the Indian elections and show how the political parties discussed the crisis in their campaigns.", "IdName": "ul2020enemy", "Citation": "", "Keywords": ""}, {"Name": "Force9: Force-assisted miniature keyboard on smart wearables", "Authors": ["Lik Hang Lee", "Ngo Yan Yeung", "Tristan Braud", "Tong Li", "Xiang Su", "Pan Hui"], "Sources": "Proceedings of the 2020 International Conference on Multimodal Interaction?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Smartwatches and other wearables are characterized by small-scale touchscreens that complicate the interaction with content. In this paper, we present Force9, the first optimized miniature keyboard leveraging force-sensitive touchscreens on wrist-worn computers. Force9 enables character selection in an ambiguous layout by analyzing the trade-off between interaction space and the easiness of force-assisted interaction. We argue that dividing the screen's pressure range into three contiguous force levels is sufficient to differentiate characters for fast and accurate text input. Our pilot study captures and calibrates the ability of users to perform force-assisted touches on miniature-sized keys on touchscreen devices. We then optimize the keyboard layout considering the goodness of character pairs (with regards to the selected English corpus) under the force-based configuration and the users? familiarity with the?\u2026", "IdName": "lee2020force9", "Citation": "", "Keywords": ""}, {"Name": "Attention-based QoE-aware digital twin empowered edge computing for immersive virtual reality", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Tailin Zhou", "Pan Hui", "Danny HK Tsang"], "Sources": "IEEE Transactions on Wireless Communications", "PublishedYears": "2024", "Doi": "", "Abstracts": "Metaverse applications such as virtual reality (VR) content streaming, require optimal resource allocation strategies for mobile edge computing (MEC) to ensure a high-quality user experience. In contrast to online reinforcement learning (RL) algorithms, which can incur substantial communication overheads and longer delays, the majority of existing works employ offline-trained RL algorithms for resource allocation decisions in MEC systems. However, they neglect the impact of desynchronization between the physical and digital worlds on the effectiveness of the allocation strategy. In this paper, we tackle this desynchronization using a continual RL (CRL) framework that facilitates the resource allocation dynamically for MEC-enabled VR content streaming. We first design a digital twin-empowered edge computing (DTEC) system and formulate a quality of experience (QoE) maximization problem based on attention?\u2026", "IdName": "yu2024attention", "Citation": "", "Keywords": ""}, {"Name": "Quantum bandit with amplitude amplification exploration in an adversarial environment", "Authors": ["Byungjin Cho", "Yu Xiao", "Pan Hui", "Daoyi Dong"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "The rapid proliferation of learning systems in an arbitrarily changing environment mandates the need to manage tensions between exploration and exploitation. This work proposes a quantum-inspired bandit learning approach for the learning-and-adapting-based offloading problem where a client observes and learns the costs of each task offloaded to the candidate resource providers, e.g., fog nodes. In this approach, a new action update strategy and novel probabilistic action selection are adopted, provoked by the amplitude amplification and collapse postulate in quantum computation theory. We devise a locally linear mapping between a quantum-mechanical phase in a quantum domain, e.g., Grover-type search algorithm, and a distilled probability-magnitude in a value-based decision-making domain, e.g., adversarial multi-armed bandit algorithm. The proposed algorithm is generalized, via the devised?\u2026", "IdName": "cho2023quantum", "Citation": "", "Keywords": ""}, {"Name": "Can underprivileged children learn effectively at home? A six-month study of game-based traditional Chinese learning during the pandemic lockdown", "Authors": ["Ka-Yan Fung", "Lik-Hang Lee", "Pan Hui", "Shenghui Song"], "Sources": "IEEE Transactions on Learning Technologies", "PublishedYears": "2023", "Doi": "", "Abstracts": "The COVID-19 pandemic has suspended physical classes and influenced students from underprivileged groups more seriously due to their poor living conditions and digital disadvantages. To understand the impact of the constrained learning, we conducted a study on game-based learning to examine the effectiveness of computer-aided and autonomous learning of traditional Chinese by underprivileged students. From December 2020 to May 2021, we collected 3245 quiz results from 26 underprivileged students over six months. The quizzes systematically covered the fundamentals of learning traditional Chinese in six aspects, i.e., literacy, orthography, phonology, morphology, speaking, and writing. We analyzed the results to understand the learning efficacy of students. Remarkably, students can significantly improve their skills in literacy and phonology through unsupervised game-based learning. Furthermore?\u2026", "IdName": "fung2023can", "Citation": "", "Keywords": ""}, {"Name": "It's All Relative! A Method to Counter Human Bias in Crowdsourced Stance Detection of News Articles", "Authors": ["Ehsan-Ul Haq", "Yang K Lu", "Pan Hui"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2022", "Doi": "", "Abstracts": "Using human intelligence to identify news articles' political stances is common in research and practical applications. But human judgement can be biased and prone to errors stemming from the comprehension of tasks and political alignment. This paper proposes a relative rating method based on news articles' stances relative to raters' own stances to avoid comprehension inconsistency and to control for human bias in crowdsourced stance detection of news articles. We also show how to use the relative ratings to construct a measure for raters' stances on a political topic and to identify raters whose ratings are of higher quality than others. We implement our proposed methods in an online experiment that recruits Amazon Mechanical Turk users as raters for news articles on Gun Control. Using the data from the experiment, we find evidence that raters' own stances on Gun Control significantly impact ratings of?\u2026", "IdName": "haq2022s", "Citation": "", "Keywords": ""}, {"Name": "Tips, tidings, and tech: Governmental communication on facebook during the covid-19 pandemic", "Authors": ["Ehsan-Ul Haq", "Tristan Braud", "Lik Hang Lee", "Reza Hadi Mogavi", "He Zhang", "Pan Hui"], "Sources": "DG. O 2022: The 23rd Annual International Conference on Digital Government?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " The COVID-19 pandemic led governments to rely on the versatility of social media to communicate with their citizens. This paper analyzes the Facebook communication of political leaders and health departments from 17 countries during the COVID-19 pandemic. We evaluate the citizen\u2019s response under the frameworks of media richness and user engagement. We note that governments and leaders communicate primarily through richer media (photos and videos), despite a negative correlation between media richness and user engagement. Plain-text messages posted by country leaders attract the most engagement, while their COVID-19 communication tends to generate lower engagement. On the other hand, health departments\u2019 pages experienced a sharp increase in engagement around COVID-19 communication as citizens sought information during the pandemic. Finally, topical analysis shows that?\u2026", "IdName": "haq2022tips", "Citation": "", "Keywords": ""}, {"Name": "MyoKey: Inertial motion sensing and gesture-based QWERTY keyboard for extended realities", "Authors": ["Kirill A Shatilov", "Young D Kwon", "Lik-Hang Lee", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Usability challenges and social acceptance of textual input in a context of extended realities (XR) motivate the research of novel input modalities. We investigate the fusion of inertial measurement unit (IMU) control and surface electromyography (sEMG) gesture recognition applied to text entry using a QWERTY-layout virtual keyboard. We design, implement, and evaluate the proposed multi-modal solution named MyoKey. The user can select characters with a combination of arm movements and hand gestures. MyoKey employs a lightweight convolutional neural network classifier that can be deployed on a mobile device with insignificant inference time. We demonstrate the practicality of interruption-free text entry with MyoKey, by recruiting 12 participants and by testing three sets of grasp micro-gestures in three scenarios: empty hand text input, tripod grasp (e.g., pen), and a cylindrical grasp (e.g., umbrella). With?\u2026", "IdName": "shatilov2022myokey", "Citation": "", "Keywords": ""}, {"Name": "Adaptive spatio-temporal convolutional network for traffic prediction", "Authors": ["Mingyang Zhang", "Yong Li", "Funing Sun", "Diansheng Guo", "Pan Hui"], "Sources": "2021 IEEE International Conference on Data Mining (ICDM)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Traffic prediction is a crucial task in many real-world applications. The task is challenging due to the implicit and dynamic spatio-temporal dependencies among traffic data. On the one hand, the spatial dependencies among traffic flows are latent and fluctuate with environmental conditions. On the other hand, the temporal dependencies among traffic flows also vary significantly over time and locations. In this paper, we propose Adaptive Spatio-Temporal Convolutional Network (ASTCN) to tackle these challenges. First, we propose a spatial graph learning module that learns the dynamic spatial relations among traffic data based on multiple influential factors. Furthermore, we design an adaptive temporal convolution module that captures complex temporal traffic dependencies with environment-aware dynamic filters. We conduct extensive experiments on three real-world traffic datasets. The results demonstrate that?\u2026", "IdName": "zhang2021adaptive", "Citation": "", "Keywords": ""}, {"Name": "Context-aware augmented reality with 5G edge", "Authors": ["Jacky Cao", "Xiaoli Liu", "Xiang Su", "Sasu Tarkoma", "Pan Hui"], "Sources": "2021 IEEE Global Communications Conference (GLOBECOM)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Augmented Reality (AR) provides immersive user experiences by overlaying digital information on physical environments. Context-awareness is crucial for delivering relevant augmentations that best suit users' requirements and their en-vironments. In this article, we combine context-aware reasoning with emerging AR applications to provide the most relevant infor-mation according to user and environment contexts. To support the best possible quality of experience, 5G edge computing enables the distribution of computation-intensive AR tasks to edge servers through 5G networks. We develop ConAR, a context-aware head-mounted display AR system that is deployed on the edge and cloud leveraging both environmental sensors and user profile context for navigation. ConAR is composed of a HoloLens application and a paired mobile client, which contains a context model for air quality forecasting, and?\u2026", "IdName": "cao2021context", "Citation": "", "Keywords": ""}, {"Name": "Finding spatiotemporal patterns of mobile application usage", "Authors": ["Tong Li", "Yong Li", "Tong Xia", "Pan Hui"], "Sources": "IEEE Transactions on Network Science and Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Understanding mobile application usage patterns is significant for producing better services and enriching user experience. The understanding of spatiotemporal patterns of application usage is still limited. In this paper, we aim at finding spatiotemporal mobile app usage patterns and propose a framework to capture who, when, where, and what applications are used. We first collect a large-scale and real-world application usage dataset covering over 400 thousand active users and 600 million records. In order to introduce spatial features, we partition the collection area into small regions. By grouping regions of similar point-of-interest attributes, we then map 796 regions onto 13 region clusters with semantic meanings. As a result, the original data is reformed as a tensor of four dimensions, i.e., users, application categories, region clusters, and time-slots. We then leverage a multi-way clustering algorithm on the?\u2026", "IdName": "li2021finding", "Citation": "", "Keywords": ""}, {"Name": "Press-n-paste: Copy-and-paste operations with pressure-sensitive caret navigation for miniaturized surface in mobile augmented reality", "Authors": ["Lik Hang Lee", "Yiming Zhu", "Yui-Pan Yau", "Pan Hui", "Susanna Pirttikangas"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2021", "Doi": "", "Abstracts": "Copy-and-paste operations are the most popular features on computing devices such as desktop computers, smartphones and tablets. However, the copy-and-paste operations are not sufficiently addressed on the Augmented Reality (AR) smartglasses designated for real-time interaction with texts in physical environments. This paper proposes two system solutions, namely Granularity Scrolling (GS) and Two Ends (TE), for the copy-and-paste operations on AR smartglasses. By leveraging a thumb-size button on a touch-sensitive and pressure-sensitive surface, both the multi-step solutions can capture the target texts through indirect manipulation and subsequently enables the copy-and-paste operations. Based on the system solutions, we implemented an experimental prototype named Press-n-Paste (PnP). After the eight-session evaluation capturing 1,296 copy-and-paste operations, 18 participants with GS and?\u2026", "IdName": "lee2021press", "Citation": "", "Keywords": ""}, {"Name": "Augmented informative cooperative perception", "Authors": ["Pengyuan Zhou", "Pranvera Korto?i", "Yui-Pan Yau", "Tristan Braud", "Xiujun Wang", "Benjamin Finley", "Lik-Hang Lee", "Sasu Tarkoma", "Jussi Kangasharju", "Pan Hui"], "Sources": "ICDCS\u201921", "PublishedYears": "2021", "Doi": "", "Abstracts": "Connected vehicles, whether equipped with advanced driver-assistance systems or fully autonomous, are currently constrained to visual information in their lines-of-sight. A cooperative perception system among vehicles increases their situational awareness by extending their perception ranges. Existing solutions imply significant network and computation load, as well as high flow of not-always-relevant data received by vehicles. To address such issues, and thus account for the inherently diverse informativeness of the data, we present Augmented Informative Cooperative Perception (AICP) as the first fast-filtering system which optimizes the informativeness of shared data at vehicles. AICP displays the filtered data to the drivers in augmented reality head-up display.To this end, an informativeness maximization problem is presented for vehicles to select a subset of data to display to their drivers. Specifically, we propose (i) a dedicated system design with custom data structure and light-weight routing protocol for convenient data encapsulation, fast interpretation and transmission, and (ii) a comprehensive problem formulation and efficient fitness-based sorting algorithm to select the most valuable data to display at the application layer. We implement a proof-of-concept prototype of AICP with a bandwidth-hungry, latency-constrained real-life augmented reality application. The prototype realizes the informative-optimized cooperative perception with only 12.6 milliseconds additional latency. Next, we test the networking performance of AICP at scale and show that AICP effectively filter out less relevant packets and decreases the channel busy time.", "IdName": "zhou2021augmented", "Citation": "", "Keywords": ""}, {"Name": "Context-driven encrypted multimedia traffic classification on mobile devices", "Authors": ["Mohammad A Hoque", "Benjamin Finley", "Ashwin Rao", "Abhishek Kumar", "Pan Hui", "Mostafa Ammar", "Sasu Tarkoma"], "Sources": "Pervasive and Mobile Computing 88", "PublishedYears": "2023", "Doi": "", "Abstracts": "The Internet has been experiencing immense growth in multimedia traffic from mobile devices. The increase in traffic presents many challenges to user-centric networks, network operators, and service providers. Foremost among these challenges is the inability of networks to determine the types of encrypted traffic and thus the level of network service the traffic needs to maintain an acceptable quality of experience. Therefore, end devices are a natural fit for performing traffic classification since end devices have more contextual information about device usage and traffic. This paper proposes a novel approach that classifies multimedia traffic types produced and consumed on mobile devices. The technique relies on a mobile device\u2019s detection of its multimedia context characterized by its utilization of different media input/output (I/O) components, e.g., camera, microphone, and speaker. We develop an algorithm?\u2026", "IdName": "hoque2023context", "Citation": "", "Keywords": ""}, {"Name": "Federated Split GANs", "Authors": ["Pranvera Korto?i", "Yilei Liang", "Pengyuan Zhou", "Lik-Hang Lee", "Abbas Mehrabi", "Pan Hui", "Sasu Tarkoma", "Jon Crowcroft"], "Sources": "Proceedings of the 1st ACM Workshop on Data Privacy and Federated Learning?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "Mobile devices and the immense amount and variety of data they generate are key enablers of machine learning (ML)-based applications. Traditional ML techniques have shifted toward new paradigms such as federated learning (FL) and split learning (SL) to improve the protection of user's data privacy. However, SL often relies on server(s) located in the edge or cloud to train computationally-heavy parts of an ML model to avoid draining the limited resource on client devices, potentially resulting in exposure of device data to such third parties. This work proposes an alternative approach to train computationally heavy ML models in user's devices themselves, where corresponding device data resides. Specifically, we focus on GANs (generative adversarial networks) and leverage their network architecture to preserve data privacy. We train the discriminative part of a GAN on user's devices with their data, whereas?\u2026", "IdName": "kortocci2022federated", "Citation": "", "Keywords": ""}, {"Name": "Meditation in Motion: Interactive Media Art Visualization Based on Ancient Tai Chi Chuan", "Authors": ["Ze Gao", "Anqi Wang", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the 30th ACM International Conference on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Tai Chi is an essential concept of Chinese philosophy which refers to the universe's most primitive state of order. Tai Chi Chuan is a martial art and meditative practice that incorporates the Tai Chi philosophy. With the advent of the digital media age, this traditional martial art is falling into disuse, and most contemporary youths are losing interest. \"Meditation in Motion\" is an interactive media art installation inspired by the Tai Chi Chuan forms. It aims to convey the central concepts of balance, narrative, and universe of Tai Chi Chuan by breaking down its movements into overlapping circles, building a visual representation of the energy flows in the body.", "IdName": "gao2022meditation", "Citation": "", "Keywords": ""}, {"Name": "Collaboration stability: Quantifying the success and failure of opportunistic collaboration", "Authors": ["Huber Flores", "Agustin Zuniga", "Sasu Tarkoma", "Leonardo Tonetto", "Tristan Braud", "Pan Hui", "Yong Li", "Mostafa Ammar", "Petteri Nurmi"], "Sources": "Computer", "PublishedYears": "2022", "Doi": "", "Abstracts": "We quantify and derive a general model for the collaboration stability of human mobility and demonstrate its importance for networking applications. Our results demonstrate that collaboration opportunities are highly dependent on the context where they take place, with diurnal patterns and spatial characteristics being particularly important.", "IdName": "flores2022collaboration", "Citation": "", "Keywords": ""}, {"Name": "3DeformR: freehand 3D model editing in virtual environments considering head movements on mobile headsets", "Authors": ["Kit Yung Lam", "Lik-Hang Lee", "Pan Hui"], "Sources": "Proceedings of the 13th ACM Multimedia Systems Conference", "PublishedYears": "2022", "Doi": "", "Abstracts": "3D objects are the primary media in virtual reality environments in immersive cyberspace, also known as the Metaverse. Users, through editing such objects, can communicate with other individuals on mobile headsets. Knowing that the tangible controllers cause the burden to carry such addendum devices, the body-centric interaction techniques, such as hand gestures, get rid of such burdens. However, object editing with hand gestures is usually overlooked. Accordingly, we propose and implement a palm-based virtual embodiment for hand gestural model editing, namely 3DeformR. We employ three optimized hand gestures on bi-harmonic deformation algorithms that enable selecting and editing 3D models in fine granularity. Our evaluation with nine participants considers three interaction techniques (two-handed tangible controller (OMC), a naive implementation of hand gestures (SH), and 3DeformR. Two?\u2026", "IdName": "lam20223deformr", "Citation": "", "Keywords": ""}, {"Name": "EmgAuth: Unlocking smartphones with EMG signals", "Authors": ["Boyu Fan", "Xiang Su", "Jianwei Niu", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Screen lock is a critical security feature for smartphones to prevent unauthorized access. Although various screen unlocking technologies, including fingerprint and facial recognition, have been widely adopted, they still have some limitations. For example, fingerprints can be stolen by special material stickers and facial recognition systems can be cheated by 3D-printed head models. In this paper, we propose EmgAuth, a novel electromyography(EMG)-based smartphone unlocking system based on the Siamese network. EmgAuth enables users to unlock their smartphones by leveraging the EMG data of the smartphone users collected from Myo armbands. When training the Siamese network, we design a special data augmentation technique to make the system resilient to the rotation of the armband, which makes EmgAuth free of calibration. We conduct extensive experiments including 80 participants and the?\u2026", "IdName": "fan2022emgauth", "Citation": "", "Keywords": ""}, {"Name": "Toward city-scale litter monitoring using autonomous ground vehicles", "Authors": ["Zhigang Yin", "Mayowa Olapade", "Mohan Liyanage", "Farooq Dar", "Agustin Zuniga", "Naser Hossein Motlagh", "Xiang Su", "Sasu Tarkoma", "Pan Hui", "Petteri Nurmi", "Huber Flores"], "Sources": "IEEE Pervasive Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Littering is a significant challenge for environmental sustainability and a major burden for cities and densely populated areas. Current solutions for litter monitoring, such as litter watch campaigns and city-operated litter collection, are costly and challenging to conduct at a large scale. This article presents a vision for using autonomous ground vehicles (AGVs) for litter monitoring and removal and introduces a mechanism for AGVs that uses thermal dissipation resulting from sunlight to identify and remove litter objects. We identify and highlight key challenges for deploying the envisioned solution on a city scale, and demonstrate the feasibility of the solution through extensive experiments.", "IdName": "yin2022toward", "Citation": "", "Keywords": ""}, {"Name": "Interpretable business survival prediction", "Authors": ["Anish K Vallapuram", "Nikhil Nanda", "Young D Kwon", "Pan Hui"], "Sources": "Proceedings of the 2021 IEEE/ACM International Conference on Advances in?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "The survival of a business is undeniably pertinent to its success. A key factor contributing to its continuity depends on its customers. The surge of location-based social networks such as Yelp, Diangping, and Foursquare has paved the way for leveraging user-generated content on these platforms to predict business survival. Prior works in this area have developed several quantitative features to capture geography and user mobility among businesses. However, the development of qualitative features is minimal. In this work, we thus perform extensive feature engineering across four feature sets, namely, geography, user mobility, business attributes, and linguistic modelling to develop classifiers for business survival prediction. We additionally employ an interpretability framework to generate explanations and qualitatively assess the classifiers' predictions. Experimentation among the feature sets reveals that?\u2026", "IdName": "vallapuram2021interpretable", "Citation": "", "Keywords": ""}, {"Name": "Toward Mobile Distributed Ledgers", "Authors": ["Dimitris Chatzopoulos", "Anurag Jain", "Sujit Gujar", "Boi Faltings", "Pan Hui"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2021", "Doi": "", "Abstracts": "Advances in mobile computing have paved the way for new types of distributed applications that can be executed solely by mobile devices on Device-to-Device (D2D) ecosystems (e.g., crowdsensing). Sophisticated applications, like cryptocurrencies, need distributed ledgers (DLs) to function. DLs, such as blockchains and directed acyclic graphs (DAGs), employ consensus protocols to add data in the form of blocks. However, such protocols are designed for resourceful devices that are interconnected via the Internet. Moreover, existing DLs are not deployable to D2D ecosystems since their storage needs are continuously increasing. In this work, we introduce and analyze Mneme, a DAG-based DL that can be maintained solely by mobile devices. Mneme utilizes two novel consensus protocols: 1) Proof of Context (PoC) and 2) Proof of Equivalence (PoE). PoC employs users\u2019 context to add data on Mneme. PoE is?\u2026", "IdName": "chatzopoulos2021toward", "Citation": "", "Keywords": ""}, {"Name": "Interoperability of the Metaverse: A Digital Ecosystem Perspective Review", "Authors": ["Liang Yang", "Shi-Ting Ni", "Yuyang Wang", "Ao Yu", "Jyh-An Lee", "Pan Hui"], "Sources": "arXiv preprint arXiv:2403.05205", "PublishedYears": "2024", "Doi": "", "Abstracts": "The Metaverse is at the vanguard of the impending digital revolution, with the potential to significantly transform industries and lifestyles. However, in 2023, skepticism surfaced within industrial and academic spheres, raising concerns that excitement may outpace actual technological progress. Interoperability, recognized as a major barrier to the Metaverse's full potential, is central to this debate. CoinMarketCap's report in February 2023 indicated that of over 240 metaverse initiatives, most existed in isolation, underscoring the interoperability challenge. Despite consensus on its critical role, there is a research gap in exploring the impact on the Metaverse, significance, and developmental extent. Our study bridges this gap via a systematic literature review and content analysis of the Web of Science (WoS) and Scopus databases, yielding 74 publications after a rigorous selection process. Interoperability, difficult to define due to varied contexts and lack of standardization, is central to the Metaverse, often seen as a digital ecosystem. Urs Gasser's framework from Harvard Law School, outlining technological, data, human, and institutional dimensions, systematically addresses interoperability complexities. Incorporating this framework, we dissect literature for a comprehensive Metaverse interoperability overview. Our study seeks to establish benchmarks for future inquiries, navigating the complex field of Metaverse interoperability studies and contributing to academic advancement.", "IdName": "yang2024interoperability", "Citation": "", "Keywords": ""}, {"Name": "Learning representations of satellite imagery by leveraging point-of-interests", "Authors": ["Tong Li", "Yanxin Xi", "Huandong Wang", "Yong Li", "Sasu Tarkoma", "Pan Hui"], "Sources": "ACM Transactions on Intelligent Systems and Technology", "PublishedYears": "2023", "Doi": "", "Abstracts": "Satellite imagery depicts the Earth\u2019s surface remotely and provides comprehensive information for many applications, such as land use monitoring and urban planning. Existing studies on unsupervised representation learning for satellite images only take into account the images\u2019 geographic information, ignoring human activity factors. To bridge this gap, we propose using the Point-of-Interest (POI) data to capture human factors and designing a contrastive learning-based framework to consolidate the representation of satellite imagery with POI information. Besides, we introduce a season-invariant representation learning model on satellite imagery, considering that human factors are mostly unchanging with respect to seasons. An attention model is designed at last to merge the representations from the geographic, seasonal, and POI perspectives adaptively. On the basis of real-world datasets collected from Beijing?\u2026", "IdName": "li2023learning", "Citation": "", "Keywords": ""}, {"Name": "Towards Trustworthy Augmented Reality in The Metaverse Era: Probing Manipulative Designs in Virtual-Physical Commercial Platforms", "Authors": ["Esm\u00e9e De Haas", "Huang Yiming", "Carlos Bermejo", "Zijun Lin", "Pan Hui", "Lik-Hang Lee"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "E-commerce has become an important activity where new advances in technology shape the shopper experience. At the same time, the metaverse is seen as the next milestone to revolutionize the e-commerce experience, where immersion, realism, and ubiquity are its main features. However, under such circumstances, manipulative designs to \u2018trick\u2019 users toward intended choices or outcomes can become more effective. This paper sheds light on the design space of manipulative techniques in e-commerce applications for the meta-verse, reinforcing our understanding of interface design guidelines and counteracting malicious practices.", "IdName": "de2023towards", "Citation": "", "Keywords": ""}, {"Name": "Bridging curatorial intent and visiting experience: Using ar guidance as a storytelling tool", "Authors": ["Ze Gao", "Anqi Wang", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Augmented Reality (AR) visits enhances the art exhibition experience by overlaying digital content. Although there has been significant interest in AR guides, few works leverage AR to bridge curatorial intent and audiences understanding. This paper focuses on integrating the curatorial intent within the AR overlays by developing the narrative layers established by the relationships between works. We develop a narrative system that identifies and links the primary art pieces of the exhibition within a digital story consistent with the curator\u2019s perspective. The system is applied to a physical exhibition composed of seven art pieces. We evaluate the impact of AR overlays through two user experiments, conducted on art professionals and general audience, respectively. Both groups considered that the AR tour system improved interactivity, self-reported learning, and user satisfaction significantly (> 4/5). Besides, visitors?\u2026", "IdName": "gao2022bridging", "Citation": "", "Keywords": ""}, {"Name": "Beyond the Blue Sky of Multimodal Interaction: A Centennial Vision of Interplanetary Virtual Spaces in Turn-based Metaverse", "Authors": ["Lik-Hang Lee", "Carlos Bermejo Fernandez", "Ahmad Alhilal", "Tristan Braud", "Simo Hosio", "Esm\u00e9e Henrieke Anne De Haas", "Pan Hui"], "Sources": "Proceedings of the 2022 International Conference on Multimodal Interaction?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": " Human habitation across multiple planets requires communication and social connection between planets. When the infrastructure of a deep space network becomes mature, immersive cyberspace, known as the Metaverse, can exchange diversified user data and host multitudinous virtual worlds. Nevertheless, such immersive cyberspace unavoidably encounters latency in minutes, and thus operates in a turn-taking manner. This Blue Sky paper illustrates a vision of an interplanetary Metaverse that connects Earthian and Martian users in a turn-based Metaverse. Accordingly, we briefly discuss several grand challenges to catalyze research initiatives for the \u2018Digital Big Bang\u2019 on Mars.", "IdName": "lee2022beyond", "Citation": "", "Keywords": ""}, {"Name": "Free  Net: Gliding Free, Orientation Free, and Anchor Free Network for Oriented Object Detection", "Authors": ["Zhonghong Ou", "Zhongjie Chen", "Shengyi Shen", "Lina Fan", "Siyuan Yao", "Meina Song", "Pan Hui"], "Sources": "IEEE Transactions on Multimedia", "PublishedYears": "2022", "Doi": "", "Abstracts": "Object detection for aerial images has achieved remarkable progress in recent years. Nevertheless, most exiting studies do not differentiate oriented object detection from horizontal detection. Certain schemes ignore the ambiguity of oriented object representation and leverage label assignment designed for horizontal object detection directly. Consequently, it leads to unstable training and causes performance degradation, because high-quality samples surrounding the oriented bounding boxes can not be leveraged effectively. To address this problem, we propose a gliding Free, orientation Free, and anchor Free Network (Free  Net) with high-efficiency for oriented object detection. Specifically, we propose an unambiguous oriented object representation scheme, named FreeGliding, by gliding the projection points of samples on each edge of horizontal bounding boxes. It makes the detection largely free from?\u2026", "IdName": "ou2022free", "Citation": "", "Keywords": ""}, {"Name": "An LTE Authentication and Key Agreement Protocol Based on the ECC Self-Certified Public Key", "Authors": ["Xiaofeng Lu", "Fan Yang", "Luwen Zou", "Pietro Lio", "Pan Hui"], "Sources": "IEEE/ACM Transactions on Networking", "PublishedYears": "2022", "Doi": "", "Abstracts": "After analyzing the long-term evolution (LTE) authentication and key agreement process (EPS-AKA), its existing security vulnerabilities are pointed out. Based on elliptic curve cryptography (ECC) self-certified public keys, this paper proposes an ECC self-certified authentication key agreement scheme (ESC-AKA). This scheme includes the addition of a trusted center (TC), which generates the public keys for the home subscriber server (HSS), the mobility management entity (MME), and the user equipment (UE). Three communication protocols are designed, including MME/HSS registration, UE registration, and UE access. A strand space model is used to carry out the formal analysis, and performance and security analyses are carried out. The results show that this scheme can compensate for the security vulnerabilities of the original EPS-AKA scheme. It implements the encrypted transmission of the international?\u2026", "IdName": "lu2022lte", "Citation": "", "Keywords": ""}, {"Name": "Video content placement at the network edge: Centralized and distributed algorithms", "Authors": ["Yanan Gao", "Song Yang", "Fan Li", "Stojan Trajanovski", "Pan Zhou", "Pan Hui", "Xiaoming Fu"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "In the traditional video streaming service paradigm, content providers typically provision the requested video content to viewers through a central content delivery network (CDN). However, remote viewers usually experience long video streaming delay due to uncertain wide area network delay, which severely affects the quality of experience. Multi-Access Edge Computing (MEC) offers a way to shorten the video streaming delay by building small-scale cloud infrastructures at the network edge, which are in close proximity to the viewers. In this paper, we present novel centralized and distributed algorithms for the video content placement problem in MEC. In the proposed centralized video content placement algorithm, we leverage the Lyapunov optimization technique to formulate the video content placement problem as a series of one-time-slot optimization problems and apply an Alternating Direction Method of?\u2026", "IdName": "gao2022video", "Citation": "", "Keywords": ""}, {"Name": "Ian: Interpretable attention network for churn prediction in lbsns", "Authors": ["Liang-yu Chen", "Yutong Chen", "Young D Kwon", "Youwen Kang", "Pan Hui"], "Sources": "Proceedings of the 2021 IEEE/ACM International Conference on Advances in?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "With the rise of Location-Based Social Networks (LBSNs) and their heavy reliance on User-Generated Content, it has become essential to attract and keep more users, which makes the churn prediction problem interesting. Recent research focuses on solving the task by utilizing complex neural networks. However, due to the black-box nature of those proposed deep learning algorithms, it is still a challenge for LBSN managers to interpret the prediction results and design strategies to prevent churning behavior. Therefore, in this paper, we perform the first investigation into the interpretability of the churn prediction in LBSNs. We proposed a novel attention-based deep learning network, Interpretable Attention Network (IAN), to achieve high performance while ensuring interpretability. The network is capable to process the complex temporal multivariate multidimensional user data from LBSN datasets (i.e. Yelp and?\u2026", "IdName": "chen2021ian", "Citation": "", "Keywords": ""}, {"Name": "Identifying mis-configured author profiles on Google Scholar using deep learning", "Authors": ["Jiaxin Tang", "Yang Chen", "Guozhen She", "Yang Xu", "Kewei Sha", "Xin Wang", "Yi Wang", "Zhenhua Zhang", "Pan Hui"], "Sources": "Applied Sciences", "PublishedYears": "2021", "Doi": "", "Abstracts": "Google Scholar has been a widely used platform for academic performance evaluation and citation analysis. The issue about the mis-configuration of author profiles may seriously damage the reliability of the data, and thus affect the accuracy of analysis. Therefore, it is important to detect the mis-configured author profiles. Dealing with this issue is challenging because the scale of the dataset is large and manual annotation is time-consuming and relatively subjective. In this paper, we first collect a dataset of Google Scholar\u2019s author profiles in the field of computer science and compare the mis-configured author profiles with the reliable ones. Then, we propose an integrated model that utilizes machine learning and node embedding to automatically detect mis-configured author profiles. Additionally, we conduct two application case studies based on the data of Google Scholar, i.e., outstanding scholar searching and university ranking, to demonstrate how the improved dataset after filtering out the mis-configured author profiles will change the results. The two case studies validate the importance and meaningfulness of the detection of mis-configured author profiles.", "IdName": "tang2021identifying", "Citation": "", "Keywords": ""}, {"Name": "Decentralizing indexing and bootstrapping for online applications", "Authors": ["Pierre Schutz", "Stanislas Gal", "Dimitris Chatzopoulos", "Pan Hui"], "Sources": "IET Blockchain", "PublishedYears": "2021", "Doi": "", "Abstracts": " Peer\u2010to\u2010peer (P2P) networks utilize centralized entities (trackers) to assist peers in finding and exchanging information. Although modern P2P protocols are now trackerless and their function relies on distributed hash tables (DHTs), centralized entities are still needed to build file indices (indexing) and assist users in joining DHT swarms (bootstrapping). Although the functionality of these centralized entities are limited, every peer in the network is expected to trust them to function as expected (e.g. to correctly index new files). In this work, a new approach for designing and building decentralized online applications is proposed by introducing DIBDApp. The approach combines blockchain, smart contracts and BitTorrent for building up a combined technology that permits to create decentralized applications that do not require any assistance from centralized entities. DIBDApp is a software library composed of?\u2026", "IdName": "schutz2021decentralizing", "Citation": "", "Keywords": ""}, {"Name": "Context-aware telco outdoor localization", "Authors": ["Yige Zhang", "Weixiong Rao", "Mingxuan Yuan", "Jia Zeng", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent years have witnessed the fast growth in telecommunication (Telco) techniques from 2G to upcoming 5G. Precise outdoor localization is important for Telco operators to manage, operate and optimize Telco networks. Differing from GPS, Telco localization is a technique employed by Telco operators to localize outdoor mobile devices by using measurement report (MR) data. When given MR samples containing noisy signals (e.g., caused by Telco signal interference and attenuation), Telco localization often suffers from high errors. To this end, the main focus of this paper is how to improve Telco localization accuracy via the algorithms to detect and repair outlier positions with high errors. Specifically, we propose a context-aware Telco localization technique, namely   , which consists of three main components: a machine-learning-based localization algorithm, a detection algorithm to find flawed samples, and a?\u2026", "IdName": "zhang2020context", "Citation": "", "Keywords": ""}, {"Name": "Sensing multimedia contexts on mobile devices", "Authors": ["Mohammad A Hoque", "Ashwin Rao", "Abhishek Kumar", "Mostafa Ammar", "Pan Hui", "Sasu Tarkoma"], "Sources": "Proceedings of the 30th ACM Workshop on Network and Operating Systems?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "We use various multimedia applications on smart devices to consume multimedia content, to communicate with our peers, and to broadcast our events live. This paper investigates the utilization of different media input/output devices, e.g., camera, microphone, and speaker, by different types of multimedia applications, and introduces the notion of multimedia context. Our measurements lead to a sensing algorithm called MediaSense, which senses the states of multiple I/O devices and identifies eleven multimedia contexts of a mobile device in real time. The algorithm distinguishes stored content playback from streaming, live broadcasting from local recording, and conversational multimedia sessions from GSM/VoLTE calls on mobile devices.", "IdName": "hoque2020sensing", "Citation": "", "Keywords": ""}, {"Name": "A satellite imagery dataset for long-term sustainable development in united states cities", "Authors": ["Yanxin Xi", "Yu Liu", "Tong Li", "Jingtao Ding", "Yunke Zhang", "Sasu Tarkoma", "Yong Li", "Pan Hui"], "Sources": "Scientific data", "PublishedYears": "2023", "Doi": "", "Abstracts": "Cities play an important role in achieving sustainable development goals (SDGs) to promote economic growth and meet social needs. Especially satellite imagery is a potential data source for studying sustainable urban development. However, a comprehensive dataset in the United States (U.S.) covering multiple cities, multiple years, multiple scales, and multiple indicators for SDG monitoring is lacking. To support the research on SDGs in U.S. cities, we develop a satellite imagery dataset using deep learning models for five SDGs containing 25 sustainable development indicators. The proposed dataset covers the 100 most populated U.S. cities and corresponding Census Block Groups from 2014 to 2023. Specifically, we collect satellite imagery and identify objects with state-of-the-art object detection and semantic segmentation models to observe cities\u2019 bird\u2019s-eye view. We further gather population, nighttime light?\u2026", "IdName": "xi2023satellite", "Citation": "", "Keywords": ""}, {"Name": "Symbiotic Hands: A virtual reality interactive system that traverses reality", "Authors": ["Ze Gao", "Simin Yang", "Xingxing Yang", "Pan Hui"], "Sources": "Proceedings of EVA London 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "\" Symbiotic Hands\" is a virtual reality interactive installation consisting of 3d reconstructed point cloud images and a temperature sensor fitted to an Oculus Quest2 and designed to emphasize the changes that affect the scene in the virtual environment through the behaviour in reality. The viewer experiences this device as a hand crossing from reality to the virtual, causing the virtual environment to undergo changes generated by temperature changes. It will be realised by this method of traversing virtual and reality in a computer-programmed way, ie, firstly, by sensing the change of outside temperature through temperature sensors, secondly, receiving multisensor data through Arduino and send the data to the computer through a serial port, and finally, the virtual scene in the device that receives the command gradually changes from a silvery winter into a lush summer scene. This project uses interactive technology to explore the real and virtual connection.The virtual reality interactive installation\" Symbiotic Hands\" can be seen as a bridge between virtual and reality through the hand of the audience that can influence the virtual environment. In today's vigorous development of virtual reality technology, many studies are increasingly focused on the physical experience in a virtual environment. However, few studies and creations present and discuss the impact of reality on virtual environments (Bhagavathula et al. 2018). However, as the technology for gestural manipulation matures", "IdName": "gao2023symbiotic", "Citation": "", "Keywords": ""}, {"Name": "Players are not Ready 101: A Tutorial on Organising Mixed-mode Events in the Metaverse", "Authors": ["Kirill Shatilov", "Ahmad Alhilal", "Tristan Braud", "Lik-Hang Lee", "Pengyuan Zhou", "Pan Hui"], "Sources": "Proceedings of the First Workshop on Metaverse Systems and Applications", "PublishedYears": "2023", "Doi": "", "Abstracts": "While the academic community tries to define and experiment with the metaverse, businesses and institutions seek to build their representation in the metaverse. Many educational institutions build meta-campuses and move online classes into virtual environments beyond simple videoconferencing. This paper describes our experience building a university metaverse, highlighting the technical, human, and organisational challenges we have encountered through two major events. Considering the issue of real-time communication and scalability in the web-based metaverse, we also present an analysis of video streaming in virtual reality (VR) platforms: Meta's Workroom, Spatial, and Mozilla Hubs.", "IdName": "shatilov2023players", "Citation": "", "Keywords": ""}, {"Name": "A human mobility dataset collected via LBSLab", "Authors": ["Yuwei Zhang", "Qingyuan Gong", "Yang Chen", "Yu Xiao", "Xin Wang", "Pan Hui", "Xiaoming Fu"], "Sources": "Data in Brief 46", "PublishedYears": "2023", "Doi": "", "Abstracts": "Location-Based Services (LBS) have been prosperous owing to technological advancements of smart devices. Analyzing location-based user-generated data is a helpful way to understand human mobility patterns, further fueling applications such as recommender systems and urban computing. This dataset documents user activities of location-based services through LBSLab, a smartphone-based system implemented as a mini-program in the WeChat app. The dataset contains activity data of multiple types including logins, profile viewing, weather checking, and check-ins with location information (latitude and longitude), POI and mood indicated, collected from 467 users over a period of 11 days. We also present some temporal and spatial data analysis and believe the reuse of the data will allow researchers to better understand user behaviors of LBS, human mobility, and also temporal and spatial characteristics?\u2026", "IdName": "zhang2023human", "Citation": "", "Keywords": ""}, {"Name": "Detecting malicious accounts in online developer communities using deep learning", "Authors": ["Qingyuan Gong", "Yushan Liu", "Jiayun Zhang", "Yang Chen", "Qi Li", "Yu Xiao", "Xin Wang", "Pan Hui"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Online developer communities like GitHub allow a massive number of developers to collaborate. However, the openness of the communities makes them vulnerable to different types of malicious attacks, since attackers can easily join these communities and interact with legitimate users. In this work, we propose GitSec, a deep learning-based solution for detecting malicious accounts in online developer communities. GitSec distinguishes malicious accounts from legitimate ones based on the account profiles, dynamic activity characteristics, as well as social interactions. First, GitSec introduces two user activity sequences and applies a parallel neural network design with an attention mechanism to process the sequences. Second, GitSec constructs two graphs to represent the interactions between users according to their repository operations. Especially, graph neural networks and structural hole theory are?\u2026", "IdName": "gong2023detecting", "Citation": "", "Keywords": ""}, {"Name": "Causal Analysis on the Anchor Store Effect in a Location-based Social Network", "Authors": ["Anish K Vallapuram", "Young D Kwon", "Lik-Hang Lee", "Fengli Xu", "Pan Hui"], "Sources": "2022 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "A particular phenomenon of interest in Retail Eco-nomics is the spillover effect of anchor stores (specific stores with a reputable brand) to non-anchor stores in terms of customer traffic. Prior works in this area rely on small and survey-based datasets that are often confidential or expensive to collect on a large scale. Also, very few works study the underlying causal mechanisms between factors that underpin the spillover effect. In this work, we analyze the causal relationship between anchor stores and customer traffic to non-anchor stores and employ a propensity score matching framework to investigate this effect more efficiently. First of all, to demonstrate the effect, we leverage open and mobile data from London Datastore and Location-Based Social Networks (LBSNs) such as Foursquare. We then perform a large-scale empirical analysis of customer visit patterns from anchor stores to non-anchor stores (e.g., non?\u2026", "IdName": "vallapuram2022causal", "Citation": "", "Keywords": ""}, {"Name": "CityNeuro: Towards Location and Time Prediction for Urban Abnormal Events", "Authors": ["Mingyang Zhang", "Tong Li", "Pan Hui"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2022", "Doi": "", "Abstracts": "Urban abnormal events constitute a significant threat to social order and public safety. It is of vital importance for emergency treatment if the location and time of abnormal events could be predicted before they happen. However, forecasting the occurrence of urban abnormal events is extremely challenging due to various influencing factors. First, the spatiotemporal environment in urban space is associated with complicated and dynamic attributes, which all potentially affect the happening of urban emergency events. Second, historical events also influence the occurrence of future events, and the impacts vary across urban regions and time due to dynamic regional relations. In this paper, we propose a framework called CityNeuro that incorporates both environmental and historical influence for location and time prediction of urban abnormal events. On the one hand, we identify important environmental factors by?\u2026", "IdName": "zhang2022cityneuro", "Citation": "", "Keywords": ""}, {"Name": "Enabling continuous object recognition in mobile augmented reality", "Authors": ["Xiang Su", "Ai Jiang", "Jacky Cao", "Wenxiao Zhang", "Pan Hui", "Juan Ye"], "Sources": "27th International Conference on Intelligent User Interfaces", "PublishedYears": "2022", "Doi": "", "Abstracts": " Mobile Augmented Reality (MAR) applications enable users to interact with physical environments through overlaying digital information on top of camera views. Detecting and classifying complex objects in the real world presents a critical challenge to enable immersive user experiences in MAR applications. Aiming to provide continuous MAR experiences, we address a key challenge of continuous object recognition, which requires accommodating an increasing number of recognition requests on different types of images in MAR systems and possible new types of images in emerging applications. Inspired by the latest advance in continual learning approaches in computer vision, this paper presents a novel MAR system to enhance its scalability with continual learning in realistic scenarios. Our experiments demonstrate that 1) the system enables efficiently recognising objects without requiring retraining from?\u2026", "IdName": "su2022enabling", "Citation": "", "Keywords": ""}, {"Name": "Towards user-centered metrics for trustworthy AI in immersive cyberspace", "Authors": ["Pengyuan Zhou", "Benjamin Finley", "Lik-Hang Lee", "Yong Liao", "Haiyong Xie", "Pan Hui"], "Sources": "arXiv preprint arXiv:2203.03718", "PublishedYears": "2022", "Doi": "", "Abstracts": "AI plays a key role in current cyberspace and future immersive ecosystems that pinpoint user experiences. Thus, the trustworthiness of such AI systems is vital as failures in these systems can cause serious user harm. Although there are related works on exploring trustworthy AI (TAI) metrics in the current cyberspace, ecosystems towards user-centered services, such as the metaverse, are much more complicated in terms of system performance and user experience assessment, thus posing challenges for the applicability of existing approaches. Thus, we give an overlook on fairness, privacy and robustness, across the historical path from existing approaches. Eventually, we propose a research agenda towards systematic yet user-centered TAI in immersive ecosystems.", "IdName": "zhou2022towards", "Citation": "", "Keywords": ""}, {"Name": "DeepPick: a deep learning approach to unveil outstanding users with public attainable features", "Authors": ["Wanda Li", "Zhiwei Xu", "Yi Sun", "Qingyuan Gong", "Yang Chen", "Aaron Yi Ding", "Xin Wang", "Pan Hui"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Outstanding users (OUs) denote the influential, \u201ccore\u201d or \u201cbridge\u201d users in online social networks. How to accurately detect and rank them is an important problem for third-party online service providers and researchers. Conventional efforts, ranging from early graph-based algorithms to recent machine learning-based approaches, typically rely on an entire social network's information. However, for privacy-conscious users or newly-registered users, such information is not easily accessible. To address this issue, we present DeepPick, a novel framework that considers both the generalization and specialization in the detection task of OUs. For generalization, we introduce deep neural networks to capture dynamic features of the users. For specialization, we leverage the traditional descriptive features to make use of public information about users. Extensive experiments based on real-world datasets demonstrate that?\u2026", "IdName": "li2021deeppick", "Citation": "", "Keywords": ""}, {"Name": "DADIM: A distance adjustment dynamic influence map model", "Authors": ["Xiaofeng Lu", "Xiaoming Wang", "Pan Hui"], "Sources": "Future Generation Computer Systems 112", "PublishedYears": "2020", "Doi": "", "Abstracts": "Influence map (IM) is often used as a decision supporting technology in game artificial intelligence (AI). However, the traditional influence map does not describe dynamic information. Some improved IM models can describe dynamic information, but not accurately enough. When an object moves, it would produce large influence in its moving direction than other directions. Therefore, the influence produce by the object to a location depends on the relation between the location and the object\u2019s moving direction. This paper proposed a dynamic influence map model based on distance adjustment, DADIM. This model produces different influence values in different direction by adjusting the \u201cdistance\u201d between two locations. This method can encode dynamic information into the influence map easily. Experiments show this model avoids the weakness of dynamic influence map with location prediction. Compared with?\u2026", "IdName": "lu2020dadim", "Citation": "", "Keywords": ""}, {"Name": "Human data model: Improving programmability of health and well-being data for enhanced perception and interaction", "Authors": ["Niko M?kitalo", "Daniel Flores-Martin", "Huber Flores", "Eemil Lagerspetz", "Francois Christophe", "Petri Ihantola", "Masiar Babazadeh", "Pan Hui", "Juan Manuel Murillo", "Sasu Tarkoma", "Tommi Mikkonen"], "Sources": "ACM Transactions on Computing for Healthcare", "PublishedYears": "2020", "Doi": "", "Abstracts": "Today, an increasing number of systems produce, process, and store personal and intimate data. Such data has plenty of potential for entirely new types of software applications, as well as for improving old applications, particularly in the domain of smart healthcare. However, utilizing this data, especially when it is continuously generated by sensors and other devices, with the current approaches is complex\u2014data is often using proprietary formats and storage, and mixing and matching data of different origin is not easy. Furthermore, many of the systems are such that they should stimulate interactions with humans, which further complicates the systems. In this article, we introduce the Human Data Model\u2014a new tool and a programming model for programmers and end users with scripting skills that help combine data from various sources, perform computations, and develop and schedule computer-human?\u2026", "IdName": "makitalo2020human", "Citation": "", "Keywords": ""}, {"Name": "The bits of silence: Redundant traffic in voip", "Authors": ["Mohammad A Hoque", "Petteri Nurmi", "Matti Siekkinen", "Pan Hui", "Sasu Tarkoma"], "Sources": "Proceedings of the 11th ACM Multimedia Systems Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": "Human conversation is characterized by brief pauses and so-called turn-taking behavior between the speakers. In the context of VoIP, this means that there are frequent periods where the microphone captures only background noise - or even silence whenever the microphone is muted. The bits transmitted from such silence periods introduce overhead in terms of data usage, energy consumption, and network infrastructure costs. In this paper, we contribute by shedding light on these costs for VoIP applications. We systematically measure the performance of six popular mobile VoIP applications with controlled human conversation and acoustic setup. Our analysis demonstrates that significant savings can indeed be achieved - with the best performing silence suppression technique being effective on 75% of silent pauses in the conversation in a quiet place. This results in 2-5 times data savings, and 50-90% lower?\u2026", "IdName": "hoque2020bits", "Citation": "", "Keywords": ""}, {"Name": "FovOptix: Human Vision-Compatible Video Encoding and Adaptive Streaming in VR Cloud Gaming", "Authors": ["Ahmad Alhilal", "Ze Wu", "Yuk Hang Tsui", "Pan Hui"], "Sources": "Proceedings of the 15th ACM Multimedia Systems Conference", "PublishedYears": "2024", "Doi": "", "Abstracts": "VR cloud gaming enables users to play high-end VR games on lightweight devices by offloading rendering tasks to cloud servers. Despite video compression, high-definition video streaming requires substantial data transfer rates. Foveated rendering (FR) and video encoding (FVE) leverage the non-uniform perception of the human visual system to reduce computing and bandwidth demand. They enhance visual quality in central gaze regions and reduce it in the periphery. However, bandwidth variation may hinder the provision of smooth VR gaming experiences. We present FovOptix, a system that combines FR with adaptive FVE to deliver video stream at a lower yet adaptive bitrate while not compromising the perceived video quality. FovOptix is based on a game-agnostic open-source to ensure reproducibility and compatibility with various games. We evaluate FovOptix against benchmarks using 5G mobile?\u2026", "IdName": "alhilal2024fovoptix", "Citation": "", "Keywords": ""}, {"Name": "Text2VRScene: Exploring the Framework of Automated Text-driven Generation System for VR Experience", "Authors": ["Zhizhuo Yin", "Yuyang Wang", "Theodoros Papatheodorou", "Pan Hui"], "Sources": "2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the recent development of the Virtual Reality (VR) industry, the increasing number of VR users pushes the demand for the massive production of immersive and expressive VR scenes in related industries. However, creating expressive VR scenes involves the reasonable organization of various digital content to express a coherent and logical theme, which is time-consuming and labor-intensive. In recent years, Large Language Models (LLMs) such as ChatGPT 3.5 and generative models such as stable diffusion have emerged as powerful tools for comprehending natural language and generating digital contents such as text, code, images, and 3D objects. In this paper, we have explored how we can generate VR scenes from text by incorporating LLMs and various generative models into an automated system. To achieve this, we first identify the possible limitations of LLMs for an automated system and propose?\u2026", "IdName": "yin2024text2vrscene", "Citation": "", "Keywords": ""}, {"Name": "Sora OpenAI's Prelude: Social Media Perspectives on Sora OpenAI and the Future of AI Video Generation", "Authors": ["Reza Hadi Mogavi", "Derrick Wang", "Joseph Tu", "Hilda Hadan", "Sabrina A Sgandurra", "Pan Hui", "Lennart E Nacke"], "Sources": "arXiv preprint arXiv:2403.14665", "PublishedYears": "2024", "Doi": "", "Abstracts": "The rapid advancement of Generative AI (Gen-AI) is transforming Human-Computer Interaction (HCI), with significant implications across various sectors. This study investigates the public's perception of Sora OpenAI, a pioneering Gen-AI video generation tool, via social media discussions on Reddit before its release. It centers on two main questions: the envisioned applications and the concerns related to Sora's integration. The analysis forecasts positive shifts in content creation, predicting that Sora will democratize video marketing and innovate game development by making video production more accessible and economical. Conversely, there are concerns about deepfakes and the potential for disinformation, underscoring the need for strategies to address disinformation and bias. This paper contributes to the Gen-AI discourse by fostering discussion on current and future capabilities, enriching the understanding of public expectations, and establishing a temporal benchmark for user anticipation. This research underscores the necessity for informed, ethical approaches to AI development and integration, ensuring that technological advancements align with societal values and user needs.", "IdName": "mogavi2024sora", "Citation": "", "Keywords": ""}, {"Name": "Behave Differently when Clustering: A Semi-asynchronous Federated Learning Approach for IoT", "Authors": ["Boyu Fan", "Xiang Su", "Sasu Tarkoma", "Pan Hui"], "Sources": "ACM Transactions on Sensor Networks", "PublishedYears": "2024", "Doi": "", "Abstracts": "The Internet of Things (IoT) has revolutionized the connectivity of diverse sensing devices, generating an enormous volume of data. However, applying machine learning algorithms to sensing devices presents substantial challenges due to resource constraints and privacy concerns. Federated learning (FL) emerges as a promising solution allowing for training models in a distributed manner while preserving data privacy on client devices. We contribute SAFI, a semi-asynchronous FL approach based on clustering to achieve a novel in-cluster synchronous and out-cluster asynchronous FL training mode. Specifically, we propose a three-tier architecture to enable IoT data processing on edge devices and design a clustering selection module to effectively group heterogeneous edge devices based on their processing capacities. The performance of SAFI has been extensively evaluated through experiments conducted?\u2026", "IdName": "fan2024behave", "Citation": "", "Keywords": ""}, {"Name": "Model-Heterogeneous Federated Learning for Internet of Things: Enabling Technologies and Future Directions", "Authors": ["Boyu Fan", "Siyang Jiang", "Xiang Su", "Pan Hui"], "Sources": "arXiv preprint arXiv:2312.12091", "PublishedYears": "2023", "Doi": "", "Abstracts": "Internet of Things (IoT) interconnects a massive amount of devices, generating heterogeneous data with diverse characteristics. IoT data emerges as a vital asset for data-intensive IoT applications, such as healthcare, smart city and predictive maintenance, harnessing the vast volume of heterogeneous data to its maximum advantage. These applications leverage different Artificial Intelligence (AI) algorithms to discover new insights. While machine learning effectively uncovers implicit patterns through model training, centralizing IoT data for training poses significant privacy and security concerns. Federated Learning (FL) offers an promising solution, allowing IoT devices to conduct local learning without sharing raw data with third parties. Model-heterogeneous FL empowers clients to train models with varying complexities based on their hardware capabilities, aligning with heterogeneity of devices in real-world IoT environments. In this article, we review the state-of-the-art model-heterogeneous FL methods and provide insights into their merits and limitations. Moreover, we showcase their applicability to IoT and identify the open problems and future directions. To the best of our knowledge, this is the first article that focuses on the topic of model-heterogeneous FL for IoT.", "IdName": "fan2023model", "Citation": "", "Keywords": ""}, {"Name": "Echo Chambers within the Russo-Ukrainian War: The Role of Bipartisan Users", "Authors": ["Peixian Zhang", "Ehsan-Ul Haq", "Yiming Zhu", "Pan Hui", "Gareth Tyson"], "Sources": "arXiv preprint arXiv:2311.09934", "PublishedYears": "2023", "Doi": "", "Abstracts": "The ongoing Russia-Ukraine war has been extensively discussed on social media. One commonly observed problem in such discussions is the emergence of echo chambers, where users are rarely exposed to opinions outside their worldview. Prior literature on this topic has assumed that such users hold a single consistent view. However, recent work has revealed that complex topics (such as the war) often trigger bipartisanship among certain people. With this in mind, we study the presence of echo chambers on Twitter related to the Russo-Ukrainian war. We measure their presence and identify an important subset of bipartisan users who vary their opinions during the invasion. We explore the role they play in the communications graph and identify features that distinguish them from remaining users. We conclude by discussing their importance and how they can improve the quality of discourse surrounding the war.", "IdName": "zhang2023echo", "Citation": "", "Keywords": ""}, {"Name": "Toward Trustworthy and Responsible Autonomous Drones in Future Smart Cities", "Authors": ["Abdul-Rasheed Ottun", "Zhigang Yin", "Mohaan Liyanage", "Michell Boerger", "Mehrdad Asadi", "Pan Hui", "Sasu Tarkoma", "Nikolay Tcholtchev", "Petteri Nurmi", "Huber Flores"], "Sources": "Authorea Preprints", "PublishedYears": "2023", "Doi": "", "Abstracts": "Autonomous drones are reaching a level of maturity when they can be deployed in cities to support tasks ranging from medicine or food delivery to environmental monitoring. These operations rely on powerful AI models integrated into the drones. Ensuring these models are robust is essential for operating in cities as any errors in the decisions of the autonomous drones can cause damage to the citizens or the urban infrastructure. We contribute a research vision for trustworthy city-scale deployments of autonomous drones. We highlight current key requirements and challenges that have to be fulfilled for achieving city-scale autonomous drone deployments. In addition, we also analyze the complexity of using XAI methods to monitor drone behavior. We demonstrate this by inducing changes in AI model behavior using data poisoning attacks. Our results demonstrate that XAI methods are sensitive enough to detect the possibility of a data attack, but a combination of multiple XAI methods is better to improve the robustness of the estimation. Our results also suggest that currently, the reaction time to counter an attack in city-scale deployment is large due to the complexity of the XAI analysis.", "IdName": "ottun2023toward", "Citation": "", "Keywords": ""}, {"Name": "A Deep Cybersickness Predictor through Kinematic Data with Encoded Physiological Representation", "Authors": ["Ruichen Li", "Yuyang Wang", "Handi Yin", "Jean-R\u00e9my Chardonnet", "Pan Hui"], "Sources": "2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Users would experience individually different sickness symptoms during or after navigating through an immersive virtual environment, generally known as cybersickness. Previous studies have predicted the severity of cybersickness based on physiological and/or kinematic data. However, compared with kinematic data, physiological data rely heavily on biosensors during the collection, which is inconvenient and limited to a few affordable VR devices. In this work, we proposed a deep neural network to predict cybersickness through kinematic data. We introduced the encoded physiological representation to characterize the individual susceptibility; therefore, the predictor could predict cybersickness only based on a user\u2019s kinematic data without counting on biosensors. Fifty-three participants were recruited to attend the user study to collect multimodal data, including kinematic data (navigation speed, head tracking?\u2026", "IdName": "li2023deep", "Citation": "", "Keywords": ""}, {"Name": "Development of an immersive simulator for improving student chemistry learning efficiency", "Authors": ["Shan Jin", "Yuyang Wang", "Lik-Hang Lee", "Xinyi Luo", "Pan Hui"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Virtual reality (VR) technology has been used for educational purposes in different learning contents during teaching and training. VR could improve users\u2019 learning efficiency and motivation to study abstract concepts. This work designed a VR environment for chemistry education to support computer-mediated hands-on exercises, including Self-propagating high-temperature synthesis (SHS) and Electrode sheet fabrication (ESF). In our evaluation with 39 participants who wore heart beat measurement wearables, we compared the students\u2019 performances in hands-on chemistry tasks, either with or without score-keeping and time-sensitive conditions. Accordingly, we designed questionnaires reflecting sixteen qualitative aspects (e.g., content, perspicuity, and interaction) and perceived user workloads. The experimental results indicate participants\u2019 preferences and attitudes in terms of efficiency and sense of safety?\u2026", "IdName": "jin2023development", "Citation": "", "Keywords": ""}, {"Name": "RLPTO: A reinforcement learning-based performance-time optimized task and resource scheduling mechanism for distributed machine learning", "Authors": ["Xiaofeng Lu", "Chao Liu", "Senhao Zhu", "Yilu Mao", "Pietro Lio", "Pan Hui"], "Sources": "IEEE Transactions on Parallel and Distributed Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "With the wide application of deep learning, the amount of data required to train deep learning models is becoming increasingly larger, resulting in an increased training time and higher requirements for computing resources. To improve the throughput of a distributed learning system, task scheduling and resource scheduling are required. This article proposes to combine ARIMA and GRU models to predict the future task volume. In terms of task scheduling, multi-priority task queues are used to divide tasks into different queues according to their priorities to ensure that high-priority tasks can be completed in advance. In terms of resource scheduling, the reinforcement learning method is adopted to manage limited computing resources. The reward function of reinforcement learning is constructed based on the resources occupied by the task, the training time, the accuracy of the model. When a distributed learning?\u2026", "IdName": "lu2023rlpto", "Citation": "", "Keywords": ""}, {"Name": "An Analysis of Twitter Discourse on the War Between Russia and Ukraine", "Authors": ["Haris Bin Zia", "Ehsan Ul Haq", "Ignacio Castro", "Pan Hui", "Gareth Tyson"], "Sources": "arXiv preprint arXiv:2306.11390", "PublishedYears": "2023", "Doi": "", "Abstracts": "On the 21st of February 2022, Russia recognised the Donetsk People's Republic and the Luhansk People's Republic, three days before launching an invasion of Ukraine. Since then, an active debate has taken place on social media, mixing organic discussions with coordinated information campaigns. The scale of this discourse, alongside the role that information warfare has played in the invasion, make it vital to better understand this ecosystem. We therefore present a study of pro-Ukrainian vs. pro-Russian discourse through the lens of Twitter. We do so from two perspectives: (i) the content that is shared; and (ii) the users who participate in the sharing. We first explore the scale and nature of conversations, including analysis of hashtags, toxicity and media sharing. We then study the users who drive this, highlighting a significant presence of new users and bots.", "IdName": "zia2023analysis", "Citation": "", "Keywords": ""}, {"Name": "Getting Back on Track: Understanding COVID-19 Impact on Urban Mobility and Segregation with Location Service Data", "Authors": ["Lin Chen", "Fengli Xu", "Qianyue Hao", "Pan Hui", "Yong Li"], "Sources": "Proceedings of the International AAAI Conference on Web and Social Media 17?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Understanding the impact of COVID-19 on urban life rhythms is crucial for accelerating the return-to-normal progress and envisioning more resilient and inclusive cities. While previous studies either depended on small-scale surveys or focused on the response to initial lockdowns, this paper uses large-scale location service data to systematically analyze the urban mobility behavior changes across three distinct phases of the pandemic, ie, pre-pandemic, lockdown, and reopen. Our analyses reveal two typical patterns that govern the mobility behavior changes in most urban venues: daily life-centered urban venues go through smaller mobility drops during the lockdown and more rapid recovery after reopening, while work-centered urban venues suffer from more significant mobility drops that are likely to persist even after reopening. Such mobility behavior changes exert deeper impacts on the underlying social fabric, where the level of mobility reduction is positively correlated with the experienced segregation at that urban venue. Therefore, urban venues undergoing more mobility reduction are also more filled with people from homogeneous socio-demographic backgrounds. Moreover, mobility behavior changes display significant heterogeneity across geographical regions, which can be largely explained by the partisan inclination at the state level. Our study shows the vast potential of location service data in deriving a timely and comprehensive understanding of the social dynamic in urban space, which is valuable for informing the gradual transition back to the normal lifestyle in a \u201cpost-pandemic era\u201d.", "IdName": "chen2023getting", "Citation": "", "Keywords": ""}, {"Name": "Towards AI-Architecture Liberty: A Comprehensive Survey on Designing and Collaborating Virtual Architecture by Deep Learning in the Metaverse", "Authors": ["Anqi Wang", "Jiahua Dong", "Lik-Hang Lee", "Jiachuan Shen", "Pan Hui"], "Sources": "arXiv preprint arXiv:2305.00510", "PublishedYears": "2023", "Doi": "", "Abstracts": "3D shape generation techniques leveraging deep learning have garnered significant interest from both the computer vision and architectural design communities, promising to enrich the content of the future metaverse. However, research on virtual architectural design remains limited, particularly regarding human-AI collaboration and deep learning-assisted design. We first illuminate the principles, generation techniques, and current literature of virtual architecture, focusing on challenges such as datasets, multimodality, design intuition, and generative frameworks. In our survey, we reviewed 187 related articles (80.7\\% of articles published between 2018 and 2022) covering architectural research, virtual environments, and technical approaches. This survey investigates the latest approaches to 3D object generation with deep generative models (DGMs) and summarizes four characteristics of deep-learning generation approaches for virtual architecture. According to our analysis of the survey, we expound on four research agendas, including agency, communication, user consideration, and integrating tools, and highlight three important enablers of ubiquitous interaction with immersive systems in deep learning-assisted architectural generation. Our work contributes to fostering understanding between designers and deep learning techniques, broadening access to human-AI collaboration. We advocate for interdisciplinary efforts to address this timely research topic, facilitating content designing and generation in the metaverse.", "IdName": "wang2023towards", "Citation": "", "Keywords": ""}, {"Name": "An immersive simulator for improving chemistry learning efficiency", "Authors": ["Jin Shan", "Yuyang Wang", "Lik-Hang Lee", "Xian Wang", "Zeming Chen", "Boya Dong", "Xinyi Luo", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper designed a virtual simulator for chemistry education and computer-mediated hands-on exercises. We compared the participants' performances in hands-on chemistry tasks with or without score-keeping and timer and used questionnaires to measure their learning performance and perceived cognitive workload. The experimental results indicate participants' preferences and attitudes toward efficiency and safety. Most participants reported that the learning simulator could improve learning efficiency and a sense of safety. Our findings shed light on the quality and learning performance of theory knowledge and operational skills for chemistry education.", "IdName": "shan2023immersive", "Citation": "", "Keywords": ""}, {"Name": "Development and penta-metric evaluation of a virtual interview simulator", "Authors": ["Xinyi Luo", "Yuyang Wang", "Lik-Hang Lee", "Zihan Xing", "Shan Jin", "Boya Dong", "Yuanyi Hu", "Zeming Chen", "Jing Yan", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The virtual reality interview training system (VRITS) can provide a manageable training approach for candidates who tend to be very ner-vous during interviews; yet, the major anxiety stimulating elements remain unknown. By developing the VRITS and analyzing people's anxiety levels with an orthogonal experiment, we investigated five factors. Results indicate that Type Of Interview Questions plays a major role in the interviewee's anxiety. Secondly, Level Of Realism and Preparation both have some degree of influence. Lastly, Interrogator's Attitude and Timed Or Untimed Answers have little to no impact. This work contributes towards cues for designing future VRITS.", "IdName": "luo2023development", "Citation": "", "Keywords": ""}, {"Name": "A Twitter Dataset for Pakistani Political Discourse", "Authors": ["Ehsan-Ul Haq", "Haris Bin Zia", "Reza Hadi Mogavi", "Gareth Tyson", "Yang K Lu", "Tristan Braud", "Pan Hui"], "Sources": "arXiv preprint arXiv:2301.06316", "PublishedYears": "2023", "Doi": "", "Abstracts": "We share the largest dataset for the Pakistani Twittersphere consisting of over 49 million tweets, collected during one of the most politically active periods in the country. We collect the data after the deposition of the government by a No Confidence Vote in April 2022. This large-scale dataset can be used for several downstream tasks such as political bias, bots detection, trolling behavior, (dis)misinformation, and censorship related to Pakistani Twitter users. In addition, this dataset provides a large collection of tweets in Urdu and Roman Urdu that can be used for optimizing language processing tasks.", "IdName": "haq2023twitter", "Citation": "", "Keywords": ""}, {"Name": "Networking and cyber foraging for mobile augmented reality", "Authors": ["Tristan Braud", "Wenxiao Zhang", "Benjamin Finley", "Pan Hui"], "Sources": "Springer Handbook of Augmented Reality", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile augmented reality (MAR) applications are gaining popularity due to the wide adoption of mobile and especially wearable devices such as smartglasses. These devices often strike a compromise between mobility, energy efficiency, and performance. On the other hand, MAR applications rely on computationally intensive computer vision algorithms with extreme latency requirements. Cyber-foraging allows resource-constrained devices to leverage the computing power of nearby machines, and has often been proposed as a solution for increasing the computing capabilities of constrained devices. However, this process introduces new constraints in the application, especially in terms of latency and bandwidth. MAR applications are so demanding that current network infrastructures are barely ready for such traffic. Such resource-hungry applications may rapidly saturate future wireless networks such as 5G. As?\u2026", "IdName": "braud2023networking", "Citation": "", "Keywords": ""}, {"Name": "Exploring Mental Health Communications among Instagram Coaches", "Authors": ["Ehsan-Ul Haq", "Lik-Hang Lee", "Gareth Tyson", "Reza Hadi Mogavi", "Tristan Braud", "Pan Hui"], "Sources": "2022 IEEE/ACM International Conference on Advances in Social Networks?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "There has been a significant expansion in the use of online social networks (OSNs) to support people experiencing mental health issues. This paper studies the role of Instagram influencers who specialize in coaching people with mental health issues. Using a dataset of 97k posts, we characterize such users' linguistic and behavioural features. We explore how these observations impact audience engagement (as measured by likes). We show that the support provided by these accounts varies based on their self-declared professional identities. For instance, Instagram accounts that declare themselves as Authors offer less support than accounts that label themselves as a Coach. We show that increasing information support in general communication positively affects user engagement. However, the effect of vocabulary on engagement is not consistent across the Instagram account types. Our findings shed light on?\u2026", "IdName": "haq2022exploring", "Citation": "", "Keywords": ""}, {"Name": "Understanding scholar social networks: taking scholat as an example", "Authors": ["Min Gao", "Yang Chen", "Qingyuan Gong", "Xin Wang", "Pan Hui"], "Sources": "CCF Conference on Computer Supported Cooperative Work and Social Computing?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Scholar social networks are composed of scholars and social connections among them. Studying such social networks can help promote academic exchanges and cooperation, and predict future trends in research. In this paper, we analyze SCHOLAT, a representative scholar social network in China, from three perspectives. First, we explore SCH-OLAT\u2019s social graph, and we find this graph has a smaller average shortest-path length and a higher clustering coefficient than other social networks, for example, the collaboration network of Google Scholar and the Flickr social network. Moreover, we leverage the structural hole theory to identify important users on SCHOLAT. By comparing the top-500 structural hole spanners with 500 randomly selected users, we have found that the former have the higher values of several graph-based metrics, and they also connect more communities. Finally, we also undertake user?\u2026", "IdName": "gao2021understanding", "Citation": "", "Keywords": ""}, {"Name": "Evaluating transport protocols on 5g for mobile augmented reality", "Authors": ["Jacky Cao", "Xiang Su", "Benjamin Finley", "Pengyuan Zhou", "Pan Hui"], "Sources": "arXiv preprint arXiv:2006.02859", "PublishedYears": "2020", "Doi": "", "Abstracts": "Mobile Augmented Reality (MAR) mixes physical environments with user-interactive virtual annotations. Immersive MAR experiences are supported by computation-intensive tasks which rely on offloading mechanisms to ease device workloads. However, this introduces additional network traffic which in turn influences the motion-to-photon latency (a determinant of user-perceived quality of experience). Therefore, a proper transport protocol is crucial to minimise transmission latency and ensure sufficient throughput to support MAR performance. Relatedly, 5G, a potential MAR supporting technology, is widely believed to be smarter, faster, and more efficient than its predecessors. However, the suitability and performance of existing transport protocols in MAR in the 5G context has not been explored. Therefore, we present an evaluation of popular transport protocols, including UDP, TCP, MPEG-TS, RTP, and QUIC, with a MAR system on a real-world 5G testbed. We also compare with their 5G performance with LTE and WiFi. Our evaluation results indicate that TCP has the lowest round-trip-time on 5G, with a median of  ms, while QUIC appears to perform better on LTE. Through an additional test with varying signal quality (specifically, degrading secondary synchronisation signal reference signal received quality), we discover that protocol performance appears to be significantly impacted by signal quality.", "IdName": "cao2020evaluating", "Citation": "", "Keywords": ""}, {"Name": "Modelling global public health strategies in COVID-19 pandemic using deep reinforcement learning", "Authors": ["Kwak Gloria Hyunjung", "Lowell Ling", "Pan Hui"], "Sources": "None", "PublishedYears": "2020", "Doi": "", "Abstracts": "Objectives:This study evaluates the timing and intensity of public health policies in each country and territory in the COVID-19 pandemic, and whether machine learning can help them to find better global health strategies.Methods:: Population and COVID-19 epidemiological data between 21st January 2020 to 7th April 2020 from 183 countries and 78 territories were included with the implemented public health interventions. We used deep reinforcement learning, and the model was trained to try to find the optimal public health strategies with maximizing total reward on controlling spread of COVID-19. The results proposed by the model were analyzed against the actual timing and intensity of lockdown and travel restrictions. Measurements and Main Results: Early implementation of the actual lockdown and travel restriction policies were associated with gradually groups of less severe crisis severity, relative to local index case date in each country or territory, not to 31st December 2019. However, our model suggested to initiate at least minimal intensity of lockdown or travel restriction even before index cases in each country and territory. In addition, the model mostly recommended a combination of lockdown and travel restrictions and higher intensity policies than the implemented policies by government, but did not always encourage rapid full lockdown and full border closures.Conclusion:Compared to actual government implementation, our model mostly recommended earlier and higher intensity of lockdown and travel restrictions. Machine learning may be used as a decision support tool for implementation of public health interventions during?\u2026", "IdName": "hyunjung2020modelling", "Citation": "", "Keywords": ""}, {"Name": "A Study of Partisan News Sharing in the Russian Invasion of Ukraine", "Authors": ["Yiming Zhu", "Ehsan-Ul Haq", "Gareth Tyson", "Lik-Hang Lee", "Yuyang Wang", "Pan Hui"], "Sources": "Proceedings of the International AAAI Conference on Web and Social Media 18?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Since the Russian invasion of Ukraine, a large volume of biased and partisan news has been spread via social media platforms. As this may lead to wider societal issues, we argue that understanding how partisan news sharing impacts users' communication is crucial for better governance of online communities. In this paper, we perform a measurement study of partisan news sharing. We aim to characterize the role of such sharing in influencing users' communications. Our analysis covers an eight-month dataset across six Reddit communities related to the Russian invasion. We first perform an analysis of the temporal evolution of partisan news sharing. We confirm that the invasion stimulates discussion in the observed communities, accompanied by an increased volume of partisan news sharing. Next, we characterize users' response to such sharing. We observe that partisan bias plays a role in narrowing its propagation. More biased media is less likely to be spread across multiple subreddits. However, we find that partisan news sharing attracts more users to engage in the discussion, by generating more comments. We then built a predictive model to identify users likely to spread partisan news. The prediction is challenging though, with 61.57% accuracy on average. Our centrality analysis on the commenting network further indicates that the users who disseminate partisan news possess lower network influence in comparison to those who propagate neutral news.", "IdName": "zhu2024study", "Citation": "", "Keywords": ""}, {"Name": "Similarity-driven and task-driven models for diversity of opinion in crowdsourcing markets", "Authors": ["Chen Jason Zhang", "Yunrui Liu", "Pengcheng Zeng", "Ting Wu", "Lei Chen", "Pan Hui", "Fei Hao"], "Sources": "The VLDB Journal", "PublishedYears": "2024", "Doi": "", "Abstracts": "The recent boom in crowdsourcing has opened up a new avenue for utilizing human intelligence in the realm of data analysis. This innovative approach provides a powerful means for connecting online workers to tasks that cannot effectively be done solely by machines or conducted by professional experts due to cost constraints. Within the field of social science, four elements are required to construct a sound crowd\u2014Diversity of Opinion, Independence, Decentralization and Aggregation. However, while the other three components have already been investigated and implemented in existing crowdsourcing platforms,\u2018Diversity of Opinion\u2019has not been functionally enabled yet. From a computational point of view, constructing a wise crowd necessitates quantitatively modeling and taking diversity into account. There are usually two paradigms in a crowdsourcing marketplace for worker selection: building a crowd to?\u2026", "IdName": "zhang2024similarity", "Citation": "", "Keywords": ""}, {"Name": "Digital Democracy at Crossroads: A Meta-Analysis of Web and AI Influence on Global Elections", "Authors": ["Zheng Wei", "Xian Xu", "Pan Hui"], "Sources": "Companion Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "2024 will be the largest election year in history involving over 50 countries and approximately 4.2 billion people. Since 1996, the Web has been instrumental in political campaigns, enhancing public engagement and creating new communication avenues for elections. Nevertheless, the proliferation of generative AI technologies has made false information dissemination simpler and quicker, posing a substantial threat to election integrity and democratic processes. The 2024 global elections underscore the need to comprehend and tackle the impact of such technologies on democracy. In this paper, we undertake a detailed meta-analysis, scrutinizing 44 papers published in The Web Conference, detailing the influence of the Web on elections. Our research reveals key historical trends on how the Web has impacted elections: first, social media has revolutionized election strategies through direct voter-candidate?\u2026", "IdName": "wei2024digital", "Citation": "", "Keywords": ""}, {"Name": "Social Media Discourses on Interracial Intimacy: Tracking Racism and Sexism through Chinese Geo-located Social Media Data", "Authors": ["Zheng Wei", "Yixuan Xie", "Danyun Xiao", "Simin Zhang", "Pan Hui", "Muzhi Zhou"], "Sources": "Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "We examine the social media discourse surrounding interracial relationships in China, specifically on the popular platform Douyin. By analyzing comments on short video posts, the study focuses on four types of interracial relationships: Black men and Chinese women, Black women and Chinese men, White men and Chinese women, and White women and Chinese men. The study also explores potential regional differences in these discourses, using IP geolocation data made available to the public since April 2022. Our content analysis revealed that the Black men and Chinese women couples attracted the most negative comments and the White women and Chinese men couples received the least negative comments. We also observed substantial regional differences in the discourses towards these interracial relationships. We investigated several regional socioeconomic development indicators and noted that?\u2026", "IdName": "wei2024social", "Citation": "", "Keywords": ""}, {"Name": "History in Making: Political Campaigns in the Era of Artificial Intelligence-Generated Content", "Authors": ["Ehsan-Ul Haq", "Yiming Zhu", "Pan Hui", "Gareth Tyson"], "Sources": "Companion Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Web 2.0 provided impactful tools, based on user-generated content, for political campaigns and opinion engineering. However, in recent months, AI advances and the ease of access to AI-generated content (AIGC) have led to a paradigm shift in political participation by politicians and electorates alike. This paper aims to explore a historical analysis of this shift. We provide anecdotal evidence of new trends, potential impact, and challenges. We discuss the usage of AIGC in political campaigns, and how AIGC is used as a substitute for incarcerated politicians. Such a usage presents novel ways for leaders to reach the public and keep them politically active. However, AIGC also has risks when used for disinformation, such as DeepFake media and caller bots, to undermine and malign the opponents. On the other hand, the evidence shows that governments can nudge AIGC content by censoring Internet services. We?\u2026", "IdName": "haq2024history", "Citation": "", "Keywords": ""}, {"Name": "APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT", "Authors": ["Yiming Zhu", "Zhizhuo Yin", "Gareth Tyson", "Ehsan-Ul Haq", "Lik-Hang Lee", "Pan Hui"], "Sources": "Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent research has highlighted the potential of LLMs, like ChatGPT, for performing label annotation on social computing data. However, it is already well known that performance hinges on the quality of the input prompts. To address this, there has been a flurry of research into prompt tuning --- techniques and guidelines that attempt to improve the quality of prompts. Yet these largely rely on manual effort and prior knowledge of the dataset being annotated. To address this limitation, we propose APT-Pipe, an automated prompt-tuning pipeline. APT-Pipe aims to automatically tune prompts to enhance ChatGPT's text classification performance on any given dataset. We implement APT-Pipe and test it across twelve distinct text classification datasets. We find that prompts tuned by APT-Pipe help ChatGPT achieve higher weighted F1-score on nine out of twelve experimented datasets, with an improvement of 7.01% on?\u2026", "IdName": "zhu2024apt", "Citation": "", "Keywords": ""}, {"Name": "OmniColor: A Global Camera Pose Optimization Approach of LiDAR-360Camera Fusion for Colorizing Point Clouds", "Authors": ["Bonan Liu", "Guoyang Zhao", "Jianhao Jiao", "Guang Cai", "Chengyang Li", "Handi Yin", "Yuyang Wang", "Ming Liu", "Pan Hui"], "Sources": "arXiv preprint arXiv:2404.04693", "PublishedYears": "2024", "Doi": "", "Abstracts": "A Colored point cloud, as a simple and efficient 3D representation, has many advantages in various fields, including robotic navigation and scene reconstruction. This representation is now commonly used in 3D reconstruction tasks relying on cameras and LiDARs. However, fusing data from these two types of sensors is poorly performed in many existing frameworks, leading to unsatisfactory mapping results, mainly due to inaccurate camera poses. This paper presents OmniColor, a novel and efficient algorithm to colorize point clouds using an independent 360-degree camera. Given a LiDAR-based point cloud and a sequence of panorama images with initial coarse camera poses, our objective is to jointly optimize the poses of all frames for mapping images onto geometric reconstructions. Our pipeline works in an off-the-shelf manner that does not require any feature extraction or matching process. Instead, we find optimal poses by directly maximizing the photometric consistency of LiDAR maps. In experiments, we show that our method can overcome the severe visual distortion of omnidirectional images and greatly benefit from the wide field of view (FOV) of 360-degree cameras to reconstruct various scenarios with accuracy and stability. The code will be released at https://github.com/liubonan123/OmniColor/.", "IdName": "liu2024omnicolor", "Citation": "", "Keywords": ""}, {"Name": "Perceived User Reachability in Mobile UIs Using Data Analytics and Machine Learning", "Authors": ["Lik-Hang Lee", "Yui-Pan Yau", "Pan Hui"], "Sources": "International Journal of Human\u2013Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "One-handed interactions on smartphone interfaces offer a prominent feature of highly mobile inputs. Thus, the design factor of user reachability is essential to realizing the incentive. However, the sole consideration of physical characteristics, such as hand size and thumb length, does not fully reflect the users\u2019 perceived choices of hand poses and the corresponding inertia. We first conducted a 6-week questionnaire-based study of UI rating tasks and collected 62,156 responses reflecting user preferences for 3000 clustered UIs. Our analysis of the responses shows that user perceptions of smartphone UI components are divergent from their physical ability of thumb reaches; e.g. they can reach an icon with a thumb reach, but they prefer alternative hand poses. Accordingly, we propose a machine learning model, i.e. XGBoost (XGB), to predict the user\u2019s choices of hand poses, with a reasonable prediction accuracy of?\u2026", "IdName": "lee2024perceived", "Citation": "", "Keywords": ""}, {"Name": "Jump Cut Effects in Cinematic Virtual Reality: Editing with the 30-degree Rule and 180-degree Rule", "Authors": ["Junjie Zhang", "Lik-Hang Lee", "Yuyang Wang", "Shan Jin", "Dan-Lu Fei", "Pan Hui"], "Sources": "2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)", "PublishedYears": "2024", "Doi": "", "Abstracts": "Virtual reality (VR) is an immersive medium that offers users a unique opportunity to experience a digital environment realistically. As the demand for VR content continues to grow, the importance of effective VR editing techniques becomes increasingly apparent. This paper is a pioneering work investigating the effects of jump cuts on the viewer\u2019s sense of presence, viewing experience, and edit quality in cinematic VR. Specifically, this work focuses on using the 30-degree and 180-degree rules in VR editing to minimize the adverse effects of jump cuts. We conducted a user study with thirteen participants, who watched nine different VR edits and completed a survey for each edited video. Our results indicate that employing the 30-degree and 180-degree rules in VR editing can significantly improve the sense of presence, viewing experience, and edit quality while mitigating the negative effects of jump cuts. We?\u2026", "IdName": "zhang2024jump", "Citation": "", "Keywords": ""}, {"Name": "AnchorLoc: Large-Scale, Real-Time Visual Localisation Through Anchor Extraction and Detection", "Authors": ["Chun Ho Park", "Ahmad Alhilal", "Tristan Braud", "Pan Hui"], "Sources": "2024 IEEE International Conference on Pervasive Computing and Communications?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Pervasive Augmented Reality (AR) requires accurate pose registration of the device in real-time at a neighbourhood-to-city scale. At such a scale, most pose registration techniques suffer from exponential computational and storage costs and a significant data collection burden. This paper introduces AnchorLoc, a framework that relies on visual anchors (stable and highly recognisable visual elements in a scene) to perform fast and accurate pose registration. Anchorloc automatically identifies these anchors from large image sequences to optimise the search space in later image retrieval and pose registration. As such, it significantly improves the computational efficiency of existing hierarchical localisation pipelines without compromising accuracy. We collect a large-scale localisation dataset consisting of image sequences and 3D reconstruction of a university campus. AnchorLoc reduces localisation runtime by 83?\u2026", "IdName": "park2024anchorloc", "Citation": "", "Keywords": ""}, {"Name": "Using a virtual reality interview simulator to explore factors influencing people\u2019s behavior", "Authors": ["Xinyi Luo", "Yuyang Wang", "Lik-Hang Lee", "Zihan Xing", "Shan Jin", "Boya Dong", "Yuanyi Hu", "Zeming Chen", "Jing Yan", "Pan Hui"], "Sources": "Virtual Reality", "PublishedYears": "2024", "Doi": "", "Abstracts": "Virtual reality interview simulator (VRIS) is an effective and valid tool that uses virtual reality technology to train people\u2019s interview skills. Typically, it offers candidates prone to being very nervous during interviews the opportunity to practice interviews in a safe and manageable virtual environment and realistic settings, providing real-time feedback from a virtual interviewer on their performance. It helps interviewees improve their skills, reduce their fears, gain confidence, and minimize the cost and time associated with traditional interview preparation. Yet, the major anxiety-inducing elements remain unknown. During an interview, the anxiety levels, overall experience, and performance of interviewees might be affected by various circumstances. By analyzing electrodermal activity and questionnaire, we investigated the influence of five variables:(I) Realism;(II) Question type;(III) Interviewer attitude;(IV) Timing; and (V?\u2026", "IdName": "luo2024using", "Citation": "", "Keywords": ""}, {"Name": "Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via Transformer-Based 360 Image Outpainting", "Authors": ["Hao Ai", "Zidong Cao", "Haonan Lu", "Chen Chen", "Jian Ma", "Pengyuan Zhou", "Tae-Kyun Kim", "Pan Hui", "Lin Wang"], "Sources": "arXiv preprint arXiv:2401.10564", "PublishedYears": "2024", "Doi": "", "Abstracts": "360 images, with a field-of-view (FoV) of 180x360, provide immersive and realistic environments for emerging virtual reality (VR) applications, such as virtual tourism, where users desire to create diverse panoramic scenes from a narrow FoV photo they take from a viewpoint via portable devices. It thus brings us to a technical challenge: `How to allow the users to freely create diverse and immersive virtual scenes from a narrow FoV image with a specified viewport?' To this end, we propose a transformer-based 360 image outpainting framework called Dream360, which can generate diverse, high-fidelity, and high-resolution panoramas from user-selected viewports, considering the spherical properties of 360 images. Compared with existing methods, e.g., [3], which primarily focus on inputs with rectangular masks and central locations while overlooking the spherical property of 360 images, our Dream360 offers higher outpainting flexibility and fidelity based on the spherical representation. Dream360 comprises two key learning stages: (I) codebook-based panorama outpainting via Spherical-VQGAN (S-VQGAN), and (II) frequency-aware refinement with a novel frequency-aware consistency loss. Specifically, S-VQGAN learns a sphere-specific codebook from spherical harmonic (SH) values, providing a better representation of spherical data distribution for scene modeling. The frequency-aware refinement matches the resolution and further improves the semantic consistency and visual fidelity of the generated results. Our Dream360 achieves significantly lower Frechet Inception Distance (FID) scores and better visual fidelity than existing methods?\u2026", "IdName": "ai2024dream360", "Citation": "", "Keywords": ""}, {"Name": "Long-Term Gamification: A Survey", "Authors": ["Lei Huang", "Chao Deng", "Jennifer Hoffman", "Reza Hadi Mogavi", "Justin Juho Kim", "Pan Hui"], "Sources": "International Conference on Human-Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "In addressing the challenge of sustaining user engagement in gamified systems, this survey explores the long-term effects of gamification strategies. It emerges that success hinges on a nuanced blend of design elements, tailored personalization, evolving challenges, collaborative features, story-driven content, and dynamic updates. These factors are found to foster a deep-rooted sense of ownership, skill development, community belonging, and continuous discovery, all of which are crucial for keeping users engaged over time. This paper contributes by providing an early analysis of longitudinal studies, offering a valuable roadmap for developing enduring gamification experiences within the fields of human-computer interaction and gamification. Our paper advocates for further research examining long-term gamification in a more systematic and thorough manner.", "IdName": "huang2024long", "Citation": "", "Keywords": ""}, {"Name": "Mobile User Traffic Generation via Multi-Scale Hierarchical GAN", "Authors": ["Tong Li", "Shuodi Hui", "Shiyuan Zhang", "Huandong Wang", "Yuheng Zhang", "Pan Hui", "Depeng Jin", "Yong Li"], "Sources": "ACM Transactions on Knowledge Discovery from Data", "PublishedYears": "2024", "Doi": "", "Abstracts": "Mobile user traffic facilitates diverse applications, including network planning and optimization, whereas large-scale mobile user traffic is hardly available due to privacy concerns. One alternative solution is to generate mobile user traffic data for downstream applications. However, existing generation models cannot simulate the multi-scale temporal dynamics in mobile user traffic on individual and aggregate levels. In this work, we propose a multi-scale hierarchical generative adversarial network (MSH-GAN) containing multiple generators and a multi-class discriminator. Specifically, the mobile traffic usage behavior exhibits a mixture of multiple behavior patterns, which are called micro-scale behavior patterns and are modeled by different pattern generators in our model. Moreover, the traffic usage behavior of different users exhibits strong clustering characteristics, with the co-existence of users with similar and?\u2026", "IdName": "li2024mobile", "Citation": "", "Keywords": ""}, {"Name": "Metaverse for Connected and Automated Vehicles and Intelligent Transportation Systems [From the Guest Editors]", "Authors": ["Pengyuan Zhou", "Lik-Hang Lee", "Zhi Liu", "Hang Qiu", "Tristan Braud", "Aaron Yi Ding", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Vehicular Technology Magazine", "PublishedYears": "2023", "Doi": "", "Abstracts": "The metaverse aims to blur the boundary between the physical world and digital content. To achieve this goal, the metaverse relies heavily on extended reality (XR), the Internet of Things, and communication technologies. Concurrently, connected vehicles and intelligent transportation systems (ITSs) are envisioned as the future paradigm of driving and becoming reality thanks to increasingly powerful onboard vehicular processing capacity and advanced vehicle-to-everything networking technologies.", "IdName": "zhou2023metaverse", "Citation": "", "Keywords": ""}, {"Name": "Head-mounted display-based augmented reality for water quality visualisation", "Authors": ["Jacky Cao", "Xiaoli Liu", "Xiang Su", "Jonas Eilertsen H?dahl", "Thomas Berg Fjellestad", "Donjete Haziri", "Andr\u00e9 Hoang-An Vu", "Jari Koskiaho", "Satu Maaria Karjalainen", "Anna-kaisa Ronkanen", "Sasu Tarkoma", "Pan Hui"], "Sources": "Water Science and Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Water covers most of the Earth\u2019s surface and is nowhere near a good ecological or recreational state in many areas of the world. Moreover, only a small fraction of the water is potable. As climate change-induced extreme weather events become ever more prevalent, more and more issues arise, such as worsening water quality problems. Therefore, protecting invaluable and useable drinking water is critical. Environmental agencies must continuously check water sources to determine whether they are in a good or healthy state regarding pollutant levels and ecological status. The currently available tools are better suited for stationary laboratory use, and domain specialists lack suitable tools for on-site visualisation and interactive exploration of environmental data. Meanwhile, data collection for laboratory analysis requires substantial time and significant effort. We, therefore, developed an augmented reality system?\u2026", "IdName": "cao2023head", "Citation": "", "Keywords": ""}, {"Name": "Is the Price Right? The Economic Value of Sharing Sensors", "Authors": ["Ngoc Thi Nguyen", "Maria Zubair", "Agustin Zuniga", "Sasu Tarkoma", "Pan Hui", "Hyowon Lee", "Simon Tangi Perrault", "Mostafa H Ammar", "Huber Flores", "Petteri Nurmi"], "Sources": "IEEE Transactions on Computational Social Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "We study user\u2019s valuations of smartphone sensing resources and the factors mediating them through a systematic auction study with 108 bids from N =18 participants, two resource use conditions [fixed battery (FB) and variable battery (VB)] and three sensors (camera, microphone, and GPS) with differing energy and privacy costs. We use a second-price sealed-bid reverse auction as this allows us to elicit the participants\u2019 truthful perceived value for sharing resources. We show that most users would be willing to share even highly-privacy intrusive sensors if they are sufficiently compensated. At the FB level, participants placed much lower value for sharing GPS (\u20ac13) than camera (\u20ac30) or microphone (\u20ac32.5). The values people place on sharing access to resources generally reflect four considerations: 1) the perceived value of the sensor type; 2) the value of the data captured by the sensor; 3) the impact of sharing?\u2026", "IdName": "nguyen2023price", "Citation": "", "Keywords": ""}, {"Name": "QoE Optimization for VR Streaming: a Continual RL Framework in Digital Twin-empowered MEC", "Authors": ["Jiadong Yu", "Ahmad Alhilal", "Tailin Zhou", "Pan Hui", "Danny HK Tsang"], "Sources": "GLOBECOM 2023-2023 IEEE Global Communications Conference", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile edge computing (MEC) resource allocation for remote rendering in virtual reality (VR) content streaming is critical for user experience. However, resource allocation becomes challenging due to the desynchronization between the physical and digital worlds in digital twin-empowered MEC. This paper presents our continual RL framework that facilitates dynamic resource allocation for MEC-enabled VR content streaming. We first design a digital twin-empowered edge computing (DTEC) system and formulate a maximization problem that considers attention-based resolution perception to maximize the quality of experience (QoE). This problem optimizes the allocation of computing and bandwidth resources while adapting the attention-based resolution of the VR content. We then apply continual reinforcement learning (CRL) to enable adaptive attention-based resolution VR streaming in a time-varying?\u2026", "IdName": "yu2023qoe", "Citation": "", "Keywords": ""}, {"Name": "VR PreM+: An Immersive Pre-learning Branching Visualization System for Museum Tours", "Authors": ["Ze Gao", "Xiang Li", "Changkun Liu", "Xian Wang", "Anqi Wang", "Liang Yang", "Yuyang Wang", "Pan Hui", "Tristan Braud"], "Sources": "Proceedings of the Eleventh International Symposium of Chinese CHI", "PublishedYears": "2023", "Doi": "", "Abstracts": "We present VR PreM+, an innovative VR system designed to enhance web exploration beyond traditional computer screens. Unlike static 2D displays, VR PreM+ leverages 3D environments to create an immersive pre-learning experience. Using keyword-based information retrieval allows users to manage and connect various content sources in a dynamic 3D space, improving communication and data comparison. We conducted preliminary and user studies that demonstrated efficient information retrieval, increased user engagement, and a greater sense of presence. These findings yielded three design guidelines for future VR information systems: display, interaction, and user-centric design. VR PreM+ bridges the gap between traditional web browsing and immersive VR, offering an interactive and comprehensive approach to information acquisition. It holds promise for research, education, and beyond.", "IdName": "gao2023vr", "Citation": "", "Keywords": ""}, {"Name": "Poster Abstract: Multi-User Privacy-Preserving Mechanism for Extended Reality in Healthcare", "Authors": ["Xiang Su", "Luyi Sun", "Pan Hui"], "Sources": "Proceedings of the 21st ACM Conference on Embedded Networked Sensor Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Health monitoring scenarios involve multiple users with conflicting privacy concerns. We envision extended reality facilitating smooth interactions among users while resolving potential conflicts arising from users' conflicting goals, ensuring that sensitive information is not unintentionally revealed. We contribute to an adaptive approach to resolving decision conflicts and content sharing and a scenario-centric access control model with a strategy mediator.", "IdName": "su2023multi", "Citation": "", "Keywords": ""}, {"Name": "Towards Risk-Averse Edge Computing With Deep Reinforcement Learning", "Authors": ["Dianlei Xu", "Xiang Su", "Huandong Wang", "Sasu Tarkoma", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, artificial intelligence paves the way for the development of smart services for people anytime and anywhere, which poses great challenges on accessing computing resources. Multi-access edge computing complements existing cloud computing infrastructure at the edge of the network, where mobile users can offload computationally intensive tasks of smart applications to edge servers that are in proximity to the users themselves. Existing offloading schemes mainly focus on selecting edge servers for each offloading task with the goal of optimizing the overall average latency. However, the solutions with the optimal overall average latency may be not the most suitable for all offloading tasks. There is still a possibility that offloading leads to an extreme case of ultra-high latency, which is not acceptable for latency-sensitive applications. To address this problem, we therefore introduce modern portfolio theory?\u2026", "IdName": "xu2023towards", "Citation": "", "Keywords": ""}, {"Name": "Towards Optimising Transport Protocols on the 5G Edge for Mobile Augmented Reality", "Authors": ["Jacky Cao", "Xiang Su", "Pan Hui"], "Sources": "Proceedings of the 2nd International Workshop on Interactive eXtended?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Mobile augmented reality (MAR) achieves immersive real-time experiences by offloading computation-intensive computer vision tasks. 5G NR (5G) networks and edge computing enable optimised latency and enhanced throughput for MAR offloading. However, efficiently leveraging the 5G edge also requires optimising the data link between MAR devices and server machines. We report preliminary experiments of optimising transport protocols (i.e., UDP and TCP) to understand how we could further modify the data link between MAR clients and servers. Preliminary analysis shows that when using a real-world 5G testbed, our evaluation indicates that for our settings, TCP with default configuration parameters has the lowest round-trip time on 5G, with a median of 15.8\\pm10.3 ms. Then by increasing the protocol buffer sizes to 100 KB and 1000 KB, the packet latency and jitter decrease while throughput increases for?\u2026", "IdName": "cao2023towards", "Citation": "", "Keywords": ""}, {"Name": "SoK: Distributed Computing in ICN", "Authors": ["Wei Geng", "Yulong Zhang", "Dirk Kutscher", "Abhishek Kumar", "Sasu Tarkoma", "Pan Hui"], "Sources": "Proceedings of the 10th ACM Conference on Information-Centric Networking", "PublishedYears": "2023", "Doi": "", "Abstracts": "Information-Centric Networking (ICN), with its data-oriented operation and generally more powerful forwarding layer, provides an attractive platform for distributed computing. This paper provides a systematic overview and categorization of different distributed computing approaches in ICN encompassing fundamental design principles, frameworks and orchestration, protocols, enablers, and applications. We discuss current pain points in legacy distributed computing, attractive ICN features, and how different systems use them. This paper also provides a discussion of potential future work for distributed computing in ICN.", "IdName": "geng2023sok", "Citation": "", "Keywords": ""}, {"Name": "Ghost Booking as a New Philanthropy Channel: A Case Study on Ukraine-Russia Conflict", "Authors": ["Fachrina Dewi Puspitasari", "Gareth Tyson", "Ehsan-Ul Haq", "Pan Hui", "Lik-Hang Lee"], "Sources": "Proceedings of the 34th ACM Conference on Hypertext and Social Media", "PublishedYears": "2023", "Doi": "", "Abstracts": "The term ghost booking has recently emerged as a new way to conduct humanitarian acts during the conflict between Russia and Ukraine in 2022. The phenomenon describes the events where netizens donate to Ukrainian citizens through no-show bookings on the Airbnb platform. Impressively, the social fundraising act that used to be organized on donation-based crowdfunding platforms is shifted into a sharing economy platform market and thus gained more visibility. Although the donation purpose is clear, the motivation of donors in selecting a property to book remains concealed. Thus, our study explores peer-to-peer donation behavior on Airbnb, which was originally intended for economic exchanges, and further identifies which platform attributes effectively drive donation behaviors. We collect over 200K guest reviews from 16K Airbnb property listings in Ukraine by employing two collection methods (screen?\u2026", "IdName": "puspitasari2023ghost", "Citation": "", "Keywords": ""}, {"Name": "Toward A Traffic Metaverse With Shared Vehicle Perception", "Authors": ["Ahmad Ahilal", "Tristan Braud", "Lik-Hang Lee", "Hang Chen", "Pan Hui"], "Sources": "IEEE Communications Standards Magazine", "PublishedYears": "2023", "Doi": "", "Abstracts": "The emergence of the Metaverse enables the creation of alternative spaces at the intersection between digital and physical through the replication of physical events and objects within physical-digital twins. In this article, we apply such twins to connected vehicles within a Traffic Metaverse as an intermediate platform for the shared perception of the road environment. The platform builds a real-time digital copy of the road conditions to serve vehicular applications on a city scale through ubiquitous sensing, reliable and low-latency communications, artificial intelligence, and extended reality. This article focuses on collaboratively building virtual 3D maps of road networks that provide road users with a pervasive view of the road conditions to increase situational awareness. Through vehicle-to-everything (V2X) cooperative perception, such a Metaverse platform expands the driver's visibility beyond the vehicle's line of?\u2026", "IdName": "ahilal2023toward", "Citation": "", "Keywords": ""}, {"Name": "Efficient Task Offloading Algorithm for Digital Twin in Edge/Cloud Computing Environment", "Authors": ["Ziru Zhang", "Xuling Zhang", "Guangzhi Zhu", "Yuyang Wang", "Pan Hui"], "Sources": "arXiv preprint arXiv:2307.05888", "PublishedYears": "2023", "Doi": "", "Abstracts": "In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to empower various areas as a bridge between physical objects and the digital world. Through virtualization and simulation techniques, multiple functions can be achieved by leveraging computing resources. In this process, Mobile Cloud Computing (MCC) and Mobile Edge Computing (MEC) have become two of the key factors to achieve real-time feedback. However, current works only considered edge servers or cloud servers in the DT system models. Besides, The models ignore the DT with not only one data resource. In this paper, we propose a new DT system model considering a heterogeneous MEC/MCC environment. Each DT in the model is maintained in one of the servers via multiple data collection devices. The offloading decision-making problem is also considered and a new offloading scheme is proposed based on Distributed Deep Learning (DDL). Simulation results demonstrate that our proposed algorithm can effectively and efficiently decrease the system's average latency and energy consumption. Significant improvement is achieved compared with the baselines under the dynamic environment of DTs.", "IdName": "zhang2023efficient", "Citation": "", "Keywords": ""}, {"Name": "Towards a 3D Evaluation Dataset for User Acceptance of Automated Shuttles", "Authors": ["Ming Yan", "Wei Geng", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "The popularity of automatic driving technology has gradually freed users from driving tasks and increased interaction with vehicles and machines. Understanding user acceptance and making them more receptive to new technologies can help businesses and researchers find better ways to design Human-Machine Interactions. The simulation experiment in an immersion environment can evaluate the user's acceptance of the design with low cost and high efficiency. Fur-ther, the evaluation methods of some existing studies are different, which creates obstacles to the reuse and reference of research results between different scholars. However, there are limited simulation data that can be used for such interactive evaluation, such as typical 3D environment data based on Virtual Reality devices. We design dataset, an ongoing 3D test dataset produced by Unity software, to be employed by different studies to evaluate?\u2026", "IdName": "yan2023towards", "Citation": "", "Keywords": ""}, {"Name": "ARCam: A User-Defined Camera for AR Photographic Art Creation", "Authors": ["Xinyi Luo", "Zihao Zhu", "Yuyang Wang", "Pan Hui"], "Sources": "2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Photography in augmented reality can be challenging due to the restrictions of pre-defined settings. However, adjustable photography settings and real-time previews are significant for AR photographic creation as creators must adjust multiple camera properties to present unique visual effects. In this work, we designed an AR camera (ARCam) with various adjustable properties to give users a high degree of freedom for photographic art creation in real-time preview.", "IdName": "luo2023arcam", "Citation": "", "Keywords": ""}, {"Name": "Learn to Optimize the Constrained Shortest Paths on Large Dynamic Graphs", "Authors": ["Jiaming Yin", "Weixiong Rao", "Qinpei Zhao", "Chenxi Zhang", "Pan Hui"], "Sources": "IEEE Transactions on Mobile Computing", "PublishedYears": "2023", "Doi": "", "Abstracts": "The constrained shortest path (  ) problem has wide applications in travel path planning, mobile video broadcasting and network routing. Existing works do not work well on large dynamic graphs and suffer from either ineffectiveness or low scalability issues. To overcome these issues, in this paper, we propose an efficient and effective solution framework, namely   . The solution framework includes two key components: (1) the techniques to decompose a large    instance into multiple small sub-instances and (2) the developed learning model    to solve small    instances. The evaluation result on real road network graphs indicates that our approach    performs well on large dynamic graphs by rather high quality and reasonable running time, and particularly adapt to significant graph changes even with broken edges. To the best of our knowledge, this is the first learning-based model to well?\u2026", "IdName": "yin2023learn", "Citation": "", "Keywords": ""}, {"Name": "Dataset for predicting cybersickness from a virtual navigation task", "Authors": ["Yuyang Wang", "Ruichen Li", "Jean-R\u00e9my Chardonnet", "Pan Hui"], "Sources": "arXiv preprint arXiv:2303.13527", "PublishedYears": "2023", "Doi": "", "Abstracts": "This work presents a dataset collected to predict cybersickness in virtual reality environments. The data was collected from navigation tasks in a virtual environment designed to induce cybersickness. The dataset consists of many data points collected from diverse participants, including physiological responses (EDA and Heart Rate) and self-reported cybersickness symptoms. The paper will provide a detailed description of the dataset, including the arranged navigation task, the data collection procedures, and the data format. The dataset will serve as a valuable resource for researchers to develop and evaluate predictive models for cybersickness and will facilitate more research in cybersickness mitigation.", "IdName": "wang2023dataset", "Citation": "", "Keywords": ""}, {"Name": "Fairness-Aware Algorithms for Seed Allocation in Social Advertising", "Authors": ["Pengzi Wang", "Yiming Zhu", "Kai Han", "Zhizhuo Yin", "Qing Xiu", "Pan Hui"], "Sources": "2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "As a crucial and widely researched application in social networks, social advertising refers to selecting seed users for several advertisers to propagate their advertisements in the network via a information cascade effect. Prior studies on this topic have presented approximation algorithms merely for maximizing the expected revenue. However, regarding to the fairness issue, no existing works have provided effective solution. Such a issue would cause polarized revenues among different advertisers and the draining of them. In this paper, we investigate the fairness issue in social advertising. That is, how the social network platform owner distributes seeds users fairly to different advertisers. We define the fairness metric according to the maximin share, a concept about fair distribution in computation economics, and develop a novel approximation algorithm. Our approach achieves an approximation factor of   , where  ?\u2026", "IdName": "wang2022fairness", "Citation": "", "Keywords": ""}, {"Name": "Federated split GANs for collaborative training with heterogeneous devices", "Authors": ["Yilei Liang", "Pranvera Korto?i", "Pengyuan Zhou", "Lik-Hang Lee", "Abbas Mehrabi", "Pan Hui", "Sasu Tarkoma", "Jon Crowcroft"], "Sources": "Software Impacts 14", "PublishedYears": "2022", "Doi": "", "Abstracts": "Applications based on machine learning (ML) are greatly facilitated by mobile devices and their enormous volume and variety of data. To better safeguard the privacy of user data, traditional ML techniques have transitioned toward new paradigms like federated learning (FL) and split learning (SL). However, existing frameworks have overlooked device heterogeneity, greatly hindering their applicability in practice. In order to address such limitations, we developed a framework based on both FL and SL to share the training load of the discriminative part of a GAN to different client devices. We make our framework available as open-source software1.", "IdName": "liang2022federated", "Citation": "", "Keywords": ""}, {"Name": "Intelligent Decision Making Based on the Combination of Deep Reinforcement Learning and an Influence Map", "Authors": ["Xiaofeng Lu", "Ao Xue", "Pietro Lio", "Pan Hui"], "Sources": "Applied Sciences", "PublishedYears": "2022", "Doi": "", "Abstracts": "Almost all recent deep reinforcement learning algorithms use four consecutive frames as the state space to retain the dynamic information. If the training state data constitute an image, the state space is used as the input of the neural network for training. As an AI-assisted decision-making technology, a dynamic influence map can describe dynamic information. In this paper, we propose the use of a frame image superimposed with an influence map as the state space to express dynamic information. Herein, we optimize Ape-x as a distributed reinforcement learning algorithm. Sparse reward is an issue that must be solved in refined intelligent decision making. The use of an influence map is proposed to generate the intrinsic reward when there is no external reward. The experiments conducted in this study prove that the combination of a dynamic influence map and deep reinforcement learning is effective. Compared with the traditional method that uses four consecutive frames to represent dynamic information, the score of the proposed method is increased by 11\u201313%, the training speed is increased by 59%, the video memory consumption is reduced by 30%, and the memory consumption is reduced by 50%. The proposed method is compared with the Ape-x algorithm without an influence map, DQN, N-Step DQN, QR-DQN, Dueling DQN, and C51. The experimental results show that the final score of the proposed method is higher than that of the compared baseline methods. In addition, the influence map is used to generate an intrinsic reward to effectively resolve the sparse reward problem.", "IdName": "lu2022intelligent", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical Multi-agent Model for Reinforced Medical Resource Allocation with Imperfect Information", "Authors": ["Qianyue Hao", "Fengli Xu", "Lin Chen", "Pan Hui", "Yong Li"], "Sources": "ACM Transactions on Intelligent Systems and Technology", "PublishedYears": "2022", "Doi": "", "Abstracts": "With the advent of the COVID-19 pandemic, the shortage in medical resources became increasingly more evident. Therefore, efficient strategies for medical resource allocation are urgently needed. However, conventional rule-based methods employed by public health experts have limited capability in dealing with the complex and dynamic pandemic-spreading situation. In addition, model-based optimization methods such as dynamic programming (DP) fail to work since we cannot obtain a precise model in real-world situations most of the time. Model-free reinforcement learning (RL) is a powerful tool for decision-making; however, three key challenges exist in solving this problem via RL: (1) complex situations and countless choices for decision-making in the real world; (2) imperfect information due to the latency of pandemic spreading; and (3) limitations on conducting experiments in the real world since we?\u2026", "IdName": "hao2022hierarchical", "Citation": "", "Keywords": ""}, {"Name": "Composition and configuration patterns in multiple-view visualizations", "Authors": ["Xi Chen", "Wei Zeng", "Yanna Lin", "Hayder Mahdi Ai-Maneea", "Jonathan Roberts", "Remco Chang"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Multiple-view visualization (MV) is a layout design technique often employed to help users see a large number of data attributes and values in a single cohesive representation. Because of its generalizability, the MV design has been widely adopted by the visualization community to help users examine and interact with large, complex, and high-dimensional data. However, although ubiquitous, there has been little work to categorize and analyze MVs in order to better understand its design space. As a result, there has been little to no guideline in how to use the MV design effectively. In this paper, we present an in-depth study of how MVs are designed in practice. We focus on two fundamental measures of multiple-view patterns: composition, which quantifies what view types and how many are there, and configuration, which characterizes spatial arrangement of view layouts in the display space. We build a new?\u2026", "IdName": "chen2020composition", "Citation": "", "Keywords": ""}, {"Name": "Revisiting the modifiable areal unit problem in deep traffic prediction with visual analytics", "Authors": ["Wei Zeng", "Chengqiao Lin", "Juncong Lin", "Jincheng Jiang", "Jiazhi Xia", "Cagatay Turkay", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a  Bivariate Map  equipped with an?\u2026", "IdName": "zeng2020revisiting", "Citation": "", "Keywords": ""}, {"Name": "VIStory: interactive storyboard for exploring visual information in scientific publications", "Authors": ["Wei Zeng", "Ao Dong", "Xi Chen", "Zhang-lin Cheng"], "Sources": "Journal of visualization", "PublishedYears": "2021", "Doi": "", "Abstracts": "Many visual analytics have been developed for examining scientific publications comprising wealthy data such as authors and citations. The studies provide unprecedented insights on a variety of applications, e.g., literature review and collaboration analysis. However, visual information (i.e., figures) that are widely employed for storytelling and methods description are often neglected. We present VIStory, an interactive storyboard for exploring visual information in scientific publications. We harvest the data using an automatic figure extraction method, resulting in a large corpora of figures. Each figure contains various attributes such as dominant color and width/height ratio, together with faceted metadata of the publication including venues, authors, and keywords. To depict these information, we develop an intuitive interface consisting of three components: 1) Faceted View enables efficient query by publication?\u2026", "IdName": "dong2019vistory", "Citation": "", "Keywords": ""}, {"Name": "VISAtlas: An image-based exploration and query system for large visualization collections via neural image embedding", "Authors": ["Yilin Ye", "Rong Huang", "Wei Zeng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "High-quality visualization collections are beneficial for a variety of applications including visualization reference and data-driven visualization design. The visualization community has created many visualization collections, and developed interactive exploration systems for the collections. However, the systems are mainly based on extrinsic attributes like authors and publication years, whilst neglect intrinsic property ( i.e ., visual appearance) of visualizations, hindering visual comparison and query of visualization designs. This paper presents  VISAtlas , an image-based approach empowered by neural image embedding, to facilitate exploration and query for visualization collections. To improve embedding accuracy, we create a comprehensive collection of synthetic and real-world visualizations, and use it to train a convolutional neural network (CNN) model with a triplet loss for taxonomical classification of?\u2026", "IdName": "ye2022visatlas", "Citation": "", "Keywords": ""}, {"Name": "UrbanVR: An immersive analytics system for context-aware urban design", "Authors": ["Chi Zhang", "Wei Zeng", "Ligang Liu"], "Sources": "Computers & Graphics 99", "PublishedYears": "2021", "Doi": "", "Abstracts": "Urban design is a highly visual discipline that requires visualization for informed decision making. However, traditional urban design tools are mostly limited to representations on 2D displays that lack intuitive awareness. The popularity of head-mounted displays (HMDs) promotes a promising alternative with consumer-grade 3D displays. We introduce UrbanVR, an immersive analytics system with effective visualization and interaction techniques, to enable architects to assess designs in a virtual reality (VR) environment. Specifically, UrbanVR incorporates 1) a customized parallel coordinates plot (PCP) design to facilitate quantitative assessment of high-dimensional design metrics, 2) a series of egocentric interactions, including gesture interactions and handle-bar metaphors, to facilitate user interactions, and 3) a viewpoint optimization algorithm to help users explore both the PCP for quantitative analysis, and?\u2026", "IdName": "zhang2021urbanvr", "Citation": "", "Keywords": ""}, {"Name": "ActFloor-GAN: activity-guided adversarial networks for human-centric floorplan design", "Authors": ["Shidong Wang", "Wei Zeng", "Xi Chen", "Yu Ye", "Yu Qiao", "Chi-Wing Fu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2021", "Doi": "", "Abstracts": "We present a novel two-stage approach for automated floorplan design in residential buildings with a given exterior wall boundary. Our approach has the unique advantage of being human-centric, that is, the generated floorplans can be geometrically plausible, as well as topologically reasonable to enhance resident interaction with the environment. From the input boundary, we first synthesize a human-activity map that reflects both the spatial configuration and human-environment interaction in an architectural space. We propose to produce the human-activity map either automatically by a pre-trained generative adversarial network (GAN) model, or semi-automatically by synthesizing it with user manipulation of the furniture. Second, we feed the human-activity map into our deep framework  ActFloor-GAN  to guide a pixel-wise prediction of room types. We adopt a re-formulated cycle-consistency constraint in?\u2026", "IdName": "wang2021actfloor", "Citation": "", "Keywords": ""}, {"Name": "Effects of view layout on situated analytics for multiple-view representations in immersive visualization", "Authors": ["Zhen Wen", "Wei Zeng", "Luoxuan Weng", "Yihan Liu", "Mingliang Xu", "Wei Chen"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Multiple-view (MV) representations enabling multi-perspective exploration of large and complex data are often employed on 2D displays. The technique also shows great potential in addressing complex analytic tasks in immersive visualization. However, although useful, the design space of MV representations in immersive visualization lacks in deep exploration. In this paper, we propose a new perspective to this line of research, by examining the effects of view layout for MV representations on situated analytics. Specifically, we disentangle situated analytics in perspectives of  situatedness  regarding spatial relationship between visual representations and physical referents, and  analytics  regarding cross-view data analysis including filtering, refocusing, and connecting tasks. Through an in-depth analysis of existing layout paradigms, we summarize design trade-offs for achieving high situatedness and effective?\u2026", "IdName": "wen2022effects", "Citation": "", "Keywords": ""}, {"Name": "SD-seq2seq: a deep learning model for bus bunching prediction based on smart card data", "Authors": ["Zengyang Gong", "Bo Du", "Zhidan Liu", "Wei Zeng", "Pascal Perez", "Kaishun Wu"], "Sources": "2020 29th International Conference on Computer Communications and Networks?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Bus bunching, a phenomenon due to the failure of headway or timetable adherence, often causes low level of public transit service with poor bus on-time performance and excessive passenger waiting time. To mitigate bus bunching, an accurate and real-time prediction method plays an important role. In this paper, we propose a supply-demand seq2seq model called SD-seq2seq to predict bus bunching using smart card data. Features from both supply and demand sides of bus service are taken into account, like bus stop type, dwelling time, passenger demand and type, and so on. Extensive experiments on multiple bus routes in real world demonstrate that our method outperforms other baseline methods. The proposed method is expected to provide useful online information of bus operation to both bus operators and passengers.", "IdName": "gong2020sd", "Citation": "", "Keywords": ""}, {"Name": "Exemplar-based layout fine-tuning for node-link diagrams", "Authors": ["Jiacheng Pan", "Wei Chen", "Xiaodong Zhao", "Shuyue Zhou", "Wei Zeng", "Minfeng Zhu", "Jian Chen", "Siwei Fu", "Yingcai Wu"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2020", "Doi": "", "Abstracts": "We design and evaluate a novel layout fine-tuning technique for node-link diagrams that facilitates exemplar-based adjustment of a group of substructures in batching mode. The key idea is to transfer user modifications on a local substructure to other substructures in the entire graph that are topologically similar to the exemplar. We first precompute a canonical representation for each substructure with node embedding techniques and then use it for on-the-fly substructure retrieval. We design and develop a light-weight interactive system to enable intuitive adjustment, modification transfer, and visual graph exploration. We also report some results of quantitative comparisons, three case studies, and a within-participant user study.", "IdName": "pan2020exemplar", "Citation": "", "Keywords": ""}, {"Name": "Deep recognition of vanishing-point-constrained building planes in urban street views", "Authors": ["Zhiliang Zeng", "Mengyang Wu", "Wei Zeng", "Chi-Wing Fu"], "Sources": "IEEE Transactions on Image Processing 29", "PublishedYears": "2020", "Doi": "", "Abstracts": "This paper presents a new approach to recognizing vanishing-point-constrained building planes from a single image of street view. We first design a novel convolutional neural network (CNN) architecture that generates geometric segmentation of per-pixel orientations from a single street-view image. The network combines two-stream features of general visual cues and surface normals in gated convolution layers, and employs a deeply supervised loss that encapsulates multi-scale convolutional features. Our experiments on a new benchmark with fine-grained plane segmentations of real-world street views show that our network outperforms state-of-the-arts methods of both semantic and geometric segmentation. The pixel-wise segmentation exhibits coarse boundaries and discontinuities. We then propose to rectify the pixel-wise segmentation into perspectively-projected quads based on spatial proximity between?\u2026", "IdName": "zeng2020deep", "Citation": "", "Keywords": ""}, {"Name": "Modeling spatial nonstationarity via deformable convolutions for deep traffic flow prediction", "Authors": ["Wei Zeng", "Chengqiao Lin", "Kang Liu", "Juncong Lin", "Anthony KH Tung"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Deep neural networks are being increasingly used for short-term traffic flow prediction, which can be generally categorized as convolutional (CNNs) or graph neural networks (GNNs). CNNs are preferable for region-wise traffic prediction by taking advantage of localized spatial correlations, whilst GNNs achieves better performance for graph-structured traffic data. When applied to region-wise traffic prediction, CNNs typically partition an underlying territory into grid-like spatial units, and employ standard convolutions to learn spatial dependence among the units. However, standard convolutions with fixed geometric structures cannot fully model the nonstationary characteristics of local traffic flows. To overcome the deficiency, we introduce deformable convolution that augments the spatial sampling locations with additional offsets, to enhance the modeling capability of spatial nonstationarity. On this basis, we design a?\u2026", "IdName": "zeng2021modeling", "Citation": "", "Keywords": ""}, {"Name": "Let the chart spark: Embedding semantic context into chart with text-to-image generative model", "Authors": ["Shishi Xiao", "Suizi Huang", "Yue Lin", "Yilin Ye", "Wei Zeng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose  ChartSpark , a novel system that embeds semantic context into chart based on text-to-image generative models.  ChartSpark  generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground?\u2026", "IdName": "xiao2023let", "Citation": "", "Keywords": ""}, {"Name": "Creative and progressive interior color design with eye-tracked user preference", "Authors": ["Shihui Guo", "Yubin Shi", "Pintong Xiao", "Yinan Fu", "Juncong Lin", "Wei Zeng", "Tong-Yee Lee"], "Sources": "ACM transactions on computer-human interaction", "PublishedYears": "2023", "Doi": "", "Abstracts": "Interior scene colorization is vastly demanded in areas such as personalized architecture design. Existing works either require manual efforts to colorize individual objects or conform to fixed color patterns automatically learned from prior knowledge, whilst neglecting user preference. Quantitatively identifying user preferences is challenging, particularly at the early stage of the design process. The 3D setup also presents new challenges as the inhabitant can observe from any possible viewpoint. We propose a representative view selection method based on visual attention and a progressive preference inference model. We particularly focus on the progressive integration of eye-tracked user preference, which enables the assistance in creativity support and allows the possibility of convergent thinking. A series of user studies have been conducted to validate the effectiveness of the proposed view selection method?\u2026", "IdName": "guo2023creative", "Citation": "", "Keywords": ""}, {"Name": "Modeling layout design for multiple-view visualization via Bayesian inference", "Authors": ["Lingdan Shao", "Zhe Chu", "Xi Chen", "Yanna Lin", "Wei Zeng"], "Sources": "Journal of Visualization", "PublishedYears": "2021", "Doi": "", "Abstracts": "Layout design for multiple-view visualization (MV) concerns primarily how to arrange views in layouts that are geometrically and topologically plausible. Guidelines for MV layout design suggest considerations on various design factors, including view (e.g., bar and line charts), viewport (e.g., mobile vs. desktop), and coordination (e.g., exploration vs. comparison), along with expertise and preference of the designer. Recent studies have revealed the diverse space of MV layout design via statistical analysis on empirical MVs, yet neglect the effects of those design factors. To address the gap, this work proposes to model the effects of design factors on MV layouts via Bayesian probabilistic inference. Specifically, we access three important properties of MV layout, i.e., maximum area ratio and weighted average aspect ratio as geometric metrics, and layout topology as a topological metric. We update the posterior?\u2026", "IdName": "shao2021modeling", "Citation": "", "Keywords": ""}, {"Name": "Semi-automatic layout adaptation for responsive multiple-view visualization design", "Authors": ["Wei Zeng", "Xi Chen", "Yihan Hou", "Lingdan Shao", "Zhe Chu", "Remco Chang"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Multiple-view (MV) visualizations have become ubiquitous for visual communication and exploratory data visualization. However, most existing MV visualizations are designed for the desktop, which can be unsuitable for the continuously evolving displays of varying screen sizes. In this paper, we present a two-stage adaptation framework that supports the automated retargeting and semi-automated tailoring of a desktop MV visualization for rendering on devices with displays of varying sizes. First, we cast layout retargeting as an optimization problem and propose a simulated annealing technique that can automatically preserve the layout of multiple views. Second, we enable fine-tuning for the visual appearance of each view, using a rule-based auto configuration method complemented with an interactive interface for chart-oriented encoding adjustment. To demonstrate the feasibility and expressivity of our?\u2026", "IdName": "zeng2023semi", "Citation": "", "Keywords": ""}, {"Name": "WYTIWYR: A User Intent\u2010Aware Framework with Multi\u2010modal Inputs for Visualization Retrieval", "Authors": ["Shishi Xiao", "Yihan Hou", "Cheng Jin", "Wei Zeng"], "Sources": "Computer Graphics Forum", "PublishedYears": "2023", "Doi": "", "Abstracts": " Retrieving charts from a large corpus is a fundamental task that can benefit numerous applications such as visualization recommendations. The retrieved results are expected to conform to both explicit visual attributes (e.g., chart type, colormap) and implicit user intents (e.g., design style, context information) that vary upon application scenarios. However, existing example\u2010based chart retrieval methods are built upon non\u2010decoupled and low\u2010level visual features that are hard to interpret, while definition\u2010based ones are constrained to pre\u2010defined attributes that are hard to extend. In this work, we propose a new framework, namely WYTIWYR (What\u2010You\u2010Think\u2010Is\u2010What\u2010You\u2010Retrieve), that integrates user intents into the chart retrieval process. The framework consists of two stages: first, the Annotation stage disentangles the visual attributes within the query chart, and second, the Retrieval stage embeds the user's?\u2026", "IdName": "xiao2023wytiwyr", "Citation": "", "Keywords": ""}, {"Name": "VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance through Large Language Models", "Authors": ["Zhan Wang", "Linping Yuan", "Liangwei Wang", "Bingchuan Jiang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2401.11923", "PublishedYears": "2024", "Doi": "", "Abstracts": "Tour guidance in virtual museums encourages multi-modal interactions to boost user experiences, concerning engagement, immersion, and spatial awareness. Nevertheless, achieving the goal is challenging due to the complexity of comprehending diverse user needs and accommodating personalized user preferences. Informed by a formative study that characterizes guidance-seeking contexts, we establish a multi-modal interaction design framework for virtual tour guidance. We then design VirtuWander, a two-stage innovative system using domain-oriented large language models to transform user inquiries into diverse guidance-seeking contexts and facilitate multi-modal interactions. The feasibility and versatility of VirtuWander are demonstrated with virtual guiding examples that encompass various touring scenarios and cater to personalized preferences. We further evaluate VirtuWander through a user study?\u2026", "IdName": "wang2024virtuwander", "Citation": "", "Keywords": ""}, {"Name": "FloorLevel-Net: recognizing floor-level lines with height-attention-guided multi-task learning", "Authors": ["Mengyang Wu", "Wei Zeng", "Chi-Wing Fu"], "Sources": "IEEE Transactions on Image Processing 30", "PublishedYears": "2021", "Doi": "", "Abstracts": "The ability to recognize the position and order of the floor-level lines that divide adjacent building floors can benefit many applications, for example, urban augmented reality (AR). This work tackles the problem of locating floor-level lines in street-view images, using a supervised deep learning approach. Unfortunately, very little data is available for training such a network - current street-view datasets contain either semantic annotations that lack geometric attributes, or rectified facades without perspective priors. To address this issue, we first compile a new dataset and develop a new data augmentation scheme to synthesize training samples by harassing (i) the rich semantics of existing rectified facades and (ii) perspective priors of buildings in diverse street views. Next, we design FloorLevel-Net, a multi-task learning network that associates explicit features of building facades and implicit floor-level lines, along with?\u2026", "IdName": "wu2021floorlevel", "Citation": "", "Keywords": ""}, {"Name": "C2Ideas: Supporting Creative Interior Color Design Ideation with a Large Language Model", "Authors": ["Yihan Hou", "Manling Yang", "Hao Cui", "Lei Wang", "Jie Xu", "Wei Zeng"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Interior color design is a creative process that endeavors to allocate colors to furniture and other elements within an interior space. While much research focuses on generating realistic interior designs, these automated approaches often misalign with user intention and disregard design rationales. Informed by a need-finding preliminary study, we develop C2Ideas, an innovative system for designers to creatively ideate color schemes enabled by an intent-aligned and domain-oriented large language model. C2Ideas integrates a three-stage process: Idea Prompting stage distills user intentions into color linguistic prompts, Word-Color Association stage transforms the prompts into semantically and stylistically coherent color schemes, and Interior Coloring stage assigns colors to interior elements complying with design principles. We also develop an interactive interface that enables flexible user refinement and?\u2026", "IdName": "hou2024c2ideas", "Citation": "", "Keywords": ""}, {"Name": "TypeDance: Creating semantic typographic logos from image through personalized generation", "Authors": ["Shishi Xiao", "Liangwei Wang", "Xiaojuan Ma", "Wei Zeng"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Semantic typographic logos harmoniously blend typeface and imagery to represent semantic concepts while maintaining legibility. Conventional methods using spatial composition and shape substitution are hindered by the conflicting requirement for achieving seamless spatial fusion between geometrically dissimilar typefaces and semantics. While recent advances made AI generation of semantic typography possible, the end-to-end approaches exclude designer involvement and disregard personalized design. This paper presents TypeDance, an AI-assisted tool incorporating design rationales with the generative model for personalized semantic typographic logo design. It leverages combinable design priors extracted from uploaded image exemplars and supports type-imagery mapping at various structural granularity, achieving diverse aesthetic designs with flexible control. Additionally, we instantiate a?\u2026", "IdName": "xiao2024typedance", "Citation": "", "Keywords": ""}, {"Name": "The contemporary art of image search: Iterative user intent expansion via vision-language model", "Authors": ["Yilin Ye", "Qian Zhu", "Shishi Xiao", "Kang Zhang", "Wei Zeng"], "Sources": "Proceedings of the ACM on Human-Computer Interaction", "PublishedYears": "2024", "Doi": "", "Abstracts": "Image search is an essential and user-friendly method to explore vast galleries of digital images. However, existing image search methods heavily rely on proximity measurements like tag matching or image similarity, requiring precise user inputs for satisfactory results. To meet the growing demand for a contemporary image search engine that enables accurate comprehension of users' search intentions, we introduce an innovative user intent expansion framework. Our framework leverages visual-language models to parse and compose multi-modal user inputs to provide more accurate and satisfying results. It comprises two-stage processes: 1) a parsing stage that incorporates a language parsing module with large language models to enhance the comprehension of textual inputs, along with a visual parsing module that integrates an interactive segmentation module to swiftly identify detailed visual elements?\u2026", "IdName": "ye2024contemporary", "Citation": "", "Keywords": ""}, {"Name": "Generative AI for visualization: State of the art and future directions", "Authors": ["Yilin Ye", "Jianing Hao", "Yihan Hou", "Zhan Wang", "Shishi Xiao", "Yuyu Luo", "Wei Zeng"], "Sources": "Visual Informatics", "PublishedYears": "2024", "Doi": "", "Abstracts": "Generative AI (GenAI) has witnessed remarkable progress in recent years and demonstrated impressive performance in various generation tasks in different domains such as computer vision and computational design. Many researchers have attempted to integrate GenAI into visualization framework, leveraging the superior generative capacity for different operations. Concurrently, recent major breakthroughs in GenAI like diffusion model and large language model have also drastically increase the potential of GenAI4VIS. From a technical perspective, this paper looks back on previous visualization studies leveraging GenAI and discusses the challenges and opportunities for future research. Specifically, we cover the applications of different types of GenAI methods including sequence, tabular, spatial and graph generation techniques for different tasks of visualization which we summarize into four major stages?\u2026", "IdName": "ye2024generative", "Citation": "", "Keywords": ""}, {"Name": "IntentTuner: An Interactive Framework for Integrating Human Intentions in Fine-tuning Text-to-Image Generative Models", "Authors": ["Xingchen Zeng", "Ziyao Gao", "Yilin Ye", "Wei Zeng"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Fine-tuning facilitates the adaptation of text-to-image generative models to novel concepts (e.g., styles and portraits), empowering users to forge creatively customized content. Recent efforts on fine-tuning focus on reducing training data and lightening computation overload but neglect alignment with user intentions, particularly in manual curation of multi-modal training data and intent-oriented evaluation. Informed by a formative study with fine-tuning practitioners for comprehending user intentions, we propose IntentTuner, an interactive framework that intelligently incorporates human intentions throughout each phase of the fine-tuning workflow. IntentTuner enables users to articulate training intentions with imagery exemplars and textual descriptions, automatically converting them into effective data augmentation strategies. Furthermore, IntentTuner introduces novel metrics to measure user intent alignment?\u2026", "IdName": "zeng2024intenttuner", "Citation": "", "Keywords": ""}, {"Name": "TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations", "Authors": ["Jianing Hao", "Qing Shi", "Yilin Ye", "Wei Zeng"], "Sources": "IEEE Transactions on Visualization and Computer Graphics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models. Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning. However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable. To improve on these limitations, this paper contributes a novel visual analytics framework, namely  TimeTuner , designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations. The system mainly consists of the following two-stage technique: We first leverage counterfactual?\u2026", "IdName": "hao2023timetuner", "Citation": "", "Keywords": ""}, {"Name": "Large-Scale Urban Multiple-Modal Transport Evacuation Model for Mass Gathering Events Considering Pedestrian and Public Transit System", "Authors": ["Jincheng Jiang", "Wei Tu", "Hui Kong", "Wei Zeng", "Rui Zhang", "Milan Konecny"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": "Mass gathering events occur frequently in urban regions. Not only serious traffic jams, but also safety risks are consequently caused. Although many evacuation strategies have been proposed, the spatiotemporal coordination issue of multiple-modal transport tools is not solved well to deal with the efficiency and safety risk during the traditional evacuations. This study presented a large-scale multi-modal transport macro-optimization evacuation model for urban mass gathering events. By taking full advantages of each kind of public transit vehicles and optimizing their spatiotemporal cooperation with pedestrian evacuation, our models can greatly improve the global evacuation efficiency. Experiments on a realistic event was carried to validate the proposed model. The numerical results demonstrated that, under the premise of no increasing additional vehicle supply, the efficiency of proposed multi-modal transport?\u2026", "IdName": "jiang2022large", "Citation": "", "Keywords": ""}, {"Name": "Make Interaction Situated: Designing User Acceptable Interaction for Situated Visualization in Public Environments", "Authors": ["Qian Zhu", "Zhuo Wang", "Wei Zeng", "Wai Tong", "Weiyue Lin", "Xiaojuan Ma"], "Sources": "Proceedings of the CHI Conference on Human Factors in Computing Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": " Situated visualization blends data into the real world to fulfill individuals\u2019 contextual information needs. However, interacting with situated visualization in public environments faces challenges posed by users\u2019 acceptance and contextual constraints. To explore appropriate interaction design, we first conduct a formative study to identify users\u2019 needs for data and interaction. Informed by the findings, we summarize appropriate interaction modalities with eye-based, hand-based and spatially-aware object interaction for situated visualization in public environments. Then, through an iterative design process with six users, we explore and implement interactive techniques for activating and analyzing with situated visualization. To assess the effectiveness and acceptance of these interactions, we integrate them into an AR prototype and conduct a within-subjects study in public scenarios using conventional hand-only?\u2026", "IdName": "zhu2024make", "Citation": "", "Keywords": ""}, {"Name": "Understanding the Impact of Referent Design on Scale Perception in Immersive Data Visualization", "Authors": ["Yihan Hou", "Hao Cui", "Rongrong Chen", "Wei Zeng"], "Sources": "Extended Abstracts of the CHI Conference on Human Factors in Computing?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": " Referents are often used to enhance scale perception in immersive visualizations. Common referent designs include the considerations of referent layout (side-by-side vs. in-situ) and referent size (small vs. medium vs. large). This paper introduces a controlled user study to assess how different referent designs affect the efficiency and accuracy of scale perception across different data scales, on the performance of the size-matching task in the virtual environment. Our results reveal that in-situ layouts significantly enhance accuracy and confidence across various data scales, particularly with large referents. Linear regression analyses further confirm that in-situ layouts exhibit greater resilience to changes in data scale. For tasks requiring efficiency, medium-sized referents emerge as the preferred choice. Based on these findings, we offer design guidelines for selecting referent layouts and sizes in immersive?\u2026", "IdName": "hou2024understanding", "Citation": "", "Keywords": ""}, {"Name": "Learning High-Quality Navigation and Zooming on Omnidirectional Images in Virtual Reality", "Authors": ["Zidong Cao", "Zhan Wang", "Yexin Liu", "Yan-Pei Cao", "Ying Shan", "Wei Zeng", "Lin Wang"], "Sources": "arXiv preprint arXiv:2405.00351", "PublishedYears": "2024", "Doi": "", "Abstracts": "Viewing omnidirectional images (ODIs) in virtual reality (VR) represents a novel form of media that provides immersive experiences for users to navigate and interact with digital content. Nonetheless, this sense of immersion can be greatly compromised by a blur effect that masks details and hampers the user's ability to engage with objects of interest. In this paper, we present a novel system, called OmniVR, designed to enhance visual clarity during VR navigation. Our system enables users to effortlessly locate and zoom in on the objects of interest in VR. It captures user commands for navigation and zoom, converting these inputs into parameters for the Mobius transformation matrix. Leveraging these parameters, the ODI is refined using a learning-based algorithm. The resultant ODI is presented within the VR media, effectively reducing blur and increasing user engagement. To verify the effectiveness of our system, we first evaluate our algorithm with state-of-the-art methods on public datasets, which achieves the best performance. Furthermore, we undertake a comprehensive user study to evaluate viewer experiences across diverse scenarios and to gather their qualitative feedback from multiple perspectives. The outcomes reveal that our system enhances user engagement by improving the viewers' recognition, reducing discomfort, and improving the overall immersive experience. Our system makes the navigation and zoom more user-friendly.", "IdName": "cao2024learning", "Citation": "", "Keywords": ""}, {"Name": "CheetahTraj: Efficient Visualization for Large Trajectory Dataset With Quality Guarantee", "Authors": ["Qiaomu Shen", "Chaozu Zhang", "Xiao Yan", "Chuan Yang", "Dan Zeng", "Wei Zeng", "Bo Tang"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2024", "Doi": "", "Abstracts": "Visualizing large-scale trajectory dataset is a core subroutine for many applications. However, rendering all trajectories could result in severe visual clutter and incur long visualization delays due to large data volume. Naively sampling the trajectories reduces visualization time but usually harms visual quality, i.e., the generated visualizations may look substantially different from the exact ones without sampling. In this paper, we propose CheetahTraj, a principled sampling framework that achieves both high visualization quality and low visualization latency. We first define the  visual quality function  measuring the similarity between two visualizations, based on which we formulate the quality optimal sampling problem (QOSP). To solve QOSP, we design the  V isual  Q uality  G uaranteed  S ampling algorithms, which reduce visual clutter while guaranteeing visual quality by considering both trajectory data distribution?\u2026", "IdName": "shen2024cheetahtraj", "Citation": "", "Keywords": ""}, {"Name": "Antarctica Storytelling: Creating Interactive Story Maps for Polar Regions with Graphic-Based Approach", "Authors": ["Liangwei Wang", "Zhan Wang", "Xi Zhao", "Fugee Tsung", "Wei Zeng"], "Sources": "None", "PublishedYears": "2024", "Doi": "", "Abstracts": "Although story maps have gained popularity for storytelling related to spatial information, existing story maps authoring tools often fall short in delivering diverse narrative forms and struggle to accurately render polar regions due to the limitations of tile-based mapping. In this work, we introduce a graphic-based method to address these challenges, developing a framework specifically designed for creating story maps for polar regions. Our key contribution lies in offering heuristic strategies for story map design, emphasizing their role in effectively visualizing and disseminating polar culture. This paper outlines essential design tasks for story map creation and introduces three pivotal narrative strategies: attention cue, linkage of map with other visual elements, and cartographic interaction. Additionally, we emphasize the significance of storyboard design, focusing on aspects such as logical sequencing, temporal order, map scale and granularity, and interactive design. To validate the effectiveness of our story map design framework, we develop several story map cases centered around the exploration history of Antarctica. These examples highlight the diversity and interactivity in the story maps produced through our methodology. Finally, we explore the challenges and limitations encountered in the process of creating story maps, and from these observations, we identify prospective areas for further research.", "IdName": "wang2024antarctica", "Citation": "", "Keywords": ""}, {"Name": "MetroBUX: A Topology-Based Visual Analytics for Bus Operational Uncertainty EXploration", "Authors": ["Shishi Xiao", "Qing Shi", "Lingdan Shao", "Bo Du", "Yang Wang", "Qiaomu Shen", "Wei Zeng"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "In the public transportation system, punctuality benefits both bus operation and passengers\u2019 travel experience. However, uncertainty exists due to complex traffic conditions and heterogeneous driving behaviors. To analyze bus operational uncertainty, transport planners and bus operators need a tool that supports multi-granular modeling, spatio-temporal representation, and interactive exploration. To meet the requirement, we present MetroBUX, a visual analytics system for     us operational     ncertainty e    ploration. MetroBUX aligns daily bus trips and models stop-level uncertainty of bus arrival time. It has a consolidated interface with three main views: Map View for presenting the spatial distribution of uncertainty, Temporal View for tracking the evolution of uncertainty, and Trip View for inspecting uncertainty propagation. Specifically, MetroBUX enables integrated spatio-temporal analysis by connecting?\u2026", "IdName": "xiao2024metrobux", "Citation": "", "Keywords": ""}, {"Name": "LOOP Meditation: Enhancing Novice's VR Meditation Experience with Physical Movement", "Authors": ["Shihan Fu", "Liangliang Qiang", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " Virtual reality (VR) and associated technologies have rapidly grew, creating new opportunities for improving mental health. In order to provide an immersive and concentrated meditation experience, this paper offers the idea of VR-assisted meditation, which integrates the advantages of VR technology with mindfulness techniques. The suggested technique, which is known as LOOP Meditation, is mainly aimed toward novice meditators and places a strong emphasis on the value of movement and breath awareness when meditating. Existing VR experiences and meditation applications sometimes ignore the value of including physical movement, which can improve mindful body sensations and maintain interest. By creating a software that incorporates body movement and breath sensing into virtual reality surroundings, LOOP Meditation addresses this gap. The LOOP Meditation design and implementation are?\u2026", "IdName": "fu2023loop", "Citation": "", "Keywords": ""}, {"Name": "Does Where You are Matter? A Visual Analytics System for COVID-19 Transmission Based on Social Hierarchical Perspective", "Authors": ["Jianing Hao", "Xibin Jiang", "Qing Shi", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " The COVID-19 pandemic requires multidisciplinary efforts to address its profound social and economic repercussions. Combining social hierarchical perspectives and a Multiple Coordinated View (MCV) visualization system, this paper depicts how social and physical residential environment shapes individuals\u2019 infection risk during such pandemic. Through analyzing the travel records of 8000+ confirmed cases in spatial and temporal channels, we identify that there exists segregation of virus transmission among different social classes and individuals from deprived neighborhoods exhibit a higher risk of the virus infection. Leveraging our proposed interactive visualization system, policymakers and stakeholders can make more informed decisions to effectively manage and contain the spread of infectious pandemics like COVID-19.", "IdName": "hao2023does", "Citation": "", "Keywords": ""}, {"Name": "The Rich, the Poor, and the Ugly: An Aesthetic-Perspective Assessment of NFT Values", "Authors": ["Yihan Chen", "Yilin Ye", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": " The adoption of non-fungible tokens (NFTs) has revolutionized digital art transactions, providing artists with unprecedented opportunities to tokenize and monetize their generative creations, leading to increased scrutiny and demand within blockchain-oriented marketplaces. The pricing of NFT artworks, however, exhibits substantial variations within and across collections, influenced by various factors. This study aims to investigate the relationship between visual features and pricing, shedding light on the variations underlying the pricing of NFTs. First, measures of both computational aesthetics and visual complexity were applied to extract multi-faceted visual aesthetic features, encompassing aesthetic factors such as color and composition as well as complexity factors like entropy. Second, with extracted visual aesthetic features and preprocessed price data, the study proceeds to conduct correlation analysis within?\u2026", "IdName": "chen2023rich", "Citation": "", "Keywords": ""}, {"Name": "Storytelling in Frozen Frontier: Exploring Graphic-Based Approach for Creating Interactive Story Maps in Antarctica", "Authors": ["Liangwei Wang", "Zhan Wang", "Xi Zhao", "Wei Zeng"], "Sources": "Proceedings of the 16th International Symposium on Visual Information?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Story maps have been widely utilized to provide a visual and spatial framework for storytelling. However, existing story map tools have limitations in creating diverse narrative structures and providing interactive options, and cannot effectively render maps for polar regions due to tile-based mapping constraints. In this paper, we propose a graphic-based approach to overcome these challenges and develop a workflow for creating story maps specifically designed for polar regions. A primary contribution is to provide heuristic strategies for story map design and explore the potential of story maps in visualizing and disseminating polar culture. We summarize the main design tasks involved in story map creation and introduce three map-based visual narrative strategies, i.e., attention cue, linkage of map and other visual elements, and cartographic interaction. Additionally, we delve into the importance of storyboard design?\u2026", "IdName": "wang2023storytelling", "Citation": "", "Keywords": ""}, {"Name": "Everyone Can Be Picasso? A Computational Framework into the Myth of Human versus AI Painting", "Authors": ["Yilin Ye", "Rong Huang", "Kang Zhang", "Wei Zeng"], "Sources": "arXiv preprint arXiv:2304.07999", "PublishedYears": "2023", "Doi": "", "Abstracts": "The recent advances of AI technology, particularly in AI-Generated Content (AIGC), have enabled everyone to easily generate beautiful paintings with simple text description. With the stunning quality of AI paintings, it is widely questioned whether there still exists difference between human and AI paintings and whether human artists will be replaced by AI. To answer these questions, we develop a computational framework combining neural latent space and aesthetics features with visual analytics to investigate the difference between human and AI paintings. First, with categorical comparison of human and AI painting collections, we find that AI artworks show distributional difference from human artworks in both latent space and some aesthetic features like strokes and sharpness, while in other aesthetic features like color and composition there is less difference. Second, with individual artist analysis of Picasso, we show human artists' strength in evolving new styles compared to AI. Our findings provide concrete evidence for the existing discrepancies between human and AI paintings and further suggest improvements of AI art with more consideration of aesthetics and human artists' involvement.", "IdName": "ye2023everyone", "Citation": "", "Keywords": ""}, {"Name": "Tensor completion for weakly-dependent data on graph for metro passenger flow prediction", "Authors": ["Ziyue Li", "Nurettin Dorukhan Sergin", "Hao Yan", "Chen Zhang", "Fugee Tsung"], "Sources": "proceedings of the AAAI conference on artificial intelligence", "PublishedYears": "2020", "Doi": "", "Abstracts": "Low-rank tensor decomposition and completion have attracted significant interest from academia given the ubiquity of tensor data. However, low-rank structure is a global property, which will not be fulfilled when the data presents complex and weak dependencies given specific graph structures. One particular application that motivates this study is the spatiotemporal data analysis. As shown in the preliminary study, weakly dependencies can worsen the low-rank tensor completion performance. In this paper, we propose a novel low-rank CANDECOMP/PARAFAC (CP) tensor decomposition and completion framework by introducing the L 1-norm penalty and Graph Laplacian penalty to model the weakly dependency on graph. We further propose an efficient optimization algorithm based on the Block Coordinate Descent for efficient estimation. A case study based on the metro passenger flow data in Hong Kong is conducted to demonstrate an improved performance over the regular tensor completion methods.", "IdName": "li2020tensor", "Citation": "", "Keywords": ""}, {"Name": "Nonparametric monitoring of multivariate data via KNN learning", "Authors": ["Wendong Li", "Chi Zhang", "Fugee Tsung", "Yajun Mei"], "Sources": "International Journal of Production Research", "PublishedYears": "2021", "Doi": "", "Abstracts": "Process monitoring of multivariate quality attributes is important in many industrial applications, in which rich historical data are often available thanks to modern sensing technologies. While multivariate statistical process control (SPC) has been receiving increasing attention, existing methods are often inadequate as they are sensitive to the parametric model assumptions of multivariate data. In this paper, we propose a novel, nonparametric k-nearest neighbours empirical cumulative sum (KNN-ECUSUM) control chart that is a machine-learning-based black-box control chart for monitoring multivariate data by utilising extensive historical data under both in-control and out-of-control scenarios. Our proposed method utilises the k-nearest neighbours (KNN) algorithm for dimension reduction to transform multivariate data into univariate data and then applies the CUSUM procedure to monitor the change on the empirical?\u2026", "IdName": "li2021nonparametric", "Citation": "", "Keywords": ""}, {"Name": "Spsequencenet: Semantic segmentation network on 4d point clouds", "Authors": ["Hanyu Shi", "Guosheng Lin", "Hao Wang", "Tzu-Yi Hung", "Zhenhua Wang"], "Sources": "Proceedings of the IEEE/CVF conference on computer vision and pattern?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Point clouds are useful in many applications like autonomous driving and robotics as they provide natural 3D information of the surrounding environments. While there are extensive research on 3D point clouds, scene understanding on 4D point clouds, a series of consecutive 3D point clouds frames, is an emerging topic and yet under-investigated. With 4D point clouds (3D point cloud videos), robotic systems could enhance their robustness by leveraging the temporal information from previous frames. However, the existing semantic segmentation methods on 4D point clouds suffer from low precision due to the spatial and temporal information loss in their network structures. In this paper, we propose SpSequenceNet to address this problem. The network is designed based on 3D sparse convolution. And we introduce two novel modules, a cross-frame global attention module and a cross-frame local interpolation module, to capture spatial and temporal information in 4D point clouds. We conduct extensive experiments on SemanticKITTI, and achieve the state-of-the-art result of 43.1% on mIoU, which is 1.5% higher than the previous best approach.", "IdName": "shi2020spsequencenet", "Citation": "", "Keywords": ""}, {"Name": "Long-short term spatiotemporal tensor prediction for passenger flow profile", "Authors": ["Ziyue Li", "Hao Yan", "Chen Zhang", "Fugee Tsung"], "Sources": "IEEE Robotics and Automation Letters", "PublishedYears": "2020", "Doi": "", "Abstracts": "Spatiotemporal data are very common in many applications, such as manufacturing systems and transportation systems. Given the intrinsic complex spatial and temporal correlations of such data, short-term and long-term prediction for spatiotemporal data is often very challenging. Most of the traditional statistical models fail to preserve innate features in data alongside their complex correlations. In this paper, we focus on a tensor-based prediction method and propose several practical techniques to improve both long-term and short-term prediction accuracy. For long-term prediction, we propose the \u201ctensor decomposition + 2-Dimensional Auto-Regressive Moving Average (2D-ARMA)\u201d model, and an effective way to update prediction in real-time; For short-term prediction, we propose to conduct tensor completion based on tensor clustering to avoid oversimplification and ensure accuracy. A case study based on the?\u2026", "IdName": "li2020long", "Citation": "", "Keywords": ""}, {"Name": "A hybrid transfer learning framework for in-plane freeform shape accuracy control in additive manufacturing", "Authors": ["Longwei Cheng", "Kai Wang", "Fugee Tsung"], "Sources": "IISE Transactions", "PublishedYears": "2020", "Doi": "", "Abstracts": "Shape accuracy control is one of the quality issues of greatest concern in Additive Manufacturing (AM). An efficient approach to improving the shape accuracy of a fabricated product is to compensate the fabrication errors of AM systems by modifying the input shape defined by a digital design model. In contrast with mass production, AM processes typically fabricate customized products with extremely low volume and huge shape varieties, which makes shape accuracy control in AM a challenging problem. In this article, we propose a hybrid transfer learning framework to predict and compensate the in-plane shape deviations of new and untried freeform products based on a small number of previously fabricated products. Within this framework, the shape deviation is decomposed into a shape-independent error and a shape-specific error. A parameter-based transfer learning approach is used to facilitate a sharing of?\u2026", "IdName": "cheng2020hybrid", "Citation": "", "Keywords": ""}, {"Name": "Configuration-based smart customization service: A multitask learning approach", "Authors": ["Yue Wang", "Xiang Li", "Fugee Tsung"], "Sources": "IEEE Transactions on Automation Science and Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "Smart customization service is an important element for smart manufacturing. The success of smart customization requires that designers, manufacturers, and customers with differences in context, semantics, and other cognitive aspects be engaged in a collaborative process. With product configurators reported to have positive impacts on product quality to meet customers' needs, this article attempts to explore an approach for smart customization service based on configurators. To better address the semantic gap between customers and designers/manufacturers, a new configuration mechanism is proposed that takes into consideration customer needs using natural language as the input and maps them to product specifications in the design stage. We collected a massive amount of review text from e-commerce websites and used ELMo, a contextualized word representation based on a deep bidirectional language?\u2026", "IdName": "wang2020configuration", "Citation": "", "Keywords": ""}, {"Name": "Individualized passenger travel pattern multi-clustering based on graph regularized tensor latent dirichlet allocation", "Authors": ["Ziyue Li", "Hao Yan", "Chen Zhang", "Fugee Tsung"], "Sources": "Data Mining and Knowledge Discovery", "PublishedYears": "2022", "Doi": "", "Abstracts": "Individual passenger travel patterns have significant value in understanding passenger\u2019s behavior, such as learning the hidden clusters of locations, time, and passengers. The learned clusters further enable commercially beneficial actions such as customized services, promotions, data-driven urban-use planning, peak hour discovery, and so on. However, the individualized passenger modeling is very challenging for the following reasons: 1) The individual passenger travel data are multi-dimensional spatiotemporal big data, including at least the origin, destination, and time dimensions; 2) Moreover, individualized passenger travel patterns usually depend on the external environment, such as the distances and functions of locations, which are ignored in most current works. This work proposes a multi-clustering model to learn the latent clusters along the multiple dimensions of Origin, Destination, Time, and?\u2026", "IdName": "li2022individualized", "Citation": "", "Keywords": ""}, {"Name": "Multi-sensor based landslide monitoring via transfer learning", "Authors": ["Wendong Li", "Fugee Tsung", "Zhenli Song", "Ke Zhang", "Dongdong Xiang"], "Sources": "Journal of Quality Technology", "PublishedYears": "2021", "Doi": "", "Abstracts": "Landslides are severe geographical activities that result in large quantities of rock and debris flowing down hill-slopes, leading to thousands of casualties and billions of dollars in infrastructure damage every year worldwide. For detecting landslides, on-site sensor systems are widely applied for data collection and many existing statistical process control methods can be adopted for modeling and monitoring. However, the conventional methods may perform poorly or even inapplicable when the sensors have different set-up times and end times, especially when the system includes newly deployed sensors with limited data collected. To make effective use of such new sensors immediately after deployment, we propose a novel multi-sensor based charting scheme for dynamic landslide modeling and monitoring by using transfer learning. A regularized parameter-based transfer learning approach integrated with the?\u2026", "IdName": "li2021multi", "Citation": "", "Keywords": ""}, {"Name": "Directional PCA for fast detection and accurate diagnosis: A unified framework", "Authors": ["Jian Li", "Dong Ding", "Fugee Tsung"], "Sources": "IEEE Transactions on Cybernetics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Many methods for monitoring multivariate processes are built on principal component analysis (PCA), which, however, simply tells whether the process is faulty or not. In fact, there is still room for the improvement of the early detection performance by exploiting fully the information given by fault directions. To this end, this article proposes a novel directional PCA (diPCA) approach. First, by narrowing down faults to a specified direction or composite mutually orthogonal directions, diPCA can speed fault detection and facilitate accurate fault diagnosis. It also has good theoretical properties that guarantee concise control limits. Second, with appropriate fault directions, diPCA provides a unified framework for process monitoring and includes existing monitoring indices, such as Hotelling\u2019s     and the squared prediction error (SPE), as special cases. Third, diPCA also naturally results in a new combined monitoring statistic?\u2026", "IdName": "li2021directional", "Citation": "", "Keywords": ""}, {"Name": "Bayesian cross-product quality control via transfer learning", "Authors": ["Kai Wang", "Fugee Tsung"], "Sources": "International Journal of Production Research", "PublishedYears": "2022", "Doi": "", "Abstracts": "Quality control is essential for modern business success. The traditional statistical process control (SPC), however, lacks efficacy in current high-variety low-volume industrial practices since the historical reference data in Phase I are usually too scarce to infer the in-control process parameters accurately. To solve this \u2018small data\u2019 challenge, a novel Bayesian process monitoring scheme via transfer learning is proposed to facilitate a cross-product data sharing. In particular, a joint prior distribution is taken to explicitly capture the relatedness between the process data of two similar products, through which the process information can be transferred from one product (source domain) to improve the Bayesian inference for the other product (target domain). The posteriors can be derived analytically in closed forms by using generalised hypergeometric functions, thereby leading to a computationally efficient control chart for?\u2026", "IdName": "wang2022bayesian", "Citation": "", "Keywords": ""}, {"Name": "Profile decomposition based hybrid transfer learning for cold-start data anomaly detection", "Authors": ["Ziyue Li", "Hao Yan", "Fugee Tsung", "Ke Zhang"], "Sources": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Anomaly detection is an essential task for quality management in smart manufacturing. An accurate data-driven detection method usually needs enough data and labels. However, in practice, there commonly exist newly set-up processes in manufacturing, and they only have quite limited data available for analysis. Borrowing the name from the recommender system, we call this process a cold-start process. The sparsity of anomaly, the deviation of the profile, and noise aggravate the detection difficulty. Transfer learning could help to detect anomalies for cold-start processes by transferring the knowledge from more experienced processes to the new processes. However, the existing transfer learning and multi-task learning frameworks are established on task- or domain-level relatedness. We observe instead, within a domain, some components (background and anomaly) share more commonality, others (profile?\u2026", "IdName": "li2022profile", "Citation": "", "Keywords": ""}, {"Name": "Optimal space-filling design for symmetrical global sensitivity analysis of complex black-box models", "Authors": ["Xiaodi Wang", "Fugee Tsung", "Wendong Li", "Dongdong Xiang", "Chao Cheng"], "Sources": "Applied Mathematical Modelling 100", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, a novel concept of optimal space-filling identifiable design is proposed in the framework of symmetrical global sensitivity analysis for exploring complex black-box models. The initial identifiable design is first generated algorithmically. Then based on two commonly used measures of space filling, the ? q and L 2-discrepancy criterions, two optimal space-filling identifiable designs are proposed. The corresponding optimization algorithms are also given, in which adjacent identifiable designs are produced sequentially by using track substitution until the space-filling property has been optimized. By using the resulting optimal space-filling identifiable design, symmetrical global sensitivity indices can be directly estimated based on model outputs with high precision. Extensive theoretical and numerical results demonstrate the optimality and effectiveness of the proposed designs, as well as the superiority?\u2026", "IdName": "wang2021optimal", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical sparse functional principal component analysis for multistage multivariate profile data", "Authors": ["Kai Wang", "Fugee Tsung"], "Sources": "IISE Transactions", "PublishedYears": "2021", "Doi": "", "Abstracts": "Modern manufacturing systems typically involve multiple production stages, the real-time status of which can be tracked continuously using sensor networks that generate a large number of profiles associated with all process variables at all stages. The analysis of the collective behavior of the multistage multivariate profile data is essential for understanding the variance patterns of the entire manufacturing process. For this purpose, two major challenges regarding the high data dimensionality and low model interpretability have to be well addressed. This article proposes integrating Multivariate Functional Principal Component Analysis (MFPCA) with a three-level structured sparsity idea to develop a novel Hierarchical Sparse MFPCA (HSMFPCA), in which the stage-wise, profile-wise and element-wise sparsity are jointly investigated to clearly identify the informative stages and variables in each eigenvector. In this?\u2026", "IdName": "wang2021hierarchical", "Citation": "", "Keywords": ""}, {"Name": "Transformer based spatial-temporal fusion network for metro passenger flow forecasting", "Authors": ["Weiqi Zhang", "Chen Zhang", "Fugee Tsung"], "Sources": "2021 IEEE 17th International Conference on Automation Science and?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Passenger flow forecasting is a very critical task for the daily operations of metro system. The rapid development of deep learning methods offers us an opportunity to give an end-to-end solution to system-level prediction. However, complex spatial-temporal correlations of passenger flow data makes it quite challenging. Existing studies tend to model spatial and temporal correlations separately, which may lead to information loss and unsatisfactory prediction performance. Meanwhile, they cannot take full advantage of human knowledge and external information, such as geographical information, metro map information, etc, for modeling. To bridge the research gap, in this study, we propose a well-designed transformer based spatial-temporal fusion network (TSTFN). To cooperate with different types of external information and give additional insights, we first use multiple pre-defined graph structures to construct multi?\u2026", "IdName": "zhang2021transformer", "Citation": "", "Keywords": ""}, {"Name": "Wiener graph deconvolutional network improves graph self-supervised learning", "Authors": ["Jiashun Cheng", "Man Li", "Jia Li", "Fugee Tsung"], "Sources": "Proceedings of the AAAI conference on artificial intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph self-supervised learning (SSL) has been vastly employed to learn representations from unlabeled graphs. Existing methods can be roughly divided into predictive learning and contrastive learning, where the latter one attracts more research attention with better empirical performance. We argue that, however, predictive models weaponed with powerful decoder could achieve comparable or even better representation power than contrastive models. In this work, we propose a Wiener Graph Deconvolutional Network (WGDN), an augmentation-adaptive decoder empowered by graph wiener filter to perform information reconstruction. Theoretical analysis proves the superior reconstruction ability of graph wiener filter. Extensive experimental results on various datasets demonstrate the effectiveness of our approach.", "IdName": "cheng2023wiener", "Citation": "", "Keywords": ""}, {"Name": "Handling missing data via max-entropy regularized graph autoencoder", "Authors": ["Ziqi Gao", "Yifan Niu", "Jiashun Cheng", "Jianheng Tang", "Lanqing Li", "Tingyang Xu", "Peilin Zhao", "Fugee Tsung", "Jia Li"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph neural networks (GNNs) are popular weapons for modeling relational data. Existing GNNs are not specified for attribute-incomplete graphs, making missing attribute imputation a burning issue. Until recently, many works notice that GNNs are coupled with spectral concentration, which means the spectrum obtained by GNNs concentrates on a local part in spectral domain, eg, low-frequency due to oversmoothing issue. As a consequence, GNNs may be seriously flawed for reconstructing graph attributes as graph spectral concentration tends to cause a low imputation precision. In this work, we present a regularized graph autoencoder for graph attribute imputation, named MEGAE, which aims at mitigating spectral concentration problem by maximizing the graph spectral entropy. Notably, we first present the method for estimating graph spectral entropy without the eigen-decomposition of Laplacian matrix and provide the theoretical upper error bound. A maximum entropy regularization then acts in the latent space, which directly increases the graph spectral entropy. Extensive experiments show that MEGAE outperforms all the other state-of-the-art imputation methods on a variety of benchmark datasets.", "IdName": "gao2023handling", "Citation": "", "Keywords": ""}, {"Name": "Robust attributed graph alignment via joint structure learning and optimal transport", "Authors": ["Jianheng Tang", "Weiqi Zhang", "Jiajin Li", "Kangfei Zhao", "Fugee Tsung", "Jia Li"], "Sources": "2023 IEEE 39th International Conference on Data Engineering (ICDE)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph alignment, which aims at identifying corresponding entities across multiple networks, has been widely applied in various domains. As the graphs to be aligned are usually constructed from different sources, the inconsistency issues of structures and features between two graphs are ubiquitous in real-world applications. Most existing methods follow the \"embed-then-cross-compare\" paradigm which computes node embeddings in each graph and then processes node correspondences based on cross-graph embedding comparison. However, we find these methods are unstable and sub-optimal when structure or feature inconsistency appears. To this end, we propose SLOTAlign, an unsupervised graph alignment framework that jointly performs Structure Learning and Optimal Transport Alignment. We convert graph alignment to an optimal transport problem between two intra-graph matrices without the?\u2026", "IdName": "tang2023robust", "Citation": "", "Keywords": ""}, {"Name": "A risk-adjusted approach to monitoring surgery for survival outcomes based on a weighted score test", "Authors": ["Xin Lai", "Xiao Li", "Liu Liu", "Fugee Tsung", "Paul BS Lai", "Jiayin Wang", "Xuanping Zhang", "Xiaoyan Zhu", "Jiaqi Liu"], "Sources": "Computers & Industrial Engineering 160", "PublishedYears": "2021", "Doi": "", "Abstracts": "In programs monitoring surgical quality, risk-adjusted control charts have been used widely to detect changes in surgical performance. Ignoring the survival time may lead to information loss and thus attenuate the monitoring efficiency. However, previous methods based on survival time information only focus on detecting the change in average risk. The stability of surgical performance measured by scale parameters could be of interest in monitoring. In this study, we extend the risk-adjusted monitoring approach to include survival outcomes, in which both the location and scale parameters are monitored simultaneously. Based on the weighted score test for the Cox model, we propose to use an exponentially weighted moving average chart to monitor changes in average surgical risk and the existence of its variance, which could be of interest in practical surgical monitoring programs. Simulation results indicate that?\u2026", "IdName": "lai2021risk", "Citation": "", "Keywords": ""}, {"Name": "Fault classification for high\u2010dimensional data streams: A directional diagnostic framework based on multiple hypothesis testing", "Authors": ["Dongdong Xiang", "Wendong Li", "Fugee Tsung", "Xiaolong Pu", "Yicheng Kang"], "Sources": "Naval Research Logistics (NRL)", "PublishedYears": "2021", "Doi": "", "Abstracts": " In various modern statistical process control applications that involve high\u2010dimensional data streams (HDDS), accurate fault diagnosis of out\u2010of\u2010control (OC) streams is becoming crucial. The existing diagnostic approaches either focus on moderate\u2010dimensional processes or are unable to determine the shift direction accurately, especially when the signal\u2010to\u2010noise ratio is low. In this paper, we conduct a bold trial and consider the fault classification problem of the mean vector of HDDS where determining the shift direction of the OC streams is important to perform customized repairs. To this end, under the basic assumptions that the in\u2010control data streams are normal with mean 0 and variance 1, and that the high\u2010dimensional observations after the alarm are solely OC, the problem is formulated into a three\u2010classification multiple testing framework, and an efficient data\u2010driven diagnostic procedure is developed to?\u2026", "IdName": "xiang2021fault", "Citation": "", "Keywords": ""}, {"Name": "Change detection in parametric multivariate dynamic data streams using the ARMAX-GARCH model", "Authors": ["Miaomiao Yu", "Chunjie Wu", "Fugee Tsung"], "Sources": "Journal of Quality Technology", "PublishedYears": "2022", "Doi": "", "Abstracts": "Dynamic data detection is one of the main concerns in the statistical process control (SPC) field. Here we focus on monitoring parametric multivariate dynamic data streams using the ARMAX-GARCH model, which reflects both the influence of exogenous variables on the mean vector and the heterogeneity of the covariance matrix. A quasi maximum likelihood estimator is used to estimate the parameter vector of a dynamic process, and a top-r control scheme is proposed to monitor the parameters of multi-dimensional data streams. Finally, a real-data example of monitoring landslide illustrates the superiorities of the proposed scheme.", "IdName": "yu2022change", "Citation": "", "Keywords": ""}, {"Name": "Sparse and robust multivariate functional principal component analysis for passenger flow pattern discovery in metro systems", "Authors": ["Kai Wang", "Fugee Tsung"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2021", "Doi": "", "Abstracts": "Modern metro systems in big cities have accumulated large amounts of passenger transit transaction data via the deployment of automatic fare collection (AFC) devices, which could facilitate a thorough analysis of passenger flow dynamics. To discover the underlying passenger flow patterns over all stations in an entire metro system, this paper proposes a multivariate functional principal component analysis (MFPCA) method. The functional integrity of a single daily passenger flow profile at each station is explicitly utilized, and the complex correlation among a multitude of daily passenger flow profiles from all stations is comprehensively modeled. Moreover, to simultaneously improve the interpretability of eigenvectors and mitigate the sensitivity to outliers, the MFPCA is formulated as a minimization problem with both a sparsity and a robustness penalty term. A computationally efficient algorithm is developed?\u2026", "IdName": "wang2021sparse", "Citation": "", "Keywords": ""}, {"Name": "Correlated time series self-supervised representation learning via spatiotemporal bootstrapping", "Authors": ["Luxuan Wang", "Lei Bai", "Ziyue Li", "Rui Zhao", "Fugee Tsung"], "Sources": "2023 IEEE 19th International Conference on Automation Science and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Correlated time series analysis plays an important role in many real-world industries. Learning an efficient representation of this large-scale data for further downstream tasks is necessary but challenging. In this paper, we propose a time-step-level representation learning framework for individual instances via bootstrapped spatiotemporal representation prediction. We evaluated the effectiveness and flexibility of our representation learning framework on correlated time series forecasting and cold-start transferring the forecasting model to new instances with limited data. A linear regression model trained on top of the learned representations demonstrates our model performs best in most cases. Especially compared to representation learning models, we reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset, respectively. Furthermore, in real-world metro passenger flow data, our?\u2026", "IdName": "wang2023correlated", "Citation": "", "Keywords": ""}, {"Name": "Real-time monitoring and diagnosis scheme for IoT-enabled devices using multivariate SPC techniques", "Authors": ["Zhenyu Wu", "Yanting Li", "Fugee Tsung", "Ershun Pan"], "Sources": "IISE Transactions", "PublishedYears": "2023", "Doi": "", "Abstracts": "This article is aimed at condition monitoring and fault identification for Internet of Things (IoT) devices, and proposes a multivariate statistical process control scheme. The new method aims to detect sparse mean shifts using spatial rank and an improved adaptive elastic net?algorithm, which can monitor the high-dimension data stream collected by IoT devices and pinpoint faulty variables. The new method is also applicable in the presence of a non-normal distribution and insufficient reference samples. Numerical simulations verify that the proposed method has clear advantages over existing methods. The case of wind turbines shows that the method can be applied to real-time monitoring and diagnosis of real IoT devices, which could provide valuable diagnosis of root cause and optimize subsequent maintenance strategies.", "IdName": "wu2023real", "Citation": "", "Keywords": ""}, {"Name": "Distribution inference from early-stage stationary data streams by transfer learning", "Authors": ["Kai Wang", "Jian Li", "Fugee Tsung"], "Sources": "IISE Transactions", "PublishedYears": "2022", "Doi": "", "Abstracts": "Data streams are prevalent in current manufacturing and service systems where real-time data arrive progressively. A quick distribution inference from such data streams at their early stages is extremely useful for prompt decision making in many industrial applications. For example, a quality monitoring scheme can be quickly started if the process data distribution is available and the optimal inventory level can be determined early once the customer demand distribution is estimated. To this end, this article proposes a novel online recursive distribution inference method for stationary data streams that can respond as soon as the streaming data are generated and update as regularly as the data accumulate. A major challenge is that the data size might be too small to produce an accurate estimation at the early stage of data streams. To solve this, we resort to an instance-based transfer learning approach which?\u2026", "IdName": "wang2022distribution", "Citation": "", "Keywords": ""}, {"Name": "Change detection of profile with jumps and its application to 3D printing", "Authors": ["Dongdong Xiang", "Fugee Tsung", "Xiaolong Pu", "Wendong Li"], "Sources": "Computers & Industrial Engineering 139", "PublishedYears": "2020", "Doi": "", "Abstracts": "Three-dimensional (3D) printing, or additive manufacturing, is widely accepted as a disruptive technology, and becomes increasingly popular in manufacturing industries in recent years. As a result, quality control of 3D printing is crucial to improve the quality of products. In this paper, motivated by a novel 3D printing application with fused deposition modeling, we propose a change detection procedure for monitoring profile data with jumps that represents regular structural changes at certain positions. Jumps along with phase variability make profile monitoring challenging because it is hard to combine information in different profiles properly. First, jumps detection procedures are developed by using jump regression analysis technique. After the jumps are detected, a novel piecewise profile registration procedure is suggested to eliminate phase variability. The key information on jumps, profile registration, and the?\u2026", "IdName": "xiang2020change", "Citation": "", "Keywords": ""}, {"Name": "A co-training approach for noisy time series learning", "Authors": ["Weiqi Zhang", "Jianfeng Zhang", "Jia Li", "Fugee Tsung"], "Sources": "Proceedings of the 32nd ACM International Conference on Information and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to?\u2026", "IdName": "zhang2023co", "Citation": "", "Keywords": ""}, {"Name": "Multi-view metro station clustering based on passenger flows: a functional data-edged network community detection approach", "Authors": ["Chen Zhang", "Baihua Zheng", "Fugee Tsung"], "Sources": "Data Mining and Knowledge Discovery", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper aims at metro station clustering based on passenger flow data. Compared with existing clustering methods that only use boarding or alighting data of each station separately, we focus on higher granularity origin-destination (O-D) path flow data, and provide more flexible and insightful clustering results. In particular, we regard the metro system as a network, with each station as a node. The real-time passenger flows over time between different O-D paths serve as directed edges between nodes. Compared with traditional networks, our edges are temporal curves, and can be regarded as functional data. For this functional data-edged graph, we are the first to develop a novel community detection approach for node clustering. Our method is based on functional factorization. First a dual time-warped sparse nonnegative functional factorization is proposed for extracting patterns of the functional edges. Then?\u2026", "IdName": "zhang2023multi", "Citation": "", "Keywords": ""}, {"Name": "Self-starting process monitoring based on transfer learning", "Authors": ["Zhijun Wang", "Chunjie Wu", "Miaomiao Yu", "Fugee Tsung"], "Sources": "Journal of Quality Technology", "PublishedYears": "2022", "Doi": "", "Abstracts": "Conventional self-starting control schemes can perform poorly when monitoring processes with early shifts, being limited by the number of historical observations sampled. In real applications, pre-observed data sets from other production lines are always available, prompting us to propose a scheme that monitors the target process using historical data obtained from other sources. The methodology of self-taught clustering from unsupervised transfer learning is revised to transfer knowledge from previous observations and improve out-of-control (OC) performance, especially for processes with early shifts. However, if the difference in distribution between the target process and the pre-observed data set is large, our scheme may not be the best. Simulation results and two illustrative examples demonstrate the superiority of the proposed scheme.", "IdName": "wang2022self", "Citation": "", "Keywords": ""}, {"Name": "A unified probabilistic framework for spatiotemporal passenger crowdedness inference within urban rail transit network", "Authors": ["Min Jiang", "Andi Wang", "Ziyue Li", "Fugee Tsung"], "Sources": "2023 IEEE 19th International Conference on Automation Science and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper proposes the Spatio-Temporal Crowdedness Inference Model (STCIM), a framework to infer the passenger distribution inside the whole urban rail transit (URT) system in real-time. Our model is practical since the model is designed in a probabilistic manner and only based on the entry and exit timestamps information collected by the automatic fare collection (AFC) system. Firstly, the entire URT system is decomposed into several components of stations and segments. By decomposing a passenger's travel actions into entering, traveling, transferring, and exiting, we build a statistical model to estimate the passengers' lingering time within each component and the passengers' destination based on historical AFC data. Then, the passengers' spatial distribution is predicted in real-time based on each passenger's elapsed travel time and their entry station. The effectiveness of the scheme is validated with a?\u2026", "IdName": "jiang2023unified", "Citation": "", "Keywords": ""}, {"Name": "Mm-dag: Multi-task dag learning for multi-modal data-with application for traffic congestion analysis", "Authors": ["Tian Lan", "Ziyue Li", "Zhishuai Li", "Lei Bai", "Man Li", "Fugee Tsung", "Wolfgang Ketter", "Rui Zhao", "Chen Zhang"], "Sources": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper proposes to learn Multi-task, Multi-modal Direct Acyclic Graphs (MM-DAGs), which are commonly observed in complex systems, e.g., traffic, manufacturing, and weather systems, whose variables are multi-modal with scalars, vectors, and functions. This paper takes the traffic congestion analysis as a concrete case, where a traffic intersection is usually regarded as a DAG. In a road network of multiple intersections, different intersections can only have someoverlapping and distinct variables observed. For example, a signalized intersection has traffic light-related variables, whereas unsignalized ones do not. This encourages the multi-task design: with each DAG as a task, the MM-DAG tries to learn the multiple DAGs jointly so that their consensus and consistency are maximized. To this end, we innovatively propose a multi-modal regression for linear causal relationship description of different variables?\u2026", "IdName": "lan2023mm", "Citation": "", "Keywords": ""}, {"Name": "Human mobility modeling during the COVID-19 pandemic via deep graph diffusion infomax", "Authors": ["Yang Liu", "Yu Rong", "Zhuoning Guo", "Nuo Chen", "Tingyang Xu", "Fugee Tsung", "Jia Li"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Non-Pharmaceutical Interventions (NPIs), such as social gathering restrictions, have shown effectiveness to slow the transmission of COVID-19 by reducing the contact of people. To support policy-makers, multiple studies have first modelled human mobility via macro indicators (eg, average daily travel distance) and then study the effectiveness of NPIs. In this work, we focus on mobility modelling and, from a micro perspective, aim to predict locations that will be visited by COVID-19 cases. Since NPIs generally cause economic and societal loss, such a prediction benefits governments when they design and evaluate them. However, in real-world situations, strict privacy data protection regulations result in severe data sparsity problems (ie, limited case and location information). To address these challenges and jointly model variables including a geometric graph, a set of diffusions and a set of locations, we propose a model named Deep Graph Diffusion Infomax (DGDI). We show the maximization of DGDI can be bounded by two tractable components: a univariate Mutual Information (MI) between geometric graph and diffusion representation, and a univariate MI between diffusion representation and location representation. To facilitate the research of COVID-19 prediction, we present two benchmarks that contain geometric graphs and location histories of COVID-19 cases. Extensive experiments on the two benchmarks show that DGDI significantly outperforms other competing methods.", "IdName": "liu2023human", "Citation": "", "Keywords": ""}, {"Name": "Optimal sequential tests for monitoring changes in the distribution of finite observation sequences", "Authors": ["Dong Han", "Fugee Tsung", "Jinguo Xian", "Miaomiao Yu"], "Sources": "Statistica Sinica", "PublishedYears": "2022", "Doi": "", "Abstracts": "This study proposes a method for constructing an optimal sequential test that monitors changes in the distribution of finite observation sequences with a general dependence structure. This method allows us to prove that different optimal sequential tests can be constructed for different performance measures of detection delay times. A formula is presented to calculate the value of the generalized out-of-control average run length for every optimal sequential test. Moreover, we show that there is an equivalent optimal control limit that does not depend on the test statistic directly when the post-change conditional densities (probabilities) of the observation sequences do not depend on the change time. The detection performance of six sequential tests, including two optimal sequential tests, are illustrated using numerical simulations and a real-data example.", "IdName": "han2022optimal", "Citation": "", "Keywords": ""}, {"Name": "Sparse and structured function-on-function quality predictive modeling by hierarchical variable selection and multitask learning", "Authors": ["Kai Wang", "Fugee Tsung"], "Sources": "IEEE Transactions on Industrial Informatics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Modern manufacturing industries are often featured with a data-rich environment. The real-time behaviors of process variables can be completely recorded as multiple various signal signatures, and the geometric quality of finished products can be thoroughly characterized by their 2-D surface data. Learning the relationship between such signal predictors and surface responses, where the input and output are no longer the conventional scalar variables but are in fact both functions in the time domain and spatial domain, respectively, is critical for quality prediction in many applications nowadays. To this end, this article proposes a novel sparse and structured function-on-function regression (SSF 2 R) model, where a hierarchical variable selection is developed to identify informative signals and further screen significant elements within the selected signals, and a multitask learning is devised to exploit the smoothness?\u2026", "IdName": "wang2020sparse", "Citation": "", "Keywords": ""}, {"Name": "Deep Insights into Noisy Pseudo Labeling on Graph Data", "Authors": ["WANG Botao", "Jia Li", "Yang Liu", "Jiashun Cheng", "Yu Rong", "Wenjia Wang", "Fugee Tsung"], "Sources": "Thirty-seventh Conference on Neural Information Processing Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view consistency. Finally, extensive experiments demonstrate that the proposed strategy improves graph learning process and outperforms other PL strategies on link prediction and node classification tasks.", "IdName": "botao2023deep", "Citation": "", "Keywords": ""}, {"Name": "Nonparametric passenger flow monitoring using a minimum distance criterion", "Authors": ["Yifan Li", "Chunjie Wu", "Wendong Li", "Fugee Tsung"], "Sources": "IISE Transactions", "PublishedYears": "2023", "Doi": "", "Abstracts": "Monitoring real-time passenger flow in urban rapid transit systems is very important to maintain social stability and prevent unexpected group events and system failure. To monitor passenger flow, data are collected by sensors deployed in important stations and many existing control charts can be applied. However, because of unknown complex distributions and the requirement to detect shifts of all ranges effectively, conventional methods may perform poorly. Nevertheless, while there are certain charting schemes that truncate the Log-Likelihood Ratio (LLR) function to detect large shifts more quickly, they can cause massive loss of information by truncation, and can only handle particular distributions, leading to unstable online monitoring. In this article, we propose a nonparametric CUSUM charting scheme to monitor passenger flow dynamically. We propose a novel minimum distance criterion to minimize the?\u2026", "IdName": "li2023nonparametric", "Citation": "", "Keywords": ""}, {"Name": "Discussion of \u201cA novel approach to the analysis of spatial and functional data over complex domains\u201d", "Authors": ["Fugee Tsung", "Ziyue Li"], "Sources": "Quality Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "DiscussionDiscussion of \u201cA novel approach to the analysis of spatial and functional data over complex domains\u201d", "IdName": "sangalli2020novel", "Citation": "", "Keywords": ""}, {"Name": "The optimal CUSUM control chart with a dynamic non-random control limit and a given sampling strategy for small samples sequence", "Authors": ["Dong Han", "Fugee Tsung", "Lei Qiao"], "Sources": "Journal of Applied Statistics", "PublishedYears": "2024", "Doi": "", "Abstracts": "This article proposes a performance measure to evaluate the detection performance of a control chart with a given sampling strategy for finite or small samples sequence and prove that the CUSUM control chart with dynamic non-random control limit and a given sampling strategy can be optimal under the measure. Numerical simulations and real data for an earthquake are provided to illustrate that for different sampling strategies, the CUSUM chart will have different monitoring performance in change-point detection. Among the six sampling strategies that take only a part of samples, the numerical comparing results illustrate that the uniform sampling strategy (uniformly dispersed sampling strategy) has the best monitoring effect.", "IdName": "han2024optimal", "Citation": "", "Keywords": ""}, {"Name": "Time-warped sparse non-negative factorization for functional data analysis", "Authors": ["Chen Zhang", "Steven CH Hoi", "Fugee Tsung"], "Sources": "ACM Transactions on Knowledge Discovery from Data (TKDD)", "PublishedYears": "2020", "Doi": "", "Abstracts": "This article proposes a novel time-warped sparse non-negative factorization method for functional data analysis. The proposed method on the one hand guarantees the extracted basis functions and their coefficients to be positive and interpretable, and on the other hand is able to handle weakly correlated functions with different features. Furthermore, the method incorporates time warping into factorization and hence allows the extracted basis functions of different samples to have temporal deformations. An efficient framework of estimation algorithms is proposed based on a greedy variable selection approach. Numerical studies together with case studies on real-world data demonstrate the efficacy and applicability of the proposed methodology.", "IdName": "zhang2020time", "Citation": "", "Keywords": ""}, {"Name": "Overcoming the semantic gap in the customer-to-manufacturer (C2M) platform: A soft prompts-based approach with pretrained language models", "Authors": ["Jianhui Huang", "Yue Wang", "Stephen CH Ng", "Fugee Tsung"], "Sources": "International Journal of Production Economics 272", "PublishedYears": "2024", "Doi": "", "Abstracts": "Customer-to-Manufacturer (C2M) is a strategy in smart manufacturing where customers collaborate with manufacturers for customized product development on an online platform. The platform enables the shift from the traditional manufacturing process, which is driven by research and marketing, toward a customer-centric product development process. However, a challenge arises as customers lack technical knowledge to communicate their product specifications effectively, creating a semantic gap. This paper proposes a soft prompt-based network structure that utilizes pretrained language models to bridge the semantic gap on the C2M platform. To address limited customer needs data and imbalanced classes, a large corpus of product review texts is used to establish a mapping between reviews and product specifications. A smaller set of customer needs text is then employed to adapt this mapping to the target?\u2026", "IdName": "huang2024overcoming", "Citation": "", "Keywords": ""}, {"Name": "A Survey of Time Series Foundation Models: Generalizing Time Series Representation with Large Language Mode", "Authors": ["Jiexia Ye", "Weiqi Zhang", "Ke Yi", "Yongzi Yu", "Ziyue Li", "Jia Li", "Fugee Tsung"], "Sources": "arXiv preprint arXiv:2405.02358", "PublishedYears": "2024", "Doi": "", "Abstracts": "Time series data are ubiquitous across various domains, making time series analysis critically important. Traditional time series models are task-specific, featuring singular functionality and limited generalization capacity. Recently, large language foundation models have unveiled their remarkable capabilities for cross-task transferability, zero-shot/few-shot learning, and decision-making explainability. This success has sparked interest in the exploration of foundation models to solve multiple time series challenges simultaneously. There are two main research lines, namely \\textbf{pre-training foundation models from scratch for time series} and \\textbf{adapting large language foundation models for time series}. They both contribute to the development of a unified model that is highly generalizable, versatile, and comprehensible for time series analysis. This survey offers a 3E analytical framework for comprehensive examination of related research. Specifically, we examine existing works from three dimensions, namely \\textbf{Effectiveness}, \\textbf{Efficiency} and \\textbf{Explainability}. In each dimension, we focus on discussing how related works devise tailored solution by considering unique challenges in the realm of time series.Furthermore, we provide a domain taxonomy to help followers keep up with the domain-specific advancements. In addition, we introduce extensive resources to facilitate the field's development, including datasets, open-source, time series libraries. A GitHub repository is also maintained for resource updates (https://github.com/start2020/Awesome-TimeSeries-LLM-FM).", "IdName": "ye2024survey", "Citation": "", "Keywords": ""}, {"Name": "A Phase II score\u2010based distribution\u2010free method for jointly monitoring location and scale", "Authors": ["Dong Ding", "Jian Li", "Fugee Tsung", "Yang Li"], "Sources": "Quality and Reliability Engineering International", "PublishedYears": "2023", "Doi": "", "Abstracts": " In recent years, motivated by various applications, the joint monitoring of location and scale parameters have attracted increasing attention from researchers. Although parametric methods are useful and have been extensively studied, their efficiency is highly compromised when the process distribution is non\u2010normal or unknown. This leads to the study of nonparametric or distribution\u2010free methods. This article proposes a novel distribution\u2010free approach for location and scale monitoring, based on the proper transformation of the score test and the incorporation of the exponentially weighted moving average (EWMA) scheme. The proposed method is efficient to detect shifts in location and scale parameters, and is robust under various underlying distributions. Simulation study and a real example from manufacturing industry have guaranteed the usefulness and effectiveness of the proposed?method.", "IdName": "ding2023phase", "Citation": "", "Keywords": ""}, {"Name": "Knockoff procedure for false discovery rate control in high-dimensional data streams", "Authors": ["Ka Wai Tsang", "Fugee Tsung", "Zhihao Xu"], "Sources": "Journal of Applied Statistics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Motivated by applications to root-cause identification of faults in high-dimensional data streams that may have very limited samples after faults are detected, we consider multiple testing in models for multivariate statistical process control (SPC). With quick fault detection, only small portion of data streams being out-of-control (OC) can be assumed. It is a long standing problem to identify those OC data streams while controlling the number of false discoveries. It is challenging due to the limited number of OC samples after the termination of the process when faults are detected. Although several false discovery rate (FDR) controlling methods have been proposed, people may prefer other methods for quick detection. With a recently developed method called Knockoff filtering, we propose a knockoff procedure that can combine with other fault detection methods in the sense that the knockoff procedure does not change?\u2026", "IdName": "wai2023knockoff", "Citation": "", "Keywords": ""}, {"Name": "Directional fault classification for correlated High-Dimensional data streams using hidden Markov models", "Authors": ["Yan He", "Yicheng Kang", "Fugee Tsung", "Dongdong Xiang"], "Sources": "Journal of Quality Technology", "PublishedYears": "2023", "Doi": "", "Abstracts": "Modern manufacturing systems are often installed with sensor networks which generate high-dimensional data at high velocity. These data streams offer valuable information about the industrial system\u2019s real-time performance. If a shift occurs in the manufacturing process, fault diagnosis based on the data streams becomes a fundamental task as it identifies the affected data streams and provides insights into the root cause. Existing fault diagnostic methods either ignore the correlation between different streams or fail to determine the shift directions. In this paper, we propose a directional fault classification procedure that incorporates the between-stream correlations. We suggest a three-state hidden Markov model that captures the correlation structure and enables inference about the shift direction. We show that our procedure is optimal in the sense that it minimizes the expected number of false discoveries while?\u2026", "IdName": "he2023directional", "Citation": "", "Keywords": ""}, {"Name": "Robust online detection in serially correlated directed network", "Authors": ["Miaomiao Yu", "Yuhao Zhou", "Fugee Tsung"], "Sources": "Naval Research Logistics (NRL)", "PublishedYears": "2023", "Doi": "", "Abstracts": " As the complexity of production processes increases, the diversity of data types drives the development of network monitoring technology. This paper mainly focuses on an online algorithm to detect serially correlated directed networks robustly and sensitively. First, we consider a transition probability matrix to resolve the double correlation of primary data. Further, since the sum of each row of the transition probability matrix is one, it standardizes the data, facilitating subsequent modeling. Then we extend the spring length based method to the multivariate case and propose an adaptive cumulative sum (CUSUM) control chart on the strength of a weighted statistic to monitor directed networks. This novel approach assumes only that the process observation is associated with nearby points without any parametric time series model, which is in line with reality. Simulation results and a real example from metro?\u2026", "IdName": "yu2023robust", "Citation": "", "Keywords": ""}, {"Name": "Efficient and interpretable monitoring of high-dimensional categorical processes", "Authors": ["Kai Wang", "Jian Li", "Fugee Tsung"], "Sources": "IISE Transactions", "PublishedYears": "2023", "Doi": "", "Abstracts": "High-Dimensional (HD) processes have become prevalent in many data-intensive scientific domains and engineering applications. The monitoring of HD categorical data, where each variable of interest is evaluated by attribute levels or nominal values, however, has seldom been studied. As the joint distribution of HD categorical variables can be fully characterized by a high-way contingency table or a high-order tensor, we propose a Probabilistic Tensor Decomposition (PTD) which factorizes a huge tensor into a few latent classes (rank-one tensors) to dramatically reduce the number of model parameters. Moreover, to enable high interpretability of this latent-class-type PTD model, a novel polarization regularization is devised, which makes each latent class focus on only a few vital combinations of attribute levels of categorical variables. An Expectation-Maximization algorithm is designed for parameter estimation?\u2026", "IdName": "wang2023efficient", "Citation": "", "Keywords": ""}, {"Name": "Missing Data Imputation with Graph Laplacian Pyramid Network", "Authors": ["Weiqi Zhang", "Guanlve Li", "Jianheng Tang", "Jia Li", "Fugee Tsung"], "Sources": "arXiv preprint arXiv:2304.04474", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data imputation is a prevalent and important task due to the ubiquitousness of missing data. Many efforts try to first draft a completed data and second refine to derive the imputation results, or \"draft-then-refine\" for short. In this work, we analyze this widespread practice from the perspective of Dirichlet energy. We find that a rudimentary \"draft\" imputation will decrease the Dirichlet energy, thus an energy-maintenance \"refine\" step is in need to recover the overall energy. Since existing \"refine\" methods such as Graph Convolutional Network (GCN) tend to cause further energy decline, in this work, we propose a novel framework called Graph Laplacian Pyramid Network (GLPN) to preserve Dirichlet energy and improve imputation performance. GLPN consists of a U-shaped autoencoder and residual networks to capture global and local detailed information respectively. By extensive experiments on several real-world datasets, GLPN shows superior performance over state-of-the-art methods under three different missing mechanisms. Our source code is available at https://github.com/liguanlue/GLPN.", "IdName": "zhang2023missing", "Citation": "", "Keywords": ""}, {"Name": "Holistic Prediction for Public Transport Crowd Flows: A Spatio Dynamic Graph Network Approach", "Authors": ["Bingjie He", "Shukai Li", "Chen Zhang", "Baihua Zheng", "Fugee Tsung"], "Sources": "Machine Learning and Knowledge Discovery in Databases. Research Track?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": " This paper targets at predicting public transport in-out crowd flows of different regions together with transit flows between them in a city. The main challenge is the complex dynamic spatial correlation of crowd flows of different regions and origin-destination (OD) paths. Different from road traffic flows whose spatial correlations mainly depend on geographical distance, public transport crowd flows significantly relate to the region\u2019s functionality and connectivity in the public transport network. Furthermore, influenced by commuters\u2019 time-varying travel patterns, the spatial correlations change over time. Though there exist many works focusing on either predicting in-out flows or OD transit flows of different regions separately, they ignore the intimate connection between the two tasks, and hence lose efficacy. To solve these limitations in the literature, we propose a Graph spAtio dynamIc Network (GAIN) to describe?\u2026", "IdName": "he2021holistic", "Citation": "", "Keywords": ""}, {"Name": "MultiFun-DAG: Multivariate Functional Directed Acyclic Graph", "Authors": ["Tian Lan", "Ziyue Li", "Junpeng Lin", "Zhishuai Li", "Lei Bai", "Man Li", "Fugee Tsung", "Rui Zhao", "Chen Zhang"], "Sources": "arXiv preprint arXiv:2404.13836", "PublishedYears": "2024", "Doi": "", "Abstracts": "Directed Acyclic Graphical (DAG) models efficiently formulate causal relationships in complex systems. Traditional DAGs assume nodes to be scalar variables, characterizing complex systems under a facile and oversimplified form. This paper considers that nodes can be multivariate functional data and thus proposes a multivariate functional DAG (MultiFun-DAG). It constructs a hidden bilinear multivariate function-to-function regression to describe the causal relationships between different nodes. Then an Expectation-Maximum algorithm is used to learn the graph structure as a score-based algorithm with acyclic constraints. Theoretical properties are diligently derived. Prudent numerical studies and a case study from urban traffic congestion analysis are conducted to show MultiFun-DAG's effectiveness.", "IdName": "lan2024multifun", "Citation": "", "Keywords": ""}, {"Name": "Low-Rank Robust Subspace Tensor Clustering for Metro Passenger Flow Modeling", "Authors": ["Jiuyun Hu", "Ziyue Li", "Chen Zhang", "Fugee Tsung", "Hao Yan"], "Sources": "arXiv preprint arXiv:2404.04403", "PublishedYears": "2024", "Doi": "", "Abstracts": "Tensor clustering has become an important topic, specifically in spatio-temporal modeling, due to its ability to cluster spatial modes (e.g., stations or road segments) and temporal modes (e.g., time of the day or day of the week). Our motivating example is from subway passenger flow modeling, where similarities between stations are commonly found. However, the challenges lie in the innate high-dimensionality of tensors and also the potential existence of anomalies. This is because the three tasks, i.e., dimension reduction, clustering, and anomaly decomposition, are inter-correlated to each other, and treating them in a separate manner will render a suboptimal performance. Thus, in this work, we design a tensor-based subspace clustering and anomaly decomposition technique for simultaneously outlier-robust dimension reduction and clustering for high-dimensional tensors. To achieve this, a novel low-rank robust subspace clustering decomposition model is proposed by combining Tucker decomposition, sparse anomaly decomposition, and subspace clustering. An effective algorithm based on Block Coordinate Descent is proposed to update the parameters. Prudent experiments prove the effectiveness of the proposed framework via the simulation study, with a gain of +25% clustering accuracy than benchmark methods in a hard case. The interrelations of the three tasks are also analyzed via ablation studies, validating the interrelation assumption. Moreover, a case study in the station clustering based on real passenger flow data is conducted, with quite valuable insights discovered.", "IdName": "hu2024low", "Citation": "", "Keywords": ""}, {"Name": "Wind Power Forecasting Based on a Spatial-Temporal Graph Convolution Network with Limited Engineering Knowledge", "Authors": ["Luo Yang", "Fugee Tsung", "Kaibo Wang", "Jie Zhou"], "Sources": "IEEE Transactions on Instrumentation and Measurement", "PublishedYears": "2024", "Doi": "", "Abstracts": "Wind power forecasting is critical for ensuring the reliability of wind power systems. A wind turbine consists of several subsystems, each containing various sensors that collect multivariate time series. These subsystems can naturally classify the turbines into clusters. This clustering strongly correlates variables within the same cluster, and the correlation between two clusters can be derived from engineering knowledge. In this study, we propose a hierarchical multivariate time series forecasting method based on a spatial\u2013temporal graph convolution network (HMTGCN) to forecast wind power by leveraging engineering knowledge. The model uses a spatial\u2013temporal graph neural network (GNN) containing a graph learning module to extract features from each time-series cluster. These features are concatenated to form graph data at the cluster level, which are subsequently processed by a graph convolution network?\u2026", "IdName": "yang2024wind", "Citation": "", "Keywords": ""}, {"Name": "Deep Insights into Noisy Pseudo Labeling on Graph Data", "Authors": ["Botao Wang", "Jia Li", "Yang Liu", "Jiashun Cheng", "Yu Rong", "Wenjia Wang", "Fugee Tsung"], "Sources": "Advances in Neural Information Processing Systems 36", "PublishedYears": "2024", "Doi": "", "Abstracts": "Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view consistency. Finally, extensive experiments demonstrate that the proposed strategy improves graph learning process and outperforms other PL strategies on link prediction and node classification tasks.", "IdName": "wang2024deep", "Citation": "", "Keywords": ""}, {"Name": "Tensor-based process control and monitoring for semiconductor manufacturing with unstable disturbances", "Authors": ["Yanrong Li", "Juan Du", "Fugee Tsung", "Wei Jiang"], "Sources": "arXiv preprint arXiv:2401.17573", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the development and popularity of sensors installed in manufacturing systems, complex data are collected during manufacturing processes, which brings challenges for traditional process control methods. This paper proposes a novel process control and monitoring method for the complex structure of high-dimensional image-based overlay errors (modeled in tensor form), which are collected in semiconductor manufacturing processes. The proposed method aims to reduce overlay errors using limited control recipes. We first build a high-dimensional process model and propose different tensor-on-vector regression algorithms to estimate parameters in the model to alleviate the curse of dimensionality. Then, based on the estimate of tensor parameters, the exponentially weighted moving average (EWMA) controller for tensor data is designed whose stability is theoretically guaranteed. Considering the fact that low-dimensional control recipes cannot compensate for all high-dimensional disturbances on the image, control residuals are monitored to prevent significant drifts of uncontrollable high-dimensional disturbances. Through extensive simulations and real case studies, the performances of parameter estimation algorithms and the EWMA controller in tensor space are evaluated. Compared with existing image-based feedback controllers, the superiority of our method is verified especially when disturbances are not stable.", "IdName": "li2024tensor", "Citation": "", "Keywords": ""}, {"Name": "A review of AI-assisted motion control", "Authors": ["Yin Li", "Hua Chen", "Fugee Tsung"], "Sources": "International Conference on Internet of Things and Machine Learning (IoTML?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper provides a comprehensive review of AI-assisted motion control, which plays a crucial role in industrial automation and robotics. The application of AI technology brings new opportunities and challenges to motion control. The paper begins by introducing the basic concepts of motion control and discussing the limitations of traditional methods. It then delves into the application of AI in motion control, including generative AI, AI during setup and tuning processes, AI for statistical process control, and adaptive motion control. Special attention is given to the application of AI-assisted soft motion control and its advantages and limitations. Through comprehensive investigations, the current research progress and application status of AI-assisted soft motion is summarized. Finally, the future trends and challenges of AI-assisted motion control, as well as potential research directions and application prospects, are?\u2026", "IdName": "li2023review", "Citation": "", "Keywords": ""}, {"Name": "Tensor Dirichlet Process Multinomial Mixture Model with Graphs for Passenger Trajectory Clustering", "Authors": ["Ziyue Li", "Hao Yan", "Chen Zhang", "Wolfgang Ketter", "Fugee Tsung"], "Sources": "Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Passenger clustering based on trajectory records is essential for transportation operators. However, existing methods cannot easily cluster the passengers due to the hierarchical structure of the passenger trip information, including multiple trips within each passenger and multi-dimensional information about each trip. Furthermore, existing approaches rely on an accurate specification of the clustering number to start. Finally, existing methods do not consider spatial semantic graphs such as geographical proximity and functional similarity between the locations. In this paper, we propose a novel tensor Dirichlet Process Multinomial Mixture model with graphs, which can preserve the hierarchical structure of the multi-dimensional trip information and cluster them in a unified one-step manner with the ability to determine the number of clusters automatically. The spatial graphs are utilized in community detection to link?\u2026", "IdName": "li2023tensor", "Citation": "", "Keywords": ""}, {"Name": "A Directional Monitoring Approach of Sequential Incomplete Wind Power Curves with Copula-based Variational Inference", "Authors": ["Peng Wang", "Yanting Li", "Fugee Tsung"], "Sources": "arXiv preprint arXiv:2311.02411", "PublishedYears": "2023", "Doi": "", "Abstracts": "Wind turbines often work under complex conditions which result in performance degradation. Accurate performance degradation monitoring is essential to ensure the reliable operation of wind turbines and reduce the maintenance costs. Wind turbine power curve monitoring is an effective way to detect performance degradation. However, due to the intermittency and fluctuation of wind speed, the wind speed range varies at different time periods, making power curves difficult to compare. Motivated by this, we proposed copula-based variational inference framework and used it to establish a sequential incomplete wind power curve estimation algorithm. First, a monotone power curve is constructed based on copula-based variational inference and integrated spline regression model. Besides, the prior distribution of model parameters are sequentially updated. Then, a directional control chart based on a new statistic named KLdivergence factor is constructed to monitor wind turbine performance degradation. The real data of a wind farm in the east of the United Kingdom shows that the proposed method can both improve the accuracy of wind turbine power curve modeling and monitor wind turbine performance degradation more precisely and comprehensively than the existing approaches.", "IdName": "wang2023directional", "Citation": "", "Keywords": ""}, {"Name": "An optimization method for change-point monitoring in finite samples sequence", "Authors": ["Dong Han", "Fugee Tsung", "Jinguo Xian"], "Sources": "Statistics", "PublishedYears": "2023", "Doi": "", "Abstracts": "This article proposes a method of optimizing control chart (sequential test) to detect an abnormal change in a sequence of finite or even small samples with the unknown change-point and the unknown post-change probability distribution. We not only introduced a performance measure for a given charting statistic to evaluate the detection effect of a control chart, but also constructed an optimal control chart under the measure. The effect of optimization method was illustrated by numerical simulations of three optimized Shewhart, CUSUM and EWMA control charts, and a real data example.", "IdName": "han2023optimization", "Citation": "", "Keywords": ""}, {"Name": "Attention-based Representation Learning for Time Series with Principal and Residual Space Monitoring", "Authors": ["Botao Wang", "Fugee Tsung", "Hao Yan"], "Sources": "2022 IEEE 18th International Conference on Automation Science and?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The encoder-decoder network is one of the most common deep learning models for time series representation learning and anomaly detection. However, it is hard to reconstruct time series, which is complex, correlated, and lacking in common patterns. In this paper, we apply the attention mechanism to rescale convolution layers and learn representation in the principal and the residual space. To avoid the reconstruction process, we define the residual space by the omitted segments according to the attention score in the encoder. We introduce the temporal information inside the token level and use sparse penalty to improve representation learning. We apply the proposed model to anomaly classification and fault detection experiments on two datasets, i.e. multivariate bearing fault dataset and UCRArchive profile dataset. The result shows that the representation learned by the proposed model is more likely to?\u2026", "IdName": "wang2022attention", "Citation": "", "Keywords": ""}, {"Name": "Latent Augmentation Improves Graph Self-Supervised Learning", "Authors": ["Jiashun Cheng", "Man Li", "Jia Li", "Fugee Tsung"], "Sources": "arXiv preprint arXiv:2206.12933", "PublishedYears": "2022", "Doi": "", "Abstracts": "Graph self-supervised learning has been vastly employed to learn representations from unlabeled graphs. Existing methods can be roughly divided into predictive learning and contrastive learning, where the latter one attracts more research attention with better empirical performance. We argue that, however, predictive models weaponed with latent augmentations and powerful decoder could achieve comparable or even better representation power than contrastive models. In this work, we introduce data augmentations into latent space for superior generalization and better efficiency. A novel graph decoder named Wiener Graph Deconvolutional Network is correspondingly designed to perform information reconstruction from augmented latent representations. Theoretical analysis proves the superior reconstruction ability of graph wiener filter. Extensive experimental results on various datasets demonstrate the effectiveness of our approach.", "IdName": "cheng2022latent", "Citation": "", "Keywords": ""}, {"Name": "Rethinking Graph Neural Networks for Anomaly Detection", "Authors": ["Jianheng Tang", "Jiajin Li", "Ziqi Gao", "Jia Li"], "Sources": "ICML", "PublishedYears": "2022", "Doi": "", "Abstracts": "Graph Neural Networks (GNNs) are widely applied for graph anomaly detection. As one of the key components for GNN design is to select a tailored spectral filter, we take the first step towards analyzing anomalies via the lens of the graph spectrum. Our crucial observation is the existence of anomalies will lead to the \u2018right-shift\u2019phenomenon, that is, the spectral energy distribution concentrates less on low frequencies and more on high frequencies. This fact motivates us to propose the Beta Wavelet Graph Neural Network (BWGNN). Indeed, BWGNN has spectral and spatial localized band-pass filters to better handle the \u2018right-shift\u2019phenomenon in anomalies. We demonstrate the effectiveness of BWGNN on four large-scale anomaly detection datasets. Our code and data are released at https://github. com/squareRoot3/Rethinking-Anomaly-Detection.", "IdName": "tang2022rethinking", "Citation": "", "Keywords": ""}, {"Name": "Adversarial attack on community detection by hiding individuals", "Authors": ["Jia Li", "Honglei Zhang", "Zhichao Han", "Yu Rong", "Hong Cheng", "Junzhou Huang"], "Sources": "Proceedings of The Web Conference 2020", "PublishedYears": "2020", "Doi": "", "Abstracts": "It has been demonstrated that adversarial graphs, i.e., graphs with imperceptible perturbations added, can cause deep graph models to fail on node/graph classification tasks. In this paper, we extend adversarial graphs to the problem of community detection which is much more difficult. We focus on black-box attack and aim to hide targeted individuals from the detection of deep graph community detection models, which has many applications in real-world scenarios, for example, protecting personal privacy in social networks and understanding camouflage patterns in transaction networks. We propose an iterative learning framework that takes turns to update two modules: one working as the constrained graph generator and the other as the surrogate community detection model. We also find that the adversarial graphs generated by our method can be transferred to other learning based community detection models. ", "IdName": "li2020adversarial", "Citation": "", "Keywords": ""}, {"Name": "All in One: Multi-Task Prompting for Graph Neural Networks", "Authors": ["Xiangguo Sun", "Hong Cheng", "Jia Li", "Bo Liu", "Jihong Guan"], "Sources": "KDD 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, \"pre-training and fine-tuning'' has been adopted as a standard workflow for many graph tasks since it can take general graph knowledge to relieve the lack of graph annotations from each application. However, graph tasks with node level, edge level, and graph level are far diversified, making the pre-training pretext often incompatible with these multiple tasks. This gap may even cause a \"negative transfer'' to the specific application, leading to poor results. Inspired by the prompt learning in natural language processing (NLP), which has presented significant effectiveness in leveraging prior knowledge for various NLP tasks, we study the prompting topic for graphs with the motivation of filling the gap between pre-trained models and various graph tasks. In this paper, we propose a novel multi-task prompting method for graph models. Specifically, we first unify the format of graph prompts and language?\u2026", "IdName": "sun2023all", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical graph learning for protein\u2013protein interaction", "Authors": ["Ziqi Gao", "Chenran Jiang", "Jiawen Zhang", "Xiaosen Jiang", "Lanqing Li", "Peilin Zhao", "Huanming Yang", "Yong Huang", "Jia Li"], "Sources": "Nature Communications", "PublishedYears": "2023", "Doi": "", "Abstracts": "Protein-Protein Interactions (PPIs) are fundamental means of functions and signalings in biological systems. The massive growth in demand and cost associated with experimental PPI studies calls for computational tools for automated prediction and understanding of PPIs. Despite recent progress, in silico methods remain inadequate in modeling the natural PPI hierarchy. Here we present a double-viewed hierarchical graph learning model, HIGH-PPI, to predict PPIs and extrapolate the molecular details involved. In this model, we create a hierarchical graph, in which a node in the PPI network (top outside-of-protein view) is a protein graph (bottom inside-of-protein view). In the bottom view, a group of chemically relevant descriptors, instead of the protein sequences, are used to better capture the structure-function relationship of the protein. HIGH-PPI examines both outside-of-protein and inside-of-protein of the?\u2026", "IdName": "gao2023hierarchical", "Citation": "", "Keywords": ""}, {"Name": "Dirichlet graph variational autoencoder", "Authors": ["Jia Li", "Jianwei Yu", "Jiajin Li", "Honglei Zhang", "Kangfei Zhao", "Yu Rong", "Hong Cheng", "Junzhou Huang"], "Sources": "NeurIPS 33", "PublishedYears": "2020", "Doi": "", "Abstracts": "Graph Neural Networks (GNN) and Variational Autoencoders (VAEs) have been widely used in modeling and generating graphs with latent factors. However there is no clear explanation of what these latent factors are and why they perform well. In this work, we present Dirichlet Graph Variational Autoencoder (DGVAE) with graph cluster memberships as latent factors. Our study connects VAEs based graph generation and balanced graph cut, and provides a new way to understand and improve the internal mechanism of VAEs based graph generation. Specifically, we first interpret the reconstruction term of DGVAE as balanced graph cut in a principled way. Furthermore, motivated by the low pass characteristics in balanced graph cut, we propose a new variant of GNN named Heatts to encode the input graph into cluster memberships. Heatts utilizes the Taylor series for fast computation of Heat kernels and has better low pass characteristics than Graph Convolutional Networks (GCN). Through experiments on graph generation and graph clustering, we demonstrate the effectiveness of our proposed framework.", "IdName": "li2020dirichlet", "Citation": "", "Keywords": ""}, {"Name": "Large Language Models Meet Harry Potter: A Bilingual Dataset for Aligning Dialogue Agents with Characters", "Authors": ["Nuo Chen", "Yan Wang", "Haiyun Jiang", "Deng Cai", "Yuhan Li", "Ziyang Chen", "Longyue Wang", "Jia Li"], "Sources": "EMNLP Findings", "PublishedYears": "2023", "Doi": "", "Abstracts": "In recent years, Dialogue-style Large Language Models (LLMs) such as ChatGPT and GPT4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character. We benchmark LLMs on HPD using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter.", "IdName": "chen2022large", "Citation": "", "Keywords": ""}, {"Name": "A survey of graph meets large language model: Progress and future directions", "Authors": ["Yuhan Li", "Zhixun Li", "Peisong Wang", "Jia Li", "Xiangguo Sun", "Hong Cheng", "Jeffrey Xu Yu"], "Sources": "IJCAI 2024", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are summarized and will be consistently updated at: https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.", "IdName": "li2023survey", "Citation": "", "Keywords": ""}, {"Name": "Deconvolutional Networks on Graph Data", "Authors": ["Jia Li", "Jiajin Li", "Yang Liu", "Jianwei Yu", "Yueting Li", "Hong Cheng"], "Sources": "NeurIPS 34", "PublishedYears": "2021", "Doi": "", "Abstracts": "In this paper, we consider an inverse problem in graph learning domain--\" given the graph representations smoothed by Graph Convolutional Network (GCN), how can we reconstruct the input graph signal?\" We propose Graph Deconvolutional Network (GDN) and motivate the design of GDN via a combination of inverse filters in spectral domain and de-noising layers in wavelet domain, as the inverse operation results in a high frequency amplifier and may amplify the noise. We demonstrate the effectiveness of the proposed method on several tasks including graph feature imputation and graph structure generation.", "IdName": "li2021deconvolutional", "Citation": "", "Keywords": ""}, {"Name": "Self-supervised hypergraph representation learning for sociological analysis", "Authors": ["Xiangguo Sun", "Hong Cheng", "Bo Liu", "Jia Li", "Hongyang Chen", "Guandong Xu", "Hongzhi Yin"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Modern sociology has profoundly uncovered many convincing social criteria for behavioral analysis. Unfortunately, many of them are too subjective to be measured and very challenging to be presented in online social networks (OSNs) for the large data volume and complicated environments to be explored. On the other hand, data mining techniques can better find data patterns but many of them leave behind unnatural understanding to humans. Although there are some works trying to integrate social observations for specific tasks, they are still hard to be applied to more general cases. In this paper, we propose a fundamental methodology to support the further fusion of data mining techniques and sociological behavioral criteria. Our highlights are three-fold: First, we propose an effective hypergraph awareness and a fast line graph construction framework. The hypergraph can more profoundly indicate the?\u2026", "IdName": "sun2023self", "Citation": "", "Keywords": ""}, {"Name": "Semi-supervised hierarchical graph classification", "Authors": ["Jia Li", "Yongfeng Huang", "Heng Chang", "Yu Rong"], "Sources": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "PublishedYears": "2022", "Doi": "", "Abstracts": "Node classification and graph classification are two graph learning problems that predict the class label of a node and the class label of a graph respectively. A node of a graph usually represents a real-world entity, e.g., a user in a social network, or a document in a document citation network. In this work, we consider a more challenging but practically useful setting, in which a node itself is a graph instance. This leads to a hierarchical graph perspective which arises in many domains such as social network, biological network and document collection. We study the node classification problem in the hierarchical graph where a \u201cnode\u201d is a graph instance. As labels are usually limited, we design a novel semi-supervised solution named SEAL-CI. SEAL-CI adopts an iterative framework that takes turns to update two modules, one working at the graph instance level and the other at the hierarchical graph level. To enforce?\u2026", "IdName": "li2022semi", "Citation": "", "Keywords": ""}, {"Name": "Graph prompt learning: A comprehensive survey and beyond", "Authors": ["Xiangguo Sun", "Jiawen Zhang", "Xixi Wu", "Hong Cheng", "Yun Xiong", "Jia Li"], "Sources": "arXiv preprint arXiv:2311.16534", "PublishedYears": "2023", "Doi": "", "Abstracts": "Artificial General Intelligence (AGI) has revolutionized numerous fields, yet its integration with graph data, a cornerstone in our interconnected world, remains nascent. This paper presents a pioneering survey on the emerging domain of graph prompts in AGI, addressing key challenges and opportunities in harnessing graph data for AGI applications. Despite substantial advancements in AGI across natural language processing and computer vision, the application to graph data is relatively underexplored. This survey critically evaluates the current landscape of AGI in handling graph data, highlighting the distinct challenges in cross-modality, cross-domain, and cross-task applications specific to graphs. Our work is the first to propose a unified framework for understanding graph prompt learning, offering clarity on prompt tokens, token structures, and insertion patterns in the graph domain. We delve into the intrinsic properties of graph prompts, exploring their flexibility, expressiveness, and interplay with existing graph models. A comprehensive taxonomy categorizes over 100 works in this field, aligning them with pre-training tasks across node-level, edge-level, and graph-level objectives. Additionally, we present, ProG, a Python library, and an accompanying website, to support and advance research in graph prompting. The survey culminates in a discussion of current challenges and future directions, offering a roadmap for research in graph prompting within AGI. Through this comprehensive analysis, we aim to catalyze further exploration and practical applications of AGI in graph data, underlining its potential to reshape AGI fields and beyond. ProG?\u2026", "IdName": "sun2023graph", "Citation": "", "Keywords": ""}, {"Name": "GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection", "Authors": ["Jianheng Tang", "Fengrui Hua", "Ziqi Gao", "Peilin Zhao", "Jia Li"], "Sources": "NeurIPS 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "With a long history of traditional Graph Anomaly Detection (GAD) algorithms and recently popular Graph Neural Networks (GNNs), it is still not clear (1) how they perform under a standard comprehensive setting,(2) whether GNNs can outperform traditional algorithms such as tree ensembles, and (3) how about their efficiency on large-scale graphs. In response, we introduce GADBench---a benchmark tool dedicated to supervised anomalous node detection in static graphs. GADBench facilitates a detailed comparison across 29 distinct models on ten real-world GAD datasets, encompassing thousands to millions (~ 6M) nodes. Our main finding is that tree ensembles with simple neighborhood aggregation can outperform the latest GNNs tailored for the GAD task. We shed light on the current progress of GAD, setting a robust groundwork for subsequent investigations in this domain. GADBench is open-sourced at https://github. com/squareRoot3/GADBench.", "IdName": "tang2024gadbench", "Citation": "", "Keywords": ""}, {"Name": "Breaking language barriers in multilingual mathematical reasoning: Insights and observations", "Authors": ["Nuo Chen", "Zinan Zheng", "Ning Wu", "Linjun Shou", "Ming Gong", "Yangqiu Song", "Dongmei Zhang", "Jia Li"], "Sources": "arXiv preprint arXiv:2310.20246", "PublishedYears": "2023", "Doi": "", "Abstracts": "Existing research predominantly focuses on developing powerful language learning models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights from extensive experiments: (1) When extending the rejection sampling strategy to the multilingual context, it proves effective for model performances, albeit limited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT) across multiple languages not only significantly enhances model performance multilingually but also elevates their monolingual performance. This indicates that crafting multilingual corpora can be regarded as a vital strategy for enhancing model performance in a specific language, especially in mathematical reasoning tasks. For instance, MathOctopus-7B improves its counterparts that trained on English from 42.2% to 50.8% on GSM8K testset.", "IdName": "chen2023breaking", "Citation": "", "Keywords": ""}, {"Name": "A Convergent Single-Loop Algorithm for Relaxation of Gromov-Wasserstein in Graph Data", "Authors": ["Jiajin Li", "Jianheng Tang", "Lemin Kong", "Huikang Liu", "Jia Li", "Anthony Man-Cho So", "Jose Blanchet"], "Sources": "ICLR 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "In this work, we present the Bregman Alternating Projected Gradient (BAPG) method, a single-loop algorithm that offers an approximate solution to the Gromov-Wasserstein (GW) distance. We introduce a novel relaxation technique that balances accuracy and computational efficiency, albeit with some compromises in the feasibility of the coupling map. Our analysis is based on the observation that the GW problem satisfies the Luo-Tseng error bound condition, which relates to estimating the distance of a point to the critical point set of the GW problem based on the optimality residual. This observation allows us to provide an approximation bound for the distance between the fixed-point set of BAPG and the critical point set of GW. Moreover, under a mild technical assumption, we can show that BAPG converges to its fixed point set. The effectiveness of BAPG has been validated through comprehensive numerical experiments in graph alignment and partition tasks, where it outperforms existing methods in terms of both solution quality and wall-clock time.", "IdName": "li2023convergent", "Citation": "", "Keywords": ""}, {"Name": "Alleviating Over-smoothing for Unsupervised Sentence Representation", "Authors": ["Nuo Chen", "Linjun Shou", "Ming Gong", "Jian Pei", "Bowen Cao", "Jianhui Chang", "Daxin Jiang", "Jia Li"], "Sources": "ACL 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "Currently, learning better unsupervised sentence representations is the pursuit of many natural language processing communities. Lots of approaches based on pre-trained language models (PLMs) and contrastive learning have achieved promising results on this task. Experimentally, we observe that the over-smoothing problem reduces the capacity of these powerful PLMs, leading to sub-optimal sentence representations. In this paper, we present a Simple method named Self-Contrastive Learning (SSCL) to alleviate this issue, which samples negatives from PLMs intermediate layers, improving the quality of the sentence representation. Our proposed method is quite simple and can be easily extended to various state-of-the-art models for performance boosting, which can be seen as a plug-and-play contrastive framework for learning unsupervised sentence representation. Extensive results prove that SSCL brings the superior performance improvements of different strong baselines (e.g., BERT and SimCSE) on Semantic Textual Similarity and Transfer datasets. Our codes are available at https://github.com/nuochenpku/SSCL.", "IdName": "chen2023alleviating", "Citation": "", "Keywords": ""}, {"Name": "Knowledge Graph Completion with Counterfactual Augmentation", "Authors": ["Heng Chang", "Jie Cai", "Jia Li"], "Sources": "WWW 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": " Graph Neural Networks (GNNs) have demonstrated great success in Knowledge Graph Completion (KGC) by modeling how entities and relations interact in recent years. However, most of them are designed to learn from the observed graph structure, which appears to have imbalanced relation distribution during the training stage. Motivated by the causal relationship among the entities on a knowledge graph, we explore this defect through a counterfactual question: \u201cwould the relation still exist if the neighborhood of entities became different from observation?\u201d. With a carefully designed instantiation of a causal model on the knowledge graph, we generate the counterfactual relations to answer the question by regarding the representations of entity pair given relation as context, structural information of relation-aware neighborhood as treatment, and validity of the composed triplet as the outcome. Furthermore, we?\u2026", "IdName": "chang2023knowledge", "Citation": "", "Keywords": ""}, {"Name": "Method and apparatus for determining object posture in image, device, and storage medium", "Authors": ["Jia Li"], "Sources": "US Patent US 2019/0355147 A1", "PublishedYears": "2021", "Doi": "", "Abstracts": "This application discloses a method and an apparatus for determining a posture of a target object in an image, a device, and a non-transitory storage medium. In the method, a training model parameter of a convolutional neural network of the target object is obtained from a server. A real-time image of the target object is obtained. At least one first image block from the real-time image is identified. The at least one first image block is a local image of the real-time image. According to the training model parameter, a label image block matching the at least one first image block is determined. The label image block is a local image of a standard image of the target object. Furthermore, the posture of the target object is determined, by processing circuitry of a terminal device, according to the at least one first image block and the determined label image block.", "IdName": "li2021method", "Citation": "", "Keywords": ""}, {"Name": "Mask-gvae: Blind denoising graphs via partition", "Authors": ["Jia Li", "Mengzhou Liu", "Honglei Zhang", "Pengyun Wang", "Yong Wen", "Lujia Pan", "Hong Cheng"], "Sources": "Proceedings of the Web Conference 2021", "PublishedYears": "2021", "Doi": "", "Abstracts": " We present Mask-GVAE, a variational generative model for blind denoising large discrete graphs, in which \u201dblind denoising\u201d means we don\u2019t require any supervision from clean graphs. We focus on recovering graph structures via deleting irrelevant edges and adding missing edges, which has many applications in real-world scenarios, for example, enhancing the quality of connections in a co-authorship network. Mask-GVAE makes use of the robustness in low eigenvectors of graph Laplacian against random noise and decomposes the input graph into several stable clusters. It then harnesses the huge computations by decoding probabilistic smoothed subgraphs in a variational manner. On a wide variety of benchmarks, Mask-GVAE outperforms competing approaches by a significant margin on PSNR and WL similarity. ", "IdName": "li2021mask", "Citation": "", "Keywords": ""}, {"Name": "Graph autoencoders with deconvolutional networks", "Authors": ["Jia Li", "Tomas Yu", "Da-Cheng Juan", "Arjun Gopalan", "Hong Cheng", "Andrew Tomkins"], "Sources": "arXiv preprint arXiv:2012.11898", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recent studies have indicated that Graph Convolutional Networks (GCNs) act as a \\emph{low pass} filter in spectral domain and encode smoothed node representations. In this paper, we consider their opposite, namely Graph Deconvolutional Networks (GDNs) that reconstruct graph signals from smoothed node representations. We motivate the design of Graph Deconvolutional Networks via a combination of inverse filters in spectral domain and de-noising layers in wavelet domain, as the inverse operation results in a \\emph{high pass} filter and may amplify the noise. Based on the proposed GDN, we further propose a graph autoencoder framework that first encodes smoothed graph representations with GCN and then decodes accurate graph signals with GDN. We demonstrate the effectiveness of the proposed method on several tasks including unsupervised graph-level representation , social recommendation and graph generation", "IdName": "li2020graph", "Citation": "", "Keywords": ""}, {"Name": "A Fused Gromov-Wasserstein Framework for Unsupervised Knowledge Graph Entity Alignment", "Authors": ["Jianheng Tang", "Kangfei Zhao", "Jia Li"], "Sources": "ACL 2023 Findings", "PublishedYears": "2023", "Doi": "", "Abstracts": "Entity alignment is the task of identifying corresponding entities across different knowledge graphs (KGs). Although recent embedding-based entity alignment methods have shown significant advancements, they still struggle to fully utilize KG structural information. In this paper, we introduce FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance, allowing for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework. To address the computational challenges associated with optimizing FGW, we devise a three-stage progressive optimization algorithm. It starts with a basic semantic embedding matching, proceeds to approximate cross-KG structural and relational similarity matching based on iterative updates of high-confidence entity links, and ultimately culminates in a global structural comparison between KGs. We perform extensive experiments on four entity alignment datasets covering 14 distinct KGs across five languages. Without any supervision or hyper-parameter tuning, FGWEA surpasses 21 competitive baselines, including cutting-edge supervised entity alignment methods. Our code is available at https://github.com/squareRoot3/FusedGW-Entity-Alignment.", "IdName": "tang2023fused", "Citation": "", "Keywords": ""}, {"Name": "Warpformer: A Multi-scale Modeling Approach for Irregular Clinical Time Series", "Authors": ["Jiawen Zhang", "Shun Zheng", "Wei Cao", "Jiang Bian", "Jia Li"], "Sources": "KDD 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "Irregularly sampled multivariate time series are ubiquitous in various fields, particularly in healthcare, and exhibit two key characteristics: intra-series irregularity and inter-series discrepancy. Intra-series irregularity refers to the fact that time-series signals are often recorded at irregular intervals, while inter-series discrepancy refers to the significant variability in sampling rates among diverse series. However, recent advances in irregular time series have primarily focused on addressing intra-series irregularity, overlooking the issue of inter-series discrepancy. To bridge this gap, we present Warpformer, a novel approach that fully considers these two characteristics. In a nutshell, Warpformer has several crucial designs, including a specific input representation that explicitly characterizes both intra-series irregularity and inter-series discrepancy, a warping module that adaptively unifies irregular time series in a given?\u2026", "IdName": "zhang2023warpformer", "Citation": "", "Keywords": ""}, {"Name": "Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension", "Authors": ["Nuo Chen", "Hongguang Li", "Yinan Bao", "Junqing He", "Xinshi Lin", "Qi Yang", "Jianfeng Liu", "Ruyi Gan", "Jiaxing Zhang", "Baoyuan Wang", "Jia Li"], "Sources": "EMNLP Findings", "PublishedYears": "2023", "Doi": "", "Abstracts": "The conversational machine reading comprehension (CMRC) task aims to answer questions in conversations, which has been a hot research topic in recent years because of its wide applications. However, existing CMRC benchmarks in which each conversation is assigned a static passage are inconsistent with real scenarios. Thus, model's comprehension ability towards real scenarios are hard to evaluate reasonably. To this end, we propose the first Chinese CMRC benchmark Orca and further provide zero-shot/few-shot settings to evaluate model's generalization ability towards diverse domains. We collect 831 hot-topic driven conversations with 4,742 turns in total. Each turn of a conversation is assigned with a response-related passage, aiming to evaluate model's comprehension ability more reasonably. The topics of conversations are collected from social media platform and cover 33 domains, trying to be consistent with real scenarios. Importantly, answers in Orca are all well-annotated natural responses rather than the specific spans or short phrase in previous datasets. Besides, we implement three strong baselines to tackle the challenge in Orca. The results indicate the great challenge of our CMRC benchmark. Our datatset and checkpoints are available at https://github.com/nuochenpku/Orca.", "IdName": "chen2023orca", "Citation": "", "Keywords": ""}, {"Name": "Improving generalization in equivariant graph neural networks with physical inductive biases", "Authors": ["Yang Liu", "Jiashun Cheng", "Haihong Zhao", "Tingyang Xu", "Peilin Zhao", "Fugee Tsung", "Jia Li", "Yu Rong"], "Sources": "The Twelfth International Conference on Learning Representations", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph Neural Networks (GNNs) with equivariant properties have emerged as powerful tools for modeling complex dynamics of multi-object physical systems. However, their generalization ability is limited by the inadequate consideration of physical inductive biases: (1) Existing studies overlook the continuity of transitions among system states, opting to employ several discrete transformation layers to learn the direct mapping between two adjacent states; (2) Most models only account for first-order velocity information, despite the fact that many physical systems are governed by second-order motion laws. To incorporate these inductive biases, we propose the Second-order Equivariant Graph Neural Ordinary Differential Equation (SEGNO). Specifically, we show how the second-order continuity can be incorporated into GNNs while maintaining the equivariant property. Furthermore, we offer theoretical insights into SEGNO, highlighting that it can learn a unique trajectory between adjacent states, which is crucial for model generalization. Additionally, we prove that the discrepancy between this learned trajectory of SEGNO and the true trajectory is bounded. Extensive experiments on complex dynamical systems including molecular dynamics and motion capture demonstrate that our model yields a significant improvement over the state-of-the-art baselines.", "IdName": "liu2024improving", "Citation": "", "Keywords": ""}, {"Name": "GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction", "Authors": ["Amit Roy", "Juan Shu", "Jia Li", "Carl Yang", "Olivier Elshocht", "Jeroen Smeets", "Pan Li"], "Sources": "WSDM 2024", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes within graphs, finding applications in network security, fraud detection, social media spam detection, and various other domains. A common method for GAD is Graph Auto-Encoders (GAEs), which encode graph data into node representations and identify anomalies by assessing the reconstruction quality of the graphs based on these representations. However, existing GAE models are primarily optimized for direct link reconstruction, resulting in nodes connected in the graph being clustered in the latent space. As a result, they excel at detecting cluster-type structural anomalies but struggle with more complex structural anomalies that do not conform to clusters. To address this limitation, we propose a novel solution called GAD-NR, a new variant of GAE that incorporates neighborhood reconstruction for graph anomaly detection. GAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the local structure, self-attributes, and neighbor attributes, based on the corresponding node representation. By comparing the neighborhood reconstruction loss between anomalous nodes and normal nodes, GAD-NR can effectively detect any anomalies. Extensive experimentation conducted on six real-world datasets validates the effectiveness of GAD-NR, showcasing significant improvements (by up to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR is openly available. Importantly, the comparative analysis reveals that the existing methods perform well only in detecting one or two types of anomalies out of the three types studied. In?\u2026", "IdName": "roy2024gad", "Citation": "", "Keywords": ""}, {"Name": "Imdrug: A benchmark for deep imbalanced learning in ai-aided drug discovery", "Authors": ["Lanqing Li", "Liang Zeng", "Ziqi Gao", "Shen Yuan", "Yatao Bian", "Bingzhe Wu", "Hengtong Zhang", "Yang Yu", "Chan Lu", "Zhipeng Zhou", "Hongteng Xu", "Jia Li", "Peilin Zhao", "Pheng-Ann Heng"], "Sources": "arXiv preprint arXiv:2209.07921", "PublishedYears": "2022", "Doi": "", "Abstracts": "The last decade has witnessed a prosperous development of computational methods and dataset curation for AI-aided drug discovery (AIDD). However, real-world pharmaceutical datasets often exhibit highly imbalanced distribution, which is overlooked by the current literature but may severely compromise the fairness and generalization of machine learning applications. Motivated by this observation, we introduce ImDrug, a comprehensive benchmark with an open-source Python library which consists of 4 imbalance settings, 11 AI-ready datasets, 54 learning tasks and 16 baseline algorithms tailored for imbalanced learning. It provides an accessible and customizable testbed for problems and solutions spanning a broad spectrum of the drug discovery pipeline such as molecular modeling, drug-target interaction and retrosynthesis. We conduct extensive empirical studies with novel evaluation metrics, to demonstrate that the existing algorithms fall short of solving medicinal and pharmaceutical challenges in the data imbalance scenario. We believe that ImDrug opens up avenues for future research and development, on real-world challenges at the intersection of AIDD and deep imbalanced learning.", "IdName": "li2022imdrug", "Citation": "", "Keywords": ""}, {"Name": "Method, device and system for sharing cross-platform account resources", "Authors": ["Hongfei Zhou", "Jia Li"], "Sources": "US Patent 10", "PublishedYears": "2020", "Doi": "", "Abstracts": "A method for sharing a cross-platform account resource is described. An authentication request carrying a user name, a password, and an ID of an APP resource server is transmitted to an account management server, based on a register account on the account management server; an authentication ticket corresponding to the APP resource server is received from the account managements server, and the authentication ticket is stored, in which the authentication ticket carries a user ID, an authorization key and a refresh key; a resource request is transmitted to the APP resource server, based on the user ID and the authorization key in the authentication ticket; an APP resource is received from the APP resource server, after the APP resource server requests the account management server to verify the authentication ticket by using the user ID and the authorization key.", "IdName": "zhou2020method", "Citation": "", "Keywords": ""}, {"Name": "Protein Multimer Structure Prediction via Prompt Learning", "Authors": ["Ziqi Gao", "Xiangguo Sun", "Zijing Liu", "Yu Li", "Hong Cheng", "Jia Li"], "Sources": "arXiv preprint arXiv:2402.18813", "PublishedYears": "2024", "Doi": "", "Abstracts": "Understanding the 3D structures of protein multimers is crucial, as they play a vital role in regulating various cellular processes. It has been empirically confirmed that the multimer structure prediction~(MSP) can be well handled in a step-wise assembly fashion using provided dimer structures and predicted protein-protein interactions~(PPIs). However, due to the biological gap in the formation of dimers and larger multimers, directly applying PPI prediction techniques can often cause a \\textit{poor generalization} to the MSP task. To address this challenge, we aim to extend the PPI knowledge to multimers of different scales~(i.e., chain numbers). Specifically, we propose \\textbf{\\textsc{PromptMSP}}, a pre-training and \\textbf{Prompt} tuning framework for \\textbf{M}ultimer \\textbf{S}tructure \\textbf{P}rediction. First, we tailor the source and target tasks for effective PPI knowledge learning and efficient inference, respectively. We design PPI-inspired prompt learning to narrow the gaps of two task formats and generalize the PPI knowledge to multimers of different scales. We provide a meta-learning strategy to learn a reliable initialization of the prompt model, enabling our prompting framework to effectively adapt to limited data for large-scale multimers. Empirically, we achieve both significant accuracy (RMSD and TM-Score) and efficiency improvements compared to advanced MSP models. The code, data and checkpoints are released at \\url{https://github.com/zqgao22/PromptMSP}.", "IdName": "gao2024protein", "Citation": "", "Keywords": ""}, {"Name": "All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining", "Authors": ["Haihong Zhao", "Aochuan Chen", "Xiangguo Sun", "Hong Cheng", "Jia Li"], "Sources": "arXiv preprint arXiv:2402.09834", "PublishedYears": "2024", "Doi": "", "Abstracts": "Large Language Models (LLMs) have revolutionized the fields of computer vision (CV) and natural language processing (NLP). One of the most notable advancements of LLMs is that a single model is trained on vast and diverse datasets spanning multiple domains -- a paradigm we term `All in One'. This methodology empowers LLMs with super generalization capabilities, facilitating an encompassing comprehension of varied data distributions. Leveraging these capabilities, a single LLM demonstrates remarkable versatility across a variety of domains -- a paradigm we term `One for All'. However, applying this idea to the graph field remains a formidable challenge, with cross-domain pretraining often resulting in negative transfer. This issue is particularly important in few-shot learning scenarios, where the paucity of training data necessitates the incorporation of external knowledge sources. In response to this challenge, we propose a novel approach called Graph COordinators for PrEtraining (GCOPE), that harnesses the underlying commonalities across diverse graph datasets to enhance few-shot learning. Our novel methodology involves a unification framework that amalgamates disparate graph datasets during the pretraining phase to distill and transfer meaningful knowledge to target tasks. Extensive experiments across multiple graph datasets demonstrate the superior efficacy of our approach. By successfully leveraging the synergistic potential of multiple graph datasets for pretraining, our work stands as a pioneering contribution to the realm of graph foundational model.", "IdName": "zhao2024all", "Citation": "", "Keywords": ""}, {"Name": "Data response method, terminal device, and server", "Authors": ["LIU Feifei", "Yong Yang", "Meng Chen", "JIA Yiwen", "Fei You", "WEN Binmin", "Jia Li", "ZONG Xuan", "HAN Wuyu", "YU Chuansheng", "Wei Tian", "CHEN Yuanbin", "Yaohua Zhang"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "Embodiments of the present disclosure disclose a data response method, a terminal device, and a server. The method in the embodiments of the present disclosure includes: sending encrypted information to a terminal device; receiving a first honeypot character, the encrypted information, and user data from the terminal device; decrypting the encrypted information, to obtain a second honeypot character comprised in the encrypted information; determining whether the first honeypot character sent by the terminal device is the same as the second honeypot character decrypted from the encrypted information; and responding to the user data in response to the first honeypot character being the same as the second honeypot character.", "IdName": "feifei2022data", "Citation": "", "Keywords": ""}, {"Name": "Bridge the gap between language models and tabular understanding", "Authors": ["Nuo Chen", "Linjun Shou", "Ming Gong", "Jian Pei", "Chenyu You", "Jianhui Chang", "Daxin Jiang", "Jia Li"], "Sources": "arXiv preprint arXiv:2302.09302", "PublishedYears": "2023", "Doi": "", "Abstracts": "Table pretrain-then-finetune paradigm has been proposed and employed at a rapid pace after the success of pre-training in the natural language domain. Despite the promising findings in tabular pre-trained language models (TPLMs), there is an input gap between pre-training and fine-tuning phases. For instance, TPLMs jointly pre-trained with table and text input could be effective for tasks also with table-text joint input like table question answering, but it may fail for tasks with only tables or text as input such as table retrieval. To this end, we propose UTP, an approach that dynamically supports three types of multi-modal inputs: table-text, table, and text. Specifically, UTP is pre-trained with two strategies: (1) We first utilize a universal mask language modeling objective on each kind of input, enforcing the model to adapt various inputs. (2) We then present Cross-Modal Contrastive Regularization (CMCR), which utilizes contrastive learning to encourage the consistency between table-text cross-modality representations via unsupervised instance-wise training signals during pre-training. By these means, the resulting model not only bridges the input gap between pre-training and fine-tuning but also advances in the alignment of table and text. Extensive results show UTP achieves superior results on uni-modal input tasks (e.g., table retrieval) and cross-modal input tasks (e.g., table question answering).", "IdName": "chen2023bridge", "Citation": "", "Keywords": ""}, {"Name": "Compress to Impress: Unleashing the Potential of Compressive Memory in Real-World Long-Term Conversations", "Authors": ["Nuo Chen", "Hongguang Li", "Juhua Huang", "Baoyuan Wang", "Jia Li"], "Sources": "arXiv preprint arXiv:2402.11975", "PublishedYears": "2024", "Doi": "", "Abstracts": "Existing retrieval-based methods have made significant strides in maintaining long-term conversations. However, these approaches face challenges in memory database management and accurate memory retrieval, hindering their efficacy in dynamic, real-world interactions. This study introduces a novel framework, COmpressive Memory-Enhanced Dialogue sYstems (COMEDY), which eschews traditional retrieval modules and memory databases. Instead, COMEDY adopts a ''One-for-All'' approach, utilizing a single language model to manage memory generation, compression, and response generation. Central to this framework is the concept of compressive memory, which intergrates session-specific summaries, user-bot dynamics, and past events into a concise memory format. To support COMEDY, we curated a large-scale Chinese instruction-tuning dataset, Dolphin, derived from real user-chatbot interactions. Comparative evaluations demonstrate COMEDY's superiority over traditional retrieval-based methods in producing more nuanced and human-like conversational experiences. Our codes are available at https://github.com/nuochenpku/COMEDY.", "IdName": "chen2024compress", "Citation": "", "Keywords": ""}, {"Name": "Structural Contrastive Pretraining for Cross-Lingual Comprehension", "Authors": ["Nuo Chen", "Linjun Shou", "Tengtao Song", "Ming Gong", "Jian Pei", "Jianhui Chang", "Daxin Jiang", "Jia Li"], "Sources": "Findings of the Association for Computational Linguistics: ACL 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "To present, multilingual language models trained using various pre-training tasks like mask language modeling (MLM) have yielded encouraging results on a wide range of downstream tasks. Despite the promising performances, structural knowledge in cross-lingual corpus is less explored in current works, leading to the semantic misalignment. In this paper, we propose a new pre-training task named Structural Contrast Pretraining (SCP) to align the structural words in a parallel sentence, enhancing the models\u2019 ability to comprehend cross-lingual representations. Concretely, each structural word in source and target languages is regarded as a positive pair in SCP. Since contrastive learning compares positive and negative pairs, an increase in the frequency of negative pairings could enhance the performance of the resulting model. Therefore, we further propose Cross-lingual Momentum Contrast (CL-MoCo) to increase the number of negative pairs by maintaining a large size of the queue. CL-MoCo extends the original Moco approach into cross-lingual training and jointly optimizes the source-to-target language and target-to-source language representations, resulting in a more suitable encoder for cross-lingual transfer. We conduct extensive experiments to validate the proposed approach on three cross-lingual tasks across five datasets such as MLQA, WikiAnn, etc, and results prove the effectiveness of our method.", "IdName": "chen2023structural", "Citation": "", "Keywords": ""}, {"Name": "Deep Reinforcement Learning for Modelling Protein Complexes", "Authors": ["Tao Feng", "Ziqi Gao", "Jiaxuan You", "Chenyi Zi", "Yan Zhou", "Chen Zhang", "Jia Li"], "Sources": "arXiv preprint arXiv:2405.02299", "PublishedYears": "2024", "Doi": "", "Abstracts": "AlphaFold can be used for both single-chain and multi-chain protein structure prediction, while the latter becomes extremely challenging as the number of chains increases. In this work, by taking each chain as a node and assembly actions as edges, we show that an acyclic undirected connected graph can be used to predict the structure of multi-chain protein complexes (a.k.a., protein complex modelling, PCM). However, there are still two challenges: 1) The huge combinatorial optimization space of  ( is the number of chains) for the PCM problem can easily lead to high computational cost. 2) The scales of protein complexes exhibit distribution shift due to variance in chain numbers, which calls for the generalization in modelling complexes of various scales. To address these challenges, we propose GAPN, a Generative Adversarial Policy Network powered by domain-specific rewards and adversarial loss through policy gradient for automatic PCM prediction. Specifically, GAPN learns to efficiently search through the immense assembly space and optimize the direct docking reward through policy gradient. Importantly, we design an adversarial reward function to enhance the receptive field of our model. In this way, GAPN will simultaneously focus on a specific batch of complexes and the global assembly rules learned from complexes with varied chain numbers. Empirically, we have achieved both significant accuracy (measured by RMSD and TM-Score) and efficiency improvements compared to leading PCM softwares. GAPN outperforms the state-of-the-art method (MoLPC) with up to 27% improvement in TM-Score, with a speed-up of 600?\u2026", "IdName": "feng2024deep", "Citation": "", "Keywords": ""}, {"Name": "GraphWiz: An Instruction-Following Language Model for Graph Problems", "Authors": ["Nuo Chen", "Yuhan Li", "Jianheng Tang", "Jia Li"], "Sources": "arXiv preprint arXiv:2402.16029", "PublishedYears": "2024", "Doi": "", "Abstracts": "Large language models (LLMs) have achieved impressive success across several fields, but their proficiency in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel and comprehensive instruction-tuning dataset designed to equip language models with the ability to tackle a broad spectrum of graph problems using explicit reasoning paths. Utilizing GraphInstruct, we build GraphWiz, an open-source language model capable of resolving various graph problem types while generating clear reasoning processes. To enhance the model's capability and reliability, we incorporate the Direct Preference Optimization (DPO) framework into the graph problem-solving context. The enhanced model, GraphWiz-DPO, achieves an average accuracy of 65% across nine tasks with different complexity levels, surpassing GPT-4 which has an average accuracy of 43.8%. Moreover, our research delves into the delicate balance between training data volume and model performance, highlighting the potential for overfitting with increased data. We also explore the transferability of the model's reasoning ability across different graph tasks, indicating the model's adaptability and practical application potential. Our investigation offers a new blueprint and valuable insights for developing LLMs specialized in graph reasoning and problem-solving.", "IdName": "chen2024graphwiz", "Citation": "", "Keywords": ""}, {"Name": "From good to great: Improving math reasoning with tool-augmented interleaf prompting", "Authors": ["Nuo Chen", "Hongguang Li", "Baoyuan Wang", "Jia Li"], "Sources": "arXiv preprint arXiv:2401.05384", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper investigates the performance of Large Language Models (LLMs) and Tool-augmented LLMs in tackling complex mathematical reasoning tasks. We introduce IMP-TIP: Improving Math Reasoning with Tool-augmented Interleaf Prompting, a framework that combines the strengths of both LLMs and Tool-augmented LLMs. IMP-TIP follows the ``From Good to Great\" concept, collecting multiple potential solutions from both LLMs and their Tool-Augmented counterparts for the same math problem, and then selecting or re-generating the most accurate answer after cross-checking these solutions via tool-augmented interleaf prompting. The framework incorporates two key aspects: self-prompt and tool-augmented interleaf prompting (TIP). The former allows LLMs to autonomously refine and improve an initial prompt related to tool usage, while the latter enables LLMs to derive the final answer by dynamically analyzing the problem, cross-checking potential solutions, and revising previous reasoning hints in an interleaved manner. Experimental analysis shows that IMP-TIP achieves enhanced mathematical capabilities and outperforms traditional LLMs and tool-augmented LLMs in accuracy and reasoning diversity on math reasoning tasks. For instance, IMP-TIP can improve Tool-augmented ChatGPT on GSM8K-Hard from 56.0% to 65.2%.", "IdName": "chen2023good", "Citation": "", "Keywords": ""}, {"Name": "Beyond Surface: Probing LLaMA Across Scales and Layers", "Authors": ["Nuo Chen", "Ning Wu", "Shining Liang", "Ming Gong", "Linjun Shou", "Dongmei Zhang", "Jia Li"], "Sources": "arXiv preprint arXiv:2312.04333", "PublishedYears": "2023", "Doi": "", "Abstracts": "This paper presents an in-depth analysis of Large Language Models (LLMs), focusing on LLaMA, a prominent open-source foundational model in natural language processing. Instead of assessing LLaMA through its generative output, we design multiple-choice tasks to probe its intrinsic understanding in high-order tasks such as reasoning and computation. We examine the model horizontally, comparing different sizes, and vertically, assessing different layers. We unveil several key and uncommon findings based on the designed probing tasks: (1) Horizontally, enlarging model sizes almost could not automatically impart additional knowledge or computational prowess. Instead, it can enhance reasoning abilities, especially in math problem solving, and helps reduce hallucinations, but only beyond certain size thresholds; (2) In vertical analysis, the lower layers of LLaMA lack substantial arithmetic and factual knowledge, showcasing logical thinking, multilingual and recognitive abilities, with top layers housing most computational power and real-world knowledge.", "IdName": "chen2023beyond", "Citation": "", "Keywords": ""}, {"Name": "Natural Response Generation for Chinese Reading Comprehension", "Authors": ["Nuo Chen", "Hongguang Li", "Yinan Bao", "Baoyuan Wang", "Jia Li"], "Sources": "EMNLP Findings", "PublishedYears": "2023", "Doi": "", "Abstracts": "Machine reading comprehension (MRC) is an important area of conversation agents and draws a lot of attention. However, there is a notable limitation to current MRC benchmarks: The labeled answers are mostly either spans extracted from the target corpus or the choices of the given candidates, ignoring the natural aspect of high-quality responses. As a result, MRC models trained on these datasets can not generate human-like responses in real QA scenarios. To this end, we construct a new dataset called Penguin to promote the research of MRC, providing a training and test bed for natural response generation to real scenarios. Concretely, Penguin consists of 200k training data with high-quality fluent, and well-informed responses. Penguin is the first benchmark towards natural response generation in Chinese MRC on a relatively large scale. To address the challenges in Penguin, we develop two strong baselines: end-to-end and two-stage frameworks. Following that, we further design Prompt-BART: fine-tuning the pre-trained generative language models with a mixture of prefix prompts in Penguin. Extensive experiments validated the effectiveness of this design.", "IdName": "chen2023natural", "Citation": "", "Keywords": ""}, {"Name": "ProG: A Graph Prompt Learning Benchmark", "Authors": ["Chenyi Zi", "Haihong Zhao", "Xiangguo Sun", "Yiqing Lin", "Hong Cheng", "Jia Li"], "Sources": "arXiv preprint arXiv:2406.05346", "PublishedYears": "2024", "Doi": "", "Abstracts": "Artificial general intelligence on graphs has shown significant advancements across various applications, yet the traditional 'Pre-train & Fine-tune' paradigm faces inefficiencies and negative transfer issues, particularly in complex and few-shot settings. Graph prompt learning emerges as a promising alternative, leveraging lightweight prompts to manipulate data and fill the task gap by reformulating downstream tasks to the pretext. However, several critical challenges still remain: how to unify diverse graph prompt models, how to evaluate the quality of graph prompts, and to improve their usability for practical comparisons and selection. In response to these challenges, we introduce the first comprehensive benchmark for graph prompt learning. Our benchmark integrates SIX pre-training methods and FIVE state-of-the-art graph prompt techniques, evaluated across FIFTEEN diverse datasets to assess performance, flexibility, and efficiency. We also present 'ProG', an easy-to-use open-source library that streamlines the execution of various graph prompt models, facilitating objective evaluations. Additionally, we propose a unified framework that categorizes existing graph prompt methods into two main approaches: prompts as graphs and prompts as tokens. This framework enhances the applicability and comparison of graph prompt techniques. The code is available at: https://github.com/sheldonresearch/ProG.", "IdName": "zi2024prog", "Citation": "", "Keywords": ""}, {"Name": "DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation", "Authors": ["Weiqi Zhang", "Jiexia Ye", "Ziyue Li", "Jia Li", "Fugee Tsung"], "Sources": "arXiv e-prints", "PublishedYears": "2024", "Doi": "", "Abstracts": "The recent rapid development of language models (LMs) has attracted attention in the field of time series, including multimodal time series modeling. However, we note that current time series multimodal methods are biased, often assigning a primary role to one modality while the other assumes a secondary role. They overlook the mutual benefits and complementary of different modalities. For example, in seizure diagnosis, relying solely on textual clinical reports makes it difficult to pinpoint the area and type of the disease, while electroencephalograms (EEGs) alone cannot provide an accurate diagnosis without considering the symptoms. In this study, based on the complementary information mining of time series multimodal data, we propose DualTime, a Dual-adapter multimodal language model for Time series representation implementing temporal-primary and textual-primary modeling simultaneously. By injecting lightweight adaption tokens, the LM pipeline shared by dual adapters encourages embedding alignment and achieves efficient fine-tuning. Empirically, our method outperforms state-of-the-art models in both supervised and unsupervised settings, highlighting the complementary benefits of different modalities. In addition, we conduct few-shot label transfer experiments, which further verifies the transferability and expressiveness of our proposed DualTime.", "IdName": "zhang2024dualtime", "Citation": "", "Keywords": ""}, {"Name": "One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments", "Authors": ["Ke Yi", "Yuhui Xu", "Heng Chang", "Chen Tang", "Yuan Meng", "Tong Zhang", "Jia Li"], "Sources": "arXiv preprint arXiv:2405.20202", "PublishedYears": "2024", "Doi": "", "Abstracts": "Large Language Models (LLMs) have advanced rapidly but face significant memory demands. While quantization has shown promise for LLMs, current methods typically require lengthy training to alleviate the performance degradation from quantization loss. However, deploying LLMs across diverse scenarios with different resource constraints, e.g., servers and personal computers, requires repeated training per application, which amplifies the lengthy training problem. Given that, it is advantageous to train a once-for-all (OFA) supernet capable of yielding diverse optimal subnets for downstream applications through one-shot training. Nonetheless, the scale of current language models impedes efficiency and amplifies interference from weight sharing between subnets. We make an initial attempt to extend the once-for-all framework to large language models. Specifically, we decouple shared weights to eliminate the interference and incorporate Low-Rank adapters for training efficiency. Furthermore, we observe the imbalance allocation of training resources from the traditional uniform sampling. A non-parametric scheduler is introduced to adjust the sampling rate for each quantization configuration, achieving a more balanced allocation among subnets with varying demands. We validate the approach on LLaMA2 families, and downstream evaluation confirms our ability to maintain high performance while significantly reducing deployment time faced with multiple scenarios.", "IdName": "yi2024one", "Citation": "", "Keywords": ""}, {"Name": "Weakly Supervised Anomaly Detection via Knowledge-Data Alignment", "Authors": ["Haihong Zhao", "Chenyi Zi", "Yang Liu", "Chen Zhang", "Yan Zhou", "Jia Li"], "Sources": "Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Anomaly detection (AD) plays a pivotal role in numerous web-based applications, including malware detection, anti-money laundering, device failure detection, and network fault analysis. Most methods, which rely on unsupervised learning, are hard to reach satisfactory detection accuracy due to the lack of labels. Weakly Supervised Anomaly Detection (WSAD) has been introduced with a limited number of labeled anomaly samples to enhance model performance. Nevertheless, it is still challenging for models, trained on an inadequate amount of labeled data, to generalize to unseen anomalies. In this paper, we introduce a novel framework Knowledge-Data Alignment (KDAlign) to integrate rule knowledge, typically summarized by human experts, to supplement the limited labeled data. Specifically, we transpose these rules into the knowledge space and subsequently recast the incorporation of knowledge as the alignment of knowledge and data. To facilitate this alignment, we employ the Optimal Transport (OT) technique. We then incorporate the OT distance as an additional loss term to the original objective function of WSAD methodologies. Comprehensive experimental results on five real-world datasets demonstrate that our proposed KDAlign framework markedly surpasses its state-of-the-art counterparts, achieving superior performance across various anomaly types.", "IdName": "zhao2024weakly", "Citation": "", "Keywords": ""}, {"Name": "Parameter-Efficient Fine-Tuning with Discrete Fourier Transform", "Authors": ["Ziqi Gao", "Qichao Wang", "Aochuan Chen", "Zijing Liu", "Bingzhe Wu", "Liang Chen", "Jia Li"], "Sources": "arXiv preprint arXiv:2405.03003", "PublishedYears": "2024", "Doi": "", "Abstracts": "Low-rank adaptation~(LoRA) has recently gained much interest in fine-tuning foundation models. It effectively reduces the number of trainable parameters by incorporating low-rank matrices  and  to represent the weight change, i.e., . Despite LoRA's progress, it faces storage challenges when handling extensive customization adaptations or larger base models. In this work, we aim to further compress trainable parameters by enjoying the powerful expressiveness of the Fourier transform. Specifically, we introduce FourierFT, which treats  as a matrix in the spatial domain and learns only a small fraction of its spectral coefficients. With the trained spectral coefficients, we implement the inverse discrete Fourier transform to recover . Empirically, our FourierFT method shows comparable or better performance with fewer parameters than LoRA on various tasks, including natural language understanding, natural language generation, instruction tuning, and image classification. For example, when performing instruction tuning on the LLaMA2-7B model, FourierFT surpasses LoRA with only 0.064M trainable parameters, compared to LoRA's 33.5M. Our code is released at \\url{https://github.com/Chaos96/fourierft}.", "IdName": "gao2024parameter", "Citation": "", "Keywords": ""}, {"Name": "ZeroG: Investigating Cross-dataset Zero-shot Transferability in Graphs", "Authors": ["Yuhan Li", "Peisong Wang", "Zhixun Li", "Jeffrey Xu Yu", "Jia Li"], "Sources": "arXiv preprint arXiv:2402.11235", "PublishedYears": "2024", "Doi": "", "Abstracts": "With the development of foundation models such as large language models, zero-shot transfer learning has become increasingly significant. This is highlighted by the generative capabilities of NLP models like GPT-4, and the retrieval-based approaches of CV models like CLIP, both of which effectively bridge the gap between seen and unseen data. In the realm of graph learning, the continuous emergence of new graphs and the challenges of human labeling also amplify the necessity for zero-shot transfer learning, driving the exploration of approaches that can generalize across diverse graph data without necessitating dataset-specific and label-specific fine-tuning. In this study, we extend such paradigms to zero-shot transferability in graphs by introducing ZeroG, a new framework tailored to enable cross-dataset generalization. Addressing the inherent challenges such as feature misalignment, mismatched label spaces, and negative transfer, we leverage a language model to encode both node attributes and class semantics, ensuring consistent feature dimensions across datasets. We also propose a prompt-based subgraph sampling module that enriches the semantic information and structure information of extracted subgraphs using prompting nodes and neighborhood aggregation, respectively. We further adopt a lightweight fine-tuning strategy that reduces the risk of overfitting and maintains the zero-shot learning efficacy of the language model. The results underscore the effectiveness of our model in achieving significant cross-dataset zero-shot transferability, opening pathways for the development of graph foundation models. Especially?\u2026", "IdName": "li2024zerog", "Citation": "", "Keywords": ""}, {"Name": "Path-based Explanation for Knowledge Graph Completion", "Authors": ["Heng Chang", "Jiangnan Ye", "Alejo Lopez Avila", "Jinhua Du", "Jia Li"], "Sources": "arXiv preprint arXiv:2401.02290", "PublishedYears": "2024", "Doi": "", "Abstracts": "Graph Neural Networks (GNNs) have achieved great success in Knowledge Graph Completion (KGC) by modelling how entities and relations interact in recent years. However, the explanation of the predicted facts has not caught the necessary attention. Proper explanations for the results of GNN-based KGC models increase model transparency and help researchers develop more reliable models. Existing practices for explaining KGC tasks rely on instance/subgraph-based approaches, while in some scenarios, paths can provide more user-friendly and interpretable explanations. Nonetheless, the methods for generating path-based explanations for KGs have not been well-explored. To address this gap, we propose Power-Link, the first path-based KGC explainer that explores GNN-based models. We design a novel simplified graph-powering technique, which enables the generation of path-based explanations with a fully parallelisable and memory-efficient training scheme. We further introduce three new metrics for quantitative evaluation of the explanations, together with a qualitative human evaluation. Extensive experiments demonstrate that Power-Link outperforms the SOTA baselines in interpretability, efficiency, and scalability.", "IdName": "chang2024path", "Citation": "", "Keywords": ""}, {"Name": "Hierarchical Graph Latent Diffusion Model for Molecule Generation", "Authors": ["Tian Bian", "Yifan Niu", "Heng Chang", "Divin Yan", "Tingyang Xu", "Yu Rong", "Jia Li", "Hong Cheng"], "Sources": "None", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, generative models based on the diffusion process have emerged as a promising direction for automating the design of molecules. However, directly adding continuous Gaussian noise to discrete graphs leads to the problem of the final noisy data not conforming to the standard Gaussian distribution. Current graph diffusion models either corrupt discrete data through a transition matrix or relax the discrete data to continuous space for the diffusion process. These approaches not only require significant computation resources due to the inclusion of the bond type matrix but also cannot easily perform scalable conditional generation, such as adding cross-attention layers, due to the lack of embedding representations. In this paper, we first introduce the Graph Latent Diffusion Model (GLDM), a novel variant of latent diffusion models that overcomes the mismatch problem of continuous diffusion space and discrete data space. Meanwhile, the latent diffusion framework avoids the issues of computational resource consumption and lack of embeddings for conditional generation faced by current graph diffusion models. However, it only utilizes graph-level embeddings for molecule generation, losing node-level and structural information. Therefore, we further ex- tend the GLDM to the Hierarchical Graph Latent Diffusion Model (HGLDM). By including node embeddings and subgraph embeddings that contain structural in- formation, our model significantly reduces computation time compared to the cur- rent graph diffusion models. We evaluate our model on three benchmarks through unconditional generation and conditional generation tasks, which?\u2026", "IdName": "bianhierarchical", "Citation": "", "Keywords": ""}, {"Name": "Trading-off Multiple Properties for Molecular Optimization", "Authors": ["Yifan Niu", "Ziqi Gao", "Tingyang Xu", "Yatao Bian", "Yu Rong", "Jia Li"], "Sources": "None", "PublishedYears": "2023", "Doi": "", "Abstracts": "Molecular optimization, a critical research area in drug discovery, aims to enhance the properties or performance of molecules through systematic modifications of their chemical structures. Recently, existing Multi-Objective Molecular Optimization (MOMO) methods are extended from Single-Objective Molecular Optimization (SOMO) approaches by employing techniques such as Linear Scalarization, Evolutionary Algorithms, and Multi-Objective Bayesian Optimization. In Multi-Objective Optimization, the ideal goal is to find Pareto optimal solutions over different preferences, which indicate the importance of different objectives. However, these straightforward extensions often struggle with trading off multiple properties due to the conflicting or correlated nature of certain properties.  More specifically, current MOMO methods derived from SOMO are still challenged in finding preference-conditioned Pareto solutions and exhibit low efficiency in Pareto search. To address the aforementioned problems, we propose the \\textbf{P}reference-\\textbf{C}onditioned \\textbf{I}nversion (PCI) framework,  efficiently ``inverting'' a pre-trained surrogate oracle under the guidance of a non-dominated gradient, to generate candidate Pareto optimal molecules over preference-conditioned distributions. Additionally, we provide theoretical guarantees for PCI's capability in converging to preference-conditioned solutions. This unique characteristic enables PCI to search the full Pareto front approximately, thereby assisting in the discovery of diverse molecules with varying ratios of properties. Comprehensive experimental evaluations show that our model significantly?\u2026", "IdName": "niutrading", "Citation": "", "Keywords": ""}, {"Name": "ProbTS: A Unified Toolkit to Probe Deep Time-series Forecasting", "Authors": ["Jiawen Zhang", "Xumeng Wen", "Shun Zheng", "Jia Li", "Jiang Bian"], "Sources": "arXiv preprint arXiv:2310.07446", "PublishedYears": "2023", "Doi": "", "Abstracts": "Time-series forecasting serves as a linchpin in a myriad of applications, spanning various domains. With the growth of deep learning, this arena has bifurcated into two salient branches: one focuses on crafting specific neural architectures tailored for time series, and the other harnesses advanced deep generative models for probabilistic forecasting. While both branches have made significant progress, their differences across data scenarios, methodological focuses, and decoding schemes pose profound, yet unexplored, research questions. To bridge this knowledge chasm, we introduce ProbTS, a pioneering toolkit developed to synergize and compare these two distinct branches. Endowed with a unified data module, a modularized model module, and a comprehensive evaluator module, ProbTS allows us to revisit and benchmark leading methods from both branches. The scrutiny with ProbTS highlights their distinct characteristics, relative strengths and weaknesses, and areas that need further exploration. Our analyses point to new avenues for research, aiming for more effective time-series forecasting.", "IdName": "zhang2023probts", "Citation": "", "Keywords": ""}, {"Name": "Decision Support System for Chronic Diseases Based on Drug-Drug Interactions", "Authors": ["Tian Bian", "Yuli Jiang", "Jia Li", "Tingyang Xu", "Yu Rong", "Yi Su", "Timothy Kwok", "Helen Meng", "Hong Cheng"], "Sources": "ICDE 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": "Many patients with chronic diseases resort to multiple medications to relieve various symptoms, which raises concerns about the safety of multiple medication use, as severe drug-drug antagonism can lead to serious adverse effects or even death. This paper presents a Decision Support System, called DSSDDI, based on drug-drug interactions to support doctors prescribing decisions. DSSDDI contains three modules, Drug-Drug Interaction (DDI) module, Medical Decision (MD) module and Medical Support (MS) module. The DDI module learns safer and more effective drug representations from the drug-drug interactions. To capture the potential causal relationship between DDI and medication use, the MD module considers the representations of patients and drugs as context, DDI and patients\u2019 similarity as treatment, and medication use as outcome to construct counterfactual links for the representation learning?\u2026", "IdName": "bian2023decision", "Citation": "", "Keywords": ""}, {"Name": "Network communication method and system, device, and storage medium", "Authors": ["Zhihao Shang", "Jia Li", "Huanxin Liu", "Hongfei Zhou"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "This application discloses a network communication method applied to a network communication system including a first network device in a first private network, a second network device in a second private network and a gateway device coupling the first private network to the second private network. The first network device receives a first data packet transmitted from a terminal to a target blockchain node, and acquires an actual network address of the target blockchain node; and generates a second data packet according to the first data packet and the actual network address, and transmits the second data packet to a virtual network address of the second network device in the second private network, so that the operation overheads generated when the gateway device generates virtual network addresses for blockchain nodes can be reduced, thereby saving a storage space of the gateway device.", "IdName": "shang2022network", "Citation": "", "Keywords": ""}, {"Name": "Learning to Iteratively Solve Routing Problems with Dual-Aspect Collaborative Transformer", "Authors": ["Yining Ma", "Jingwen Li", "Zhiguang Cao", "Wen Song", "Le Zhang", "Zhenghua Chen", "Jing Tang"], "Sources": "Advances in Neural Information Processing Systems (NeurIPS) 34", "PublishedYears": "2021", "Doi": "", "Abstracts": "Recently, Transformer has become a prevailing deep architecture for solving vehicle routing problems (VRPs). However, it is less effective in learning improvement models for VRP because its positional encoding (PE) method is not suitable in representing VRP solutions. This paper presents a novel Dual-Aspect Collaborative Transformer (DACT) to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. Moreover, the positional features are embedded through a novel cyclic positional encoding (CPE) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions (ie, cyclic sequences). We train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. We apply DACT to solve the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP). Results show that our DACT outperforms existing Transformer based improvement models, and exhibits much better generalization performance across different problem sizes on synthetic and benchmark instances, respectively.", "IdName": "ma2021learning", "Citation": "", "Keywords": ""}, {"Name": "Campus3D: A Photogrammetry Point Cloud Benchmark for Hierarchical Understanding of Outdoor Scene", "Authors": ["Xinke Li", "Chongshou Li", "Zekun Tong", "Andrew Lim", "Junsong Yuan", "Yuwei Wu", "Jing Tang", "Raymond Huang"], "Sources": "2020 ACM International Conference on Multimedia (ACM MM)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Learning on 3D scene-based point cloud has received extensive attention as its promising application in many fields, and well-annotated and multisource datasets can catalyze the development of those data-driven approaches. To facilitate the research of this area, we present a richly-annotated 3D point cloud dataset for multiple outdoor scene understanding tasks and also an effective learning framework for its hierarchical segmentation task. The dataset was generated via the photogrammetric processing on unmanned aerial vehicle (UAV) images of the National University of Singapore (NUS) campus, and has been point-wisely annotated with both hierarchical and instance-based labels. Based on it, we formulate a hierarchical learning problem for 3D point cloud segmentation and propose a measurement evaluating consistency across various hierarchies. To solve this problem, a two-stage method including?\u2026", "IdName": "li2020campus3d", "Citation": "", "Keywords": ""}, {"Name": "Do the Rich Get Richer? Fairness Analysis for Blockchain Incentives", "Authors": ["Yuming Huang", "Jing Tang", "Qianhao Cong", "Andrew Lim", "Jianliang Xu"], "Sources": "Proceedings of the 2021 SIGMOD International Conference on Management of?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Proof-of-Work (PoW) is the most widely adopted incentive model in current blockchain systems, which unfortunately is energy inefficient. Proof-of-Stake (PoS) is then proposed to tackle the energy issue. The rich-get-richer concern of PoS has been heavily debated in the blockchain community. The debate is centered around the argument that whether rich miners possessing more stakes will obtain higher staking rewards and further increase their potential income in the future. In this paper, we define two types of fairness, i.e., expectational fairness and robust fairness, that are useful for answering this question. In particular, expectational fairness illustrates that the expected income of a miner is proportional to her initial investment, indicating that the expected return on investment is a constant. To better capture the uncertainty of mining outcomes, robust fairness is proposed to characterize whether the return on?\u2026", "IdName": "huang2021rich", "Citation": "", "Keywords": ""}, {"Name": "Efficient Approximation Algorithms for Adaptive Influence Maximization", "Authors": ["Keke Huang", "Jing Tang", "Kai Han", "Xiaokui Xiao", "Wei Chen", "Aixin Sun", "Xueyan Tang", "Andrew Lim"], "Sources": "The VLDB Journal", "PublishedYears": "2020", "Doi": "", "Abstracts": " Given a social network G and an integer k, the influence maximization (IM) problem asks for a seed set S of k nodes from G to maximize the expected number of nodes influenced via a propagation model. The majority of the existing algorithms for the IM problem are developed only under the non-adaptive setting, i.e., where all k seed nodes are selected in one batch without observing how they influence other users in real world. In this paper, we study the adaptive IM problem where the k seed nodes are selected in batches of equal size b, such that the i-th batch is identified after the actual influence results of the former  batches are observed. In this paper, we propose the first practical algorithm for the adaptive IM problem that could provide the worst-case approximation guarantee of , where  and  is a user-specified parameter. In particular, we propose a general?\u2026", "IdName": "huang2020efficient", "Citation": "", "Keywords": ""}, {"Name": "Pricing Influential Nodes in Online Social Networks", "Authors": ["Yuqing Zhu", "Jing Tang", "Xueyan Tang"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2020", "Doi": "", "Abstracts": "Influential nodes with rich connections in online social networks (OSNs) are of great values to initiate marketing campaigns. However, the potential influence spread that can be generated by these influential nodes is hidden behind the structures of OSNs, which are often held by OSN providers and unavailable to advertisers for privacy concerns. A social advertising model known as influencer marketing is to have OSN providers offer and price candidate nodes for advertisers to purchase for seeding marketing campaigns. In this setting, a reasonable price profile for the candidate nodes should effectively reflect the expected influence gain they can bring in a marketing campaign. In this paper, we study the problem of pricing the influential nodes based on their expected influence spread to help advertisers select the initiators of marketing campaigns without the knowledge of OSN structures. We design a function?\u2026", "IdName": "zhu2020pricing", "Citation": "", "Keywords": ""}, {"Name": "An Analysis of Blockchain Consistency in Asynchronous Networks: Deriving a Neat Bound", "Authors": ["Jun Zhao", "Jing Tang", "Zengxiang Li", "Huaxiong Wang Wang", "Kwok-Yan Lam", "Kaiping Xue"], "Sources": "2020 IEEE 40th International Conference on Distributed Computing Systems (ICDCS)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Formal analyses of blockchain protocols have received much attention recently. Consistency results of Nakamoto's blockchain protocol are often expressed in a quantity c, which denotes the expected number of network delays before some block is mined. With \u03bc (resp., \u03bd) denoting the fraction of computational power controlled by benign miners (resp., the adversary), where \u03bc+\u03bd =1, we prove for the first time that to ensure the consistency property of Nakamoto's blockchain protocol in an asynchronous network, it suffices to have c to be just slightly greater than 2\u03bc/(ln(\u03bc/\u03bd)). Such a result is both neater and stronger than existing ones. In the proof, we formulate novel Markov chains which characterize the numbers of mined blocks in different rounds.", "IdName": "zhao2020analysis", "Citation": "", "Keywords": ""}, {"Name": "Influence Maximization Revisited: Efficient Sampling with Bound Tightened", "Authors": ["Qintian Guo", "Sibo Wang", "Zhewei Wei", "Wenqing Lin", "Jing Tang"], "Sources": "ACM Transactions on Database Systems (TODS)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Given a social network G with n nodes and m edges, a positive integer k, and a cascade model C, the influence maximization (IM) problem asks for k nodes in G such that the expected number of nodes influenced by the k nodes under cascade model C is maximized. The state-of-the-art approximate solutions run in O(k(n+m)log n/\u03b52) expected time while returning a (1 - 1/e - \u03b5) approximate solution with at least 1 - 1/n probability. A key phase of these IM algorithms is the random reverse reachable (RR) set generation, and this phase significantly affects the efficiency and scalability of the state-of-the-art IM algorithms. In this article, we present a study on this key phase and propose an efficient random RR set generation algorithm under IC model. With the new algorithm, we show that the expected running time of existing IM algorithms under IC model can be improved to O(k ? n log n ?2), when for any node v, the total?\u2026", "IdName": "guo2022influence", "Citation": "", "Keywords": ""}, {"Name": "Revisiting Modified Greedy Algorithm for Monotone Submodular Maximization with a Knapsack Constraint", "Authors": ["Jing Tang", "Xueyan Tang", "Andrew Lim", "Kai Han", "Chongshou Li", "Junsong Yuan"], "Sources": "Proceedings of the ACM on Measurement and Analysis of Computing Systems 5 (1?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Monotone submodular maximization with a knapsack constraint is NP-hard. Various approximation algorithms have been devised to address this optimization problem. In this paper, we revisit the widely known modified greedy algorithm. First, we show that this algorithm can achieve an approximation factor of 0.405, which significantly improves the known factors of 0.357 given by Wolsey and (1-1/e)/2\\approx 0.316 given by Khuller et al. More importantly, our analysis closes a gap in Khuller et al.'s proof for the extensively mentioned approximation factor of (1-1/\\sqrte )\\approx 0.393 in the literature to clarify a long-standing misconception on this issue. Second, we enhance the modified greedy algorithm to derive a data-dependent upper bound on the optimum. We empirically demonstrate the tightness of our upper bound with a real-world application. The bound enables us to obtain a data-dependent ratio typically?\u2026", "IdName": "tang2021revisiting", "Citation": "", "Keywords": ""}, {"Name": "Optimal Streaming Algorithms for Multi-Armed Bandits", "Authors": ["Tianyuan Jin", "Keke Huang", "Jing Tang", "Xiaokui Xiao"], "Sources": "International Conference on Machine Learning", "PublishedYears": "2021", "Doi": "", "Abstracts": "This paper studies two variants of the best arm identification (BAI) problem under the streaming model, where we have a stream of n arms with reward distributions supported on [0, 1] with unknown means. The arms in the stream are arriving one by one, and the algorithm cannot access an arm unless it is stored in a limited size memory. We first study the streaming\\epslion-topk-arms identification problem, which asks for k arms whose reward means are lower than that of the k-th best arm by at most\\epsilon with probability at least 1-\\delta. For general\\epsilon\\in (0, 1), the existing solution for this problem assumes k= 1 and achieves the optimal sample complexity O (\\frac {n}{\\epsilon^ 2}\\log\\frac {1}{\\delta}) using O (\\log^*(n)) memory and a single pass of the stream. We propose an algorithm that works for any k and achieves the optimal sample complexity O (\\frac {n}{\\epsilon^ 2}\\log\\frac {k}{\\delta}) using a single-arm memory and a single pass of the stream. Second, we study the streaming BAI problem, where the objective is to identify the arm with the maximum reward mean with at least 1-\\delta probability, using a single-arm memory and as few passes of the input stream as possible. We present a single-arm-memory algorithm that achieves a near instance-dependent optimal sample complexity within O (\\log\\Delta_2^{-1}) passes, where\\Delta_2 is the gap between the mean of the best arm and that of the second best arm.", "IdName": "jin2021optimal", "Citation": "", "Keywords": ""}, {"Name": "Almost Optimal Anytime Algorithm for Batched Multi-Armed Bandits", "Authors": ["Tianyuan Jin", "Jing Tang", "Pan Xu", "Keke Huang", "Xiaokui Xiao", "Quanquan Gu"], "Sources": "International Conference on Machine Learning", "PublishedYears": "2021", "Doi": "", "Abstracts": "In batched multi-armed bandit problems, the learner can adaptively pull arms and adjust strategy in batches. In many real applications, not only the regret but also the batch complexity need to be optimized. Existing batched bandit algorithms usually assume that the time horizon T is known in advance. However, many applications involve an unpredictable stopping time. In this paper, we study the anytime batched multi-armed bandit problem. We propose an anytime algorithm that achieves the asymptotically optimal regret for exponential families of reward distributions with $ O (\\log\\log T\\ilog^{\\alpha}(T)) $\\footnote {Notation\\ilog^{\\alpha}(T) is the result of iteratively applying the logarithm function on T for\\alpha times, eg,\\ilog^{3}(T)=\\log\\log\\log T.} batches, where . Moreover, we prove that for any constant c> 0, no algorithm can achieve the asymptotically optimal regret within c\\log\\log T batches.", "IdName": "jin2021almost", "Citation": "", "Keywords": ""}, {"Name": "Randomized Algorithms for Submodular Function Maximization with a -System Constraint", "Authors": ["Shuang Cui", "Kai Han", "Tianshuai Zhu", "Jing Tang", "Benwei Wu", "He Huang"], "Sources": "International Conference on Machine Learning", "PublishedYears": "2021", "Doi": "", "Abstracts": "Submodular optimization has numerous applications such as crowdsourcing and viral marketing. In this paper, we study the problem of non-negative submodular function maximization subject to a -system constraint, which generalizes many other important constraints in submodular optimization such as cardinality constraint, matroid constraint, and -extendible system constraint. The existing approaches for this problem are all based on deterministic algorithmic frameworks, and the best approximation ratio achieved by these algorithms (for a general submodular function) is . We propose a randomized algorithm with an improved approximation ratio of , while achieving nearly-linear time complexity significantly lower than that of the state-of-the-art algorithm. We also show that our algorithm can be further generalized to address a stochastic case where the elements can be adaptively selected, and propose an approximation ratio of  for the adaptive optimization case. The empirical performance of our algorithms is extensively evaluated in several applications related to data mining and social computing, and the experimental results demonstrate the superiorities of our algorithms in terms of both utility and efficiency.", "IdName": "cui2021randomized", "Citation": "", "Keywords": ""}, {"Name": "Node-wise Diffusion for Scalable Graph Learning", "Authors": ["Keke Huang", "Jing Tang", "Juncheng Liu", "Renchi Yang", "Xiaokui Xiao"], "Sources": "Proceedings of the ACM Web Conference (WWW)", "PublishedYears": "2023", "Doi": "", "Abstracts": " Graph Neural Networks (GNNs) have shown superior performance for semi-supervised learning of numerous web applications, such as classification on web services and pages, analysis of online social networks, and recommendation in e-commerce. The state of the art derives representations for all nodes in graphs following the same diffusion (message passing) model without discriminating their uniqueness. However, (i) labeled nodes involved in model training usually account for a small portion of graphs in the semi-supervised setting, and (ii) different nodes locate at different graph local contexts and it inevitably degrades the representation qualities if treating them undistinguishedly in diffusion.  To address the above issues, we develop NDM, a universal node-wise diffusion model, to capture the unique characteristics of each node in diffusion, by which NDM is able to yield high-quality node representations?\u2026", "IdName": "huang2023node", "Citation": "", "Keywords": ""}, {"Name": "2-hop+ Sampling: Efficient and Effective Influence Estimation", "Authors": ["Yuqing Zhu", "Jing Tang", "Xueyan Tang", "Sibo Wang", "Andrew Lim"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "With rapidly growing sizes of online social networks, computational challenges arise in analyzing the diffusion process over networks. Sampling methods are commonly used to study the cascade effect and estimate users\u2019 influence. In this paper, we propose a brand-new sampling method, called 2-hop+ sampling for quickly and accurately estimating the cascade size generated by a set of seed users under the independent cascade model. Our method generates only samples with at least one 2-hop live path from the source to reduce the number of samples. We further enhance the sampling efficiency of our method by a    technique. Moreover, we improve the generalized stopping rule algorithm to obtain an   -estimate of the mean of random variables with fewer samples needed. Extensive experiments with real-world datasets show that our techniques can significantly improve the estimation efficiency?\u2026", "IdName": "zhu20212", "Citation": "", "Keywords": ""}, {"Name": "Efficient and Effective Algorithms for Revenue Maximization in Social Advertising", "Authors": ["Kai Han", "Benwei Wu", "Jing Tang", "Shuang Cui", "Cigdem Aslay", "Laks VS Lakshmanan"], "Sources": "Proceedings of the 2021 SIGMOD International Conference on Management of?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "We consider the revenue maximization problem in social advertising, where a social network platform owner needs to select seed users for a group of advertisers, each with a payment budget, such that the total expected revenue that the owner gains from the advertisers by propagating their ads in the network is maximized. Previous studies on this problem show that it is intractable and present approximation algorithms. We revisit this problem from a fresh perspective and develop novel efficient approximation algorithms, both under the setting where an exact influence oracle is assumed and under one where this assumption is relaxed. Our approximation ratios significantly improve upon the previous ones. Furthermore, we empirically show, using extensive experiments on four datasets, that our algorithms considerably outperform the existing methods on both the solution quality and computation efficiency.", "IdName": "han2021efficient", "Citation": "", "Keywords": ""}, {"Name": "Dq-lore: Dual queries with low rank approximation re-ranking for in-context learning", "Authors": ["Jing Xiong", "Zixuan Li", "Chuanyang Zheng", "Zhijiang Guo", "Yichun Yin", "Enze Xie", "Zhicheng Yang", "Qingxing Cao", "Haiming Wang", "Xiongwei Han", "Jing Tang", "Chengming Li", "Xiaodan Liang"], "Sources": "arXiv preprint arXiv:2310.02954", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recent advances in natural language processing, primarily propelled by Large Language Models (LLMs), have showcased their remarkable capabilities grounded in in-context learning. A promising avenue for guiding LLMs in intricate reasoning tasks involves the utilization of intermediate reasoning steps within the Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies in the effective selection of exemplars for facilitating in-context learning. In this study, we introduce a framework that leverages Dual Queries and Low-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars for in-context learning. Dual Queries first query LLM to obtain LLM-generated knowledge such as CoT, then query the retriever to obtain the final exemplars via both question and the knowledge. Moreover, for the second query, LoRe employs dimensionality reduction techniques to refine exemplar selection, ensuring close alignment with the input question's knowledge. Through extensive experiments, we demonstrate that DQ-LoRe significantly outperforms prior state-of-the-art methods in the automatic selection of exemplars for GPT-4, enhancing performance from 92.5% to 94.2%. Our comprehensive analysis further reveals that DQ-LoRe consistently outperforms retrieval-based approaches in terms of both performance and adaptability, especially in scenarios characterized by distribution shifts. DQ-LoRe pushes the boundaries of in-context learning and opens up new avenues for addressing complex reasoning challenges. We will release the code soon.", "IdName": "xiong2023dq", "Citation": "", "Keywords": ""}, {"Name": "Distributed Influence Maximization for Large-Scale Online Social Networks", "Authors": ["Jing Tang", "Yuqing Zhu", "Xueyan Tang", "Kai Han"], "Sources": "2022 IEEE 38th International Conference on Data Engineering (ICDE)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Thanks to billions of users in online social networks (OSNs), viral marketing becomes one of the most effective promotion channels for various new products or campaigns. Influence maximization is a classic problem in viral marketing, which has been extensively studied in the past two decades. Existing algorithms for influence maximization, however, mostly focus on single machine processing. To address the influence maximization problem on a massive scale, we design distributed algorithms via a cluster of machines, which can effectively speed up the computation while maintaining the state-of-the-art (1 -1/e-c)-approximation guarantee. Our distributed algorithms consist of two building blocks: (i) distributed reverse influence sampling, and (ii) element-distributed maximum coverage. We carry out extensive experiments on real datasets with millions of nodes and billions of edges to demonstrate the scalability of?\u2026", "IdName": "tang2022distributed", "Citation": "", "Keywords": ""}, {"Name": "LSGNN: Towards General Graph Neural Network in Node Classification by Local Similarity", "Authors": ["Yuhan Chen", "Yihong Luo", "Jing Tang", "Liang Yang", "Siya Qiu", "Chuan Wang", "Xiaochun Cao"], "Sources": "arXiv preprint arXiv:2305.04225", "PublishedYears": "2023", "Doi": "", "Abstracts": "Heterophily has been considered as an issue that hurts the performance of Graph Neural Networks (GNNs). To address this issue, some existing work uses a graph-level weighted fusion of the information of multi-hop neighbors to include more nodes with homophily. However, the heterophily might differ among nodes, which requires to consider the local topology. Motivated by it, we propose to use the local similarity (LocalSim) to learn node-level weighted fusion, which can also serve as a plug-and-play module. For better fusion, we propose a novel and efficient Initial Residual Difference Connection (IRDC) to extract more informative multi-hop information. Moreover, we provide theoretical analysis on the effectiveness of LocalSim representing node homophily on synthetic graphs. Extensive evaluations over real benchmark datasets show that our proposed method, namely Local Similarity Graph Neural Network (LSGNN), can offer comparable or superior state-of-the-art performance on both homophilic and heterophilic graphs. Meanwhile, the plug-and-play model can significantly boost the performance of existing GNNs. Our code is provided at https://github.com/draym28/LSGNN.", "IdName": "chen2023lsgnn", "Citation": "", "Keywords": ""}, {"Name": "Randomized Pricing with Deferred Acceptance for Revenue Maximization with Submodular Objectives", "Authors": ["He Huang", "Kai Han", "Shuang Cui", "Jing Tang"], "Sources": "Proceedings of the ACM Web Conference (WWW)", "PublishedYears": "2023", "Doi": "", "Abstracts": " A lot of applications in web economics need to maximize the revenue under a budget for payments and also guarantee the truthfulness of users, so Budget-Feasible Mechanism (BFM) Design has aroused great interests during last decade. Most of the existing BFMs concentrate on maximizing a monotone submodular function subject to a knapsack constraint, which is insufficient for many applications with complex objectives or constraints. Observing this, the recent studies (e.g., [4, 5, 11]) have considered non-monotone submodular objectives or more complex constraints such as a k-system constraint. In this study, we follow this line of research and propose truthful BFMs with improved performance bounds for non-monotone submodular objectives with or without a k-system constraint. Our BFMs leverage the idea of providing random prices to users while deferring the decision on the final winning set, and are also?\u2026", "IdName": "huang2023randomized", "Citation": "", "Keywords": ""}, {"Name": "Practical Parallel Algorithms for Submodular Maximization subject to a Knapsack Constraint with Nearly Optimal Adaptivity", "Authors": ["Shuang Cui", "Kai Han", "Jing Tang", "He Huang", "Xueying Li", "Zhiyu Li"], "Sources": "Proceedings of the 37th AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Submodular maximization has wide applications in machine learning and data mining, where massive datasets have brought the great need for designing efficient and parallelizable algorithms. One measure of the parallelizability of a submodular maximization algorithm is its adaptivity complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an (8+ epsilon)-approximation under O (log n) adaptive complexity, which is optimal up to a factor of O (loglog n). Moreover, under slightly larger adaptivity, we also propose approximation algorithms with nearly optimal query complexity of O (n), while achieving better approximation ratios. We show that our algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.", "IdName": "cui2023practical", "Citation": "", "Keywords": ""}, {"Name": "Streaming Algorithms for Constrained Submodular Maximization", "Authors": ["Shuang Cui", "Kai Han", "Jing Tang", "He Huang", "Xueying Li", "Zhiyu Li"], "Sources": "Proceedings of the ACM on Measurement and Analysis of Computing Systems 6 (3?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "It is of great importance to design streaming algorithms for submodular maximization, as many applications (e.g., crowdsourcing) have large volume of data satisfying the well-known ''diminishing returns'' property, which cannot be handled by offline algorithms requiring full access to the whole dataset. However, streaming submodular maximization has been less studied than the offline algorithms due to the hardness brought by more stringent requirements on memory consumption. In this paper, we consider the fundamental problem of Submodular Maximization under k-System and d-Knapsack constraints (SMSK), which has only been successfully addressed by offline algorithms in previous studies, and we propose the first streaming algorithm for it with provable performance bounds. Our approach adopts a novel algorithmic framework dubbed MultiplexGreedy, making it also perform well under a single k-system?\u2026", "IdName": "cui2022streaming", "Citation": "", "Keywords": ""}, {"Name": "Analysis of Influence Contribution in Social Advertising", "Authors": ["Yuqing Zhu", "Jing Tang", "Xueyan Tang", "Lei Chen"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2022", "Doi": "", "Abstracts": "Online Social Network (OSN) providers usually conduct advertising campaigns by inserting social ads into promoted posts. Whenever a user engages in a promoted ad, she may further propagate the promoted ad to her followers recursively and the propagation process is known as the word-of-mouth effect. In order to spread the promotion cascade widely and efficiently, the OSN provider often tends to select the influencers, who normally have large audiences over the social network, to initiate the advertising campaign. This marketing model, also termed as influencer marketing, has been gaining increasing traction and investment and is rapidly becoming one of the most widely-used channels in digital marketing. In this paper, we formulate the problem for the OSN provider to derive the influence contributions of influencers given the campaign result, considering the viral propagation of the ads, namely influence?\u2026", "IdName": "zhu2021analysis", "Citation": "", "Keywords": ""}, {"Name": "Efficient Estimation of Pairwise Effective Resistance", "Authors": ["Renchi Yang", "Jing Tang"], "Sources": "Proceedings of the 2023 SIGMOD International Conference on Management of Data", "PublishedYears": "2023", "Doi": "", "Abstracts": "Given an undirected graph G, the effective resistance r(s,t) measures the dissimilarity of node pair s,t in G, which finds numerous applications in real-world problems, such as recommender systems, combinatorial optimization, molecular chemistry, and electric power networks. Existing techniques towards pairwise effective resistance estimation either trade approximation guarantees for practical efficiency, or vice versa. In particular, the state-of-the-art solution is based on a multitude of Monte Carlo random walks, rendering it rather inefficient in practice, especially on large graphs. Motivated by this, this paper first presents an improved Monte Carlo approach, AMC, which reduces both the length and amount of random walks required without degrading the theoretical accuracy guarantee, through careful theoretical analysis and an adaptive sampling scheme. Further, we develop a greedy approach, GEER, which?\u2026", "IdName": "yang2023efficient", "Citation": "", "Keywords": ""}, {"Name": "Cost-Effective Algorithms for Average-Case Interactive Graph Search", "Authors": ["Qianhao Cong", "Jing Tang", "Yuming Huang", "Lei Chen", "Yeow Meng Chee"], "Sources": "2022 IEEE 38th International Conference on Data Engineering (ICDE)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Interactive graph search (IGS) uses human intelligence to locate the target node in hierarchy, which can be applied for image classification, product categorization and searching a database. Specifically, IGS aims to categorize an object from a given category hierarchy via several rounds of interactive queries. In each round of query, the search algorithm picks a category and receives a boolean answer on whether the object is under the chosen category. The main efficiency goal asks for the minimum number of queries to identify the correct hierarchical category for the object. In this paper, we study the average-case interactive graph search (AIGS) problem that aims to minimize the expected number of queries when the objects follow a probability distribution. We propose a greedy search policy that splits the candidate categories as evenly as possible with respect to the probability weights, which offers an approximation?\u2026", "IdName": "cong2022cost", "Citation": "", "Keywords": ""}, {"Name": "Chromatic Correlation Clustering, Revisited", "Authors": ["Qing Xiu", "Kai Han", "Jing Tang", "Shuang Cui", "He Huang"], "Sources": "Advances in Neural Information Processing Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": "Chromatic Correlation Clustering (CCC)(introduced by Bonchi et al.[6]) is a natural generalization of the celebrated Correlation Clustering (CC) problem, introduced by Bonchi et al.[6]. It models objects with categorical pairwise relationships by an edge-colored graph, and has many applications in data mining, social networks and bioinformatics. We show that there exists a -approximation to the CCC problem based on a Linear Programming (LP) approach, thus improving the best-known approximation ratio of 3 achieved by Klodt et al.[21]. We also present an efficient heuristic algorithm for CCC leveraging a greedy clustering strategy, and conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.", "IdName": "xiu2022chromatic", "Citation": "", "Keywords": ""}, {"Name": "Structure-Aware Label Smoothing for Graph Neural Networks", "Authors": ["Yiwei Wang", "Yujun Cai", "Yuxuan Liang", "Wei Wang", "Henghui Ding", "Muhao Chen", "Jing Tang", "Bryan Hooi"], "Sources": "arXiv preprint arXiv:2112.00499", "PublishedYears": "2021", "Doi": "", "Abstracts": "Representing a label distribution as a one-hot vector is a common practice in training node classification models. However, the one-hot representation may not adequately reflect the semantic characteristics of a node in different classes, as some nodes may be semantically close to their neighbors in other classes. It would cause over-confidence since the models are encouraged to assign full probabilities when classifying every node. While training models with label smoothing can ease this problem to some degree, it still fails to capture the nodes' semantic characteristics implied by the graph structures. In this work, we propose a novel SALS (\\textit{Structure-Aware Label Smoothing}) method as an enhancement component to popular node classification models. SALS leverages the graph structures to capture the semantic correlations between the connected nodes and generate the structure-aware label distribution to replace the original one-hot label vectors, thus improving the node classification performance without inference costs. Extensive experiments on seven node classification benchmark datasets reveal the effectiveness of our SALS on improving both transductive and inductive node classification. Empirical results show that SALS is superior to the label smoothing method and enhances the node classification models to outperform the baseline methods.", "IdName": "wang2021structure", "Citation": "", "Keywords": ""}, {"Name": "How Fragile is Relation Extraction under Entity Replacements?", "Authors": ["Yiwei Wang", "Bryan Hooi", "Fei Wang", "Yujun Cai", "Yuxuan Liang", "Wenxuan Zhou", "Jing Tang", "Manjuan Duan", "Muhao Chen"], "Sources": "Proceedings of the 27th Conference on Computational Natural Language?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Relation extraction (RE) aims to extract the relations between entity names from the textual context. In principle, textual context determines the ground-truth relation and the RE models should be able to correctly identify the relations reflected by the textual context. However, existing work has found that the RE models memorize the entity name patterns to make RE predictions while ignoring the textual context. This motivates us to raise the question: are RE models robust to the entity replacements? In this work, we operate the random and type-constrained entity replacements over the RE instances in TACRED and evaluate the state-of-the-art RE models under the entity replacements. We observe the 30%-50% F1 score drops on the state-of-the-art RE models under entity replacements. These results suggest that we need more efforts to develop effective RE models robust to entity replacements. We release the source code at https://github. com/wangywUST/RobustRE.", "IdName": "wang2023fragile", "Citation": "", "Keywords": ""}, {"Name": "Optimal Batched Best Arm Identification", "Authors": ["Tianyuan Jin", "Yu Yang", "Jing Tang", "Xiaokui Xiao", "Pan Xu"], "Sources": "arXiv preprint arXiv:2310.14129", "PublishedYears": "2023", "Doi": "", "Abstracts": "We study the batched best arm identification (BBAI) problem, where the learner's goal is to identify the best arm while switching the policy as less as possible. In particular, we aim to find the best arm with probability  for some small constant  while minimizing both the sample complexity (total number of arm pulls) and the batch complexity (total number of batches). We propose the three-batch best arm identification (Tri-BBAI) algorithm, which is the first batched algorithm that achieves the optimal sample complexity in the asymptotic setting (i.e., ) and runs only in at most  batches. Based on Tri-BBAI, we further propose the almost optimal batched best arm identification (Opt-BBAI) algorithm, which is the first algorithm that achieves the near-optimal sample and batch complexity in the non-asymptotic setting (i.e.,  is arbitrarily fixed), while enjoying the same batch and sample complexity as Tri-BBAI when  tends to zero. Moreover, in the non-asymptotic setting, the complexity of previous batch algorithms is usually conditioned on the event that the best arm is returned (with a probability of at least ), which is potentially unbounded in cases where a sub-optimal arm is returned. In contrast, the complexity of Opt-BBAI does not rely on such an event. This is achieved through a novel procedure that we design for checking whether the best arm is eliminated, which is of independent interest.", "IdName": "jin2023optimal", "Citation": "", "Keywords": ""}, {"Name": "Constrained Subset Selection from Data Streams for Profit Maximization", "Authors": ["Shuang Cui", "Kai Han", "Jing Tang", "He Huang"], "Sources": "Proceedings of the ACM Web Conference (WWW)", "PublishedYears": "2023", "Doi": "", "Abstracts": " The problem of constrained subset selection from a large data stream for profit maximization has many applications in web data mining and machine learning, such as social advertising, team formation and recommendation systems. Such a problem can be formulated as maximizing a regularized submodular function under certain constraints. In this paper, we consider a generalized k-system constraint, which captures various requirements in real-world applications. For this problem, we propose the first streaming algorithm with provable performance bounds, leveraging a novel multitudinous distorted filter framework. The empirical performance of our algorithm is extensively evaluated in several applications including web data mining and recommendation systems, and the experimental results demonstrate the superiorities of our algorithm in terms of both effectiveness and efficiency.", "IdName": "cui2023constrained", "Citation": "", "Keywords": ""}, {"Name": "Process-Driven Autoformalization in Lean 4", "Authors": ["Jianqiao Lu", "Zhengying Liu", "Yingjia Wan", "Yinya Huang", "Haiming Wang", "Zhicheng Yang", "Jing Tang", "Zhijiang Guo"], "Sources": "arXiv preprint arXiv:2406.01940", "PublishedYears": "2024", "Doi": "", "Abstracts": "Autoformalization, the conversion of natural language mathematics into formal languages, offers significant potential for advancing mathematical reasoning. However, existing efforts are limited to formal languages with substantial online corpora and struggle to keep pace with rapidly evolving languages like Lean 4. To bridge this gap, we propose a new benchmark \\textbf{Form}alization for \\textbf{L}ean~\\textbf{4} (\\textbf{\\name}) designed to evaluate the autoformalization capabilities of large language models (LLMs). This benchmark encompasses a comprehensive assessment of questions, answers, formal statements, and proofs. Additionally, we introduce a \\textbf{P}rocess-\\textbf{S}upervised \\textbf{V}erifier (\\textbf{PSV}) model that leverages the precise feedback from Lean 4 compilers to enhance autoformalization. Our experiments demonstrate that the PSV method improves autoformalization, enabling higher accuracy using less filtered training data. Furthermore, when fine-tuned with data containing detailed process information, PSV can leverage the data more effectively, leading to more significant improvements in autoformalization for Lean 4. Our dataset and code are available at \\url{https://github.com/rookie-joe/PDA}.", "IdName": "lu2024process", "Citation": "", "Keywords": ""}, {"Name": "Proving Theorems Recursively", "Authors": ["Haiming Wang", "Huajian Xin", "Zhengying Liu", "Wenda Li", "Yinya Huang", "Jianqiao Lu", "Zhicheng Yang", "Jing Tang", "Jian Yin", "Zhenguo Li", "Xiaodan Liang"], "Sources": "arXiv preprint arXiv:2405.14414", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent advances in automated theorem proving leverages language models to explore expanded search spaces by step-by-step proof generation. However, such approaches are usually based on short-sighted heuristics (e.g., log probability or value function scores) that potentially lead to suboptimal or even distracting subgoals, preventing us from finding longer proofs. To address this challenge, we propose POETRY (PrOvE Theorems RecursivelY), which proves theorems in a recursive, level-by-level manner in the Isabelle theorem prover. Unlike previous step-by-step methods, POETRY searches for a verifiable sketch of the proof at each level and focuses on solving the current level's theorem or conjecture. Detailed proofs of intermediate conjectures within the sketch are temporarily replaced by a placeholder tactic called sorry, deferring their proofs to subsequent levels. This approach allows the theorem to be tackled incrementally by outlining the overall theorem at the first level and then solving the intermediate conjectures at deeper levels. Experiments are conducted on the miniF2F and PISA datasets and significant performance gains are observed in our POETRY approach over state-of-the-art methods. POETRY on miniF2F achieves an average proving success rate improvement of 5.1%. Moreover, we observe a substantial increase in the maximum proof length found by POETRY, from 10 to 26.", "IdName": "wang2024proving", "Citation": "", "Keywords": ""}, {"Name": "Link Recommendation to Augment Influence Diffusion with Provable Guarantees", "Authors": ["Xiaolong Chen", "Yifan Song", "Jing Tang"], "Sources": "Proceedings of the ACM on Web Conference 2024", "PublishedYears": "2024", "Doi": "", "Abstracts": "Link recommendation systems in online social networks (OSNs), such as Facebook's ``People You May Know'', Twitter's ``Who to Follow'', and Instagram's ``Suggested Accounts'', facilitate the formation of new connections among users. This paper addresses the challenge of link recommendation for the purpose of social influence maximization. In particular, given a graph  and the seed set , our objective is to select  edges that connect seed nodes and ordinary nodes to optimize the influence dissemination of the seed set. This problem, referred to as influence maximization with augmentation (IMA), has been proven to be NP-hard. In this paper, we propose an algorithm, namely \\textsf{AIS}, consisting of an efficient estimator for augmented influence estimation and an accelerated sampling approach. \\textsf{AIS} provides a -approximate solution with a high probability of , and runs in  time assuming that the influence of any singleton node is smaller than that of the seed set. To the best of our knowledge, this is the first algorithm that can be implemented on large graphs containing millions of nodes while preserving strong theoretical guarantees. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.", "IdName": "chen2024link", "Citation": "", "Keywords": ""}, {"Name": "You Only Sample Once: Taming One-Step Text-To-Image Synthesis by Self-Cooperative Diffusion GANs", "Authors": ["Yihong Luo", "Xiaolong Chen", "Jing Tang"], "Sources": "arXiv preprint arXiv:2403.12931", "PublishedYears": "2024", "Doi": "", "Abstracts": "We introduce YOSO, a novel generative model designed for rapid, scalable, and high-fidelity one-step image synthesis. This is achieved by integrating the diffusion process with GANs. Specifically, we smooth the distribution by the denoising generator itself, performing self-cooperative learning. We show that our method can serve as a one-step generation model training from scratch with competitive performance. Moreover, we show that our method can be extended to finetune pre-trained text-to-image diffusion for high-quality one-step text-to-image synthesis even with LoRA fine-tuning. In particular, we provide the first diffusion transformer that can generate images in one step trained on 512 resolution, with the capability of adapting to 1024 resolution without explicit training. Our code is provided at https://github.com/Luo-Yihong/YOSO.", "IdName": "luo2024you", "Citation": "", "Keywords": ""}, {"Name": "Speak Like a Native: Prompting Large Language Models in a Native Style", "Authors": ["Zhicheng Yang", "Yiwei Wang", "Yinya Huang", "Jing Xiong", "Xiaodan Liang", "Jing Tang"], "Sources": "arXiv preprint arXiv:2311.13538", "PublishedYears": "2023", "Doi": "", "Abstracts": "Existing work has found that the prompt engineering heavily influences the performance of large language models (LLMs). Chain-of-thought (CoT), as a popular prompt engineering technique, prompted LLMs using in-context examples with reasoning steps. In current studies, the few-shot examples of CoT are generally handcrafted by humans. However, how the text style of in-context examples influence the outputs of LLMs still remains under-explored. This paper presents a novel and effective approach, named \\textbf{AlignCoT}, to improve the reasoning capability of LLMs by aligning the in-context examples with the native style of LLMs. ``Native'' refers to the inherent characteristic style of LLMs which can be probed by original zero-shot scenarios. AlignCoT is orthogonal to other prompt engineering methods, making it easy to combine with state-of-the-art techniques to further improve the LLMs' performance. We conduct extensive and comprehensive experiments on several benchmarks. The empirical results demonstrate that our AlignCoTsignificantly improves performance over the carefully handcrafted in-context examples. For instance, with GPT-3.5-turbo, we observed a +2.5\\% improvement on GSM8K. Furthermore, our AlignCoT consistently improve the performance when combined with other state-of-the-art prompt engineering methods. The source code and dataset will be available at \\href{https://github.com/yangzhch6/AlignCoT}{https://github.com/yangzhch6/AlignCoT}.", "IdName": "yang2023speak", "Citation": "", "Keywords": ""}, {"Name": "EntRED: Benchmarking Relation Extraction with Fewer Shortcuts", "Authors": ["Yiwei Wang", "Bryan Hooi", "Fei Wang", "Yujun Cai", "Yuxuan Liang", "Wenxuan Zhou", "Jing Tang", "Manjuan Duan", "Muhao Chen"], "Sources": "arXiv preprint arXiv:2305.13551", "PublishedYears": "2023", "Doi": "", "Abstracts": "Entity names play an effective role in relation extraction (RE) and often influence model performance. As a result, the entity names in the benchmarks' test sets significantly influence the evaluation of RE models. In this work, we find that the standard RE benchmarks' datasets have a large portion of incorrect entity annotations, low entity name diversity, and are prone to have shortcuts from entity names to ground-truth relations. These issues make the standard benchmarks far from reflecting the real-world scenarios. Hence, in this work, we present EntRED, a challenging RE benchmark with reduced shortcuts and higher diversity of entities. To build EntRED, we propose an end-to-end entity replacement pipeline based on causal inference (CI): ERIC. ERIC performs type-constrained replacements on entities to reduce the shortcuts from entity bias to ground-truth relations. ERIC applies CI in two aspects: 1) targeting the instances that need entity replacements, and 2) determining the candidate entities for replacements. We apply ERIC on TACRED to produce EntRED. Our EntRED evaluates whether the RE model can correctly extract the relations from the text instead of relying on entity bias. Empirical results reveal that even the strong RE model has a significant performance drop on EntRED, which memorizes entity name patterns instead of reasoning from the textual context. We release ERIC's source code and the EntRED benchmark at https://github.com/wangywUST/ENTRED.", "IdName": "wang2023entred", "Citation": "", "Keywords": ""}, {"Name": "Optimal price profile for influential nodes in online social networks", "Authors": ["Yuqing Zhu", "Jing Tang", "Xueyan Tang"], "Sources": "The VLDB Journal", "PublishedYears": "2022", "Doi": "", "Abstracts": "Influential nodes with rich connections in online social networks (OSNs) are of great values to initiate marketing campaigns. However, the potential influence spread that can be generated by these influential nodes is hidden behind the structures of OSNs, which are often held by OSN providers and unavailable to advertisers for privacy concerns. A social advertising model known as influencer marketing is to have OSN providers offer and price candidate nodes for advertisers to purchase for seeding marketing campaigns. In this setting, a reasonable price profile for the candidate nodes should effectively reflect the expected influence gain they can bring in a marketing campaign. In this paper, we study the problem of pricing the influential nodes based on their expected influence spread to help advertisers select the initiators of marketing campaigns without the knowledge of OSN structures. We design a function?\u2026", "IdName": "zhu2022optimal", "Citation": "", "Keywords": ""}, {"Name": "Noisy Interactive Graph Search", "Authors": ["Qianhao Cong", "Jing Tang", "Kai Han", "Yuming Huang", "Lei Chen", "Yeow Meng Chee"], "Sources": "Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The interactive graph search (IGS) problem aims to locate an initially unknown target node leveraging human intelligence. In IGS, we can gradually find the target node by sequentially asking humans some reachability queries like \"is the target node reachable from a given node x?\". However, human workers may make mistakes when answering these queries. Motivated by this concern, in this paper, we study a noisy version of the IGS problem. Our objective in this problem is to minimize the query complexity while ensuring accuracy. We propose a method to select the query node such that we can push the search process as much as possible and an online method to infer which node is the target after collecting a new answer. By rigorous theoretical analysis, we show that the query complexity of our approach is near-optimal up to a constant factor. The extensive experiments on two real datasets also demonstrate?\u2026", "IdName": "cong2022noisy", "Citation": "", "Keywords": ""}, {"Name": "The Power of Randomization: Efficient and Effective Algorithms for Constrained Submodular Maximization", "Authors": ["Kai Han", "Shuang Cui", "Tianshuai Zhu", "Jing Tang", "Benwei Wu", "He Huang"], "Sources": "arXiv preprint arXiv:2106.07116", "PublishedYears": "2021", "Doi": "", "Abstracts": "Submodular optimization has numerous applications such as crowdsourcing and viral marketing. In this paper, we study the fundamental problem of non-negative submodular function maximization subject to a -system constraint, which generalizes many other important constraints in submodular optimization such as cardinality constraint, matroid constraint, and -extendible system constraint. The existing approaches for this problem achieve the best-known approximation ratio of  (for a general submodular function) based on deterministic algorithmic frameworks. We propose several randomized algorithms that improve upon the state-of-the-art algorithms in terms of approximation ratio and time complexity, both under the non-adaptive setting and the adaptive setting. The empirical performance of our algorithms is extensively evaluated in several applications related to data mining and social computing, and the experimental results demonstrate the superiorities of our algorithms in terms of both utility and efficiency.", "IdName": "han2021power", "Citation": "", "Keywords": ""}, {"Name": "Fast Query Decomposition for Batch Shortest Path Processing in Road Networks", "Authors": ["Lei Li", "Mengxuan Zhang", "Wen Hua", "Xiaofang Zhou"], "Sources": "2020 IEEE 36th International Conference on Data Engineering (ICDE)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Shortest path query is a fundamental operation in various location-based services (LBS) and most of them process queries on the server-side. As the business expands, scalability becomes a severe issue. Instead of simply deploying more servers to cope with the quickly increasing query number, batch shortest path algorithms have been proposed recently to answer a set of queries together using shareable computation. Besides, they can also work in a highly dynamic environment as no index is needed. However, the existing batch algorithms either assume the batch queries are finely decomposed or just process them without differentiation, resulting in poor query efficiency. In this paper, we aim to improve the performance of batch shortest path algorithms by revisiting the problem of query clustering. Specifically, we first propose three query decomposition methods to cluster queries: Zigzag that considers the 1-N?\u2026", "IdName": "li2020fast", "Citation": "", "Keywords": ""}, {"Name": "Dynamic Hub Labeling for Road Networks", "Authors": ["Mengxuan Zhang", "Lei Li", "Wen Hua", "Rui Mao", "Pingfu Chao", "Xiaofang Zhou"], "Sources": "2021 IEEE 37th International Conference on Data Engineering (ICDE)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Shortest path finding is the building block of various applications in road networks and the index-based algorithms, especially hub labeling, can boost the query performance dramatically. However, the traffic condition keeps changing in real life, making the pre-computed index unable to answer the query correctly. In this work, we adopt the state-of-the-art tree decomposition-based hub labeling as the underlying index, and design efficient algorithms to incrementally maintain the index. Specifically, we first analyze the structural stability of the index in dynamic road networks which enables us to concentrate on label value maintenance. We then introduce the minimum weight property and minimum distance property to guarantee the index correctness without graph traversal. Moreover, we propose the star-centric paradigm for tracing index change and design various pruning techniques to further accelerate the index?\u2026", "IdName": "zhang2021dynamic", "Citation": "", "Keywords": ""}, {"Name": "Efficient 2-Hop Labeling Maintenance in Dynamic Small-World Networks", "Authors": ["Mengxuan Zhang", "Lei Li", "Wen Hua", "Xiaofang Zhou"], "Sources": "2021 IEEE 37th International Conference on Data Engineering (ICDE)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Shortest path computation is a fundamental operation in small-world networks and index-based methods, especially 2-hop labeling, are commonly applied which have achieved high query efficiency. However, small-world networks keep evolving in real life, making it indispensable to study the maintenance of shortest path index. In this work, we adopt the state-of-the-art Parallel Shortest-distance Labeling (PSL) as the underlying 2-hop labeling construction method, and design algorithms to support efficient update of the index given edge weight change (increase and decrease) in the network. Specifically, we focus on weighted PSL (WPSL) and propose the update propagation mechanism for both synchronous propagation and asynchronous propagation. We then identify the curse of pruning power generated for the propagation under edge weight increase, and solve this problem with a balance between index?\u2026", "IdName": "zhang2021efficient", "Citation": "", "Keywords": ""}, {"Name": "Fastest Path Query Answering using Time-Dependent Hop-Labeling in Road Network", "Authors": ["Lei Li", "Sibo Wang", "Xiaofang Zhou"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "Finding the fastest path in the time-dependent road network is time consuming because its problem complexity is   , where    is the size of the result's time-dependent function,    and    are the number of vertices and edges. There are three kinds of fastest path problems:  SSFP (Single-Staring Time Fastest Path)  that has a fixed departure time,  ISFP (Interval-Staring Time Fastest Path)  that selects the best departure time from an interval, and  FPP (Fastest Path Profile)  that returns the travel time of the entire time domain. In this paper, we aim to answer these three queries in time-dependent road network faster by extending the  2-hop labeling  approach, which is fast in answering shortest distance query in the static graph. However, it is hard to construct index for  SSFP  and  ISFP  because there are    and    possible time points and intervals, where    is the time domain. Therefore?\u2026", "IdName": "li2020fastest", "Citation": "", "Keywords": ""}, {"Name": "Efficient Constrained Shortest Path Query Answering with Forest Hop Labeling", "Authors": ["Ziyi Liu", "Lei Li", "Mengxuan Zhang", "Wen Hua", "Pingfu Chao", "Xiaofang Zhou"], "Sources": "2021 IEEE 37th International Conference on Data Engineering (ICDE)", "PublishedYears": "2021", "Doi": "", "Abstracts": "The Constrained Shortest Path (CSP) problem aims to find the shortest path between two nodes in a road network subject to a given constraint on another attribute. It is typically processed as a skyline path problem on the two attributes, resulting in very high computational cost which can be prohibitive for large road networks. The main bottleneck is to deal with a large amount of partial skyline paths, which further makes the existing index-based methods incapable to obtain the complete exact skyline paths. In this paper, we propose a novel skyline path concatenation approach to avoid the expensive skyline path search, which is then used to efficiently construct a 2-hop labeling index for the CSP queries. Specifically, a rectangle-based technique is designed to prune the concatenation space from multiple hops, and a constraint pruning method is used to further speed up the CSP query processing. To further scale up?\u2026", "IdName": "liu2021efficient", "Citation": "", "Keywords": ""}, {"Name": "An Experimental Evaluation and Guideline for Path Finding in Weighted Dynamic Network", "Authors": ["Mengxuan Zhang", "Lei Li", "Xiaofang Zhou"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2021", "Doi": "", "Abstracts": "Shortest path computation is a building block of various network applications. Since real-life networks evolve as time passes, the Dynamic Shortest Path (DSP) problem has drawn lots of attention in recent years. However, as DSP has many factors related to network topology, update patterns, and query characteristics, existing works only test their algorithms on limited situations without sufficient comparisons with other approaches. Thus, it is still hard to choose the most suitable method in practice. To this end, we first identify the determinant dimensions and constraint dimensions of the DSP problem and create a complete problem space to cover all possible situations. Then we evaluate the state-of-the-art DSP methods under the same implementation standard and test them systematically under a set of synthetic dynamic networks. Furthermore, we propose the concept of dynamic degree to classify the dynamic?\u2026", "IdName": "zhang2021experimental", "Citation": "", "Keywords": ""}, {"Name": "Stream Processing of Shortest Path Queries in Dynamic Road Networks", "Authors": ["Mengxuan Zhang", "Lei Li", "Wen Hua", "Xiaofang Zhou"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "Shortest path query in road network is pervasive in various location-based services nowadays. As the business expands, the scalability issue becomes severer and more servers are deployed to cope with it. Moreover, as the traffic condition keeps changing over time, the existing index-based approaches can hardly adapt to the real-life dynamic environment. Therefore, batch shortest path algorithms have been proposed recently to answer a set of queries together using shareable computation. Besides, they can also work in a highly dynamic environment as no index is needed. However, the existing batch algorithms either assume the batch queries are finely decomposed or just process them without differentiation, resulting in poor query efficiency. In this work, we assume the traffic condition is stable over a short period and treat the issued queries within that period as a stream of query sets. Specifically, we first?\u2026", "IdName": "zhang2020stream", "Citation": "", "Keywords": ""}, {"Name": "Diversified Top-k Route Planning in Road Network", "Authors": ["Zihan Luo", "Lei Li", "Mengxuan Zhang", "Wen Hua", "Xiaofang Zhou"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2022", "Doi": "", "Abstracts": "Route planning is ubiquitous and has a profound impact on our daily life. However, the existing path algorithms tend to produce similar paths between similar OD (Origin-Destination) pairs because they optimize query results without considering their influence on the whole network, which further introduces congestions. Therefore, we investigate the problem of diversifying the top-k paths between an OD pair such that their similarities are under a threshold while their total length is minimal. However, the current solutions all depend on the expensive graph traversal which is too slow to apply in practice. Therefore, we first propose an edge deviation and concatenation-based method to avoid the expensive graph search in path enumeration. After that, we dive into the path relations and propose a path similarity computation method with constant complexity, and propose a pruning technique to improve efficiency. Finally?\u2026", "IdName": "luo2022diversified", "Citation": "", "Keywords": ""}, {"Name": "Efficient Trajectory Contact Query Processing", "Authors": ["Pingfu Chao", "Dan He", "Lei Li", "Mengxuan Zhang", "Xiaofang Zhou"], "Sources": "DASFAA", "PublishedYears": "2021", "Doi": "", "Abstracts": " During an infectious disease outbreak, the contact tracing is regarded as the most crucial and effective way of disease control. As the users\u2019 trajectories are widely obtainable due to the ubiquity of positioning devices, the contact tracing can be achieved by examining trajectories of confirmed patients to identify other trajectories that are contacted either directly or indirectly. In this paper, we propose a generalised Trajectory Contact Search (TCS) query, which models the contact tracing problem as well as other similar trajectory-based problems. In addition, we answer the query by proposing an iterative algorithm that finds contacted trajectories progressively along the transmission chains, and we further optimise each iteration in terms of time and space efficiency by proposing a hop scanning algorithm and a grid-based time interval tree. Extensive experiments on large-scale real-world data demonstrate the?\u2026", "IdName": "chao2021efficient", "Citation": "", "Keywords": ""}, {"Name": "Multi-Constraint Shortest Path using Forest Hop Labeling", "Authors": ["Ziyi Liu", "Lei Li", "Mengxuan Zhang", "Wen Hua", "Xiaofang Zhou"], "Sources": "The VLDB Journal", "PublishedYears": "2022", "Doi": "", "Abstracts": "The Multi-Constraint Shortest Path (MCSP) problem aims to find the shortest path between two nodes in a network subject to a given constraint set. It is typically processed as a skyline path problem. However, the number of intermediate skyline paths becomes larger as the network size increases and the constraint number grows, which brings about the dramatical growth of computational cost and further makes the existing index-based methods hardly capable of obtaining the complete exact results. In this paper, we propose a novel high-dimensional skyline path concatenation method to avoid the expensive skyline path search, which supports the efficient construction of hop labeling index for MCSP queries. Specifically, a set of insightful observations and techniques are proposed to improve the efficiency of concatenating two skyline path set, a n-Cube technique is designed to prune the concatenation space?\u2026", "IdName": "liu2023multi", "Citation": "", "Keywords": ""}, {"Name": "FHL-Cube:Multi-Constraint Shortest Path Querying with Varying Combination of Constraints", "Authors": ["Ziyi Liu", "Lei Li", "Mengxuan Zhang", "Wen Hua", "Xiaofang Zhou"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2022", "Doi": "", "Abstracts": "Multi-Constraint Shortest Path (MCSP) generalizes the classic shortest path from single to multiple criteria such that more personalized needs can be satisfied. However, MCSP query is essentially a high-dimensional skyline problem and thus time-consuming to answer. Although the current Forest Hop Labeling (FHL) index can answer MCSP efficiently, it takes a long time to construct and lacks the flexibility to handle arbitrary criteria combinations. In this paper, we propose a skyline-cube-based FHL index that can handle the flexible MCSP efficiently. Firstly, we analyze the relation between low and high-dimensional skyline paths theoretically and use a cube to organize them hierarchically. After that, we propose methods to derive the high-dimensional path from the lower ones, which can adapt to the flexible scenario naturally and reduce the expensive high dimensional path concatenation. Then we introduce?\u2026", "IdName": "liu2022fhl", "Citation": "", "Keywords": ""}, {"Name": "Efficient kNN query for moving objects on time-dependent road networks", "Authors": ["Jiajia Li", "Cancan Ni", "Dan He", "Lei Li", "Xiufeng Xia", "Xiaofang Zhou"], "Sources": "The VLDB Journal", "PublishedYears": "2023", "Doi": "", "Abstracts": "In this paper, we study the Time-Dependent k Nearest Neighbor (TD-kNN) query on moving objects that aims to return k objects arriving at the query location with the least traveling cost departing at a given time t. Although the kNN query on moving objects has been widely studied in the scenario of the static road network, the TD-kNN query tends to be more complicated and challenging because under the time-dependent road network, the cost of each edge is measured by a cost function rather than a fixed distance value. To tackle such difficulty, we adopt the framework of GLAD and develop an advanced index structure to support efficient fastest travel cost query on time-dependent road network. In particular, we propose the Time-Dependent H2H (TD-H2H) index, which pre-computes the aggregated weight functions between each node to some specific nodes in the decomposition tree derived from the road?\u2026", "IdName": "li2023efficient", "Citation": "", "Keywords": ""}, {"Name": "Path Query Processing Using Typical Snapshots in Dynamic Road Networks", "Authors": ["Mengxuan Zhang", "Lei Li", "Pingfu Chao", "Wen Hua", "Xiaofang Zhou"], "Sources": "DASFAA", "PublishedYears": "2020", "Doi": "", "Abstracts": " The shortest path query in road network is a fundamental operation in navigation and location-based services. The existing shortest path algorithms aim at improving efficiency in the static/time-dependent environment. However, the real-life road networks are dynamic, so they can hardly meet the requirement in practice. In this paper, we aim to support the path query in dynamic road networks by identifying the typical snapshots from the snapshot sequences, building the path indexes on them, and finally processing the query with the most suitable typical snapshot. Specifically, we first use the typical OD pairs to capture the dynamic information and represent the snapshots. Then the snapshot similarity is measured by considering the shortest path error and the shortest path similarity of these OD pairs. Because the OD pair number is huge and they have different power in capturing the traffic condition, we further propose?\u2026", "IdName": "zhang2020path", "Citation": "", "Keywords": ""}, {"Name": "Utility-based Matching of Vehicles and Hybrid Requests on Rider Demand Responsive Systems", "Authors": ["Lai Yongxuan", "Yang Shipeng", "Xiong Anshu", "Yang Fan", "Li Lei", "Zhou Xiaofang"], "Sources": "IEEE Transactions on Intelligent Transportation Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "In rider demand responsive systems riders submit requests to demand transit services and the incoming requests and vehicles are matched by the system. This demand-responsive transport problem is viewed by existing research as a kind of spatial matching problem between vehicles and riders. However, existing schemes mainly focus on maximizing the number of matching pairs. It neglects other factors like the length of pickup trajectories and riders\u2019 waiting time. And the matching is not revocable, which loses the chance for further optimizations. Moreover, there is still not much work on handling and matching the appointment-based requests that play a key role in the demand-responsive transport market. In this article, we propose an algorithm called BMCF ( Bipartite Minimal-Cost Flow ) to solve the taxi-rider matching problem with appointment-based rider requests on a time-dependent road network. Unlike?\u2026", "IdName": "lai2020utility", "Citation": "", "Keywords": ""}, {"Name": "Typical snapshots selection for shortest path query in dynamic road networks", "Authors": ["Mengxuan Zhang", "Lei Li", "Wen Hua", "Xiaofang Zhou"], "Sources": "Databases Theory and Applications: 31st Australasian Database Conference?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": " Finding the shortest paths in road network is an important query in our life nowadays, and various index structures are constructed to speed up the query answering. However, these indexes can hardly work in real-life scenario because the traffic condition changes dynamically, which makes the pathfinding slower than in the static environment. In order to speed up path query answering in the dynamic road network, we propose a framework to support these indexes. Firstly, we view the dynamic graph as a series of static snapshots. After that, we propose two kinds of methods to select the typical snapshots. The first kind is time-based and it only considers the temporal information. The second category is the graph representation-based, which considers more insights: edge-based that captures the road continuity, and vertex-based that reflects the region traffic fluctuation. Finally, we propose the snapshot matching to?\u2026", "IdName": "zhang2020typical", "Citation": "", "Keywords": ""}, {"Name": "Deep learning for trajectory data management and mining: A survey and beyond", "Authors": ["Wei Chen", "Yuxuan Liang", "Yuanshao Zhu", "Yanchuan Chang", "Kang Luo", "Haomin Wen", "Lei Li", "Yanwei Yu", "Qingsong Wen", "Chao Chen", "Kai Zheng", "Yunjun Gao", "Xiaofang Zhou", "Yu Zheng"], "Sources": "arXiv preprint arXiv:2403.14151", "PublishedYears": "2024", "Doi": "", "Abstracts": "Trajectory computing is a pivotal domain encompassing trajectory data management and mining, garnering widespread attention due to its crucial role in various practical applications such as location services, urban traffic, and public safety. Traditional methods, focusing on simplistic spatio-temporal features, face challenges of complex calculations, limited scalability, and inadequate adaptability to real-world complexities. In this paper, we present a comprehensive review of the development and recent advances in deep learning for trajectory computing (DL4Traj). We first define trajectory data and provide a brief overview of widely-used deep learning models. Systematically, we explore deep learning applications in trajectory management (pre-processing, storage, analysis, and visualization) and mining (trajectory-related forecasting, trajectory-related recommendation, trajectory classification, travel time estimation, anomaly detection, and mobility generation). Notably, we encapsulate recent advancements in Large Language Models (LLMs) that hold the potential to augment trajectory computing. Additionally, we summarize application scenarios, public datasets, and toolkits. Finally, we outline current challenges in DL4Traj research and propose future directions. Relevant papers and open-source resources have been collated and are continuously updated at: \\href{https://github.com/yoshall/Awesome-Trajectory-Computing}{DL4Traj Repo}.", "IdName": "chen2024deep", "Citation": "", "Keywords": ""}, {"Name": "Parallel Hub Labeling Maintenance with High Efficiency in Dynamic Small-World Networks", "Authors": ["Mengxuan Zhang", "Lei Li", "Goce Trajcevski", "Anderas Zufle", "Xiaofang Zhou"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Shortest path computation is a fundamental operation in many application domains and is especially challenging in frequently evolving small-world networks (i.e., graphs in which many nodes can be reached from every other node by a small number of hops). Index-based methods, especially ones based on 2-hop labeling are often used for high query efficiency. However, the evolvements of small-world networks in many realistic scenarios pose the challenge of efficient maintenance of the shortest path index. In this work, we adopt the state-of-the-art  Parallel Shortest-distance Labeling (PSL)  as the underlying 2-hop labeling construction method, and design algorithms to support its efficient update given edge weight changes (increase and decrease). Specifically, we focus on weighted  PSL (WPSL)  and propose a propagation-based update mechanism for both synchronous and asynchronous propagation. We?\u2026", "IdName": "zhang2023parallel", "Citation": "", "Keywords": ""}, {"Name": "Finding Top-k Optimal Routes with Collective Spatial Keywords on Road Networks", "Authors": ["Jiajia Li", "Xing Xiong", "Lei Li", "Dan He", "Chuanyu Zong", "Xiaofang Zhou"], "Sources": "2023 IEEE 39th International Conference on Data Engineering (ICDE)", "PublishedYears": "2023", "Doi": "", "Abstracts": "As more detailed POI (Point of Interest) information has been incorporated into road network, routing has evolved from finding paths from one place to another, to satisfying users\u2019 needs (keywords) along the trip. However, the existing solutions either only support one keyword per POI, or require a fixed visiting order, or only provide one option to choose from. Therefore, we study the top-k Optimal Routes with Collective Spatial Keywords (k-ORCSK) problem, which is the most general keyword-aware routing problem that supports multiple keywords, arbitrary orders, and top-k results. To solve this problem, we apply an enumeration framework and reduce the complexity by contracting non POI-related vertices and taking the keywords into account. After that, we propose a best-first path expansion method DA-CSK based on deviation to convert the enumeration paradigm from the distance-oriented to the keyword?\u2026", "IdName": "li2023finding", "Citation": "", "Keywords": ""}, {"Name": "Global routing optimization in road networks", "Authors": ["Yehong Xu", "Lei Li", "Mengxuan Zhang", "Zizhuo Xu", "Xiaofang Zhou"], "Sources": "2023 IEEE 39th International Conference on Data Engineering (ICDE)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Route planning plays an increasingly important role in our society, and the routing results, which are the paths that vehicles actually travel in a road network, which influence the traffic condition naturally. However, the existing routing algorithms cannot consider the routing results and their influence simultaneously, so traffic congestion could be created when many vehicles are directed to follow similar routes. In this paper, we propose the Global Routing Optimization problem that aims to minimize traffic congestion by continuously evaluating traffic conditions for a set of routing tasks. It is non-trivial to achieve this global optimization goal, as routing and traffic condition evaluation is both time-consuming and interdependent. To break this dependency, we propose a global routing optimization paradigm that can evaluate the routing results\u2019 influence on the traffic condition, and then plan the routes accordingly. To?\u2026", "IdName": "xu2023global", "Citation": "", "Keywords": ""}, {"Name": "Trajectory Representation Learning Based on Road Network Partition for Similarity Computation", "Authors": ["Jiajia Li", "Mingshen Wang", "Lei Li", "Kexuan Xin", "Wen Hua", "Zhou", "Xiaofang"], "Sources": "DASFAA", "PublishedYears": "2023", "Doi": "", "Abstracts": "In the tasks of location-based services and vehicle trajectory mining, trajectory similarity computation is the fundamental operation and affects both the efficiency and effectiveness of the downstream applications. Existing trajectory representation learning works either use grids to cluster trajectory points or require external information such as road network types, which is not good enough in terms of query accuracy and applicable scenarios. In this paper, we propose a novel partition-based representation learning framework PT2vec for similarity computation by exploiting the underlying road segments without extra information. To reduce the number of words and ensure that two spatially similar trajectories have embeddings closely located in the latent feature space, we partition the network into multiple sub-networks where each is represented by a word. Then we adopt the GRU-based seq2seq model for word?\u2026", "IdName": "li2023trajectory", "Citation": "", "Keywords": ""}, {"Name": "A Top-Down Scheme for Coverage Centrality Queries on Road Networks", "Authors": ["Yehong Xu", "Mengxuan Zhang", "Ruizhong Wu", "Lei Li", "Xiaofang Zhou"], "Sources": "Australasian Database Conference", "PublishedYears": "2022", "Doi": "", "Abstracts": "Coverage Centrality is an important metric to evaluate the node importance in road networks. However, the current solutions have to compute the coverage centrality of all the nodes together, which is resource-wasting especially when only some nodes\u2019 centrality is required. In addition, they have poor adaption to the dynamic scenario because of the computation inefficiency. In this paper, we focus on the coverage centrality query problem and propose an efficient algorithm to compute the centrality of a single node efficiently in both static and dynamic scenarios, with the help of the intra-region pruning, inter-region pruning, and top-down search. Experiments validate the efficiency and effectiveness of our algorithm compared with the state-of-the-art method.", "IdName": "xu2022top", "Citation": "", "Keywords": ""}, {"Name": "Efficient processing of coverage centrality queries on road networks", "Authors": ["Yehong Xu", "Mengxuan Zhang", "Ruizhong Wu", "Lei Li", "Xiaofang Zhou"], "Sources": "World Wide Web", "PublishedYears": "2024", "Doi": "", "Abstracts": "Coverage Centrality is an important metric to evaluate vertex importance in road networks. However, current solutions have to compute the coverage centrality of all the vertices together, which is resource-wasting, especially when only some vertices centrality is required. In addition, they have poor adaption to the dynamic scenario because of the computation inefficiency. In this paper, we focus on the coverage centrality query problem and propose a method that efficiently computes the centrality of single vertices without relying on the underlying graph being static by employing the intra-region pruning, inter-region pruning, and top-down search. We further propose the bottom-up search and mixed search to improve efficiency. Experiments validate the efficiency and effectiveness of our algorithms compared with the state-of-the-art method.", "IdName": "xu2024efficient", "Citation": "", "Keywords": ""}, {"Name": "I/O-Efficient Multi-Criteria Shortest Paths Query Processing on Large Graphs", "Authors": ["Xinjie Zhou", "Kai Huang", "Lei Li", "Mengxuan Zhang", "Xiaofang Zhou"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2024", "Doi": "", "Abstracts": "Shortest path computation is a basic operation for many graph-based applications and has been extensively studied. However, most existing works only consider the optimal path of a single criterion but ignore real-world situations involving multiple criteria. This paper investigates a new Multi-Criteria Shortest Paths (MCSPs) problem, aiming to compute the shortest paths of all criteria between a vertex pair. It is significant for real-world applications such as GPS navigation and social network analysis. Nevertheless, the rapid growth of graph size or memory-limited devices poses a memory-constraint challenge, making the adaptation of existing methods extremely time-consuming. To solve the memory-constraint MCSPs problem, we propose a general  STOP & SHARE  scheme to synchronize the search speeds of all criteria for sharing partition accesses. Two algorithms called  OHP  and  MHP , adopting the one-hop?\u2026", "IdName": "zhou2024efficient", "Citation": "", "Keywords": ""}, {"Name": "A Universal Scheme for Partitioned Dynamic Shortest Path Index", "Authors": ["Mengxuan Zhang", "Xinjie Zhou", "Lei Li", "Ziyi Liu", "Goce Trajcevski", "Yan Huang", "Xiaofang Zhou"], "Sources": "arXiv preprint arXiv:2310.08213", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph partitioning is a common solution to scale up the graph algorithms, and shortest path (SP) computation is one of them. However, the existing solutions typically have a fixed partition method with a fixed path index and fixed partition structure, so it is unclear how the partition method and path index influence the pathfinding performance. Moreover, few studies have explored the index maintenance of partitioned SP (PSP) on dynamic graphs. To provide a deeper insight into the dynamic PSP indexes, we systematically deliberate on the existing works and propose a universal scheme to analyze this problem theoretically. Specifically, we first propose two novel partitioned index strategies and one optimization to improve index construction, query answering, or index maintenance of PSP index. Then we propose a path-oriented graph partitioning classification criteria for easier partition method selection. After that, we re-couple the dimensions in our scheme (partitioned index strategy, path index, and partition structure) to propose five new partitioned SP indexes that are more efficient either in the query or update on different networks. Finally, we demonstrate the effectiveness of our new indexes by comparing them with state-of-the-art PSP indexes through comprehensive evaluations.", "IdName": "zhang2023universal", "Citation": "", "Keywords": ""}, {"Name": "Efficient Frequency-based Randomization for Spatial Trajectories under Differential Privacy", "Authors": ["Fengmei Jin", "Wen Hua", "Lei Li", "Boyu Ruan", "Xiaofang Zhou"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "The uniqueness of trajectory data for user re-identification has received unprecedented attention as the increasing popularity of location-based services boosts the excessive collection of daily trajectories with sufficient spatiotemporal coverage. Consequently, leveraging or releasing personally-sensitive trajectories without proper protection severely threatens individual privacy despite simply removing IDs. Trajectory privacy protection is never a trivial task due to the trade-off between privacy protection, utility preservation, and computational efficiency. Furthermore,  recovery attack , one of the most threatening attacks specific to trajectory data, has not been well studied in the current literature. To tackle these challenges, we propose a frequency-based randomization model with a rigorous differential privacy guarantee for privacy-preserving trajectory data publishing. In particular, two randomized mechanisms are?\u2026", "IdName": "jin2023efficient", "Citation": "", "Keywords": ""}, {"Name": "Continuously Monitoring Optimal Routes With Collective Spatial Keywords on Road Networks", "Authors": ["Jiajia Li", "Zongbo Wang", "Yifei Zhang", "Liang Zhao", "Lei Li", "Chuanyu Zong"], "Sources": "The 19th IEEE International Conference on Ubiquitous Intelligence and Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "The keyword-aware route planning problem, which returns the best route satisfying all the user-specified keywords, has attracted more and more research attention. However, existing research work mainly focuses on improving the efficiency of snapshot queries, but does not consider continuously monitoring queries. This paper is the first to investigate the continuous Optimal Routes with Collective Spatial Keywords (ORCSK) problem, which continuously returns the optimal route that can collectively cover the required spatial keywords for the given path on which a user is travelling. The direct solution is to perform multiple snapshot queries, which is obviously inefficient and infeasible. Based on the state-of-the-art algorithm DAPrune for answering ORCSK, we Figure out the safe-region for queries based on two proposed theorem, which means that results do not change within this region. Moreover, when the user?\u2026", "IdName": "li2022continuously", "Citation": "", "Keywords": ""}, {"Name": "Efficient Multi-Request Route Planning on Road Network", "Authors": ["Jiajia Li", "Jiahui Hu", "Lei Li", "Xing Xiong", "Xiufeng Xia"], "Sources": "IEEE International Symposium on Parallel and Distributed Processing with?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Given a source node, a destination node and a request list, the result of the requirement-oriented route planning is a path which has minimum distance/travel time/money and could satisfy all the requests at the same time. Most of the previous studies supposed that each Point-Of-Interest (POI) provides only one type of service, which is known as the trip planning query (TPQ). The problem is more complicated if each POI provides multiple services, which is called multi-request route planning (MRRP) problem. The existing MRRP method is designed based on A* algorithm in the POI network. However, they need a huge amount of calculations to get the heuristic values based on the detour distances, which is inefficient especially for large scale road networks. Moreover, it doesn't pay attention to the request on the list which is hard to satisfy. If some required service can be provided only by one node, this node should?\u2026", "IdName": "li2020efficient", "Citation": "", "Keywords": ""}, {"Name": "Generalizing from a few examples: A survey on few-shot learning", "Authors": ["Yaqing Wang", "Quanming Yao", "James T Kwok", "Lionel M Ni"], "Sources": "ACM computing surveys (csur)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to?\u2026", "IdName": "wang2020generalizing", "Citation": "", "Keywords": ""}, {"Name": "Dino: Detr with improved denoising anchor boxes for end-to-end object detection", "Authors": ["Hao Zhang", "Feng Li", "Shilong Liu", "Lei Zhang", "Hang Su", "Jun Zhu", "Lionel M Ni", "Heung-Yeung Shum"], "Sources": "arXiv preprint arXiv:2203.03605", "PublishedYears": "2022", "Doi": "", "Abstracts": "We present DINO (\\textbf{D}ETR with \\textbf{I}mproved de\\textbf{N}oising anch\\textbf{O}r boxes), a state-of-the-art end-to-end object detector. % in this paper. DINO improves over previous DETR-like models in performance and efficiency by using a contrastive way for denoising training, a mixed query selection method for anchor initialization, and a look forward twice scheme for box prediction. DINO achieves AP in  epochs and AP in  epochs on COCO with a ResNet-50 backbone and multi-scale features, yielding a significant improvement of \\textbf{AP} and \\textbf{AP}, respectively, compared to DN-DETR, the previous best DETR-like model. DINO scales well in both model size and data size. Without bells and whistles, after pre-training on the Objects365 dataset with a SwinL backbone, DINO obtains the best results on both COCO \\texttt{val2017} (\\textbf{AP}) and \\texttt{test-dev} (\\textbf{AP}). Compared to other models on the leaderboard, DINO significantly reduces its model size and pre-training data size while achieving better results. Our code will be available at \\url{https://github.com/IDEACVR/DINO}.", "IdName": "zhang2022dino", "Citation": "", "Keywords": ""}, {"Name": "Dn-detr: Accelerate detr training by introducing query denoising", "Authors": ["Feng Li", "Hao Zhang", "Shilong Liu", "Jian Guo", "Lionel M Ni", "Lei Zhang"], "Sources": "Proceedings of the IEEE/CVF conference on computer vision and pattern?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "We present in this paper a novel denoising training method to speedup DETR (DEtection TRansformer) training and offer a deepened understanding of the slow convergence issue of DETR-like methods. We show that the slow convergence results from the instability of bipartite graph matching which causes inconsistent optimization goals in early training stages. To address this issue, except for the Hungarian loss, our method additionally feeds ground-truth bounding boxes with noises into Transformer decoder and trains the model to reconstruct the original boxes, which effectively reduces the bipartite graph matching difficulty and leads to a faster convergence. Our method is universal and can be easily plugged into any DETR-like methods by adding dozens of lines of code to achieve a remarkable improvement. As a result, our DN-DETR results in a remarkable improvement (+ 1.9 AP) under the same setting and achieves the best result (AP 43.4 and 48.6 with 12 and 50 epochs of training respectively) among DETR-like methods with ResNet-50 backbone. Our code will be released after the blind review.", "IdName": "li2022dn", "Citation": "", "Keywords": ""}, {"Name": "Mask dino: Towards a unified transformer-based framework for object detection and segmentation", "Authors": ["Feng Li", "Hao Zhang", "Huaizhe Xu", "Shilong Liu", "Lei Zhang", "Lionel M Ni", "Heung-Yeung Shum"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "In this paper we present Mask DINO, a unified object detection and segmentation framework. Mask DINO extends DINO (DETR with Improved Denoising Anchor Boxes) by adding a mask prediction branch which supports all image segmentation tasks (instance, panoptic, and semantic). It makes use of the query embeddings from DINO to dot-product a high-resolution pixel embedding map to predict a set of binary masks. Some key components in DINO are extended for segmentation through a shared architecture and training process. Mask DINO is simple, efficient, scalable, and benefits from joint large-scale detection and segmentation datasets. Our experiments show that Mask DINO significantly outperforms all existing specialized segmentation methods, both on a ResNet-50 backbone and a pre-trained model with SwinL backbone. Notably, Mask DINO establishes the best results to date on instance segmentation (54.5 AP on COCO), panoptic segmentation (59.4 PQ on COCO), and semantic segmentation (60.8 mIoU on ADE20K) among models under one billion parameters. We will release the code after the blind review.", "IdName": "li2023mask", "Citation": "", "Keywords": ""}, {"Name": "Knowledge modeling via contextualized representations for LSTM-based personalized exercise recommendation", "Authors": ["Yujia Huo", "Derek F Wong", "Lionel M Ni", "Lidia S Chao", "Jing Zhang"], "Sources": "Information Sciences 523", "PublishedYears": "2020", "Doi": "", "Abstracts": "Intelligent education systems have enabled personalized learning (PL). In PL, students are presented with educational contents that are consistent with their personal knowledge states (KS), and the critical task is accurately estimating these states through data. Knowledge tracing (KT) infers KS (latent) through historical student interactions (observed) with the knowledge components (KCs). A wide variety of KT techniques have been developed, from Bayesian Knowledge Tracing (BKT) to Deep Knowledge Tracing (DKT). However, in most of these methods, the KCs are represented as stand-alone entities, and the effect of representing KCs using contexts such as learning-related factors has been under-investigated. Also, KT needs to generate personalized results to facilitate tasks such as exercise recommendation. In this paper, we propose two approaches that use a contextualized representation of KCs, one with?\u2026", "IdName": "huo2020knowledge", "Citation": "", "Keywords": ""}, {"Name": "FraudTrip: Taxi fraudulent trip detection from corresponding trajectories", "Authors": ["Ye Ding", "Wenyi Zhang", "Xibo Zhou", "Qing Liao", "Qiong Luo", "Lionel M Ni"], "Sources": "IEEE Internet of Things Journal", "PublishedYears": "2020", "Doi": "", "Abstracts": "A passenger is overcharged by the taxi driver is one common type of fraudulent trip, and it brings negative impacts to modern cities. Most existing fraudulent trip detection works rely on the assumption that the trip is correctly recorded by the taximeter. However, there are many taxi drivers in China carrying passengers without activating the taximeter, especially when the taxi driver is trying to overcharge the passengers. Hence, existing detection methods cannot be directly applied to such real-world scenario. In this article, we propose a system, called \u201cFraudTrip,\u201d which detects \u201cunmetered\u201d taxi trips based on a novel fraud detection algorithm and a heuristic maximum fraudulent trajectory construction algorithm. Based on the experiments on both synthetic and real-world trajectory data sets, FraudTrip can effectively and efficiently detect fraudulent trips without the help of taximeters.", "IdName": "ding2020fraudtrip", "Citation": "", "Keywords": ""}, {"Name": "Lite detr: An interleaved multi-scale encoder for efficient detr", "Authors": ["Feng Li", "Ailing Zeng", "Shilong Liu", "Hao Zhang", "Hongyang Li", "Lei Zhang", "Lionel M Ni"], "Sources": "Proceedings of the IEEE/CVF conference on computer vision and pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recent DEtection TRansformer-based (DETR) models have obtained remarkable performance. Its success cannot be achieved without the re-introduction of multi-scale feature fusion in the encoder. However, the excessively increased tokens in multi-scale features, especially for about 75% of low-level features, are quite computationally inefficient, which hinders real applications of DETR models. In this paper, we present Lite DETR, a simple yet efficient end-to-end object detection framework that can effectively reduce the GFLOPs of the detection head by 60% while keeping 99% of the original performance. Specifically, we design an efficient encoder block to update high-level features (corresponding to small-resolution feature maps) and low-level features (corresponding to large-resolution feature maps) in an interleaved way. In addition, to better fuse cross-scale features, we develop a key-aware deformable attention to predict more reliable attention weights. Comprehensive experiments validate the effectiveness and efficiency of the proposed Lite DETR, and the efficient encoder strategy can generalize well across existing DETR-based models. The code will be released after the blind review.", "IdName": "li2023lite", "Citation": "", "Keywords": ""}, {"Name": "Vision-language intelligence: Tasks, representation learning, and large models", "Authors": ["Feng Li", "Hao Zhang", "Yi-Fan Zhang", "Shilong Liu", "Jian Guo", "Lionel M Ni", "PengChuan Zhang", "Lei Zhang"], "Sources": "arXiv preprint arXiv:2203.01922", "PublishedYears": "2022", "Doi": "", "Abstracts": "This paper presents a comprehensive survey of vision-language (VL) intelligence from the perspective of time. This survey is inspired by the remarkable progress in both computer vision and natural language processing, and recent trends shifting from single modality processing to multiple modality comprehension. We summarize the development in this field into three time periods, namely task-specific methods, vision-language pre-training (VLP) methods, and larger models empowered by large-scale weakly-labeled data. We first take some common VL tasks as examples to introduce the development of task-specific methods. Then we focus on VLP methods and comprehensively review key components of the model structures and training methods. After that, we show how recent work utilizes large-scale raw image-text data to learn language-aligned visual representations that generalize better on zero or few shot learning tasks. Finally, we discuss some potential future trends towards modality cooperation, unified representation, and knowledge incorporation. We believe that this review will be of help for researchers and practitioners of AI and ML, especially those interested in computer vision and natural language processing.", "IdName": "li2022vision", "Citation": "", "Keywords": ""}, {"Name": "Mp-former: Mask-piloted transformer for image segmentation", "Authors": ["Hao Zhang", "Feng Li", "Huaizhe Xu", "Shijia Huang", "Shilong Liu", "Lionel M Ni", "Lei Zhang"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "We present a mask-piloted Transformer which improves masked-attention in Mask2Former for image segmentation. The improvement is based on our observation that Mask2Former suffers from inconsistent mask predictions between consecutive decoder layers, which leads to inconsistent optimization goals and low utilization of decoder queries. To address this problem, we propose a mask-piloted training approach, which additionally feeds noised ground-truth masks in masked-attention and trains the model to reconstruct the original ones. Compared with the predicted masks used in mask-attention, the ground-truth masks serve as a pilot and effectively alleviate the negative impact of inaccurate mask predictions in Mask2Former. Based on this technique, our MP-Former achieves a remarkable performance improvement on all three image segmentation tasks (instance, panoptic, and semantic), yielding+ 2.3 AP and+ 1.6 mIoU on the Cityscapes instance and semantic segmentation tasks with a ResNet-50 backbone. Our method also significantly speeds up the training, outperforming Mask2Former with half of the number of training epochs on ADE20K with both a ResNet-50 and a Swin-L backbones. Moreover, our method only introduces little computation during training and no extra computation during inference. Our code will be released at https://github. com/IDEA-Research/MP-Former.", "IdName": "zhang2023mp", "Citation": "", "Keywords": ""}, {"Name": "HeTROPY: Explainable learning diagnostics via heterogeneous maximum-entropy and multi-spatial knowledge representation", "Authors": ["Yujia Huo", "Derek F Wong", "Lionel M Ni", "Lidia S Chao", "Jing Zhang"], "Sources": "Knowledge-Based Systems 207", "PublishedYears": "2020", "Doi": "", "Abstracts": "Autonomous learning diagnostics, where the students\u2019 strengths and weaknesses are disclosed from their observed performance data, is a challenging task in e-learning systems. Current student knowledge models can alleviate some of the problems in learning (i.e. predicting student performance) but they neglect learning diagnostics, which is based on causal reasoning. To this end, we propose a novel heterogeneous attention interpreter with a maximum entropy regularizer on top of a student knowledge model to achieve explainable learning diagnostics. Our model segregates the impact of the homogeneous knowledge points, while promoting the heterogeneous relatives by maximizing their chance to contribute to the prediction. We also propose a multi-spatial knowledge representation that is readily generalizable to other data-driven educational tasks. Extensive experiments on real-world datasets reveal that?\u2026", "IdName": "huo2020hetropy", "Citation": "", "Keywords": ""}, {"Name": "DA-BEV: Depth aware BEV transformer for 3D object detection", "Authors": ["Hao Zhang", "Hongyang Li", "Xingyu Liao", "Feng Li", "Shilong Liu", "Lionel M Ni", "Lei Zhang"], "Sources": "arXiv preprint arXiv:2302.13002 3", "PublishedYears": "2023", "Doi": "", "Abstracts": "None", "IdName": "zhang2023bev", "Citation": "", "Keywords": ""}, {"Name": "Generalized convolutional sparse coding with unknown noise", "Authors": ["Yaqing Wang", "James T Kwok", "Lionel M Ni"], "Sources": "IEEE Transactions on Image Processing 29", "PublishedYears": "2020", "Doi": "", "Abstracts": "Convolutional sparse coding (CSC) can learn representative shift-invariant patterns from data. However, existing CSC methods assume the Gaussian noise, which can be restrictive in some challenging applications. In this paper, we propose a generalized CSC model capable of handling complicated unknown noise. The noise is modeled by the Gaussian mixture model, which can approximate any continuous probability density function. The Expectation-Maximization algorithm is used to solve the resultant learning problem. For efficient optimization, the crux is to speed up the convolution in the frequency domain while keeping the other computations involving the weight matrix in the spatial domain. We design an efficient solver for the weighted CSC problem in the M-step. The dictionary and codes are updated simultaneously by an efficient nonconvex accelerated proximal gradient algorithm. The resultant?\u2026", "IdName": "wang2020generalized", "Citation": "", "Keywords": ""}, {"Name": "Alpha-gpt: Human-ai interactive alpha mining for quantitative investment", "Authors": ["Saizhuo Wang", "Hang Yuan", "Leon Zhou", "Lionel M Ni", "Heung-Yeung Shum", "Jian Guo"], "Sources": "arXiv preprint arXiv:2308.00016", "PublishedYears": "2023", "Doi": "", "Abstracts": "One of the most important tasks in quantitative investment research is mining new alphas (effective trading signals or factors). Traditional alpha mining methods, either hand-crafted factor synthesizing or algorithmic factor mining (e.g., search with genetic programming), have inherent limitations, especially in implementing the ideas of quants. In this work, we propose a new alpha mining paradigm by introducing human-AI interaction, and a novel prompt engineering algorithmic framework to implement this paradigm by leveraging the power of large language models. Moreover, we develop Alpha-GPT, a new interactive alpha mining system framework that provides a heuristic way to ``understand'' the ideas of quant researchers and outputs creative, insightful, and effective alphas. We demonstrate the effectiveness and advantage of Alpha-GPT via a number of alpha mining experiments.", "IdName": "wang2023alpha", "Citation": "", "Keywords": ""}, {"Name": "Ubiquitous WiFi and Acoustic Sensing: Principles, Technologies, and Applications", "Authors": ["Jia-Ling Huang", "Yun-Shu Wang", "Yong-Pan Zou", "Kai-Shun Wu", "Lionel Ming-shuan Ni"], "Sources": "Journal of Computer Science and Technology", "PublishedYears": "2023", "Doi": "", "Abstracts": "With the increasing pervasiveness of mobile devices such as smartphones, smart TVs, and wearables, smart sensing, transforming the physical world into digital information based on various sensing medias, has drawn researchers\u2019 great attention. Among different sensing medias, WiFi and acoustic signals stand out due to their ubiquity and zero hardware cost. Based on different basic principles, researchers have proposed different technologies for sensing applications with WiFi and acoustic signals covering human activity recognition, motion tracking, indoor localization, health monitoring, and the like. To enable readers to get a comprehensive understanding of ubiquitous wireless sensing, we conduct a survey of existing work to introduce their underlying principles, proposed technologies, and practical applications. Besides we also discuss some open issues of this research area. Our survey reals that as a?\u2026", "IdName": "huang2023ubiquitous", "Citation": "", "Keywords": ""}, {"Name": "Quant 4.0: Engineering Quantitative Investment with Automated, Explainable and Knowledge-driven Artificial Intelligence", "Authors": ["Jian Guo", "Saizhuo Wang", "Lionel M Ni", "Heung-Yeung Shum"], "Sources": "arXiv preprint arXiv:2301.04020", "PublishedYears": "2022", "Doi": "", "Abstracts": "Quantitative investment (``quant'') is an interdisciplinary field combining financial engineering, computer science, mathematics, statistics, etc. Quant has become one of the mainstream investment methodologies over the past decades, and has experienced three generations: Quant 1.0, trading by mathematical modeling to discover mis-priced assets in markets; Quant 2.0, shifting quant research pipeline from small ``strategy workshops'' to large ``alpha factories''; Quant 3.0, applying deep learning techniques to discover complex nonlinear pricing rules. Despite its advantage in prediction, deep learning relies on extremely large data volume and labor-intensive tuning of ``black-box'' neural network models. To address these limitations, in this paper, we introduce Quant 4.0 and provide an engineering perspective for next-generation quant. Quant 4.0 has three key differentiating components. First, automated AI changes quant pipeline from traditional hand-craft modeling to the state-of-the-art automated modeling, practicing the philosophy of ``algorithm produces algorithm, model builds model, and eventually AI creates AI''. Second, explainable AI develops new techniques to better understand and interpret investment decisions made by machine learning black-boxes, and explains complicated and hidden risk exposures. Third, knowledge-driven AI is a supplement to data-driven AI such as deep learning and it incorporates prior knowledge into modeling to improve investment decision, in particular for quantitative value investing. Moreover, we discuss how to build a system that practices the Quant 4.0 concept. Finally, we propose ten challenging?\u2026", "IdName": "guo2022quant", "Citation": "", "Keywords": ""}, {"Name": "Learning cognitive embedding using signed knowledge interaction graph", "Authors": ["Yujia Huo", "Derek F Wong", "Lionel M Ni", "Lidia S Chao", "Jing Zhang", "Xin Zuo"], "Sources": "Knowledge-Based Systems 229", "PublishedYears": "2021", "Doi": "", "Abstracts": "Measuring learner cognition based on their problem-solving performance is a joint discipline of cognitive psychology and machine learning. In the case of learner problem-solving, the interaction between learner and knowledge forms a typical type of signed interaction graph. Interaction graphs are a widely used and effective solution to model the relationships between interacting entities. However, most of previous interaction graph methods are inclined to the observed interactions as positive links but they often fail to consider unobserved and negative links, which leads to an insufficiency in capturing the complete cognition/mis-cognition proximity information. To address this limitation, we propose a knowledge graph representation learning method that is based on signed knowledge interaction network (SKIN). We explicitly model the correct/incorrect cognitive performance as the positively+/negatively? signed?\u2026", "IdName": "huo2021learning", "Citation": "", "Keywords": ""}, {"Name": "Closed-loop transcription via convolutional sparse coding", "Authors": ["Xili Dai", "Ke Chen", "Shengbang Tong", "Jingyuan Zhang", "Xingjian Gao", "Mingyang Li", "Druv Pai", "Yuexiang Zhai", "XIaojun Yuan", "Heung-Yeung Shum", "Lionel M Ni", "Yi Ma"], "Sources": "arXiv preprint arXiv:2302.09347", "PublishedYears": "2023", "Doi": "", "Abstracts": "Autoencoding has achieved great empirical success as a framework for learning generative models for natural images. Autoencoders often use generic deep networks as the encoder or decoder, which are difficult to interpret, and the learned representations lack clear structure. In this work, we make the explicit assumption that the image distribution is generated from a multi-stage sparse deconvolution. The corresponding inverse map, which we use as an encoder, is a multi-stage convolution sparse coding (CSC), with each stage obtained from unrolling an optimization algorithm for solving the corresponding (convexified) sparse coding program. To avoid computational difficulties in minimizing distributional distance between the real and generated images, we utilize the recent closed-loop transcription (CTRL) framework that optimizes the rate reduction of the learned sparse representations. Conceptually, our method has high-level connections to score-matching methods such as diffusion models. Empirically, our framework demonstrates competitive performance on large-scale datasets, such as ImageNet-1K, compared to existing autoencoding and generative methods under fair conditions. Even with simpler networks and fewer computational resources, our method demonstrates high visual quality in regenerated images. More surprisingly, the learned autoencoder performs well on unseen datasets. Our method enjoys several side benefits, including more structured and interpretable representations, more stable convergence, and scalability to large datasets. Our method is arguably the first to demonstrate that a concatenation of multiple?\u2026", "IdName": "dai2023closed", "Citation": "", "Keywords": ""}, {"Name": "HXPY: A high-performance data processing package for financial time-series data", "Authors": ["Jiadong Guo", "Jingshu Peng", "Hang Yuan", "Lionel Ming-shuan Ni"], "Sources": "Journal of Computer Science and Technology", "PublishedYears": "2023", "Doi": "", "Abstracts": "A tremendous amount of data has been generated by global financial markets everyday, and such time-series data needs to be analyzed in real time to explore its potential value. In recent years, we have witnessed the successful adoption of machine learning models on financial data, where the importance of accuracy and timeliness demands highly effective computing frameworks. However, traditional financial time-series data processing frameworks have shown performance degradation and adaptation issues, such as the outlier handling with stock suspension in Pandas and TA-Lib. In this paper, we propose HXPY, a high-performance data processing package with a C++/Python interface for financial time-series data. HXPY supports miscellaneous acceleration techniques such as the streaming algorithm, the vectorization instruction set, and memory optimization, together with various functions such as time?\u2026", "IdName": "guo2023hxpy", "Citation": "", "Keywords": ""}, {"Name": "iMatching: An interactive map-matching system", "Authors": ["Ye Ding", "Xibo Zhou", "Qing Liao", "Haoyu Tan", "Qiong Luo", "Lionel M Ni"], "Sources": "Neurocomputing 444", "PublishedYears": "2021", "Doi": "", "Abstracts": "Map-matching is a process that aligns location points on a digital map and it is an essential step in location-based services. However, regular map-matching methods cannot archive very high accuracy due to the errors in raw location data and the complexity of road networks. Hence, the final resort for map matching is often through manual annotation, which is human labour intensive. Therefore, we propose iMatching, an interactive system for map-matching which greatly reduces annotation cost and achieves a high accuracy through an active learning approach. Specifically, we model the mapping of a sequence of location points to a road network as a hidden Markov model and automatically generate an initial result. Then, we select error-prone points on the trajectory and guide the annotator to review, and possibly correct, the results. Our evaluation on both real-world and synthetic data demonstrates that?\u2026", "IdName": "ding2021imatching", "Citation": "", "Keywords": ""}, {"Name": "Unsupervised Learning for Human Mobility Behaviors", "Authors": ["Siyuan Liu", "Shaojie Tang", "Jiangchuan Zheng", "Lionel M Ni"], "Sources": "INFORMS Journal on Computing", "PublishedYears": "2022", "Doi": "", "Abstracts": "Learning human mobility behaviors from location-sensing data are crucial to mobility data mining because of its potential to address a range of analytical purposes in mobile context reasoning, including exploration, inference, and prediction. However, existing approaches suffer from two practical problems: temporal and spatial sparsity. To address these shortcomings, we present two unsupervised learning methods to model the mobility behaviors of multiple users (i.e., a population), considering efficiency and accuracy. These methods intelligently overcome the sparsity in individual data by seeking temporal commonality among users\u2019 heterogeneous location behaviors. The advantages of our models are highlighted through experiments on several real-world mobility data sets, which also show how our methods can realize the three analytical purposes in a unified manner.", "IdName": "liu2022unsupervised", "Citation": "", "Keywords": ""}, {"Name": "Two-Stream Convolution Augmented Transformer for Human Activity Recognition", "Authors": ["Bing Li", "Wei Cui", "Wei Wang", "Le Zhang", "Zhenghua Chen", "Min Wu"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2021", "Doi": "", "Abstracts": "Recognition of human activities is an important task due to its far-reaching applications such as healthcare system, context-aware applications, and security monitoring. Recently, WiFi based human activity recognition (HAR) is becoming ubiquitous due to its non-invasiveness. Existing WiFi-based HAR methods regard WiFi signals as a temporal sequence of channel state information (CSI), and employ deep sequential models (eg, RNN, LSTM) to automatically capture channel-over-time features. Although being remarkably effective, they suffer from two major drawbacks. Firstly, the granularity of a single temporal point is blindly elementary for representing meaningful CSI patterns. Secondly, the time-over-channel features are also important, and could be a natural data augmentation. To address the drawbacks, we propose a novel Two-stream Convolution Augmented Human Activity Transformer (THAT) model. Our model proposes to utilize a two-stream structure to capture both time-over-channel and channel-over-time features, and use the multi-scale convolution augmented transformer to capture range-based patterns. Extensive experiments on four real experiment datasets demonstrate that our model outperforms state-of-the-art models in terms of both effectiveness and efficiency.", "IdName": "li2021two", "Citation": "", "Keywords": ""}, {"Name": "An experimental study of state-of-the-art entity alignment approaches", "Authors": ["Xiang Zhao", "Weixin Zeng", "Jiuyang Tang", "Wei Wang", "Fabian Suchanek"], "Sources": "IEEE Transactions on Knowledge & Data Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "Entity alignment (EA) finds equivalent entities that are located in different knowledge graphs (KGs), which is an essential step to enhance the quality of KGs, and hence of significance to downstream applications (e.g., question answering and recommendation). Recent years have witnessed a rapid increase of EA approaches, yet the relative performance of them remains unclear, partly due to the incomplete empirical evaluations, as well as the fact that comparisons were carried out under different settings (i.e., datasets, information used as input, etc.). In this paper, we fill in the gap by conducting a comprehensive evaluation and detailed analysis of state-of-the-art EA approaches. We first propose a general EA framework that encompasses all the current methods, and then group existing methods into three major categories. Next, we judiciously evaluate these solutions on a wide range of use cases, based on their?\u2026", "IdName": "zhao2020experimental", "Citation": "", "Keywords": ""}, {"Name": "Degree-Aware Alignment for Entities in Tail", "Authors": ["Weixin Zeng", "Xiang Zhao", "Wei Wang", "Jiuyang Tang", "Zhen Tan"], "Sources": "Proceedings of the 43rd International ACM SIGIR Conference on Research and?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Entity alignment (EA) is to discover equivalent entities in knowledge graphs (KGs), which bridges heterogeneous sources of information and facilitates the integration of knowledge. Existing EA solutions mainly rely on structural information to align entities, typically through KG embedding. Nonetheless, in real-life KGs, only a few entities are densely connected to others, and the rest majority possess rather sparse neighborhood structure. We refer to the latter as long-tail entities, and observe that such phenomenon arguably limits the use of structural information for EA.  To mitigate the issue, we revisit and investigate into the conventional EA pipeline in pursuit of elegant performance. For pre-alignment, we propose to amplify long-tail entities, which are of relatively weak structural information, with entity name information that is generally available (but overlooked) in the form of concatenated power mean word?\u2026", "IdName": "zeng2020degree", "Citation": "", "Keywords": ""}, {"Name": "Unsupervised domain adaptation for nonintrusive load monitoring via adversarial and joint adaptation network", "Authors": ["Yinyan Liu", "Li Zhong", "Jing Qiu", "Junda Lu", "Wei Wang"], "Sources": "IEEE Transactions on Industrial Informatics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Nonintrusive load monitoring (NILM) is a technique to disaggregate an appliance's load consumption from the aggregate load in a house. Monitoring the energy behavior has become increasingly important for home energy management. For many machine learning-based models, model training needs enough, and diverse appliance-level labeled data from different houses, which is very time-consuming, expensive, and unacceptable for users. In this article, we propose an algorithm based on the adversarial network and the joint adaptation network for energy disaggregation to decrease the distribution gaps of both the feature space and the label space between the source and target domains. With only very limited labeled data in the source domain and enough unlabeled data in the target domain, our proposed algorithm can obtain satisfactory accuracy results for NILM. Extensive experiments for intradomain and?\u2026", "IdName": "liu2021unsupervised", "Citation": "", "Keywords": ""}, {"Name": "VHP: approximate nearest neighbor search via virtual hypersphere partitioning", "Authors": ["Kejing Lu", "Hongya Wang", "Wei Wang", "Mineichi Kudo"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2020", "Doi": "", "Abstracts": "Locality sensitive hashing (LSH) is a widely practiced c-approximate nearest neighbor(c-ANN) search algorithm in high dimensional spaces. The state-of-the-art LSH based algorithm searches an unbounded and irregular space to identify candidates, which jeopardizes the efficiency. To address this issue, we introduce the concept of virtual hypersphere partitioning. The core idea is to impose a virtual hypersphere, centered at the query, in the original feature space and only examine points inside the hypersphere. The search space of a hypersphere is isotropic and bounded, and thus more efficient than the existing one. In practice, we use multiple physical hyperspheres with different radii in corresponding projection subspaces to emulate the single virtual hypersphere. We also developed a principled method to compute the hypersphere radii for given success probability. Based on virtual hypersphere partitioning, we propose a novel disk-based indexing and searching scheme VHP to answer c-ANN queries. In the indexing phase, VHP stores LSH projections with independent B+-trees. To process a query, VHP keeps increasing the radii of physical hyperspheres coordinately, which in effect amounts to enlarging the virtual hypersphere, to accommodate more candidates until the success probability is met. Rigorous theoretical analysis shows that the proposed algorithm supports c-ANN search for arbitrarily small c >= 1 with probability guarantee. Extensive experiments on a variety of datasets, including the billion-scale ones, demonstrate that VHP could achieve different tradeoffs between efficiency and accuracy, and achieves up to 2x speedup in?\u2026", "IdName": "lu2020vhp", "Citation": "", "Keywords": ""}, {"Name": "GraphER: Token-Centric Entity Resolution with Graph Convolutional Neural Networks", "Authors": ["Bing Li", "Wei Wang", "Yifang Sun", "Linhan Zhang", "Muhammad Asif Ali", "Yi Wang"], "Sources": "AAAI", "PublishedYears": "2020", "Doi": "", "Abstracts": "Entity resolution (ER) aims to identify entity records that refer to the same real-world entity, which is a critical problem in data cleaning and integration. Most of the existing models are attribute-centric, that is, matching entity pairs by comparing similarities of pre-aligned attributes, which require the schemas of records to be identical and are too coarse-grained to capture subtle key information within a single attribute. In this paper, we propose a novel graph-based ER model GraphER. Our model is token-centric: the final matching results are generated by directly aggregating token-level comparison features, in which both the semantic and structural information has been softly embedded into token embeddings by training an Entity Record Graph Convolutional Network (ER-GCN). To the best of our knowledge, our work is the first effort to do token-centric entity resolution with the help of GCN in entity resolution task. Extensive experiments on two real-world datasets demonstrate that our model stably outperforms state-of-the-art models.", "IdName": "li2020grapher", "Citation": "", "Keywords": ""}, {"Name": "Lion: Adversarial Distillation of Closed-Source Large Language Model", "Authors": ["Yuxin Jiang", "Chunkit Chan", "Mingyang Chen", "Wei Wang"], "Sources": "arXiv preprint arXiv:2305.12870", "PublishedYears": "2023", "Doi": "", "Abstracts": "The practice of transferring knowledge from a sophisticated, closed-source large language model (LLM) to a compact, open-source LLM has garnered considerable attention. Previous works have focused on a unidirectional knowledge distillation way by aligning the responses of the student model with those of the teacher model to a set of instructions. Nevertheless, they overlooked the possibility of incorporating any reciprocal \"feedback\"--identifying challenging instructions where the student model's performance falls short--to boost the student model's proficiency iteratively. To this end, we propose a novel adversarial distillation framework for a more efficient knowledge transfer. Leveraging the versatile role adaptability of LLMs, we prompt the closed-source model to identify \"hard\" instructions and generate new \"hard\" instructions for the student model, creating a three-stage adversarial loop of imitation, discrimination, and generation. By applying this adversarial framework, we successfully transfer knowledge from ChatGPT to a 7B student model (named Lion), achieving nearly 95% capability approximation using a mere 70k training data. We aspire that this proposed model may serve as the baseline to reflect the performance of ChatGPT, especially the open-source instruction-following language model baseline for our community.", "IdName": "jiang2023lion", "Citation": "", "Keywords": ""}, {"Name": "MDERank: A masked document embedding rank approach for unsupervised keyphrase extraction", "Authors": ["Linhan Zhang", "Qian Chen", "Wen Wang", "Chong Deng", "Shiliang Zhang", "Bing Li", "Wei Wang", "Xin Cao"], "Sources": "arXiv preprint arXiv:2110.06651", "PublishedYears": "2021", "Doi": "", "Abstracts": "Keyphrase extraction (KPE) automatically extracts phrases in a document that provide a concise summary of the core content, which benefits downstream information retrieval and NLP tasks. Previous state-of-the-art (SOTA) methods select candidate keyphrases based on the similarity between learned representations of the candidates and the document. They suffer performance degradation on long documents due to discrepancy between sequence lengths which causes mismatch between representations of keyphrase candidates and the document. In this work, we propose a novel unsupervised embedding-based KPE approach, Masked Document Embedding Rank (MDERank), to address this problem by leveraging a mask strategy and ranking candidates by the similarity between embeddings of the source document and the masked document. We further develop a KPE-oriented BERT (KPEBERT) model by proposing a novel self-supervised contrastive learning method, which is more compatible to MDERank than vanilla BERT. Comprehensive evaluations on six KPE benchmarks demonstrate that the proposed MDERank outperforms state-of-the-art unsupervised KPE approach by average 1.80 $F1@15$ improvement. MDERank further benefits from KPEBERT and overall achieves average 3.53 $F1@15$ improvement over the SOTA SIFRank. Our code is available at \\url{https://github.com/LinhanZ/mderank}.", "IdName": "zhang2021mderank", "Citation": "", "Keywords": ""}, {"Name": "HAMNER: Headword Amplified Multi-span Distantly Supervised Method for Domain Specific Named Entity Recognition", "Authors": ["Shifeng Liu", "Yifang Sun", "Bing Li", "Wei Wang", "Xiang Zhao"], "Sources": "AAAI", "PublishedYears": "2020", "Doi": "", "Abstracts": "To tackle Named Entity Recognition (NER) tasks, supervised methods need to obtain sufficient cleanly annotated data, which is labor and time consuming. On the contrary, distantly supervised methods acquire automatically annotated data using dictionaries to alleviate this requirement. Unfortunately, dictionaries hinder the effectiveness of distantly supervised methods for NER due to its limited coverage, especially in specific domains. In this paper, we aim at the limitations of the dictionary usage and mention boundary detection. We generalize the distant supervision by extending the dictionary with headword based non-exact matching. We apply a function to better weight the matched entity mentions. We propose a span-level model, which classifies all the possible spans then infers the selected spans with a proposed dynamic programming algorithm. Experiments on all three benchmark datasets demonstrate that our method outperforms previous state-of-the-art distantly supervised methods.", "IdName": "liu2020hamner", "Citation": "", "Keywords": ""}, {"Name": "Improving the Efficiency and Effectiveness for BERT-based Entity Resolution", "Authors": ["Bing Li", "Yukai Miao", "Yaoshu Wang", "Yifang Sun", "Wei Wang"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2021", "Doi": "", "Abstracts": "BERT has set a new state-of-the-art performance on entity resolution (ER) task, largely owed to fine-tuning pre-trained language models and the deep pair-wise interaction. Albeit being remarkably effective, it comes with a steep increase in computational cost, as the deep-interaction requires to exhaustively compute every tuple pair to search for co-references. For ER task, it is often prohibitively expensive due to the large cardinality to be matched. To tackle this, we introduce a siamese network structure that independently encodes tuples using BERT but delays the pair-wise interaction via an enhanced alignment network. This siamese structure enables a dedicated blocking module to quickly filter out obviously dissimilar tuple pairs, and thus drastically reduces the cardinality of fine-grained matching. Further, the blocking and entity matching are integrated into a multi-task learning framework for facilitating both tasks. Extensive experiments on multiple datasets demonstrate that our model significantly outperforms state-of-the-art models (including BERT) in both efficiency and effectiveness.", "IdName": "li2021improving", "Citation": "", "Keywords": ""}, {"Name": "Monotonic Cardinality Estimation of Similarity Selection: A Deep Learning Approach", "Authors": ["Yaoshu Wang", "Chuan Xiao", "Jianbin Qin", "Xin Cao", "Yifang Sun", "Wei Wang", "Makoto Onizuka"], "Sources": "SIGMOD", "PublishedYears": "2020", "Doi": "", "Abstracts": "In this paper, we investigate the possibilities of utilizing deep learning for cardinality estimation of similarity selection. Answering this problem accurately and efficiently is essential to many data management applications, especially for query optimization. Moreover, in some applications the estimated cardinality is supposed to be consistent and interpretable. Hence a monotonic estimation w.r.t. the query threshold is preferred. We propose a novel and generic method that can be applied to any data type and distance function. Our method consists of a feature extraction model and a regression model. The feature extraction model transforms original data and threshold to a Hamming space, in which a deep learning-based regression model is utilized to exploit the incremental property of cardinality w.r.t. the threshold for both accuracy and monotonicity. We develop a training strategy tailored to our model as well as?\u2026", "IdName": "wang2020monotonic", "Citation": "", "Keywords": ""}, {"Name": "A home energy management system incorporating data-driven uncertainty-aware user preference", "Authors": ["Yinyan Liu", "Jin Ma", "Xinjie Xing", "Xinglu Liu", "Wei Wang"], "Sources": "Applied Energy 326", "PublishedYears": "2022", "Doi": "", "Abstracts": "Today, with the increase in the integration of renewable sources, the home energy management system (HEMS) has become a promising approach to improve grid energy efficiency and relieve network stress. Traditionally, complicated thermal models or passive participation of the users prevents HEMS from fully automating the involvement of demand-side energy management. In this paper, an advanced HEMS is proposed incorporating uncertainty-aware user preference. The energy consumption user behavior, including temporal and temperature habits, is firstly characterized in a data-driven way with non-intrusive load monitoring (NILM). To capture the potential uncertainties resulting from the characteristics of NILM modeling, a novel NILM model is developed with Bayesian theory. The NILM-based preference level is further integrated into the HEMS to schedule the appliances and respond the demand?\u2026", "IdName": "liu2022home", "Citation": "", "Keywords": ""}, {"Name": "Fine-Grained Named Entity Typing over Distantly Supervised Data Based on Refined Representation", "Authors": ["Muhammad Asif Ali", "Yifang Sun", "Bing Li", "Wei Wang"], "Sources": "AAAI", "PublishedYears": "2020", "Doi": "", "Abstracts": "Fine-Grained Named Entity Typing (FG-NET) is a key component in Natural Language Processing (NLP). It aims at classifying an entity mention into a wide range of entity types. Due to a large number of entity types, distant supervision is used to collect training data for this task, which noisily assigns type labels to entity mentions irrespective of the context. In order to alleviate the noisy labels, existing approaches on FG-NET analyze the entity mentions entirely independent of each other and assign type labels solely based on mention's sentence-specific context. This is inadequate for highly overlapping and/or noisy type labels as it hinders information passing across sentence boundaries. For this, we propose an edge-weighted attentive graph convolution network that refines the noisy mention representations by attending over corpus-level contextual clues prior to the end classification. Experimental evaluation shows that the proposed model outperforms the existing research by a relative score of upto 10.2% and 8.3% for macro-f1 and micro-f1 respectively.", "IdName": "ali2020fine", "Citation": "", "Keywords": ""}, {"Name": "On entity alignment at scale", "Authors": ["Weixin Zeng", "Xiang Zhao", "Xinyi Li", "Jiuyang Tang", "Wei Wang"], "Sources": "The VLDB Journal", "PublishedYears": "2022", "Doi": "", "Abstracts": "Knowledge graph (KG), as an effective approach of organizing and storing data, has received growing attention over the last decade. A KG can hardly reach completeness since there are always a large amount of new data emerging. To increase the scale and coverage of KGs, a possible solution is to incorporate data from other KGs, and entity alignment (EA) plays a vital role during this process. EA is the task of detecting the entities that refer to the same real-world object but come from different KGs. Although a pile of approaches have been put forward to tackle this task, they are mostly evaluated on datasets in small size and cannot deal with large-scale data in practice. In this work, we study the task of EA at scale and put forward a novel solution that can manage large-scale KG pairs and meanwhile achieve promising alignment performance. First, we devise seed-oriented graph partition strategies to divide large?\u2026", "IdName": "zeng2022entity", "Citation": "", "Keywords": ""}, {"Name": "Neural subgraph counting with wasserstein estimator", "Authors": ["Hanchen Wang", "Rong Hu", "Ying Zhang", "Lu Qin", "Wei Wang", "Wenjie Zhang"], "Sources": "Proceedings of the 2022 International Conference on Management of Data", "PublishedYears": "2022", "Doi": "", "Abstracts": "Subgraph counting is a fundamental graph analysis task which has been widely used in many applications. As the problem of subgraph counting is NP-complete and hence intractable, approximate solutions have been widely studied, which fail to work with large and complex query graphs. Alternatively, Machine Learning techniques have been recently applied for this problem, yet the existing ML approaches either only support very small data graphs or cannot make full use of the data graph information, which inherently limits their scalability, estimation accuracies and robustness. In this paper, we propose a novel approximate subgraph counting algorithm, NeurSC, that can exploit and combine information from both the query graphs and the data graphs effectively and efficiently. It consists of two components: (1) an extraction module that adaptively generates simple yet representative substructures from data?\u2026", "IdName": "wang2022neural", "Citation": "", "Keywords": ""}, {"Name": "DAIR: A Query-Efficient Decision-based Attack on Image Retrieval Systems", "Authors": ["Mingyang Chen", "Junda Lu", "Yi Wang", "Jianbin Qin", "Wei Wang"], "Sources": "Proceedings of the 44th International ACM SIGIR Conference on Research and?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "There is an increasing interest in studying adversarial attacks on image retrieval systems. However, most of the existing attack methods are based on the white-box setting, where the attackers have access to all the model and database details, which is a strong assumption for practical attacks. The generic transfer-based attack also requires substantial resources yet the effect was shown to be unreliable. In this paper, we make the first attempt in proposing a query-efficient decision-based attack framework for the image retrieval (DAIR) to completely subvert the top-K retrieval results with human imperceptible perturbations. We propose an optimization-based method with a smoothed utility function to overcome the challenging discrete nature of the problem. To further improve the query efficiency, we propose a novel sampling method that can achieve the transferability between the surrogate and the target model?\u2026", "IdName": "chen2021dair", "Citation": "", "Keywords": ""}, {"Name": "A smart adversarial attack on deep hashing based image retrieval", "Authors": ["Junda Lu", "Mingyang Chen", "Yifang Sun", "Wei Wang", "Yi Wang", "Xiaochun Yang"], "Sources": "Proceedings of the 2021 international conference on multimedia retrieval?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Deep hashing based retrieval models have been widely used in large-scale image retrieval systems. Recently, there has been a surging interest in studying the adversarial attack problem in deep hashing based retrieval models. However, the effectiveness of existing adversarial attacks is limited by their poor perturbation management, unawareness of ranking weight, and only laser-focusing on the attack image. These shortages lead to high perturbation costs yet low AP reductions. To overcome these shortages, we propose a novel adversarial attack framework to improve the effectiveness of adversarial attacks. Our attack designs a dimension-wise surrogate Hamming distance function to help with wiser perturbation management. Further, in generating adversarial examples, instead of focusing on a single image, we propose to collectively incorporate relevant images combined with an AP-oriented (average?\u2026", "IdName": "lu2021smart", "Citation": "", "Keywords": ""}, {"Name": "A Learning Based Approach to Predict Shortest-Path Distances", "Authors": ["Jianzhong Qi", "Wei Wang", "Rui Zhang", "Zhuowei Zhao"], "Sources": "EDBT", "PublishedYears": "2020", "Doi": "", "Abstracts": "", "IdName": "qi2020learning", "Citation": "", "Keywords": ""}, {"Name": "Reinforcement learning based query vertex ordering model for subgraph matching", "Authors": ["Hanchen Wang", "Ying Zhang", "Lu Qin", "Wei Wang", "Wenjie Zhang", "Xuemin Lin"], "Sources": "2022 IEEE 38th International Conference on Data Engineering (ICDE)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Subgraph matching is a fundamental problem in various fields that use graph structured data. Subgraph matching algorithms enumerate all isomorphic embeddings of a query graph    in a data graph G. An important branch of matching algorithms exploit the backtracking search approach which recursively extends intermediate results following a matching order of query vertices. It has been shown that the matching order plays a critical role in time efficiency of these backtracking based subgraph matching algorithms. In recent years, many advanced techniques for query vertex ordering (i.e., matching order generation) have been proposed to reduce the unpromising intermediate results according to the preset heuristic rules. In this paper, for the first time we apply the Reinforcement Learning (RL) and Graph Neural Networks (GNNs) techniques to generate the high-quality matching order for subgraph matching?\u2026", "IdName": "wang2022reinforcement", "Citation": "", "Keywords": ""}, {"Name": "High-Dimensional Similarity Query Processing for Data Science", "Authors": ["Jianbin Qin", "Wei Wang", "Chuan Xiao", "Ying Zhang", "Yaoshu Wang"], "Sources": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Similarity query (a.k.a. nearest neighbor query) processing has been an active research topic for several decades. It is an essential procedure in a wide range of applications (e.g., classification & regression, deduplication, image retrieval, and recommender systems). Recently, representation learning and auto-encoding methods as well as pre-trained models have gained popularity. They basically deal with dense high-dimensional data, and this trend brings new opportunities and challenges to similarity query processing. Meanwhile, new techniques have emerged to tackle this long-standing problem theoretically and empirically.   This tutorial aims to provide a comprehensive review of high-dimensional similarity query processing for data science. It introduces solutions from a variety of research communities, including data mining (DM), database (DB), machine learning (ML), computer vision (CV), natural?\u2026", "IdName": "qin2021high", "Citation": "", "Keywords": ""}, {"Name": "Similarity query processing for high-dimensional data", "Authors": ["Jianbin Qin", "Wei Wang", "Chuan Xiao", "Ying Zhang"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2020", "Doi": "", "Abstracts": "Similarity query processing has been an active research topic for several decades. It is an essential procedure in a wide range of applications. Recently, embedding and auto-encoding methods as well as pre-trained models have gained popularity. They basically deal with high-dimensional data, and this trend brings new opportunities and challenges to similarity query processing for high-dimensional data. Meanwhile, new techniques have emerged to tackle this long-standing problem theoretically and empirically. In this tutorial, we summarize existing solutions, especially recent advancements from both database (DB) and machine learning (ML) communities, and analyze their strengths and weaknesses. We review exact and approximate methods such as cover tree, locality sensitive hashing, product quantization, and proximity graphs. We also discuss the selectivity estimation problem and show how researchers are bringing in state-of-the-art ML techniques to address the problem. By highlighting the strong connections between DB and ML, we hope that this tutorial provides an impetus towards new ML for DB solutions and vice versa.", "IdName": "qin2020similarity", "Citation": "", "Keywords": ""}, {"Name": "Consistent and flexible selectivity estimation for high-dimensional data", "Authors": ["Yaoshu Wang", "Chuan Xiao", "Jianbin Qin", "Rui Mao", "Makoto Onizuka", "Wei Wang", "Rui Zhang", "Yoshiharu Ishikawa"], "Sources": "Proceedings of the 2021 International Conference on Management of Data", "PublishedYears": "2021", "Doi": "", "Abstracts": "Selectivity estimation aims at estimating the number of database objects that satisfy a selection criterion. Answering this problem accurately and efficiently is essential to many applications, such as density estimation, outlier detection, query optimization, and data integration. The estimation problem is especially challenging for large-scale high-dimensional data due to the curse of dimensionality, the large variance of selectivity across different queries, and the need to make the estimator consistent (i.e., the selectivity is non-decreasing in the threshold). We propose a new deep learning-based model that learns a query-dependent piecewise linear function as selectivity estimator, which is flexible to fit the selectivity curve of any distance function and query object, while guaranteeing that the output is non-decreasing in the threshold. To improve the accuracy for large datasets, we propose to partition the dataset into?\u2026", "IdName": "wang2021consistent", "Citation": "", "Keywords": ""}, {"Name": "EI-LSH: An early-termination driven I/O efficient incremental c-approximate nearest neighbor search", "Authors": ["Wanqi Liu", "Hanchen Wang", "Ying Zhang", "Wei Wang", "Lu Qin", "Xuemin Lin"], "Sources": "The VLDB Journal 30", "PublishedYears": "2021", "Doi": "", "Abstracts": " Nearest neighbor in high-dimensional space has been widely used in various fields such as databases, data mining and machine learning. The problem has been well solved in low-dimensional space. However, when it comes to high-dimensional space, due to the curse of dimensionality, the problem is challenging. As a trade-off between accuracy and efficiency, c-approximate nearest neighbor (c-ANN) is considered instead of an exact NN search in high-dimensional space. A variety of c-ANN algorithms have been proposed, one of the important schemes for the c-ANN problem is called Locality-sensitive hashing (LSH), which projects a high-dimensional dataset into a low-dimensional dataset and can return a c-ANN with a constant probability. In this paper, we propose a new aggressive early-termination (ET) condition which stops the algorithm with LSH scheme earlier under the same theoretical?\u2026", "IdName": "liu2021ei", "Citation": "", "Keywords": ""}, {"Name": "Ks-gnn: Keywords search over incomplete graphs via graphs neural network", "Authors": ["Yu Hao", "Xin Cao", "Yufan Sheng", "Yixiang Fang", "Wei Wang"], "Sources": "Advances in Neural Information Processing Systems 34", "PublishedYears": "2021", "Doi": "", "Abstracts": "Keyword search is a fundamental task to retrieve information that is the most relevant to the query keywords. Keyword search over graphs aims to find subtrees or subgraphs containing all query keywords ranked according to some criteria. Existing studies all assume that the graphs have complete information. However, real-world graphs may contain some missing information (such as edges or keywords), thus making the problem much more challenging. To solve the problem of keyword search over incomplete graphs, we propose a novel model named KS-GNN based on the graph neural network and the auto-encoder. By considering the latent relationships and the frequency of different keywords, the proposed KS-GNN aims to alleviate the effect of missing information and is able to learn low-dimensional representative node embeddings that preserve both graph structure and keyword features. Our model can effectively answer keyword search queries with linear time complexity over incomplete graphs. The experiments on four real-world datasets show that our model consistently achieves better performance than state-of-the-art baseline methods in graphs having missing information.", "IdName": "hao2021ks", "Citation": "", "Keywords": ""}, {"Name": "Adversarial Defence by Diversified Simultaneous Training of Deep Ensembles", "Authors": ["Bo Huang", "Zhiwei Ke", "Yi Wang", "Wei Wang", "Linlin Shen", "Feng Liu"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2021", "Doi": "", "Abstracts": "Learning-based classifiers are susceptible to adversarial examples. Existing defence methods are mostly devised on individual classifiers. Recent studies showed that it is viable to increase adversarial robustness by promoting diversity over an ensemble of models. In this paper, we propose adversarial defence by encouraging ensemble diversity on learning high-level feature representations and gradient dispersion in simultaneous training of deep ensemble networks. We perform extensive evaluations under white-box and black-box attacks including transferred examples and adaptive attacks. Our approach achieves a significant gain of up to 52% in adversarial robustness, compared with the baseline and the state-of-the-art method on image benchmarks with complex data scenes. The proposed approach complements the defence paradigm of adversarial training, and can further boost the performance. The source code is available at https://github. com/ALIS-Lab/AAAI2021-PDD.", "IdName": "huang2021adversarial", "Citation": "", "Keywords": ""}, {"Name": "Software-defined network assimilation: bridging the last mile towards centralized network configuration management with NAssim", "Authors": ["Huangxun Chen", "Yukai Miao", "Li Chen", "Haifeng Sun", "Hong Xu", "Libin Liu", "Gong Zhang", "Wei Wang"], "Sources": "Proceedings of the ACM SIGCOMM 2022 Conference", "PublishedYears": "2022", "Doi": "", "Abstracts": "On-boarding new devices into an existing SDN network is a pain for network operations (NetOps) teams, because much expert effort is required to bridge the gap between the configuration models of the new devices and the unified data model in the SDN controller. In this work, we present an assistant framework NAssim, to help NetOps accelerate the process of assimilating a new device into a SDN network. Our solution features a unified parser framework to parse diverse device user manuals into preliminary configuration models, a rigorous validator that confirm the correctness of the models via formal syntax analysis, model hierarchy validation and empirical data validation, and a deep-learning-based mapping algorithm that uses state-of-the-art neural language processing techniques to produce human-comprehensible recommended mapping between the validated configuration model and the one in the SDN?\u2026", "IdName": "chen2022software", "Citation": "", "Keywords": ""}, {"Name": "Boosting Accuracy and Robustness of Student Models via Adaptive Adversarial Distillation", "Authors": ["Bo Huang", "Mingyang Chen", "Yi Wang", "Junda Lu", "Minhao Cheng", "Wei Wang"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Distilled student models in teacher-student architectures are widely considered for computational-effective deployment in real-time applications and edge devices. However, there is a higher risk of student models to encounter adversarial attacks at the edge. Popular enhancing schemes such as adversarial training have limited performance on compressed networks. Thus, recent studies concern about adversarial distillation (AD) that aims to inherit not only prediction accuracy but also adversarial robustness of a robust teacher model under the paradigm of robust optimization. In the min-max framework of AD, existing AD methods generally use fixed supervision information from the teacher model to guide the inner optimization for knowledge distillation which often leads to an overcorrection towards model smoothness. In this paper, we propose an adaptive adversarial distillation (AdaAD) that involves the teacher model in the knowledge optimization process in a way interacting with the student model to adaptively search for the inner results. Comparing with state-of-the-art methods, the proposed AdaAD can significantly boost both the prediction accuracy and adversarial robustness of student models in most scenarios. In particular, the ResNet-18 model trained by AdaAD achieves top-rank performance (54.23% robust accuracy) on RobustBench under AutoAttack.", "IdName": "huang2023boosting", "Citation": "", "Keywords": ""}, {"Name": "Sent2Span: span detection for PICO extraction in the biomedical text without span annotations", "Authors": ["Shifeng Liu", "Yifang Sun", "Bing Li", "Wei Wang", "Florence T Bourgeois", "Adam G Dunn"], "Sources": "arXiv preprint arXiv:2109.02254", "PublishedYears": "2021", "Doi": "", "Abstracts": "The rapid growth in published clinical trials makes it difficult to maintain up-to-date systematic reviews, which requires finding all relevant trials. This leads to policy and practice decisions based on out-of-date, incomplete, and biased subsets of available clinical evidence. Extracting and then normalising Population, Intervention, Comparator, and Outcome (PICO) information from clinical trial articles may be an effective way to automatically assign trials to systematic reviews and avoid searching and screening - the two most time-consuming systematic review processes. We propose and test a novel approach to PICO span detection. The major difference between our proposed method and previous approaches comes from detecting spans without needing annotated span data and using only crowdsourced sentence-level annotations. Experiments on two datasets show that PICO span detection results achieve much higher results for recall when compared to fully supervised methods with PICO sentence detection at least as good as human annotations. By removing the reliance on expert annotations for span detection, this work could be used in human-machine pipeline for turning low-quality crowdsourced, and sentence-level PICO annotations into structured information that can be used to quickly assign trials to relevant systematic reviews.", "IdName": "liu2021sent2span", "Citation": "", "Keywords": ""}, {"Name": "Efficient query autocompletion with edit distance-based error tolerance", "Authors": ["Jianbin Qin", "Chuan Xiao", "Sheng Hu", "Jie Zhang", "Wei Wang", "Yoshiharu Ishikawa", "Koji Tsuda", "Kunihiko Sadakane"], "Sources": "The VLDB Journal 29", "PublishedYears": "2020", "Doi": "", "Abstracts": " Query autocompletion is an important feature saving users many keystrokes from typing the entire query. In this paper, we study the problem of query autocompletion that tolerates errors in users\u2019 input using edit distance constraints. Previous approaches index data strings in a trie, and continuously maintain all the prefixes of data strings whose edit distances from the query string are within the given threshold. The major inherent drawback of these approaches is that the number of such prefixes is huge for the first few characters of the query string and is exponential in the alphabet size. This results in slow query response even if the entire query approximately matches only few prefixes. We propose a novel neighborhood generation-based method to process error-tolerant query autocompletion. Our proposed method only maintains a small set of active nodes, thus saving both space and time to process the?\u2026", "IdName": "qin2020efficient", "Citation": "", "Keywords": ""}, {"Name": "Global and Local Hierarchy-aware Contrastive Framework for Implicit Discourse Relation Recognition", "Authors": ["Yuxin Jiang", "Linhan Zhang", "Wei Wang"], "Sources": "arXiv preprint arXiv:2211.13873", "PublishedYears": "2022", "Doi": "", "Abstracts": "Due to the absence of explicit connectives, implicit discourse relation recognition (IDRR) remains a challenging task in discourse analysis. The critical step for IDRR is to learn high-quality discourse relation representations between two arguments. Recent methods tend to integrate the whole hierarchical information of senses into discourse relation representations for multi-level sense recognition. Nevertheless, they insufficiently incorporate the static hierarchical structure containing all senses (defined as global hierarchy), and ignore the hierarchical sense label sequence corresponding to each instance (defined as local hierarchy). For the purpose of sufficiently exploiting global and local hierarchies of senses to learn better discourse relation representations, we propose a novel GlObal and Local Hierarchy-aware Contrastive Framework (GOLF), to model two kinds of hierarchies with the aid of multi-task learning and contrastive learning. Experimental results on PDTB 2.0 and PDTB 3.0 datasets demonstrate that our method remarkably outperforms current state-of-the-art models at all hierarchical levels. Our code is publicly available at https://github.com/YJiangcm/GOLF_for_IDRR", "IdName": "jiang2022global", "Citation": "", "Keywords": ""}, {"Name": "DifFormer: Multi-Resolutional Differencing Transformer With Dynamic Ranging for Time Series Analysis", "Authors": ["Bing Li", "Wei Cui", "Le Zhang", "Ce Zhu", "Wei Wang", "Ivor Tsang", "Joey Tianyi Zhou"], "Sources": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Time series analysis is essential to many far-reaching applications of data science and statistics including economic and financial forecasting, surveillance, and automated business processing. Though being greatly successful of Transformer in computer vision and natural language processing, the potential of employing it as the general backbone in analyzing the ubiquitous times series data has not been fully released yet. Prior Transformer variants on time series highly rely on task-dependent designs and pre-assumed \u201cpattern biases\u201d, revealing its insufficiency in representing nuanced seasonal, cyclic, and outlier patterns which are highly prevalent in time series. As a consequence, they can not generalize well to different time series analysis tasks. To tackle the challenges, we propose  DifFormer , an effective and efficient Transformer architecture that can serve as a workhorse for a variety of time-series analysis?\u2026", "IdName": "li2023difformer", "Citation": "", "Keywords": ""}, {"Name": "A deep neural network for general scattering matrix", "Authors": ["Yongxin Jing", "Hongchen Chu", "Bo Huang", "Jie Luo", "Wei Wang", "Yun Lai"], "Sources": "Nanophotonics", "PublishedYears": "2023", "Doi": "", "Abstracts": " The scattering matrix is the mathematical representation of the scattering characteristics of any scatterer. Nevertheless, except for scatterers with high symmetry like spheres or cylinders, the scattering matrix does not have any analytical forms and thus can only be calculated numerically, which requires heavy computation. Here, we have developed a well-trained deep neural network (DNN) that can calculate the scattering matrix of scatterers without symmetry at a speed thousands of times faster than that of finite element solvers. Interestingly, the scattering matrix obtained from the DNN inherently satisfies the fundamental physical principles, including energy conservation, time reversal and reciprocity. Moreover, inverse design based on the DNN is made possible by applying the gradient descent algorithm. Finally, we demonstrate an application of the DNN, which is to design scatterers with desired scattering?\u2026", "IdName": "jing2023deep", "Citation": "", "Keywords": ""}, {"Name": "LMSFC: A Novel Multidimensional Index based on Learned Monotonic Space Filling Curves", "Authors": ["Jian Gao", "Xin Cao", "Xin Yao", "Gong Zhang", "Wei Wang"], "Sources": "arXiv preprint arXiv:2304.12635", "PublishedYears": "2023", "Doi": "", "Abstracts": "The recently proposed learned indexes have attracted much attention as they can adapt to the actual data and query distributions to attain better search efficiency. Based on this technique, several existing works build up indexes for multi-dimensional data and achieve improved query performance. A common paradigm of these works is to (i) map multi-dimensional data points to a one-dimensional space using a fixed space-filling curve (SFC) or its variant and (ii) then apply the learned indexing techniques. We notice that the first step typically uses a fixed SFC method, such as row-major order and z-order. It definitely limits the potential of learned multi-dimensional indexes to adapt variable data distributions via different query workloads. In this paper, we propose a novel idea of learning a space-filling curve that is carefully designed and actively optimized for efficient query processing. We also identify innovative offline and online optimization opportunities common to SFC-based learned indexes and offer optimal and/or heuristic solutions. Experimental results demonstrate that our proposed method, LMSFC, outperforms state-of-the-art non-learned or learned methods across three commonly used real-world datasets and diverse experimental settings.", "IdName": "gao2023lmsfc", "Citation": "", "Keywords": ""}, {"Name": "Deep learning for approximate nearest neighbour search: A survey and future directions", "Authors": ["Mingjie Li", "Yuan-Gen Wang", "Peng Zhang", "Hanpin Wang", "Lisheng Fan", "Enxia Li", "Wei Wang"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2022", "Doi": "", "Abstracts": "Approximate nearest neighbour search (ANNS) in high-dimensional space is an essential and fundamental operation in many applications from many domains such as multimedia database, information retrieval and computer vision. With the rapidly growing volume of data and the dramatically increasing demands of users, traditional heuristic-based ANNS solutions have been facing great challenges in terms of both efficiency and accuracy. Inspired by the recent successes of deep learning in many fields, substantial efforts have been devoted to applying deep learning techniques to ANNS for learning to index and learning to search, resulting in numerous algorithms that achieve state-of-the-art performance compared with conventional methods. In this survey paper, we comprehensively review the different types of deep learning-based ANNS methods according to two learning paradigms:  learning to index  and?\u2026", "IdName": "li2022deep", "Citation": "", "Keywords": ""}, {"Name": "Fine-Grained Named Entity Typing over Distantly Supervised Data via Refinement in Hyperbolic Space", "Authors": ["Muhammad Asif Ali", "Yifang Sun", "Bing Li", "Wei Wang"], "Sources": "arXiv preprint arXiv:2101.11212", "PublishedYears": "2021", "Doi": "", "Abstracts": "None", "IdName": "ali2021fine", "Citation": "", "Keywords": ""}, {"Name": "GCP: Graph Encoder With Content-Planning for Sentence Generation From Knowledge Bases", "Authors": ["Bayu Distiawan Trisedya", "Jianzhong Qi", "Wei Wang", "Rui Zhang"], "Sources": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "PublishedYears": "2021", "Doi": "", "Abstracts": "A knowledge base is a large repository of facts usually represented as triples, each consisting of a subject, a predicate, and an object. The triples together form a graph, i.e., a  knowledge graph . The triple representation in a knowledge graph offers a simple interface for applications to access the facts. However, this representation is not in a natural language form, which is difficult for humans to understand. We address this problem by proposing a system to translate a set of triples (i.e., a graph) into natural sentences. We take an encoder-decoder based approach. Specifically, we propose a  Graph encoder with C ontent- P lanning capability  ( GCP ) to encode an input graph. GCP not only works as an encoder but also serves as a content-planner by using an entity-order aware topological traversal to encode a graph. This way, GCP can capture the relationships between entities in a knowledge graph as well as providing?\u2026", "IdName": "trisedya2021gcp", "Citation": "", "Keywords": ""}, {"Name": "A Recurrent Model for Collective Entity Linking with Adaptive Features", "Authors": ["Xiaoling Zhou", "Yukai Miao", "Wei Wang", "Jianbin Qin"], "Sources": "AAAI", "PublishedYears": "2020", "Doi": "", "Abstracts": "The vast amount of web data enables us to build knowledge bases with unprecedented quality and coverage. Named Entity Disambiguation (NED) is an important task that automatically resolves ambiguous mentions in free text to correct target entries in the knowledge base. Traditional machine learning based methods for NED were outperformed and made obsolete by the state-of-the-art deep learning based models. However, deep learning models are more complex, requiring large amount of training data and lengthy training and parameter tuning time. In this paper, we revisit traditional machine learning techniques and propose a light-weight, tuneable and time-efficient method without using deep learning or deep learning generated features. We propose novel adaptive features that focus on extracting discriminative features to better model similarities between candidate entities and the mention's context. We learn a local ranking model based on traditional and the new adaptive features based on the learning-to-rank framework. While arriving at linking decisions individually via the local model, our method also takes into consideration the correlation between decisions by running multiple recurrent global models, which can be deemed as a learned local search method. Our method attains performances comparable to the state-of-the-art deep learning-based methods on NED benchmark datasets while being significantly faster to train.", "IdName": "zhou2020recurrent", "Citation": "", "Keywords": ""}, {"Name": "Relation prediction via graph neural network in heterogeneous information networks with missing type information", "Authors": ["Han Zhang", "Yu Hao", "Xin Cao", "Yixiang Fang", "Won-Yong Shin", "Wei Wang"], "Sources": "Proceedings of the 30th ACM International Conference on Information?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Relation prediction is a fundamental task in network analysis which aims to predict the relationship between two nodes. Thus, this differes from the traditional link prediction problem predicting whether a link exists between a pair of nodes, which can be viewed as a binary classification task. However, in the heterogeneous information network (HIN) which contains multiple types of nodes and multiple relations between nodes, the relation prediction task is more challenging. In addition, the HIN might have missing relation types on some edges and missing node types on some nodes, which makes the problem even harder. In this work, we propose RPGNN, a novel relation prediction model based on the graph neural network (GNN) and multi-task learning to solve this problem. Existing GNN models for HIN representation learning usually focus on the node classification/clustering task. They require the type information?\u2026", "IdName": "zhang2021relation", "Citation": "", "Keywords": ""}, {"Name": "A Note on Graph-Based Nearest Neighbor Search", "Authors": ["Hongya Wang", "Zhizheng Wang", "Wei Wang", "Yingyuan Xiao", "Zeng Zhao", "Kaixiang Yang"], "Sources": "arXiv preprint arXiv:2012.11083", "PublishedYears": "2020", "Doi": "", "Abstracts": "Nearest neighbor search has found numerous applications in machine learning, data mining and massive data processing systems. The past few years have witnessed the popularity of the graph-based nearest neighbor search paradigm because of its superiority over the space-partitioning algorithms. While a lot of empirical studies demonstrate the efficiency of graph-based algorithms, not much attention has been paid to a more fundamental question: why graph-based algorithms work so well in practice? And which data property affects the efficiency and how? In this paper, we try to answer these questions. Our insight is that \"the probability that the neighbors of a point o tends to be neighbors in the KNN graph\" is a crucial data property for query efficiency. For a given dataset, such a property can be qualitatively measured by clustering coefficient of the KNN graph. To show how clustering coefficient affects the performance, we identify that, instead of the global connectivity, the local connectivity around some given query q has more direct impact on recall. Specifically, we observed that high clustering coefficient makes most of the k nearest neighbors of q sit in a maximum strongly connected component (SCC) in the graph. From the algorithmic point of view, we show that the search procedure is actually composed of two phases - the one outside the maximum SCC and the other one in it, which is different from the widely accepted single or multiple paths search models. We proved that the commonly used graph-based search algorithm is guaranteed to traverse the maximum SCC once visiting any point in it. Our analysis reveals that high clustering?\u2026", "IdName": "wang2020note", "Citation": "", "Keywords": ""}, {"Name": "Recursively Binary Modification Model for Nested Named Entity Recognition", "Authors": ["Bing Li", "Shifeng Liu", "Yifang Sun", "Wei Wang", "Xiang Zhao"], "Sources": "AAAI", "PublishedYears": "2020", "Doi": "", "Abstracts": "Recently, there has been an increasing interest in identifying named entities with nested structures. Existing models only make independent typing decisions on the entire entity span while ignoring strong modification relations between sub-entity types. In this paper, we present a novel Recursively Binary Modification model for nested named entity recognition. Our model utilizes the modification relations among sub-entities types to infer the head component on top of a Bayesian framework and uses entity head as a strong evidence to determine the type of the entity span. The process is recursive, allowing lower-level entities to help better model those on the outer-level. To the best of our knowledge, our work is the first effort that uses modification relation in nested NER task. Extensive experiments on four benchmark datasets demonstrate that our model outperforms state-of-the-art models in nested NER tasks, and delivers competitive results with state-of-the-art models in flat NER task, without relying on any extra annotations or NLP tools.", "IdName": "li2020recursively", "Citation": "", "Keywords": ""}, {"Name": "A Single-to-Multi Network for Latency-Free Non-Intrusive Load Monitoring", "Authors": ["Yinyan Liu", "Jing Qiu", "Junda Lu", "Wei Wang", "Jin Ma"], "Sources": "IEEE Transactions on Network Science and Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "As one of the most important smart grid features, non-intrusive load monitoring (NILM) has become a practical technology for identifying the users\u2019 energy consumption behavior. The conventional studies are usually based on the assumption that only one appliance is active or the signature database of all appliances is already known. Existing deep learning-based algorithms need to train a model for each target appliance. This paper, however, proposes an energy disaggregation network (EDNet) with deep encoder-decoder architecture to remove the unrealistic assumptions and reduce the size of the network to achieve latency-free NILM with only one model. Firstly, the blind source separation and mask mechanism used for speech recognition are creatively adopted for energy disaggregation. Then, the on/off states of each target appliance is detected based on the results of energy disaggregation. Finally, a?\u2026", "IdName": "liu2021single", "Citation": "", "Keywords": ""}, {"Name": "SMINT: Toward Interpretable and Robust Model Sharing for Deep Neural Networks", "Authors": ["Huijun Wu", "Chen Wang", "Richard Nock", "Wei Wang", "Jie Yin", "Kai Lu", "Liming Zhu"], "Sources": "ACM Transactions on the Web (TWEB)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Sharing a pre-trained machine learning model, particularly a deep neural network via prediction APIs, is becoming a common practice on machine learning as a service (MLaaS) platforms nowadays. Although deep neural networks (DNN) have shown remarkable successes in many tasks, they are also criticized for the lack of interpretability and transparency. Interpreting a shared DNN model faces two additional challenges compared with interpreting a general model. (1) Limited training data can be disclosed to users. (2) The internal structure of the models may not be available. These two challenges impede the application of most existing interpretability approaches, such as saliency maps or influence functions, for DNN models. Case-based reasoning methods have been used for interpreting decisions; however, how to select and organize the data points under the constraints of shared DNN models is not?\u2026", "IdName": "wu2020smint", "Citation": "", "Keywords": ""}, {"Name": "Self-Supervised Feature Learning for Appliance Recognition in Non-Intrusive Load Monitoring", "Authors": ["Yinyan Liu", "Lei Bai", "Jin Ma", "Wei Wang", "Wanli Ouyang"], "Sources": "IEEE Transactions on Industrial Informatics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Nonintrusive load monitoring (NILM) can monitor the operating state and energy consumption of electric appliances in a nonintrusive manner and provides a promising approach to improving electricity usage efficiency for residential and commercial buildings. Although machine learning (ML) methods are powerful and have significantly advanced the developments of NILM, they request a sizable amount of labeled data for model training. However, getting operational data of each electrical appliance in real life is challenging, so the requirements for labeled data limit the NLIM's practicality. To tackle this challenge, a novel multilayer momentum contrast (MLMoCo) learning mechanism is proposed for self-supervised feature representation learning. With only unlabeled aggregate load data, the proposed MLMoCo contrasts the augmented versions of the same sample (\u201cpositives\u201d) with instances extracted from other?\u2026", "IdName": "liu2023self", "Citation": "", "Keywords": ""}, {"Name": "Data predictive control of nonlinear process feature dynamics through latent variable behaviours", "Authors": ["Mengjie Zhao", "Yitao Yan", "Jie Bao", "Wei Wang"], "Sources": "Computers & Chemical Engineering 163", "PublishedYears": "2022", "Doi": "", "Abstracts": "The paper presents a new big data-based approach to control of feature dynamics of continuous nonlinear chemical/industrial processes, based on the behavioural systems theory and deep learning tools. From time-series process data, the feature dynamics of a nonlinear process are extracted using an Autoencoder (AE), a type of artificial neural network. The feature dynamics are embedded in, and can be constructed from, a linear dynamic behaviour of latent variables. The latent variable dynamic space is described by a kernel representation and linearly maps the feature variable space. A Data Predictive Control (DPC) approach is developed to optimise the feature variables by controlling the latent variable dynamics using a system behaviour framework. Behaviour-based dissipativity conditions are adopted to deal with errors that arise in the latent and feature variable spaces during neural network training. A?\u2026", "IdName": "zhao2022data", "Citation": "", "Keywords": ""}, {"Name": "Efficient regular expression matching based on positional inverted index", "Authors": ["Tao Qiu", "Xiaochun Yang", "Bin Wang", "Wei Wang"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2020", "Doi": "", "Abstracts": "We study the efficient regular expression (regex) matching problem. Existing algorithms are the scanning-based algorithms which typically use an equivalent automaton compiled from the regex query to verify a document. Although some works propose various strategies to quickly jump to  candidate locations  in a document where a query result may appear, they still need to utilize the scanning-based method to verify these candidate locations. These methods become inefficient when there are still many candidate locations needed to be verified. In this article, we propose a novel approach to efficiently compute all matching positions for a regex query purely based on a positional   -gram inverted index. We propose a gram-driven NFA to represent the language of a regex and show all regex matching locations can be obtained by finding positions on   -grams of GNFA that satisfy certain positional constraints. Then?\u2026", "IdName": "qiu2020efficient", "Citation": "", "Keywords": ""}, {"Name": "Unbiased quasi-hyperbolic nesterov-gradient momentum-based optimizers for accelerating convergence", "Authors": ["Weiwei Cheng", "Xiaochun Yang", "Bin Wang", "Wei Wang"], "Sources": "World Wide Web", "PublishedYears": "2023", "Doi": "", "Abstracts": "In the training process of deep learning models, one of the important steps is to choose an appropriate optimizer that directly determines the final performance of the model. Choosing the appropriate direction and step size (i.e. learning rate) of parameter update are decisive factors for optimizers. Previous gradient descent optimizers could be oscillated and fail to converge to a minimum point because they are only sensitive to the current gradient. Momentum-Based Optimizers (MBOs) have been widely adopted recently since they can relieve oscillation to accelerate convergence by using the exponentially decaying average of gradients to fine-tune the direction. However, we find that most of the existing MBOs are biased and inconsistent with the local fastest descent direction resulting in a high number of iterations. To accelerate convergence, we propose an Unbiased strategy to adjust the descent direction of a?\u2026", "IdName": "cheng2023unbiased", "Citation": "", "Keywords": ""}, {"Name": "Graph Self-supervised Learning with Augmentation-aware Contrastive Learning", "Authors": ["Dong Chen", "Xiang Zhao", "Wei Wang", "Zhen Tan", "Weidong Xiao"], "Sources": "Proceedings of the ACM Web Conference 2023", "PublishedYears": "2023", "Doi": "", "Abstracts": " Graph self-supervised learning aims to mine useful information from unlabeled graph data, and has been successfully applied to pre-train graph representations. Many existing approaches use contrastive learning to learn powerful embeddings by learning contrastively from two augmented graph views. However, none of these graph contrastive methods fully exploits the diversity of different augmentations, and hence is prone to overfitting and limited generalization ability of learned representations. In this paper, we propose a novel Graph Self-supervised Learning method with Augmentation-aware Contrastive Learning. Our method is based on the finding that the pre-trained model after adding augmentation diversity can achieve better generalization ability. To make full use of the information from the diverse augmentation method, this paper constructs new augmentation-aware prediction task which?\u2026", "IdName": "chen2023graph", "Citation": "", "Keywords": ""}, {"Name": "Expanding Reverse Nearest Neighbors", "Authors": ["Wentao Li", "Maolin Cai", "Min Gao", "Dong Wen", "Lu Qin", "Wei Wang"], "Sources": "Proceedings of the VLDB Endowment", "PublishedYears": "2023", "Doi": "", "Abstracts": "In a graph the reverse nearest neighbors RNN of vertex f refer to the set of vertices that consider f as their nearest neighbor When f represents a facility like a subway station its RNN comprises potential users who prefer the nearest facility In practice there may be underutilized facilities with small RNN sizes and relocating these facilities to expand their service can be costly or infeasible A more cost effective approach involves selectively upgrading some edges e g reducing their weights to expand the RNN sizes of underutilized facilities This motivates our research on the Expanding Reverse Nearest Neighbors ERNN problem which aims to maximize the RNN size of a target facility by upgrading a limited number of edges Solving the ERNN problem allows underutilized facilities to serve more users and alleviate the burden on other facilities Despite numerous potential applications ERNN is hard to solve It can be proven to be NP hard and APX hard and it exhibits non monotonic and non submodular properties To overcome these challenges we propose novel greedy algorithms that improve efficiency by minimizing the number of edges that need to be processed and the cost of processing each edge Experimental results demonstrate that the proposed algorithms achieve orders of magnitude speedup compared to the standard greedy algorithm while greatly expanding the RNN", "IdName": "liexpanding", "Citation": "", "Keywords": ""}, {"Name": "CoSaR: Combating Label Noise Using Collaborative Sample Selection and Adversarial Regularization", "Authors": ["Xiaobo Zhang", "Yutao Liu", "Hao Wang", "Wei Wang", "Panpan Ni", "Ji Zhang"], "Sources": "Proceedings of the 32nd ACM International Conference on Information and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Learning with noisy labels is nontrivial for deep learning models. Sample selection is a widely investigated research topic for handling noisy labels. However, most existing methods face challenges such as imprecise selection, a lack of global selection capabilities, and the need for tedious hyperparameter tuning. In this paper, we propose CoSaR (Collaborative Selection and adversarial Regularization ), a twin-networks based model that performs globally adaptive sample selection to tackle label noise. Specifically, the collaborative selection estimates the average distribution distances between predictions and generation labels through the collaboration of two networks to address the bias of the average distribution distances and the manual tuning of hyperparameters. Adversarial regularization is integrated into CoSaR to restrict the network's tendency to fit and memorize noisy labels, thereby enhancing its?\u2026", "IdName": "zhang2023cosar", "Citation": "", "Keywords": ""}, {"Name": "Cardinality Estimation of Subgraph Search Queries with Direction Learner", "Authors": ["Wenzhe Hou", "Xiang Zhao", "Wei Wang"], "Sources": "International Conference on Advanced Data Mining and Applications", "PublishedYears": "2023", "Doi": "", "Abstracts": "In recent years, graph data has been widely used in various fields, which has made graph data management a hot topic of research. Subgraph searching is a crucial operation for graph data management, but its NP-complete nature makes exact matching algorithms time-consuming. To address this problem, new methods have begun to employ deep learning techniques to produce approximate results in less time. However, the distinctiveness of representations of different type of nodes are still limited, and edge information are not well used. To address these limitations, a novel graph neural network architecture, Directional Embedding Network (), is proposed for cardinality estimation of subgraph search queries. It effectively captures node relationships to distinguish different nodes through direction discrepancy, and accurately represents edges with learnable structural information. Experimental results?\u2026", "IdName": "hou2023cardinality", "Citation": "", "Keywords": ""}, {"Name": "Weighted Sampling for Masked Language Modeling", "Authors": ["Linhan Zhang", "Qian Chen", "Wen Wang", "Chong Deng", "Xin Cao", "Kongzhang Hao", "Yuxin Jiang", "Wei Wang"], "Sources": "ICASSP 2023-2023 IEEE International Conference on Acoustics", "PublishedYears": "2023", "Doi": "", "Abstracts": "Masked Language Modeling (MLM) is widely used to pretrain language models. The standard random masking strategy in MLM causes the pre-trained language models (PLMs) to be biased towards high-frequency tokens. Representation learning of rare tokens is poor and PLMs have limited performance on downstream tasks. To alleviate this frequency bias issue, we propose two simple and effective Weighted Sampling strategies for masking tokens based on token frequency and training loss. We apply these two strategies to BERT and obtain Weighted-Sampled BERT (WSBERT). Experiments on the Semantic Textual Similarity benchmark (STS) show that WSBERT significantly improves sentence embeddings over BERT. Combining WSBERT with calibration methods and prompt learning further improves sentence embeddings. We also investigate fine-tuning WSBERT on the GLUE benchmark and show that?\u2026", "IdName": "zhang2023weighted", "Citation": "", "Keywords": ""}, {"Name": "Tao: A Learning Framework for Adaptive Nearest Neighbor Search using Static Features Only", "Authors": ["Kaixiang Yang", "Hongya Wang", "Bo Xu", "Wei Wang", "Yingyuan Xiao", "Ming Du", "Junfeng Zhou"], "Sources": "arXiv preprint arXiv:2110.00696", "PublishedYears": "2021", "Doi": "", "Abstracts": "Approximate nearest neighbor (ANN) search is a fundamental problem in areas such as data management,information retrieval and machine learning. Recently, Li et al. proposed a learned approach named AdaptNN to support adaptive ANN query processing. In the middle of query execution, AdaptNN collects a number of runtime features and predicts termination condition for each individual query, by which better end-to-end latency is attained. Despite its efficiency, using runtime features complicates the learning process and leads to performance degradation. Radically different from AdaptNN, we argue that it is promising to predict termination condition before query exetution. Particularly, we developed Tao, a general learning framework for Terminating ANN queries Adaptively using Only static features. Upon the arrival of a query, Tao first maps the query to a local intrinsic dimension (LID) number, and then predicts the termination condition using LID instead of runtime features. By decoupling prediction procedure from query execution, Tao eliminates the laborious feature selection process involved in AdaptNN. Besides, two design principles are formulated to guide the application of Tao and improve the explainability of the prediction model. We integrate two state-of-the-art indexing approaches, i.e., IMI and HNSW, into Tao, and evaluate the performance over several million to billion-scale datasets. Experimental results show that, in addition to its simplicity and generality , Tao achieves up to 2.69x speedup even compared to its counterpart, at the same high accuracy targets.", "IdName": "yang2021tao", "Citation": "", "Keywords": ""}, {"Name": "FGNET-RH: Fine-Grained Named Entity Typing via Refinement in Hyperbolic Space", "Authors": ["Muhammad Asif Ali", "Yifang Sun", "Bing Li", "Wei Wang"], "Sources": "arXiv preprint arXiv:2101.11212", "PublishedYears": "2021", "Doi": "", "Abstracts": "Fine-Grained Named Entity Typing (FG-NET) aims at classifying the entity mentions into a wide range of entity types (usually hundreds) depending upon the context. While distant supervision is the most common way to acquire supervised training data, it brings in label noise, as it assigns type labels to the entity mentions irrespective of mentions context. In attempts to deal with the label noise, leading research on the FG-NET assumes that the fine-grained entity typing data possesses a euclidean nature, which restraints the ability of the existing models in combating the label noise. Given the fact that the fine-grained type hierarchy exhibits a hierarchical structure, it makes hyperbolic space a natural choice to model the FG-NET data. In this research, we propose FGNET-RH, a novel framework that benefits from the hyperbolic geometry in combination with the graph structures to perform entity typing in a performance-enhanced fashion. FGNET-RH initially uses LSTM networks to encode the mention in relation with its context, later it forms a graph to distill/refine the mention encodings in the hyperbolic space. Finally, the refined mention encoding is used for entity typing. Experimentation using different benchmark datasets shows that FGNET-RH improves the performance on FG-NET by up to 3.5-% in terms of strict accuracy.", "IdName": "ali2021fgnet", "Citation": "", "Keywords": ""}, {"Name": "Regularization Matters: A Nonparametric Perspective on Overparametrized Neural Network", "Authors": ["Tianyang Hu*", "Wenjia Wang*", "Cong Lin", "Guang Cheng", "(*equal contributions)"], "Sources": "the 24th International Conference on Artificial Intelligence and Statistics", "PublishedYears": "2021", "Doi": "", "Abstracts": "Overparametrized neural networks trained by gradient descent (GD) can provably overfit any training data. However, the generalization guarantee may not hold for noisy data. From a nonparametric perspective, this paper studies how well overparametrized neural networks can recover the true target function in the presence of random noises. We establish a lower bound on the L2 estimation error with respect to the GD iteration, which is away from zero without a delicate choice of early stopping. In turn, through a comprehensive analysis of L2-regularized GD trajectories, we prove that for overparametrized one-hidden-layer ReLU neural network with the L2 regularization:(1) the output is close to that of the kernel ridge regression with the corresponding neural tangent kernel;(2) minimax optimal rate of the L2 estimation error is achieved. Numerical experiments confirm our theory and further demonstrate that the L2 regularization approach improves the training robustness and works for a wider range of neural networks.", "IdName": "hu2021regularization", "Citation": "", "Keywords": ""}, {"Name": "Gaussian process regression: Optimality, robustness, and relationship with kernel ridge regression", "Authors": ["Wenjia Wang", "Bing-Yi Jing"], "Sources": "Journal of Machine Learning Research", "PublishedYears": "2022", "Doi": "", "Abstracts": "Gaussian process regression is widely used in many fields, for example, machine learning, reinforcement learning and uncertainty quantification. One key component of Gaussian process regression is the unknown correlation function, which needs to be specified. In this paper, we investigate what would happen if the correlation function is misspecified. We derive upper and lower error bounds for Gaussian process regression with possibly misspecified correlation functions. We find that when the sampling scheme is quasi-uniform, the optimal convergence rate can be attained even if the smoothness of the imposed correlation function exceeds that of the true correlation function. We also obtain convergence rates of kernel ridge regression with misspecified kernel function, where the underlying truth is a deterministic function. Our study reveals a close connection between the convergence rates of Gaussian process regression and kernel ridge regression, which is aligned with the relationship between sample paths of Gaussian process and the corresponding reproducing kernel Hilbert space. This work establishes a bridge between Bayesian learning based on Gaussian process and frequentist kernel methods with reproducing kernel Hilbert space.", "IdName": "wang2022gaussian", "Citation": "", "Keywords": ""}, {"Name": "On the inference of applying Gaussian process modeling to a deterministic function", "Authors": ["Wenjia Wang"], "Sources": "Electronic Journal of Statistics", "PublishedYears": "2021", "Doi": "", "Abstracts": " Gaussian process modeling is a standard tool for building emulators for computer experiments, which are usually used to study deterministic functions, for example, a solution to a given system of partial differential equations. This work investigates applying Gaussian process modeling to a deterministic function from prediction and uncertainty quantification perspectives, where the Gaussian process model is misspecified. Specifically, we consider the case where the underlying function is fixed and from a reproducing kernel Hilbert space generated by some kernel function, and the same kernel function is used in the Gaussian process modeling as the correlation function for prediction and uncertainty quantification. While upper bounds and the optimal convergence rate of prediction in the Gaussian process modeling have been extensively studied in the literature, a comprehensive exploration of convergence rates?\u2026", "IdName": "wang2021inference", "Citation": "", "Keywords": ""}, {"Name": "Your contrastive learning is secretly doing stochastic neighbor embedding", "Authors": ["Tianyang Hu", "Zhili Liu", "Fengwei Zhou", "Wenjia Wang", "Weiran Huang"], "Sources": "arXiv preprint arXiv:2205.14814", "PublishedYears": "2022", "Doi": "", "Abstracts": "Contrastive learning, especially self-supervised contrastive learning (SSCL), has achieved great success in extracting powerful features from unlabeled data. In this work, we contribute to the theoretical understanding of SSCL and uncover its connection to the classic data visualization method, stochastic neighbor embedding (SNE), whose goal is to preserve pairwise distances. From the perspective of preserving neighboring information, SSCL can be viewed as a special case of SNE with the input space pairwise similarities specified by data augmentation. The established correspondence facilitates deeper theoretical understanding of learned features of SSCL, as well as methodological guidelines for practical improvement. Specifically, through the lens of SNE, we provide novel analysis on domain-agnostic augmentations, implicit bias and robustness of learned features. To illustrate the practical advantage, we demonstrate that the modifications from SNE to -SNE can also be adopted in the SSCL setting, achieving significant improvement in both in-distribution and out-of-distribution generalization.", "IdName": "hu2022your", "Citation": "", "Keywords": ""}, {"Name": "Understanding Square Loss in Training Overparametrized Neural Network Classifiers", "Authors": ["Tianyang Hu*", "Jun Wang*", "Wenjia Wang*", "Zhenguo Li", "(*equal contributions)"], "Sources": "Neural Information Processing Systems 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Deep learning has achieved many breakthroughs in modern classification tasks. Numerous architectures have been proposed for different data structures but when it comes to the loss function, the cross-entropy loss is the predominant choice. Recently, several alternative losses have seen revived interests for deep classifiers. In particular, empirical evidence seems to promote square loss but a theoretical justification is still lacking. In this work, we contribute to the theoretical understanding of square loss in classification by systematically investigating how it performs for overparametrized neural networks in the neural tangent kernel (NTK) regime. Interesting properties regarding the generalization error, robustness, and calibration error are revealed. We consider two cases, according to whether classes are separable or not. In the general non-separable case, fast convergence rate is established for both misclassification rate and calibration error. When classes are separable, the misclassification rate improves to be exponentially fast. Further, the resulting margin is proven to be lower bounded away from zero, providing theoretical guarantees for robustness. We expect our findings to hold beyond the NTK regime and translate to practical settings. To this end, we conduct extensive empirical studies on practical neural networks, demonstrating the effectiveness of square loss in both synthetic low-dimensional data and real image data. Comparing to cross-entropy, square loss has comparable generalization error but noticeable advantages in robustness and model calibration.", "IdName": "hu2021understanding", "Citation": "", "Keywords": ""}, {"Name": "Neural network Gaussian process considering input uncertainty for composite structure assembly", "Authors": ["Cheolhei Lee", "Jianguo Wu", "Wenjia Wang", "Xiaowei Yue"], "Sources": "IEEE/ASME Transactions on Mechatronics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Developing machine-learning-enabled smart manufacturing is promising for a composite structure assembly process. To improve production quality and efficiency of the assembly process, accurate predictive analysis on dimensional deviations and residual stress of the composite structures is required. The novel composite structure assembly involves two challenges: 1) the highly nonlinear and anisotropic properties of composite materials; and 2) inevitable uncertainty in the assembly process. To overcome those problems, in this article, we propose a neural network Gaussian process model considering input uncertainty for composite structure assembly. Deep architecture of our model allows us to approximate a complex process better, and consideration of input uncertainty enables robust modeling with complete incorporation of the process uncertainty. Based on simulation and case study, the neural network?\u2026", "IdName": "lee2020neural", "Citation": "", "Keywords": ""}, {"Name": "Differentiable and scalable generative adversarial models for data imputation", "Authors": ["Yangyang Wu", "Jun Wang", "Xiaoye Miao", "Wenjia Wang", "Jianwei Yin"], "Sources": "IEEE Transactions on Knowledge and Data Engineering", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data imputation has been extensively explored to solve the missing data problem. The dramatically increasing volume of incomplete data makes the imputation models computationally infeasible in many real-life applications. In this paper, we propose an effective scalable imputation system named    to significantly speed up the training of the differentiable generative adversarial imputation models under accuracy-guarantees for large-scale incomplete data.    consists of two modules,  differentiable imputation modeling  (DIM) and  sample size estimation  (SSE). DIM leverages a new  masking Sinkhorn  divergence function to make an arbitrary generative adversarial imputation model differentiable, while for such a differentiable imputation model, SSE can estimate an appropriate sample size to ensure the user-specified imputation accuracy of the final model. Moreover,    can also accelerate the autoencoder?\u2026", "IdName": "wu2023differentiable", "Citation": "", "Keywords": ""}, {"Name": "Random smoothing regularization in kernel gradient descent learning", "Authors": ["Liang Ding", "Tianyang Hu", "Jiahang Jiang", "Donghao Li", "Wenjia Wang", "Yuan Yao"], "Sources": "arXiv preprint arXiv:2305.03531", "PublishedYears": "2023", "Doi": "", "Abstracts": "Random smoothing data augmentation is a unique form of regularization that can prevent overfitting by introducing noise to the input data, encouraging the model to learn more generalized features. Despite its success in various applications, there has been a lack of systematic study on the regularization ability of random smoothing. In this paper, we aim to bridge this gap by presenting a framework for random smoothing regularization that can adaptively and effectively learn a wide range of ground truth functions belonging to the classical Sobolev spaces. Specifically, we investigate two underlying function spaces: the Sobolev space of low intrinsic dimension, which includes the Sobolev space in -dimensional Euclidean space or low-dimensional sub-manifolds as special cases, and the mixed smooth Sobolev space with a tensor structure. By using random smoothing regularization as novel convolution-based smoothing kernels, we can attain optimal convergence rates in these cases using a kernel gradient descent algorithm, either with early stopping or weight decay. It is noteworthy that our estimator can adapt to the structural assumptions of the underlying data and avoid the curse of dimensionality. This is achieved through various choices of injected noise distributions such as Gaussian, Laplace, or general polynomial noises, allowing for broad adaptation to the aforementioned structural assumptions of the underlying data. The convergence rate depends only on the effective dimension, which may be significantly smaller than the actual data dimension. We conduct numerical experiments on simulated data to validate our theoretical results.", "IdName": "ding2023random", "Citation": "", "Keywords": ""}, {"Name": "Deciphering the projection head: Representation evaluation self-supervised learning", "Authors": ["Jiajun Ma", "Tianyang Hu", "Wenjia Wang"], "Sources": "arXiv preprint arXiv:2301.12189", "PublishedYears": "2023", "Doi": "", "Abstracts": "Self-supervised learning (SSL) aims to learn intrinsic features without labels. Despite the diverse architectures of SSL methods, the projection head always plays an important role in improving the performance of the downstream task. In this work, we systematically investigate the role of the projection head in SSL. Specifically, the projection head targets the uniformity part of SSL, which pushes the dissimilar samples away from each other, thus enabling the encoder to focus on extracting semantic features. Based on this understanding, we propose a Representation Evaluation Design (RED) in SSL models in which a shortcut connection between the representation and the projection vectors is built. Extensive experiments with different architectures, including SimCLR, MoCo-V2, and SimSiam, on various datasets, demonstrate that the representation evaluation design can consistently improve the baseline models in the downstream tasks. The learned representation from the RED-SSL models shows superior robustness to unseen augmentations and out-of-distribution data.", "IdName": "ma2023deciphering", "Citation": "", "Keywords": ""}, {"Name": "Eigenvector-based sparse canonical correlation analysis: Fast computation for estimation of multiple canonical vectors", "Authors": ["Wenjia Wang", "Yi-Hui Zhou"], "Sources": "Journal of Multivariate Analysis 185", "PublishedYears": "2021", "Doi": "", "Abstracts": "Classical canonical correlation analysis (CCA) requires matrices to be low dimensional, i.e. the number of features cannot exceed the sample size. Recent developments in CCA have mainly focused on the high-dimensional setting, where the number of features in both matrices under analysis greatly exceeds the sample size. These approaches impose penalties in the optimization problems that are needed to be solve iteratively, and estimate multiple canonical vectors sequentially. In this work, we provide an explicit link between sparse multiple regression with sparse canonical correlation analysis, and an efficient algorithm that can estimate multiple canonical pairs simultaneously rather than sequentially. Furthermore, the algorithm naturally allows parallel computing. These properties make the algorithm much efficient. We provide theoretical results on the consistency of canonical pairs. The algorithm and?\u2026", "IdName": "wang2021eigenvector", "Citation": "", "Keywords": ""}, {"Name": "Complexity matters: Rethinking the latent space for generative modeling", "Authors": ["Tianyang Hu", "Fei Chen", "Haonan Wang", "Jiawei Li", "Wenjia Wang", "Jiacheng Sun", "Zhenguo Li"], "Sources": "Advances in Neural Information Processing Systems 36", "PublishedYears": "2024", "Doi": "", "Abstracts": "In generative modeling, numerous successful approaches leverage a low-dimensional latent space, eg, Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel\" distance\" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propose a two-stage training strategy called Decoupled Autoencoder (DAE), where the encoder is only updated in the first stage with an auxiliary decoder and then frozen in the second stage while the actual decoder is being trained. DAE can improve the latent distribution and as a result, improve the generative performance. Our theoretical analyses are corroborated by comprehensive experiments on various models such as VQGAN and Diffusion Transformer, where our modifications yield significant improvements in sample quality with decreased model complexity.", "IdName": "hu2024complexity", "Citation": "", "Keywords": ""}, {"Name": "Elucidating the design space of classifier-guided diffusion generation", "Authors": ["Jiajun Ma", "Tianyang Hu", "Wenjia Wang", "Jiacheng Sun"], "Sources": "arXiv preprint arXiv:2310.11311", "PublishedYears": "2023", "Doi": "", "Abstracts": "Guidance in conditional diffusion generation is of great importance for sample quality and controllability. However, existing guidance schemes are to be desired. On one hand, mainstream methods such as classifier guidance and classifier-free guidance both require extra training with labeled data, which is time-consuming and unable to adapt to new conditions. On the other hand, training-free methods such as universal guidance, though more flexible, have yet to demonstrate comparable performance. In this work, through a comprehensive investigation into the design space, we show that it is possible to achieve significant performance improvements over existing guidance schemes by leveraging off-the-shelf classifiers in a training-free fashion, enjoying the best of both worlds. Employing calibration as a general guideline, we propose several pre-conditioning techniques to better exploit pretrained off-the-shelf classifiers for guiding diffusion generation. Extensive experiments on ImageNet validate our proposed method, showing that state-of-the-art diffusion models (DDPM, EDM, DiT) can be further improved (up to 20%) using off-the-shelf classifiers with barely any extra computational cost. With the proliferation of publicly available pretrained classifiers, our proposed approach has great potential and can be readily scaled up to text-to-image generation tasks. The code is available at https://github.com/AlexMaOLS/EluCD/tree/main.", "IdName": "ma2023elucidating", "Citation": "", "Keywords": ""}, {"Name": "Smooth Nested Simulation: Bridging Cubic and Square Root Convergence Rates in High Dimensions", "Authors": ["Wenjia Wang*", "Yanyuan Wang*", "Xiaowei Zhang*", "(*equal contributions)"], "Sources": "arXiv preprint arXiv:2201.02958", "PublishedYears": "2022", "Doi": "", "Abstracts": "Nested simulation concerns estimating functionals of a conditional expectation via simulation. In this paper, we propose a new method based on kernel ridge regression to exploit the smoothness of the conditional expectation as a function of the multidimensional conditioning variable. Asymptotic analysis shows that the proposed method can effectively alleviate the curse of dimensionality on the convergence rate as the simulation budget increases, provided that the conditional expectation is sufficiently smooth. The smoothness bridges the gap between the cubic root convergence rate (that is, the optimal rate for the standard nested simulation) and the square root convergence rate (that is, the canonical rate for the standard Monte Carlo simulation). We demonstrate the performance of the proposed method via numerical examples from portfolio risk management and input uncertainty quantification.This paper was?\u2026", "IdName": "wang2024smooth", "Citation": "", "Keywords": ""}, {"Name": "Functional-Input Gaussian Processes with Applications to Inverse Scattering Problems", "Authors": ["Chih-Li Sung*", "Wenjia Wang*", "Fioralba Cakoni", "Isaac Harris", "Ying Hung", "(*equal contributions)"], "Sources": "arXiv preprint arXiv:2201.01682", "PublishedYears": "2022", "Doi": "", "Abstracts": "Surrogate modeling based on Gaussian processes (GPs) has received increasing attention in the analysis of complex problems in science and engineering. Despite extensive studies on GP modeling, the developments for functional inputs are scarce. Motivated by an inverse scattering problem in which functional inputs representing the support and material properties of the scatterer are involved in the partial differential equations, a new class of kernel functions for functional inputs is introduced for GPs. Based on the proposed GP models, the asymptotic convergence properties of the resulting mean squared prediction errors are derived and the finite sample performance is demonstrated by numerical examples. In the application to inverse scattering, a surrogate model is constructed with functional inputs, which is crucial to recover the reflective index of an inhomogeneous isotropic scattering region of interest for a given far-field pattern.", "IdName": "sung2022functional", "Citation": "", "Keywords": ""}, {"Name": "Counterclr: Counterfactual contrastive learning with non-random missing data in recommendation", "Authors": ["Jun Wang", "Haoxuan Li", "Chi Zhang", "Dongxu Liang", "Enyun Yu", "Wenwu Ou", "Wenjia Wang"], "Sources": "2023 IEEE International Conference on Data Mining (ICDM)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recommender systems are designed to learn user preferences from observed feedback and comprise many fundamental tasks, such as rating prediction and post-click conversion rate (pCVR) prediction. However, the observed feedback usually suffer from two issues: selection bias and data sparsity, where biased and insufficient feedback seriously degrade the performance of recommender systems in terms of accuracy and ranking. Existing solutions for handling the issues, such as data imputation and inverse propensity score, are highly susceptible to additional trained imputation or propensity models. In this work, we propose a novel counterfactual contrastive learning framework for recommendation, named CounterCLR, to tackle the problem of non-random missing data by exploiting the advances in contrast learning. Specifically, the proposed CounterCLR employs a deep representation network, called?\u2026", "IdName": "wang2023counterclr", "Citation": "", "Keywords": ""}, {"Name": "High-dimensional non-parametric density estimation in mixed smooth sobolev spaces", "Authors": ["Liang Ding", "Lu Zou", "Wenjia Wang", "Shahin Shahrampour", "Rui Tuo"], "Sources": "arXiv preprint arXiv:2006.03696", "PublishedYears": "2020", "Doi": "", "Abstracts": "Density estimation plays a key role in many tasks in machine learning, statistical inference, and visualization. The main bottleneck in high-dimensional density estimation is the prohibitive computational cost and the slow convergence rate. In this paper, we propose novel estimators for high-dimensional non-parametric density estimation called the adaptive hyperbolic cross density estimators, which enjoys nice convergence properties in the mixed smooth Sobolev spaces. As modifications of the usual Sobolev spaces, the mixed smooth Sobolev spaces are more suitable for describing high-dimensional density functions in some applications. We prove that, unlike other existing approaches, the proposed estimator does not suffer the curse of dimensionality under Integral Probability Metric, including Holder Integral Probability Metric, where Total Variation Metric and Wasserstein Distance are special cases. Applications of the proposed estimators to generative adversarial networks (GANs) and goodness of fit test for high-dimensional data are discussed to illustrate the proposed estimator's good performance in high-dimensional problems. Numerical experiments are conducted and illustrate the efficiency of our proposed method.", "IdName": "ding2020high", "Citation": "", "Keywords": ""}, {"Name": "Reduced Rank Multivariate Kernel Ridge Regression", "Authors": ["Wenjia Wang", "Yi-Hui Zhou"], "Sources": "arXiv preprint arXiv:2005.01559", "PublishedYears": "2020", "Doi": "", "Abstracts": "In the multivariate regression, also referred to as multi-task learning in machine learning, the goal is to recover a vector-valued function based on noisy observations. The vector-valued function is often assumed to be of low rank. Although the multivariate linear regression is extensively studied in the literature, a theoretical study on the multivariate nonlinear regression is lacking. In this paper, we study reduced rank multivariate kernel ridge regression, proposed by \\cite{mukherjee2011reduced}. We prove the consistency of the function predictor and provide the convergence rate. An algorithm based on nuclear norm relaxation is proposed. A few numerical examples are presented to show the smaller mean squared prediction error comparing with the elementwise univariate kernel ridge regression.", "IdName": "wang2020reduced", "Citation": "", "Keywords": ""}, {"Name": "Uncertainty Quantification for Bayesian Optimization", "Authors": ["Rui Tuo*", "Wenjia Wang*", "(*equal contributions)"], "Sources": "he 25th International Conference on Artificial Intelligence and Statistics", "PublishedYears": "2020", "Doi": "", "Abstracts": "Bayesian optimization is a class of global optimization techniques. In Bayesian optimization, the underlying objective function is modeled as a realization of a Gaussian process. Although the Gaussian process assumption implies a random distribution of the Bayesian optimization outputs, quantification of this uncertainty is rarely studied in the literature. In this work, we propose a novel approach to assess the output uncertainty of Bayesian optimization algorithms, which proceeds by constructing confidence regions of the maximum point (or value) of the objective function. These regions can be computed efficiently, and their confidence levels are guaranteed by the uniform error bounds for sequential Gaussian process regression newly developed in the present work. Our theory provides a unified uncertainty quantification framework for all existing sequential sampling policies and stopping criteria.", "IdName": "tuo2022uncertainty", "Citation": "", "Keywords": ""}, {"Name": "Improved Convergence Rate of Nested Simulation with LSE on Sieve", "Authors": ["Ruoxue Liu", "Liang Ding", "Wenjia Wang", "Lu Zou"], "Sources": "arXiv preprint arXiv:2310.11756", "PublishedYears": "2023", "Doi": "", "Abstracts": "Nested simulation encompasses the estimation of functionals linked to conditional expectations through simulation techniques. In this paper, we treat conditional expectation as a function of the multidimensional conditioning variable and provide asymptotic analyses of general Least Squared Estimators on sieve, without imposing specific assumptions on the function's form. Our study explores scenarios in which the convergence rate surpasses that of the standard Monte Carlo method and the one recently proposed based on kernel ridge regression. We also delve into the conditions that allow for achieving the best possible square root convergence rate among all methods. Numerical experiments are conducted to support our statements.", "IdName": "liu2023improved", "Citation": "", "Keywords": ""}, {"Name": "A Double Penalty Model for Ensemble Learning", "Authors": ["Wenjia Wang", "Yi-Hui Zhou"], "Sources": "Mathematics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Modern statistical learning techniques often include learning ensembles, for which the combination of multiple separate prediction procedures (ensemble components) can improve prediction accuracy. Although ensemble approaches are widely used, work remains to improve our understanding of the theoretical underpinnings of aspects such as identifiability and relative convergence rates of the ensemble components. By considering ensemble learning for two learning ensemble components as a double penalty model, we provide a framework to better understand the relative convergence and identifiability of the two components. In addition, with appropriate conditions the framework provides convergence guarantees for a form of residual stacking when iterating between the two components as a cyclic coordinate ascent procedure. We conduct numerical experiments on three synthetic simulations and two real world datasets to illustrate the performance of our approach, and justify our theory.", "IdName": "wang2022double", "Citation": "", "Keywords": ""}, {"Name": "AutoML: A Survey of the State-of-the-Art", "Authors": ["Xin He", "Kaiyong Zhao", "Xiaowen Chu"], "Sources": "Knowledge-Based Systems 212", "PublishedYears": "2021", "Doi": "", "Abstracts": "Deep learning (DL) techniques have obtained remarkable achievements on various tasks, such as image recognition, object detection, and language modeling. However, building a high-quality DL system for a specific task highly relies on human expertise, hindering its wide application. Meanwhile, automated machine learning (AutoML) is a promising solution for building a DL system without human assistance and is being extensively studied. This paper presents a comprehensive and up-to-date review of the state-of-the-art (SOTA) in AutoML. According to the DL pipeline, we introduce AutoML methods \u2013 covering data preparation, feature engineering, hyperparameter optimization, and neural architecture search (NAS) \u2013 with a particular focus on NAS, as it is currently a hot sub-topic of AutoML. We summarize the representative NAS algorithms\u2019 performance on the CIFAR-10 and ImageNet datasets and further?\u2026", "IdName": "he2021automl", "Citation": "", "Keywords": ""}, {"Name": "FMore: An Incentive Scheme of Multi-dimensional Auction for Federated Learning in MEC", "Authors": ["Rongfei Zeng", "Shixun Zhang", "Jiaqi Wang", "Xiaowen Chu"], "Sources": "IEEE ICDCS 2020", "PublishedYears": "2020", "Doi": "", "Abstracts": "Promising federated learning coupled with Mobile Edge Computing (MEC) is considered as one of the most promising solutions to the AI-driven service provision. Plenty of studies focus on federated learning from the performance and security aspects, but they neglect the incentive mechanism. In MEC, edge nodes would not like to voluntarily participate in learning, and they differ in the provision of multi-dimensional resources, both of which might deteriorate the performance of federated learning. Also, lightweight schemes appeal to edge nodes in MEC. These features require the incentive mechanism to be well designed for MEC. In this paper, we present an incentive mechanism FMore with multi-dimensional procurement auction of K winners. Our proposal FMore not only is lightweight and incentive compatible, but also encourages more high-quality edge nodes with low cost to participate in learning and?\u2026", "IdName": "zeng2020fmore", "Citation": "", "Keywords": ""}, {"Name": "A survey of deep learning techniques for neural machine translation", "Authors": ["Shuoheng Yang", "Yuxin Wang", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2002.07526", "PublishedYears": "2020", "Doi": "", "Abstracts": "In recent years, natural language processing (NLP) has got great development with deep learning techniques. In the sub-field of machine translation, a new approach named Neural Machine Translation (NMT) has emerged and got massive attention from both academia and industry. However, with a significant number of researches proposed in the past several years, there is little work in investigating the development process of this new technology trend. This literature survey traces back the origin and principal development timeline of NMT, investigates the important branches, categorizes different research orientations, and discusses some future research trends in this field.", "IdName": "yang2020survey", "Citation": "", "Keywords": ""}, {"Name": "Vfchain: Enabling verifiable and auditable federated learning via blockchain systems", "Authors": ["Zhe Peng", "Jianliang Xu", "Xiaowen Chu", "Shang Gao", "Yuan Yao", "Rong Gu", "Yuzhe Tang"], "Sources": "IEEE Transactions on Network Science and Engineering", "PublishedYears": "2021", "Doi": "", "Abstracts": "Advanced artificial intelligence techniques, such as federated learning, has been applied to broad areas, e.g., image classification, speech recognition, smart city, and healthcare. Despite intensive research on federated learning, existing schemes are vulnerable to attacks and can hardly meet the security requirements for real-world applications. The problem of designing a secure federated learning framework to ensure the correctness of training procedure has not been sufficiently studied and remains open. In this paper, we propose VFChain, a verifiable and auditable federated learning framework based on the blockchain system. First, to provide the verifiability, a committee is selected through the blockchain to collectively aggregate models and record verifiable proofs in the blockchain. Then, to provide the auditability, a novel authenticated data structure is proposed for blockchain to improve the search efficiency?\u2026", "IdName": "peng2021vfchain", "Citation": "", "Keywords": ""}, {"Name": "Communication-efficient distributed deep learning: A comprehensive survey", "Authors": ["Zhenheng Tang", "Shaohuai Shi", "Xiaowen Chu", "Wei Wang", "Bo Li"], "Sources": "arXiv preprint arXiv:2003.06307", "PublishedYears": "2020", "Doi": "", "Abstracts": "Distributed deep learning (DL) has become prevalent in recent years to reduce training time by leveraging multiple computing devices (e.g., GPUs/TPUs) due to larger models and datasets. However, system scalability is limited by communication becoming the performance bottleneck. Addressing this communication issue has become a prominent research topic. In this paper, we provide a comprehensive survey of the communication-efficient distributed training algorithms, focusing on both system-level and algorithmic-level optimizations. We first propose a taxonomy of data-parallel distributed training algorithms that incorporates four primary dimensions: communication synchronization, system architectures, compression techniques, and parallelism of communication and computing tasks. We then investigate state-of-the-art studies that address problems in these four dimensions. We also compare the convergence rates of different algorithms to understand their convergence speed. Additionally, we conduct extensive experiments to empirically compare the convergence performance of various mainstream distributed training algorithms. Based on our system-level communication cost analysis, theoretical and experimental convergence speed comparison, we provide readers with an understanding of which algorithms are more efficient under specific distributed environments. Our research also extrapolates potential directions for further optimizations.", "IdName": "tang2020communication", "Citation": "", "Keywords": ""}, {"Name": "A comprehensive survey of incentive mechanism for federated learning", "Authors": ["Rongfei Zeng", "Chao Zeng", "Xingwei Wang", "Bo Li", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2106.15406", "PublishedYears": "2021", "Doi": "", "Abstracts": "Federated learning utilizes various resources provided by participants to collaboratively train a global model, which potentially address the data privacy issue of machine learning. In such promising paradigm, the performance will be deteriorated without sufficient training data and other resources in the learning process. Thus, it is quite crucial to inspire more participants to contribute their valuable resources with some payments for federated learning. In this paper, we present a comprehensive survey of incentive schemes for federate learning. Specifically, we identify the incentive problem in federated learning and then provide a taxonomy for various schemes. Subsequently, we summarize the existing incentive mechanisms in terms of the main techniques, such as Stackelberg game, auction, contract theory, Shapley value, reinforcement learning, blockchain. By reviewing and comparing some impressive results, we figure out three directions for the future study.", "IdName": "zeng2021comprehensive", "Citation": "", "Keywords": ""}, {"Name": "GossipFL: A Decentralized Federated Learning Framework with Sparsified and Adaptive Communication", "Authors": ["Zhenheng Tang", "Shaohuai Shi", "Bo Li", "Xiaowen Chu"], "Sources": "IEEE Transactions on Parallel and Distributed Systems", "PublishedYears": "2023", "Doi": "", "Abstracts": "Recently, federated learning (FL) techniques have enabled multiple users to train machine learning models collaboratively without data sharing. However, existing FL algorithms suffer from the communication bottleneck due to network bandwidth pressure and/or low bandwidth utilization of the participating clients in both centralized and decentralized architectures. To deal with the communication problem while preserving the convergence performance, we introduce a communication-efficient decentralized FL framework GossipFL. In GossipFL, we 1) design a novel sparsification algorithm to enable that each client only needs to communicate with one peer with a highly sparsified model, and 2) propose a new and novel gossip matrix generation algorithm that can better utilize the bandwidth resources while preserving the convergence property. We also theoretically prove that GossipFL has convergence guarantees. We?\u2026", "IdName": "tang2022gossipfl", "Citation": "", "Keywords": ""}, {"Name": "Automated Model Design and Benchmarking of 3D Deep Learning Models for COVID-19 Detection with Chest CT Scans", "Authors": ["Xin He", "Shihao Wang", "Xiaowen Chu", "Shaohuai Shi", "Jiangping Tang", "Xin Liu", "Chenggang Yan", "Jiyong Zhang", "Guiguang Ding"], "Sources": "AAAI 2021", "PublishedYears": "2021", "Doi": "", "Abstracts": "The COVID-19 pandemic has spread globally for several months. Because its transmissibility and high pathogenicity seriously threaten people's lives, it is crucial to accurately and quickly detect COVID-19 infection. Many recent studies have shown that deep learning (DL) based solutions can help detect COVID-19 based on chest CT scans. However, most existing work focuses on 2D datasets, which may result in low quality models as the real CT scans are 3D images. Besides, the reported results span a broad spectrum on different datasets with a relatively unfair comparison. In this paper, we first use three state-of-the-art 3D models (ResNet3D101, DenseNet3D121, and MC3\\_18) to establish the baseline performance on three publicly available chest CT scan datasets. Then we propose a differentiable neural architecture search (DNAS) framework to automatically search the 3D DL models for 3D chest CT scans classification and use the Gumbel Softmax technique to improve the search efficiency. We further exploit the Class Activation Mapping (CAM) technique on our models to provide the interpretability of the results. The experimental results show that our searched models (CovidNet3D) outperform the baseline human-designed models on three datasets with tens of times smaller model size and higher accuracy. Furthermore, the results also verify that CAM can be well applied in CovidNet3D for COVID-19 datasets to provide interpretability for medical diagnosis. Code: https://github. com/HKBU-HPML/CovidNet3D.", "IdName": "he2021automated", "Citation": "", "Keywords": ""}, {"Name": "FADNet: A Fast and Accurate Network for Disparity Estimation", "Authors": ["Qiang Wang", "Shaohuai Shi", "Shizhen Zheng", "Kaiyong Zhao", "Xiaowen Chu"], "Sources": "2020 International Conference on Robotics and Automation (ICRA)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Deep neural networks (DNNs) have achieved great success in the area of computer vision. The disparity estimation problem tends to be addressed by DNNs which achieve much better prediction accuracy in stereo matching than traditional hand-crafted feature based methods. On one hand, however, the designed DNNs require significant memory and computation resources to accurately predict the disparity, especially for those 3D convolution based networks, which makes it difficult for deployment in real-time applications. On the other hand, existing computation-efficient networks lack expression capability in large-scale datasets so that they cannot make an accurate prediction in many scenarios. To this end, we propose an efficient and accurate deep network for disparity estimation named FADNet with three main features: 1) It exploits efficient 2D based correlation layers with stacked blocks to preserve fast?\u2026", "IdName": "wang2020fadnet", "Citation": "", "Keywords": ""}, {"Name": "Dissecting Mining Pools of Bitcoin Network: Measurement, Analysis and Modeling", "Authors": ["Canhui Wang", "Xiaowen Chu", "Yang Qin"], "Sources": "IEEE Transactions on Network Science and Engineering", "PublishedYears": "2022", "Doi": "", "Abstracts": "Bitcoin network is one of the most popular blockchain systems. Mining pools are the main components of the Bitcoin network that invest a large amount of computing power to maximize their expected mining payoffs, which guarantees the security of the Bitcoin network. Although many existing works about mining pools are available, the long-term evolution of mining pools, and their effects on both the Bitcoin system and end-users, remain to be investigated. To fill this gap, we trace over 2.54 hundred thousand blocks from Feb 2016 to Nov 2020 and collect over 12 million unconfirmed transactions from Mar 2018 to Nov 2020. We then conduct a broad range of analyses, including the pool evolution, labeled transactions, and labeled blocks. We make the following observations from our measured data: 1) A few mining pools control most of the peer-to-peer network's computing power. 2) The long-term computing power?\u2026", "IdName": "wang2022dissecting", "Citation": "", "Keywords": ""}, {"Name": "Demystifying tensor cores to optimize half-precision matrix multiply", "Authors": ["Da Yan", "Wei Wang", "Xiaowen Chu"], "Sources": "2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Half-precision matrix multiply has played a key role in the training of deep learning models. The newly designed Nvidia Tensor Cores offer the native instructions for half-precision small matrix multiply, based on which Half-precision General Matrix Multiply (HGEMM) routines are developed and can be accessed through high-level APIs. In this paper, we, for the first time, demystify how Tensor Cores on NVIDIA Turing architecture work in great details, including the instructions used, the registers and data layout required, as well as the throughput and latency of Tensor Core operations. We further benchmark the memory system of Turing GPUs and conduct quantitative analysis of the performance. Our analysis shows that the bandwidth of DRAM, L2 cache and shared memory is the new bottleneck for HGEMM, whose performance is previously believed to be bound by computation. Based on our newly discovered?\u2026", "IdName": "yan2020demystifying", "Citation": "", "Keywords": ""}, {"Name": "Benchmarking the performance and energy efficiency of AI accelerators for AI training", "Authors": ["Yuxin Wang", "Qiang Wang", "Shaohuai Shi", "Xin He", "Zhenheng Tang", "Kaiyong Zhao", "Xiaowen Chu"], "Sources": "2020 20th IEEE/ACM International Symposium on Cluster", "PublishedYears": "2020", "Doi": "", "Abstracts": "Deep learning has become widely used in complex AI applications. Yet, training a deep neural network (DNNs) model requires a considerable amount of calculations, long running time, and much energy. Nowadays, many-core AI accelerators (e.g., GPUs and TPUs) are designed to improve the performance of AI training. However, processors from different vendors perform dissimilarly in terms of performance and energy consumption. To investigate the differences among several popular off-the-shelf processors (i.e., Intel CPU, NVIDIA GPU, AMD GPU, and Google TPU) in training DNNs, we carry out a comprehensive empirical study on the performance and energy efficiency of these processors 1  by benchmarking a representative set of deep learning workloads, including computation-intensive operations, classical convolutional neural networks (CNNs), recurrent neural networks (LSTM), Deep Speech 2, and?\u2026", "IdName": "wang2020benchmarking", "Citation": "", "Keywords": ""}, {"Name": "GPGPU performance estimation with core and memory frequency scaling", "Authors": ["Qiang Wang", "Xiaowen Chu"], "Sources": "IEEE Transactions on Parallel and Distributed Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Contemporary graphics processing units (GPUs) support dynamic voltage and frequency scaling to balance computational performance and energy consumption. However, accurate and straightforward performance estimation for a given GPU kernel under different frequency settings is still lacking for real hardware, which is essential to determine the best frequency configuration for energy saving. In this article, we reveal a fine-grained analytical model to estimate the execution time of GPU kernels with both core and memory frequency scaling. Compared to the cycle-level simulators, which are too slow to apply on real hardware, our model only needs simple and one-off micro-benchmarks to extract a set of hardware parameters and kernel performance counters without any source code analysis. Our experimental results show that the proposed performance model can capture the kernel performance scaling?\u2026", "IdName": "wang2020gpgpu", "Citation": "", "Keywords": ""}, {"Name": "Optimizing batched winograd convolution on GPUs", "Authors": ["Da Yan", "Wei Wang", "Xiaowen Chu"], "Sources": "Proceedings of the 25th ACM SIGPLAN symposium on principles and practice of?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "In this paper, we present an optimized implementation for single-precision Winograd convolution on NVIDIA Volta and Turing GPUs. Compared with the state-of-the-art Winograd convolution in cuDNN 7.6.1, our implementation achieves up to 2.13X speedup on Volta V100 and up to 2.65X speedup on Turing RTX2070. On both Volta and Turing GPUs, our implementation achieves up to 93% of device peak. Apart from analyzing and benchmarking different high-level optimization options, we also build a SASS assembler TuringAs for Volta and Turing that enables tuning the performance at the native assembly level. The new optimization opportunities uncovered by TuringAs not only improve the Winograd convolution but can also benefit CUDA compilers and native assembly programming. We have released TuringAs as an open-source software. To the best of our knowledge, this is the first public-available?\u2026", "IdName": "yan2020optimizing", "Citation": "", "Keywords": ""}, {"Name": "Communication-efficient distributed deep learning with merged gradient sparsification on gpus", "Authors": ["Shaohuai Shi", "Qiang Wang", "Xiaowen Chu", "Bo Li", "Yang Qin", "Ruihao Liu", "Xinxiao Zhao"], "Sources": "Proc. of IEEE INFOCOM 2020", "PublishedYears": "2020", "Doi": "", "Abstracts": "Distributed synchronous stochastic gradient descent (SGD) algorithms are widely used in large-scale deep learning applications, while it is known that the communication bottleneck limits the scalability of the distributed system. Gradient sparsification is a promising technique to significantly reduce the communication traffic, while pipelining can further overlap the communications with computations. However, gradient sparsification introduces extra computation time, and pipelining requires many layer-wise communications which introduce significant communication startup overheads. Merging gradients from neighbor layers could reduce the startup overheads, but on the other hand it would increase the computation time of sparsification and the waiting time for the gradient computation. In this paper, we formulate the trade-off between communications and computations (including backward computation and?\u2026", "IdName": "shi2020communication", "Citation": "", "Keywords": ""}, {"Name": "Fedcv: a federated learning framework for diverse computer vision tasks", "Authors": ["Chaoyang He", "Alay Dilipbhai Shah", "Zhenheng Tang", "Di Fan1Adarshan Naiynar Sivashunmugam", "Keerti Bhogaraju", "Mita Shimpi", "Li Shen", "Xiaowen Chu", "Mahdi Soltanolkotabi", "Salman Avestimehr"], "Sources": "arXiv preprint arXiv:2111.11066", "PublishedYears": "2021", "Doi": "", "Abstracts": "Federated Learning (FL) is a distributed learning paradigm that can learn a global or personalized model from decentralized datasets on edge devices. However, in the computer vision domain, model performance in FL is far behind centralized training due to the lack of exploration in diverse tasks with a unified FL framework. FL has rarely been demonstrated effectively in advanced computer vision tasks such as object detection and image segmentation. To bridge the gap and facilitate the development of FL for computer vision tasks, in this work, we propose a federated learning library and benchmarking framework, named FedCV, to evaluate FL on the three most representative computer vision tasks: image classification, image segmentation, and object detection. We provide non-I.I.D. benchmarking datasets, models, and various reference FL algorithms. Our benchmark study suggests that there are multiple challenges that deserve future exploration: centralized training tricks may not be directly applied to FL; the non-I.I.D. dataset actually downgrades the model accuracy to some degree in different tasks; improving the system efficiency of federated training is challenging given the huge number of parameters and the per-client memory cost. We believe that such a library and benchmark, along with comparable evaluation settings, is necessary to make meaningful progress in FL on computer vision tasks. FedCV is publicly available: https://github.com/FedML-AI/FedCV.", "IdName": "he2021fedcv", "Citation": "", "Keywords": ""}, {"Name": "Performance Characterization and Bottleneck Analysis of Hyperledger Fabric", "Authors": ["Canhui Wang", "Xiaowen Chu"], "Sources": "BlockApp 2020", "PublishedYears": "2020", "Doi": "", "Abstracts": "Hyperledger Fabric is a popular open-source project for deploying permissioned blockchains. Many performance characteristics of the latest Hyperledger Fabric (e.g., performance characteristics of each phase, the impacts of ordering services, bottleneck and scalability) are still not well understood due to the performance complexity of distributed systems. We conducted a thorough performance evaluation on the first long term support release of Hyperledger Fabric. We studied the performance characteristics of each phase, including execute, order, and the validate phase, according to Hyperledger Fabric's new execute-order-validate architecture. We also studied the ordering services, including Solo, Kafka, and Raft. Our experimental results showed some findings as follows. 1) The execution phase exhibited a good scalability under the OR endorsement policy but not with the AND endorsement policy. 2) We were?\u2026", "IdName": "wang2020performance", "Citation": "", "Keywords": ""}, {"Name": "Virtual Homogeneity Learning: Defending against Data Heterogeneity in Federated Learning", "Authors": ["Zhenheng Tang", "Yonggang Zhang", "Shaohuai Shi", "Xin He", "Bo Han", "Xiaowen Chu"], "Sources": "The 39th International Conference on Machine Learning (ICML 2022)", "PublishedYears": "2022", "Doi": "", "Abstracts": "In federated learning (FL), model performance typically suffers from client drift induced by data heterogeneity, and mainstream works focus on correcting client drift. We propose a different approach named virtual homogeneity learning (VHL) to directly \u201crectify\u201d the data heterogeneity. In particular, VHL conducts FL with a virtual homogeneous dataset crafted to satisfy two conditions: containing no private information and being separable. The virtual dataset can be generated from pure noise shared across clients, aiming to calibrate the features from the heterogeneous clients. Theoretically, we prove that VHL can achieve provable generalization performance on the natural distribution. Empirically, we demonstrate that VHL endows FL with drastically improved convergence speed and generalization performance. VHL is the first attempt towards using a virtual dataset to address data heterogeneity, offering new and effective means to FL.", "IdName": "tang2022virtual", "Citation": "", "Keywords": ""}, {"Name": "P2B-Trace: Privacy-Preserving Blockchain-based Contact Tracing to Combat Pandemics", "Authors": ["Zhe Peng", "Cheng Xu", "Haixin Wang", "Jinbin Huang", "Jianliang Xu", "Xiaowen Chu"], "Sources": "Proceedings of the 2021 international conference on management of data", "PublishedYears": "2021", "Doi": "", "Abstracts": "The eruption of a pandemic, such as COVID-19, can cause an unprecedented global crisis. Contact tracing, as a pillar of communicable disease control in public health for decades, has shown its effectiveness on pandemic control. Despite intensive research on contact tracing, existing schemes are vulnerable to attacks and can hardly simultaneously meet the requirements of data integrity and user privacy. The design of a privacy-preserving contact tracing framework to ensure the integrity of the tracing procedure has not been sufficiently studied and remains a challenge. In this paper, we propose P2B-Trace, a privacy-preserving contact tracing initiative based on blockchain. First, we design a decentralized architecture with blockchain to record an authenticated data structure of the user's contact records, which prevents the user from intentionally modifying his local records afterward. Second, we develop a zero?\u2026", "IdName": "peng2021p2b", "Citation": "", "Keywords": ""}, {"Name": "Towards Scalable Distributed Training of Deep Learning on Public Cloud Clusters", "Authors": ["Shaohuai Shi", "Xianhao Zhou", "Shutao Song", "Xingyao Wang", "Zilin Zhu", "Xue Huang", "Xinan Jiang", "Feihu Zhou", "Zhenyu Guo", "Liqiang Xie", "Rui Lan", "Xianbin Ouyang", "Yan Zhang", "Jieqian Wei", "Jing Gong", "Weiliang Lin", "Ping Gao", "Peng Meng", "Xiaomin Xu", "Chenyang Guo", "Bo Yang", "Zhibo Chen", "Yongjian Wu", "Xiaowen Chu"], "Sources": "MLSys 2021", "PublishedYears": "2021", "Doi": "", "Abstracts": "Distributed training techniques have been widely deployed in large-scale deep models training on dense-GPU clusters. However, on public cloud clusters, due to the moderate inter-connection bandwidth between instances, traditional state-of-the-art distributed training systems cannot scale well in training large-scale models. In this paper, we propose a new computing and communication efficient top-k sparsification communication library for distributed training. To further improve the system scalability, we optimize I/O by proposing a simple yet efficient multi-level data caching mechanism and optimize the update operation by introducing a novel parallel tensor operator. Experimental results on a 16-node Tencent Cloud cluster (each node with 8 Nvidia Tesla V100 GPUs) show that our system achieves 25%-40% faster than existing state-of-the-art systems on CNNs and Transformer. We finally break the record on DAWNBench on training ResNet-50 to 93% top-5 accuracy on ImageNet.", "IdName": "shi2021towards", "Citation": "", "Keywords": ""}, {"Name": "Irs: A large naturalistic indoor robotics stereo dataset to train deep models for disparity and surface normal estimation", "Authors": ["Qiang Wang", "Shizhen Zheng", "Qingsong Yan", "Fei Deng", "Kaiyong Zhao", "Xiaowen Chu"], "Sources": "2021 IEEE International Conference on Multimedia and Expo (ICME)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Indoor robotics applications heavily rely on scene understanding and reconstruction. Compared to monocular vision, stereo vision methods are more promising to produce accurate geometrical information, such as surface normal and depth/disparity. Besides, deep learning models have shown their superior performance in stereo vision tasks. However, existing stereo datasets rarely contain high-quality surface normal and disparity ground truth, hardly satisfying the demand of training a prospective deep model. To this end, we introduce a large-scale indoor robotics stereo (IRS) dataset with over 100K stereo images and high-quality surface normal and disparity maps. Leveraging the advanced techniques of our customized rendering engine, the dataset is considerably close to the real-world scenes. Besides, we present DTN-Net, a two-stage deep model for surface normal estimation. Extensive experiments show?\u2026", "IdName": "wang2021irs", "Citation": "", "Keywords": ""}, {"Name": "A quantitative survey of communication optimizations in distributed deep learning", "Authors": ["Shaohuai Shi", "Zhenheng Tang", "Xiaowen Chu", "Chengjian Liu", "Wei Wang", "Bo Li"], "Sources": "IEEE Network", "PublishedYears": "2020", "Doi": "", "Abstracts": "Nowadays, large and complex deep learning (DL) models are increasingly trained in a distributed manner across multiple worker machines, in which extensive communications between workers pose serious scaling problems. In this article, we present a quantitative survey of communication optimization techniques for data parallel distributed DL. We first identify the major communication challenges and classify the existing solutions into three levels, namely the learning algorithm, the system architecture, and the network infrastructure. We present the state-of-the-art communication optimization techniques and conduct a comparative study of seven common lossless distributed DL methods on a 32-GPU cluster with 100Gb/s InfiniBand (IB). We show that the DL models with low model intensity (such as BERT and BERT-Large) are difficult to scale out even with the best available lossless algorithm over 100Gb/s IB?\u2026", "IdName": "shi2020quantitative", "Citation": "", "Keywords": ""}, {"Name": "Deep learning identifies leak in water pipeline system using transient frequency response", "Authors": ["Ziyuan Liao", "Hexiang Yan", "Zhenheng Tang", "Xiaowen Chu", "Tao Tao"], "Sources": "Process Safety and Environmental Protection 155", "PublishedYears": "2021", "Doi": "", "Abstracts": "Pipeline leak identification method using transient frequency response (TFR) has been researched in the past two decades. To extend this method to a more general water pipeline system with hydraulic uncertainties, this work (1) introduces deep learning (DL) into the TFR-based leak identification framework and (2) develops extended TFR equations in matrix form for DL learning set generation. In this framework, TFR equations are firstly solved in a pre-calibrated hydraulic model of the system to extract frequency response function (FRF) for the training set preparation. Then the simulated FRFs are fed to train fully linear DenseNet (FL-DenseNet) for feature recognition. Finally, the measured FRF of the system is fed to the trained FL-DenseNet to identify a leak to a pipe in the suspected leak area. A study on a hypothetical small system shows that the proposed framework has robustness against uncertainties of?\u2026", "IdName": "liao2021deep", "Citation": "", "Keywords": ""}, {"Name": "Leveraging graph neural networks for point-of-interest recommendations", "Authors": ["Jiyong Zhang", "Xin Liu", "Xiaofei Zhou", "Xiaowen Chu"], "Sources": "Neurocomputing 462", "PublishedYears": "2021", "Doi": "", "Abstracts": "Point-of-Interest (POI) recommendation, i.e., suggesting POIs that a user is likely to visit, is a key task to improve user experience in location based social networks (LBSNs). Existing models either focus on geographical influence without considering other factors such as social influence and temporal influence or rely on linear methods to combine different modeling factors, lacking a sophisticated and systematical way to learn representations for users and POIs for recommendation. To remedy these issues, in this work we propose GNN-POI, a generic POI recommendation framework that leverages Graph Neural Networks (GNNs), which demonstrate powerful modeling capacity to learn node representations from node information and topological structure to improve POI recommendation. Specifically, we construct a LBSN graph comprising of two types of nodes, i.e., user node and POI node. For a target user, her?\u2026", "IdName": "zhang2021leveraging", "Citation": "", "Keywords": ""}, {"Name": "Incentive mechanisms in federated learning and a game-theoretical approach", "Authors": ["Rongfei Zeng", "Chao Zeng", "Xingwei Wang", "Bo Li", "Xiaowen Chu"], "Sources": "IEEE Network", "PublishedYears": "2022", "Doi": "", "Abstracts": "Federated learning (FL) represents a new machine learning paradigm, utilizing various resources from participants to collaboratively train a global model without exposing the privacy of training data. The learning performance critically depends on various resources provided by participants and their active participation. Hence, it is essential to enable more participants to actively contribute their valuable resources in FL. In this article, we present a survey of incentive mechanisms for FL. We identify the incentive problem, outline its framework, and categorically discuss the state-of-the-art incentive mechanisms in Shapley value, Stackelberg game, auction, contract, and reinforcement learning. In addition, we propose three multi-dimensional game-theoretical models to study the economical behaviors of participants and demonstrate their applicability in cross-silo FL scenarios.", "IdName": "zeng2022incentive", "Citation": "", "Keywords": ""}, {"Name": "Lora-fa: Memory-efficient low-rank adaptation for large language models fine-tuning", "Authors": ["Longteng Zhang", "Lin Zhang", "Shaohuai Shi", "Xiaowen Chu", "Bo Li"], "Sources": "arXiv preprint arXiv:2308.03303", "PublishedYears": "2023", "Doi": "", "Abstracts": "The low-rank adaptation (LoRA) method can largely reduce the amount of trainable parameters for fine-tuning large language models (LLMs), however, it still requires expensive activation memory to update low-rank weights. Reducing the number of LoRA layers or using activation recomputation could harm the fine-tuning performance or increase the computational overhead. In this work, we present LoRA-FA, a memory-efficient fine-tuning method that reduces the activation memory without performance degradation and expensive recomputation. LoRA-FA chooses to freeze the projection-down weight of  and update the projection-up weight of  in each LoRA layer. It ensures the change of model weight reside in a low-rank space during LLMs fine-tuning, while eliminating the requirement to store full-rank input activations. We conduct extensive experiments across multiple model types (RoBERTa, T5, LLaMA) and model scales. Our results show that LoRA-FA can always achieve close fine-tuning accuracy across different tasks compared to full parameter fine-tuning and LoRA. Furthermore, LoRA-FA can reduce the overall memory cost by up to 1.4 compared to LoRA.", "IdName": "zhang2023lora", "Citation": "", "Keywords": ""}, {"Name": "Layer-wise Adaptive Gradient Sparsification for Distributed Deep Learning with Convergence Guarantees", "Authors": ["Shaohuai Shi", "Zhenheng Tang", "Qiang Wang", "Kaiyong Zhao", "Xiaowen Chu"], "Sources": "The 24th European Conference on Artificial Intelligence", "PublishedYears": "2020", "Doi": "", "Abstracts": "To reduce the long training time of large deep neural network (DNN) models, distributed synchronous stochastic gradient descent (S-SGD) is commonly used on a cluster of workers. However, the speedup brought by multiple workers is limited by the communication overhead. Two approaches, namely pipelining and gradient sparsification, have been separately proposed to alleviate the impact of communication overheads. Yet, the gradient sparsification methods can only initiate the communication after the backpropagation, and hence miss the pipelining opportunity. In this paper, we propose a new distributed optimization method named LAGS-SGD, which combines S-SGD with a novel layer-wise adaptive gradient sparsification (LAGS) scheme. In LAGS-SGD, every worker selects a small set of \"significant\" gradients from each layer independently whose size can be adaptive to the communication-to-computation ratio of that layer. The layer-wise nature of LAGS-SGD opens the opportunity of overlapping communications with computations, while the adaptive nature of LAGS-SGD makes it flexible to control the communication time. We prove that LAGS-SGD has convergence guarantees and it has the same order of convergence rate as vanilla S-SGD under a weak analytical assumption. Extensive experiments are conducted to verify the analytical assumption and the convergence performance of LAGS-SGD. Experimental results on a 16-GPU cluster show that LAGS-SGD outperforms the original S-SGD and existing sparsified S-SGD without losing obvious model accuracy.", "IdName": "shi2020layer", "Citation": "", "Keywords": ""}, {"Name": "Energy-aware non-preemptive task scheduling with deadline constraint in dvfs-enabled heterogeneous clusters", "Authors": ["Qiang Wang", "Xinxin Mei", "Hai Liu", "Yiu-Wing Leung", "Zongpeng Li", "Xiaowen Chu"], "Sources": "IEEE Transactions on Parallel and Distributed Systems", "PublishedYears": "2022", "Doi": "", "Abstracts": "Energy conservation of large data centers for high performance computing workloads, such as deep learning with Big Data, is of critical significance, where cutting down a few percent of electricity translates into million-dollar savings. This work studies energy conservation on emerging CPU-GPU hybrid clusters through dynamic voltage and frequency scaling (DVFS). We aim at minimizing the total energy consumption of processing a batch of offline tasks or a sequence of real-time tasks under deadline constraints. We derive a fast and accurate analytical model to compute the appropriate voltage/frequency setting for each task, and assign multiple tasks to the cluster with heuristic scheduling algorithms. In particular, our model stresses the nonlinear relationship between task execution time and processor speed for GPU-accelerated applications, for more accurately capturing real-world GPU energy consumption. In?\u2026", "IdName": "wang2022energy", "Citation": "", "Keywords": ""}, {"Name": "Ednet: Efficient disparity estimation with cost volume combination and attention-based spatial residual", "Authors": ["Songyan Zhang", "Zhicheng Wang", "Qiang Wang", "Jinshuo Zhang", "Gang Wei", "Xiaowen Chu"], "Sources": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Existing state-of-the-art disparity estimation works mostly leverage the 4D concatenation volume and construct a very deep 3D convolution neural network (CNN) for disparity regression, which is inefficient due to the high memory consumption and slow inference speed. In this paper, we propose a network named EDNet for efficient disparity estimation. Firstly, we construct a combined volume which incorporates contextual information from the squeezed concatenation volume and feature similarity measurement from the correlation volume. The combined volume can be next aggregated by 2D convolutions which are faster and require less memory than 3D convolutions. Secondly, we propose an attention-based spatial residual module to generate attention-aware residual features. The attention mechanism is applied to provide intuitive spatial evidence about inaccurate regions with the help of error maps at multiple scales and thus improve the residual learning efficiency. Extensive experiments on the Scene Flow and KITTI datasets show that EDNet outperforms the previous 3D CNN based works and achieves state-of-the-art performance with significantly faster speed and less memory consumption.", "IdName": "zhang2021ednet", "Citation": "", "Keywords": ""}, {"Name": "Adaprop: Learning adaptive propagation for graph neural network based knowledge graph reasoning", "Authors": ["Yongqi Zhang", "Zhanke Zhou", "Quanming Yao", "Xiaowen Chu", "Bo Han"], "Sources": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Due to the popularity of Graph Neural Networks (GNNs), various GNN-based methods have been designed to reason on knowledge graphs (KGs). An important design component of GNN-based KG reasoning methods is called the propagation path, which contains a set of involved entities in each propagation step. Existing methods use hand-designed propagation paths, ignoring the correlation between the entities and the query relation. In addition, the number of involved entities will explosively grow at larger propagation steps. In this work, we are motivated to learn an adaptive propagation path in order to filter out irrelevant entities while preserving promising targets. First, we design an incremental sampling mechanism where the nearby targets and layer-wise connections can be preserved with linear complexity. Second, we design a learning-based sampling distribution to identify the semantically related?\u2026", "IdName": "zhang2023adaprop", "Citation": "", "Keywords": ""}, {"Name": "MG-WFBP: Merging Gradients Wisely for Efficient Communication in Distributed Deep Learning", "Authors": ["Shaohuai Shi", "Xiaowen Chu", "Bo Li"], "Sources": "IEEE Transactions on Parallel and Distributed Systems", "PublishedYears": "2021", "Doi": "", "Abstracts": "Distributed synchronous stochastic gradient descent has been widely used to train deep neural networks (DNNs) on computer clusters. With the increase of computational power, network communications generally limit the system scalability. Wait-free backpropagation (WFBP) is a popular solution to overlap communications with computations during the training process. In this article, we observe that many DNNs have a large number of layers with only a small amount of data to be communicated at each layer in distributed training, which could make WFBP inefficient. Based on the fact that merging some short communication tasks into a single one can reduce the overall communication time, we formulate an optimization problem to minimize the training time in pipelining communications and computations. We derive an optimal solution that can be solved efficiently without affecting the training performance. We then?\u2026", "IdName": "shi2021mg", "Citation": "", "Keywords": ""}, {"Name": "Exploiting simultaneous communications to accelerate data parallel distributed deep learning", "Authors": ["Shaohuai Shi", "Xiaowen Chu", "Bo Li"], "Sources": "IEEE INFOCOM 2021-IEEE Conference on Computer Communications", "PublishedYears": "2021", "Doi": "", "Abstracts": "Synchronous stochastic gradient descent (S-SGD) with data parallelism is widely used for training deep learning (DL) models in distributed systems. A pipelined schedule of the computing and communication tasks of a DL training job is an effective scheme to hide some communication costs. In such pipelined S-SGD, tensor fusion (i.e., merging some consecutive layers' gradients for a single communication) is a key ingredient to improve communication efficiency. However, existing tensor fusion techniques schedule the communication tasks sequentially, which overlooks their independence nature. In this paper, we expand the design space of scheduling by exploiting simultaneous All-Reduce communications. Through theoretical analysis and experiments, we show that simultaneous All-Reduce communications can effectively improve the communication efficiency of small tensors. We formulate an optimization?\u2026", "IdName": "shi2021exploiting", "Citation": "", "Keywords": ""}, {"Name": "An erasure-coded storage system for edge computing", "Authors": ["Lixin Liang", "Huan He", "Jian Zhao", "Chengjian Liu", "Qiuming Luo", "Xiaowen Chu"], "Sources": "IEEE Access 8", "PublishedYears": "2020", "Doi": "", "Abstracts": "Emerging computing paradigm edge computing expects to store and process data at the network edge with reduced latency and improved network bandwidth. To the best of our knowledge, key performance issues such as coding performance of erasure-coded storage systems haven't been investigated for edge computing. In this paper, we present an erasure-coded storage system for edge computing. Unlike the data center and cloud storage systems, it employs edge devices to perform encoding and decoding operations, which can be a performance bottleneck of the whole storage system due to limited computing power. Hence, we present a comprehensive study of the performance of erasure coding to see if it can match the network performance of 5G and Wi-Fi 6 at the network edge. We use the popular edge device Jetson Nano and two state-of-the-art coding libraries: Jerasure and G-CRS. Our evaluation?\u2026", "IdName": "liang2020erasure", "Citation": "", "Keywords": ""}, {"Name": "Esetstore: An erasure-coded storage system with fast data recovery", "Authors": ["Chengjian Liu", "Qiang Wang", "Xiaowen Chu", "Yiu-Wing Leung", "Hai Liu"], "Sources": "IEEE transactions on parallel and distributed systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Erasure codes have been used extensively in large-scale storage systems to reduce the storage overhead of triplication-based storage systems. One key performance issue introduced by erasure codes is the long time needed to recover from a single failure, which occurs constantly in large-scale storage systems. We present ESetStore, a prototype erasure-coded storage system that aims to achieve fast recovery from failures. ESetStore is novel in the following aspects. We proposed a data placement algorithm named ESet for our ESetStore that can aggregate adequate I/O resources from available storage servers to recover from each single failure. We designed and implemented efficient read and write operations on our erasure-coded storage system via effective use of available I/O and computation resources. We evaluated the performance of ESetStore with extensive experiments on a cluster with 50 storage?\u2026", "IdName": "liu2020esetstore", "Citation": "", "Keywords": ""}, {"Name": "A blockchain-enabled framework for enhancing scalability and security in IIoT", "Authors": ["Ruonan Li", "Yang Qin", "Canhui Wang", "Mengya Li", "Xiaowen Chu"], "Sources": "IEEE Transactions on Industrial Informatics", "PublishedYears": "2022", "Doi": "", "Abstracts": "Industrial Internet of Things (IIoT) technology is widely used in modern industrial fields like transportation, but data security remains a major challenge. The blockchain-based access control mechanism can address the data security issue by preventing unauthorized devices from accessing limited IIoT resources. However, most existing blockchain-based access control mechanism for IIoT still has scalability and privacy issues. To deal with the above-mentioned problems, we propose a new scalable and secure strategy for the blockchain-based access control framework for IIoT via sharding, which consists of two components. First, the network sharding scheme based on the access frequency set (N2SAF) is designed to 1) improve the scalability of our proposed strategy by transaction sharding to reduce the storage pressure on nodes, and 2) increase the transaction processing speed on a three-layer architecture?\u2026", "IdName": "li2022blockchain", "Citation": "", "Keywords": ""}, {"Name": "Efficient Sparse-Dense Matrix-Matrix Multiplication on GPUs Using the Customized Sparse Storage Format", "Authors": ["Shaohuai Shi", "Qiang Wang", "Xiaowen Chu"], "Sources": "2020 International Conference on Parallel and Distributed Systems", "PublishedYears": "2020", "Doi": "", "Abstracts": "Multiplication of a sparse matrix to a dense matrix (SpDM) is widely used in many areas like scientific computing and machine learning. However, existing work under-looks the performance optimization of SpDM on modern manycore architectures like GPUs. The storage data structures help sparse matrices store in a memory-saving format, but they bring difficulties in optimizing the performance of SpDM on modern GPUs due to irregular data access of the sparse structure, which results in lower resource utilization and poorer performance. In this paper, we refer to the roofline performance model of GPUs to design an efficient SpDM algorithm called GCOOSpDM, in which we exploit coalescent global memory access, fast shared memory reuse, and more operations per byte of global memory traffic. Experiments are evaluated on three Nvidia GPUs (i.e., GTX 980, GTX Titan X Pascal, and Tesla P100) using a large?\u2026", "IdName": "shi2020efficient", "Citation": "", "Keywords": ""}, {"Name": "Joint access point placement and power-channel-resource-unit assignment for 802.11 ax-based dense WiFi with QoS requirements", "Authors": ["Shuwei Qiu", "Xiaowen Chu", "Yiu-Wing Leung", "Joseph Kee Yin Ng"], "Sources": "IEEE INFOCOM 2020-IEEE Conference on Computer Communications", "PublishedYears": "2020", "Doi": "", "Abstracts": "IEEE 802.11ax is a promising standard for the next-generation WiFi network, which uses orthogonal frequency division multiple access (OFDMA) to segregate the wireless spectrum into time-frequency resource units (RUs). In this paper, we aim at designing an 802.11ax-based dense WiFi network to provide WiFi services to a large number of users within a given area with the following objectives: (1) to minimize the number of access points (APs); (2) to fulfil the users\u2019 throughput requirement; and (3) to be resistant to AP failures. We formulate the above into a joint AP placement and power-channel-RU assignment optimization problem, which is NP-hard. To tackle this problem, we first derive an analytical model to estimate each user\u2019s throughput under the mechanism of OFDMA and a widely used interference model. We then design a heuristic algorithm to find high-quality solutions with polynomial time complexity?\u2026", "IdName": "qiu2020joint", "Citation": "", "Keywords": ""}, {"Name": "Enhancing the efficiency and scalability of blockchain through probabilistic verification and clustering", "Authors": ["Mengya Li", "Yang Qin", "Bing Liu", "Xiaowen Chu"], "Sources": "Information Processing & Management", "PublishedYears": "2021", "Doi": "", "Abstracts": "Blockchain is a disruptive technique that finds many applications in FinTech, IoT, and token economy. Because of the asynchrony, the competitive mining, and the indeterministic block propagation delay in networks, forks in the blockchain occur frequently, which not only waste a lot of computing resources but also result in potential security issues. This issue will greatly affect the efficiency of blockchain networks. In the meantime, when blockchain networks expand, the storage data for each node will be increasing dramatically. Participates are about to face the problem of storage limitation. Blockchain is hard to scale. This paper introduced PvScheme, a probabilistic verification scheme that could effectively reduce the block propagation delay and reduce the occurrence of blockchain forks. We further enhanced the security of PvScheme to provide reliable block delivery. We also analysed the resistance of PvScheme?\u2026", "IdName": "li2021enhancing", "Citation": "", "Keywords": ""}, {"Name": "BU-trace: A permissionless mobile system for privacy-preserving intelligent contact tracing", "Authors": ["Zhe Peng", "Jinbin Huang", "Haixin Wang", "Shihao Wang", "Xiaowen Chu", "Xinzhi Zhang", "Li Chen", "Xin Huang", "Xiaoyi Fu", "Yike Guo", "Jianliang Xu"], "Sources": "International Conference on Database Systems for Advanced Applications", "PublishedYears": "2021", "Doi": "", "Abstracts": " The coronavirus disease 2019 (COVID-19) pandemic has caused an unprecedented health crisis for the global. Digital contact tracing, as a transmission intervention measure, has shown its effectiveness on pandemic control. Despite intensive research on digital contact tracing, existing solutions can hardly meet users\u2019 requirements on privacy and convenience. In this paper, we propose -, a novel permissionless mobile system for privacy-preserving intelligent contact tracing based on QR code and NFC technologies. First, a user study is conducted to investigate and quantify the user acceptance of a mobile contact tracing system. Second, a decentralized system is proposed to enable contact tracing while protecting user privacy. Third, an intelligent behavior detection algorithm is designed to ease the use of our system. We implement - and conduct extensive experiments in several real-world?\u2026", "IdName": "peng2021bu", "Citation": "", "Keywords": ""}, {"Name": "Dear: accelerating distributed deep learning with fine-grained all-reduce pipelining", "Authors": ["Lin Zhang", "Shaohuai Shi", "Xiaowen Chu", "Wei Wang", "Bo Li", "Chengjian Liu"], "Sources": "2023 IEEE 43rd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Communication scheduling has been shown to be effective in accelerating distributed training, which enables all-reduce communications to be overlapped with backpropagation computations. This has been commonly adopted in popular distributed deep learning frameworks. However, there exist two fundamental problems: (1) excessive startup latency proportional to the number of workers for each all-reduce operation; (2) it only achieves sub-optimal training performance due to the dependency and synchronization requirement of the feed-forward computation in the next iteration. We propose a novel scheduling algorithm, DeAR, that decouples the all-reduce primitive into two continuous operations, which overlaps with both backpropagation and feed-forward computations without extra communications. We further design a practical tensor fusion algorithm to improve the training performance. Experimental results?\u2026", "IdName": "zhang2023dear", "Citation": "", "Keywords": ""}, {"Name": "System for efficient large-scale data distribution in distributed and parallel processing environment", "Authors": ["Xiaowen Chu", "SHI Shaohuai", "Kaiyong Zhao"], "Sources": "US Patent 11", "PublishedYears": "2022", "Doi": "", "Abstracts": "The present invention relates to a system for efficient large-scale data distribution in a distributed and parallel processing environment. In particular, the present invention relates to global Top-k sparsification for low bandwidth networks. The present invention verifies that gTop-k S-SGD has nearly consistent convergence performance with S-SGD and evaluates the training efficiency of gTop-k on a cluster with 32 GPU machines which are inter-connected with 1 Gbps Ethernet. The experimental results show that the present invention achieves up to 2.7-12\u00d7 higher scaling efficiency than S-SGD with dense gradients, and 1.1-1.7\u00d7 improvement than the existing Top-k S-SGD.", "IdName": "chu2022system", "Citation": "", "Keywords": ""}, {"Name": "Efficient multi-objective evolutionary 3D neural architecture search for COVID-19 detection with chest CT scans", "Authors": ["Xin He", "Shihao Wang", "Guohao Ying", "Jiyong Zhang", "Xiaowen Chu"], "Sources": "None", "PublishedYears": "2021", "Doi": "", "Abstracts": "COVID-19 pandemic has spread globally for months. Due to its long incubation period and high testing cost, there is no clue showing its spread speed is slowing down, and hence a faster testing method is in dire need. This paper proposes an efficient Evolutionary Multi-objective neural ARchitecture Search (EMARS) framework, which can automatically search for 3D neural architectures based on a well-designed search space for COVID-19 chest CT scan classification. Within the framework, we use weight sharing strategy to significantly improve the search efficiency and finish the search process in 8 hours. We also propose a new objective, namely potential, which is of benefit to improve the search process's robustness. With the objectives of accuracy, potential, and model size, we find a lightweight model (3.39 MB), which outperforms three baseline human-designed models, ie, ResNet3D101 (325.21 MB), DenseNet3D121 (43.06 MB), and MC3_18 (43.84 MB). Besides, our well-designed search space enables the class activation mapping algorithm to be easily embedded into all searched models, which can provide the interpretability for medical diagnosis by visualizing the judgment based on the models to locate the lesion areas.", "IdName": "he2021efficient", "Citation": "", "Keywords": ""}, {"Name": "Data Resampling for Federated Learning with Non-IID Labels", "Authors": ["Zhenheng Tang", "Zhikai Hu", "Shaohuai Shi", "Yiu-ming Cheung", "Yilun Jin", "Zhenghang Ren", "Xiaowen Chu"], "Sources": "International Workshop on Federated and Transfer Learning for Data Sparsity?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Recently, federated learning has received increasing attention from academe and industry, since it makes training models with decentralized data possible. However, most existing federated learning approaches suffer from Non-Independent and Identically data distribution in clients. Observing that each client has an imbalanced label distribution in many federated learning scenarios, we examine the effects of combining imbalanced learning techniques with federated learning. Through comprehensive experiments, we obtain the following findings:(1) By data resampling, the label sampling probabilities are made more similar across clients, which leads to faster convergence;(2) Imbalanced data resampling results in final accuracy decreasing on local dataset. Based on these two key findings, we propose a simple but effective data resampling strategy named Imbalanced Weight Decay Sampling (IWDS) that dynamically regulates the sampling probability of labels, remarkably accelerating the training process. The effectiveness of IWDS has been verified on several modern federated learning algorithms such as FedAvg, FedProx, and FedNova.", "IdName": "tang2021data", "Citation": "", "Keywords": ""}, {"Name": "EAGAN: Efficient Two-stage Evolutionary Architecture Search for GANs", "Authors": ["Guohao Ying", "Xin He", "Bin Gao", "Bo Han", "Xiaowen Chu"], "Sources": "European Conference on Computer Vision 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Generative adversarial networks (GANs) have proven successful in image generation tasks. However, GAN training is inherently unstable. Although many works try to stabilize it by manually modifying GAN architecture, it requires much expertise. Neural architecture search (NAS) has become an attractive solution to search GANs automatically. The early NAS-GANs search only generators to reduce search complexity but lead to a sub-optimal GAN. Some recent works try to search both generator (G) and discriminator (D), but they suffer from the instability of GAN training. To alleviate the instability, we propose an efficient two-stage evolutionary algorithm-based NAS framework to search GANs, namely EAGAN. We decouple the search of G and D into two stages, where stage-1 searches G with a fixed D and adopts the many-to-one training strategy, and stage-2 searches D with the optimal G found in stage-1 and?\u2026", "IdName": "ying2022eagan", "Citation": "", "Keywords": ""}, {"Name": "Communication contention aware scheduling of multiple deep learning training jobs", "Authors": ["Qiang Wang", "Shaohuai Shi", "Canhui Wang", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2002.10105", "PublishedYears": "2020", "Doi": "", "Abstracts": "Distributed Deep Learning (DDL) has rapidly grown its popularity since it helps boost the training performance on high-performance GPU clusters. Efficient job scheduling is indispensable to maximize the overall performance of the cluster when training multiple jobs simultaneously. However, existing schedulers do not consider the communication contention of multiple communication tasks from different distributed training jobs, which could deteriorate the system performance and prolong the job completion time. In this paper, we first establish a new DDL job scheduling framework which organizes DDL jobs as Directed Acyclic Graphs (DAGs) and considers communication contention between nodes. We then propose an efficient algorithm, LWF-, to balance the GPU utilization and consolidate the allocated GPUs for each job. When scheduling those communication tasks, we observe that neither avoiding all the contention nor blindly accepting them is optimal to minimize the job completion time. We thus propose a provable algorithm, AdaDUAL, to efficiently schedule those communication tasks. Based on AdaDUAL, we finally propose Ada-SRSF for the DDL job scheduling problem. Simulations on a 64-GPU cluster connected with 10 Gbps Ethernet show that LWF- achieves up to  improvement over the classical first-fit algorithms. More importantly, Ada-SRSF reduces the average job completion time by  and , as compared to the SRSF(1) scheme (avoiding all the contention) and the SRSF(2) scheme (blindly accepting all of two-way communication contention) respectively.", "IdName": "wang2020communication", "Citation": "", "Keywords": ""}, {"Name": "FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs", "Authors": ["Zhenheng Tang", "Yuxin Wang", "Xin He", "Longteng Zhang", "Xinglin Pan", "Qiang Wang", "Rongfei Zeng", "Kaiyong Zhao", "Shaohuai Shi", "Bingsheng He", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2309.01172", "PublishedYears": "2023", "Doi": "", "Abstracts": "The rapid growth of memory and computation requirements of large language models (LLMs) has outpaced the development of hardware, hindering people who lack large-scale high-end GPUs from training or deploying LLMs. However, consumer-level GPUs, which constitute a larger market share, are typically overlooked in LLM due to their weaker computing performance, smaller storage capacity, and lower communication bandwidth. Additionally, users may have privacy concerns when interacting with remote LLMs. In this paper, we envision a decentralized system unlocking the potential vast untapped consumer-level GPUs in pre-training, inference and fine-tuning of LLMs with privacy protection. However, this system faces critical challenges, including limited CPU and GPU memory, low network bandwidth, the variability of peer and device heterogeneity. To address these challenges, our system design incorporates: 1) a broker with backup pool to implement dynamic join and quit of computing providers; 2) task scheduling with hardware performance to improve system efficiency; 3) abstracting ML procedures into directed acyclic graphs (DAGs) to achieve model and task universality; 4) abstracting intermediate represention and execution planes to ensure compatibility of various devices and deep learning (DL) frameworks. Our performance analysis demonstrates that 50 RTX 3080 GPUs can achieve throughputs comparable to those of 4 H100 GPUs, which are significantly more expensive.", "IdName": "tang2023fusionai", "Citation": "", "Keywords": ""}, {"Name": "Advances in mobile, edge and cloud computing", "Authors": ["Xiaowen Chu", "Hongbo Jiang", "Bo Li", "Dan Wang", "Wei Wang"], "Sources": "Mobile Networks and Applications", "PublishedYears": "2022", "Doi": "", "Abstracts": "Editorial: Emerging mobile applications exhibit heterogeneous requirements on the computing power, communication bandwidth, security and privacy. Given the restriction on the computing capability on battery-operated mobile devices, a variety of offloading techniques have been designed to leverage the abundant computing resources available on cloud servers. Mobile Cloud Computing provides enormous computing and storage resources for mobile applications that can tolerate a certain level of network delay, while Mobile Edge Computing offers an intelligent platform to enhance mobile devices\u2019 capabilities and improve the Quality of Service of mobile applications. Both Mobile Cloud Computing and Mobile Edge Computing are key enabling paradigms for emerging mobile applications in Internet of Things (IoT), smart grids, robotics, crowd sensing, etc. New research challenges arise due to the heterogeneity?\u2026", "IdName": "chu2022advances", "Citation": "", "Keywords": ""}, {"Name": "Evolutionary multi-objective architecture search framework: Application to covid-19 3d ct classification", "Authors": ["Xin He", "Guohao Ying", "Jiyong Zhang", "Xiaowen Chu"], "Sources": "International Conference on Medical Image Computing and Computer-Assisted?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "The COVID-19 pandemic has threatened global health. Many studies have applied deep convolutional neural networks (CNN) to recognize COVID-19 based on chest 3D computed tomography (CT). Recent works show that no model generalizes well across CT datasets from different countries, and manually designing models for specific datasets requires expertise; thus, neural architecture search (NAS) that aims to search models automatically has become an attractive solution. To reduce the search cost on large 3D CT datasets, most NAS-based works use the weight-sharing (WS) strategy to make all models share weights within a supernet; however, WS inevitably incurs search instability, leading to inaccurate model estimation. In this work, we propose an efficient Evolutionary Multi-objective ARchitecture Search (EMARS) framework. We propose a new objective, namely potential, which can help exploit?\u2026", "IdName": "he2022evolutionary", "Citation": "", "Keywords": ""}, {"Name": "Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity", "Authors": ["Qingsong Yan", "Qiang Wang", "Kaiyong Zhao", "Bo Li", "Xiaowen Chu", "Fei Deng"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "Existing learning-based multi-view stereo (MVS) methods rely on the depth range to build the 3D cost volume and may fail when the range is too large or unreliable. To address this problem, we propose a disparity-based MVS method based on the epipolar disparity flow (E-flow), called DispMVS, which infers the depth information from the pixel movement between two views. The core of DispMVS is to construct a 2D cost volume on the image plane along the epipolar line between each pair (between the reference image and several source images) for pixel matching and fuse uncountable depths triangulated from each pair by multi-view geometry to ensure multi-view consistency. To be robust, DispMVS starts from a randomly initialized depth map and iteratively refines the depth map with the help of the coarse-to-fine strategy. Experiments on DTUMVS and Tanks\\&Temple datasets show that DispMVS is not sensitive to the depth range and achieves state-of-the-art results with lower GPU memory.", "IdName": "yan2023rethinking", "Citation": "", "Keywords": ""}, {"Name": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic Dimension", "Authors": ["Xin He", "Jiangchao Yao", "Yuxin Wang", "Zhenheng Tang", "Ka Chu Cheung", "Simon See", "Bo Han", "Xiaowen Chu"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2023", "Doi": "", "Abstracts": "One-shot neural architecture search (NAS) substantially improves the search efficiency by training one supernet to estimate the performance of every possible child architecture (ie, subnet). However, the inconsistency of characteristics among subnets incurs serious interference in the optimization, resulting in poor performance ranking correlation of subnets. Subsequent explorations decompose supernet weights via a particular criterion, eg, gradient matching, to reduce the interference; yet they suffer from huge computational cost and low space separability. In this work, we propose a lightweight and effective local intrinsic dimension (LID)-based method NAS-LID. NAS-LID evaluates the geometrical properties of architectures by calculating the low-cost LID features layer-by-layer, and the similarity characterized by LID enjoys better separability compared with gradients, which thus effectively reduces the interference among subnets. Extensive experiments on NASBench-201 indicate that NAS-LID achieves superior performance with better efficiency. Specifically, compared to the gradient-driven method, NAS-LID can save up to 86% of GPU memory overhead when searching on NASBench-201. We also demonstrate the effectiveness of NAS-LID on ProxylessNAS and OFA spaces. Source code: https://github. com/marsggbo/NAS-LID.", "IdName": "he2023lid", "Citation": "", "Keywords": ""}, {"Name": "\u201cBarcode\u201d cell sensor microfluidic system: Rapid and sample-to-answer antimicrobial susceptibility testing applicable in resource-limited conditions", "Authors": ["Chiu-Wing Chan", "Han Sun", "Yisu Wang", "Zhihao Zhao", "Ryan O'Neill", "Sin-Yung Siu", "Xiaowen Chu", "Niaz Banaei", "Kangning Ren"], "Sources": "Biosensors and Bioelectronics 192", "PublishedYears": "2021", "Doi": "", "Abstracts": "Many rapid antimicrobial susceptibility testing (AST) methods have been proposed to contain clinical antimicrobial resistance (AMR) and preserve the effectiveness of remaining antimicrobials. However, far fewer methods have been proposed to test AMR in resource-limited conditions, such as for frequent safety screenings of water/food/public facilities, urgent surveys of massive samples during a pandemic, or AMR tests in low-income countries. Rapid AST methods realized thus far have a variety of drawbacks when used for such surveys, e.g., high cost and the requirement of expensive instruments such as microscopy. A more reasonable strategy would be to screen samples via onsite testing first, and then send any sample suspected to contain AMR bacteria for advanced testing. Accordingly, a cost-efficient AST is demanded, which can rapidly process a large number of samples without using expensive?\u2026", "IdName": "chan2021barcode", "Citation": "", "Keywords": ""}, {"Name": "Fadnet++: Real-time and accurate disparity estimation with configurable networks", "Authors": ["Qiang Wang", "Shaohuai Shi", "Shizhen Zheng", "Kaiyong Zhao", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2110.02582", "PublishedYears": "2021", "Doi": "", "Abstracts": "Deep neural networks (DNNs) have achieved great success in the area of computer vision. The disparity estimation problem tends to be addressed by DNNs which achieve much better prediction accuracy than traditional hand-crafted feature-based methods. However, the existing DNNs hardly serve both efficient computation and rich expression capability, which makes them difficult for deployment in real-time and high-quality applications, especially on mobile devices. To this end, we propose an efficient, accurate, and configurable deep network for disparity estimation named FADNet++. Leveraging several liberal network design and training techniques, FADNet++ can boost its accuracy with a fast model inference speed for real-time applications. Besides, it enables users to easily configure different sizes of models for balancing accuracy and inference efficiency. We conduct extensive experiments to demonstrate the effectiveness of FADNet++ on both synthetic and realistic datasets among six GPU devices varying from server to mobile platforms. Experimental results show that FADNet++ and its variants achieve state-of-the-art prediction accuracy, and run at a significant order of magnitude faster speed than existing 3D models. With the constraint of running at above 15 frames per second (FPS) on a mobile GPU, FADNet++ achieves a new state-of-the-art result for the SceneFlow dataset.", "IdName": "wang2021fadnet", "Citation": "", "Keywords": ""}, {"Name": "A probabilistic approach towards an unbiased semi-supervised cluster tree", "Authors": ["Zhaocai Sun", "Xiaofeng Zhang", "Yunming Ye", "Xiaowen Chu", "Zhi Liu"], "Sources": "Knowledge-Based Systems 192", "PublishedYears": "2020", "Doi": "", "Abstracts": "Conventionally, it is a prerequisite to acquire a good number of annotated data to train an accurate classifier. However, the acquisition of such dataset is usually infeasible due to the high annotation cost. Therefore, semi-supervised learning has emerged and attracts increasing research efforts in recent years. Essentially, semi-supervised learning is sensitive to the manner how the unlabeled data is sampled. However, the model performance might be seriously deteriorated if biased unlabeled data is sampled at the early stage. In this paper, an unbiased semi-supervised cluster tree is proposed which is learnt using only very few labeled data. Specifically, a K-means algorithm is adopted to build each level of this hierarchical tree in a decent top-down manner. The number of clusters is determined by the number of classes contained in the labeled data. The confidence error of the cluster tree is theoretically analyzed?\u2026", "IdName": "sun2020probabilistic", "Citation": "", "Keywords": ""}, {"Name": "FedML Parrot: A scalable federated learning system via heterogeneity-aware scheduling on sequential and hierarchical training", "Authors": ["Zhenheng Tang", "Xiaowen Chu", "Ryan Yide Ran", "Sunwoo Lee", "Shaohuai Shi", "Yonggang Zhang", "Yuxin Wang", "Alex Qiaozhong Liang", "Salman Avestimehr", "Chaoyang He"], "Sources": "arXiv preprint arXiv:2303.01778", "PublishedYears": "2023", "Doi": "", "Abstracts": "Federated Learning (FL) enables collaborations among clients for train machine learning models while protecting their data privacy. Existing FL simulation platforms that are designed from the perspectives of traditional distributed training, suffer from laborious code migration between simulation and production, low efficiency, low GPU utility, low scalability with high hardware requirements and difficulty of simulating stateful clients. In this work, we firstly demystify the challenges and bottlenecks of simulating FL, and design a new FL system named as FedML \\texttt{Parrot}. It improves the training efficiency, remarkably relaxes the requirements on the hardware, and supports efficient large-scale FL experiments with stateful clients by: (1) sequential training clients on devices; (2) decomposing original aggregation into local and global aggregation on devices and server respectively; (3) scheduling tasks to mitigate straggler problems and enhance computing utility; (4) distributed client state manager to support various FL algorithms. Besides, built upon our generic APIs and communication interfaces, users can seamlessly transform the simulation into the real-world deployment without modifying codes. We evaluate \\texttt{Parrot} through extensive experiments for training diverse models on various FL datasets to demonstrate that \\texttt{Parrot} can achieve simulating over 1000 clients (stateful or stateless) with flexible GPU devices setting () and high GPU utility, 1.2  4 times faster than FedScale, and 10  100 times memory saving than FedML. And we verify that \\texttt{Parrot} works well with homogeneous and heterogeneous devices in three?\u2026", "IdName": "tang2023fedml", "Citation": "", "Keywords": ""}, {"Name": "Energy-efficient inference service of transformer-based deep learning models on GPUS", "Authors": ["Yuxin Wang", "Qiang Wang", "Xiaowen Chu"], "Sources": "2020 International Conferences on Internet of Things (iThings) and IEEE?\u2026", "PublishedYears": "2020", "Doi": "", "Abstracts": "Inference-as-a-service (IAAS) has been recently launched by cloud service providers to support on-demand AI applications. Many natural language processing (NLP) services are based on the Transformer Sequence Transduction model. However, the inference process of the Transformer model consumes a significant amount of energy due to the large model size (e.g., billions of parameters) and tremendous computations. How to reduce the energy consumption of IAAS without violating the service-level agreement (SLA) becomes a practical challenge for service providers. In this work, we conduct a comprehensive study on the inference performance and energy efficiency of a Transformer model trained for the language translation service. First, we empirically characterize some essential performance metrics, including latency, throughput, and energy consumption on three different GPUs with diversified workload?\u2026", "IdName": "wang2020energy", "Citation": "", "Keywords": ""}, {"Name": "Towards Efficient and Reliable LLM Serving: A Real-World Workload Study", "Authors": ["Yuxin Wang", "Yuhan Chen", "Zeyu Li", "Zhenheng Tang", "Rui Guo", "Xin Wang", "Qiang Wang", "Amelie Chi Zhou", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2401.17644", "PublishedYears": "2024", "Doi": "", "Abstracts": "Large language models (LLMs), especially Generative Pretrained Transformer (GPT) models, have significantly advanced in the industry in recent years. However, these models' broader development faces considerable challenges due to high operational and deployment costs. This has led to active research in improving the hardware efficiency of LLMs. Yet, the characteristics of real-world LLM workloads are often overlooked in current optimizations of LLM serving systems. In this work, we find that the absence of reliable workload data for evaluating LLM serving systems impacts the quality of service (QoS) and reliability in industrial deployments. This paper introduces the first real-world trace dataset of LLM serving workloads, detailing user, system, and LLM behaviors. We analyze this trace, highlighting burstiness, request and response distributions, and focusing on the reliability of GPT services. Based on this, we have developed a benchmark suite that reflects our dataset's workload patterns, enabling performance evaluation of serving systems. This suite captures the core patterns of workload distributions, allowing for precise scaling of the workload dataset to match system sizes. Our evaluation uncovers a previously unrecognized vulnerability of LLM serving systems to short-term burstiness, particularly in common workload scenarios. We observe that GPU memory limitations, caused by the fluctuating nature of burstiness, lead to significant performance degradation in existing LLM serving systems. Beyond benchmarking, understanding these patterns is valuable for optimizing LLM workload management, enabling elastic hardware?\u2026", "IdName": "wang2024towards", "Citation": "", "Keywords": ""}, {"Name": "EASNet: Searching Elastic and Accurate Network Architecture for Stereo Matching", "Authors": ["Qiang Wang", "Shaohuai Shi", "Kaiyong Zhao", "Xiaowen Chu"], "Sources": "European Conference on Computer Vision 2022", "PublishedYears": "2022", "Doi": "", "Abstracts": "Recent advanced studies have spent considerable human efforts on optimizing network architectures for stereo matching but hardly achieved both high accuracy and fast inference speed. To ease the workload in network design, neural architecture search (NAS) has been applied with great success to various sparse prediction tasks, such as image classification and object detection. However, existing NAS studies on the dense prediction task, especially stereo matching, still cannot be efficiently and effectively deployed on devices of different computing capability. To this end, we propose to train an elastic and accurate network for stereo matching (EASNet) that supports various 3D architectural settings on devices with different compute capability. Given the deployment latency constraint on the target device, we can quickly extract a sub-network from the full EASNet without additional training while the accuracy of the?\u2026", "IdName": "wang2022easnet", "Citation": "", "Keywords": ""}, {"Name": "BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation", "Authors": ["Dayou Du", "Yijia Zhang", "Shijie Cao", "Jiaqi Guo", "Ting Cao", "Xiaowen Chu", "Ningyi Xu"], "Sources": "arXiv preprint arXiv:2402.10631", "PublishedYears": "2024", "Doi": "", "Abstracts": "The upscaling of Large Language Models (LLMs) has yielded impressive advances in natural language processing, yet it also poses significant deployment challenges. Weight quantization has emerged as a widely embraced solution to reduce memory and computational demands. This paper introduces BitDistiller, a framework that synergizes Quantization-Aware Training (QAT) with Knowledge Distillation (KD) to boost the performance of LLMs at ultra-low precisions (sub-4-bit). Specifically, BitDistiller first incorporates a tailored asymmetric quantization and clipping technique to maximally preserve the fidelity of quantized weights, and then proposes a novel Confidence-Aware Kullback-Leibler Divergence (CAKLD) objective, which is employed in a self-distillation manner to enable faster convergence and superior model performance. Empirical evaluations demonstrate that BitDistiller significantly surpasses existing methods in both 3-bit and 2-bit configurations on general language understanding and complex reasoning benchmarks. Notably, BitDistiller is shown to be more cost-effective, demanding fewer data and training resources. The code is available at https://github.com/DD-DuDa/BitDistiller.", "IdName": "du2024bitdistiller", "Citation": "", "Keywords": ""}, {"Name": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models", "Authors": ["Longteng Zhang", "Xiang Liu", "Zeyu Li", "Xinglin Pan", "Peijie Dong", "Ruibo Fan", "Rui Guo", "Xin Wang", "Qiong Luo", "Shaohuai Shi", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2311.03687", "PublishedYears": "2023", "Doi": "", "Abstracts": "Large Language Models (LLMs) have seen great advance in both academia and industry, and their popularity results in numerous open-source frameworks and techniques in accelerating LLM pre-training, fine-tuning, and inference. Training and deploying LLMs are expensive as it requires considerable computing resources and memory, hence many efficient approaches have been developed for improving system pipelines as well as operators. However, the runtime performance can vary significantly across hardware and software stacks, which makes it difficult to choose the best configuration. In this work, we aim to benchmark the performance from both macro and micro perspectives. First, we benchmark the end-to-end performance of pre-training, fine-tuning, and serving LLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and 70B) on three 8-GPU platforms with and without individual optimization techniques, including ZeRO, quantization, recomputation, FlashAttention. Then, we dive deeper to provide a detailed runtime analysis of the sub-modules, including computing and communication operators in LLMs. For end users, our benchmark and findings help better understand different optimization techniques, training and inference frameworks, together with hardware platforms in choosing configurations for deploying LLMs. For researchers, our in-depth module-wise analyses discover potential opportunities for future work to further optimize the runtime performance of LLMs.", "IdName": "zhang2023dissecting", "Citation": "", "Keywords": ""}, {"Name": "Evaluation and optimization of gradient compression for distributed deep learning", "Authors": ["Lin Zhang", "Longteng Zhang", "Shaohuai Shi", "Xiaowen Chu", "Bo Li"], "Sources": "2023 IEEE 43rd International Conference on Distributed Computing Systems?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "To accelerate distributed training, many gradient compression methods have been proposed to alleviate the communication bottleneck in synchronous stochastic gradient descent (S-SGD), but their efficacy in real-world applications still remains unclear. In this work, we first evaluate the efficiency of three representative compression methods (quantization with Sign-SGD, sparsification with Top-k SGD, and low-rank with Power-SGD) on a 32-GPU cluster. The results show that they cannot always outperform well-optimized S-SGD or even worse due to their incompatibility with three key system optimization techniques (all-reduce, pipelining, and tensor fusion) in S-SGD. To this end, we propose a novel gradient compression method, called alternate compressed Power-SGD (ACP-SGD), which alternately compresses and communicates low-rank matrices. ACP-SGD not only significantly reduces the communication?\u2026", "IdName": "zhang2023evaluation", "Citation": "", "Keywords": ""}, {"Name": "Fast Sparse GPU Kernels for Accelerated Training of Graph Neural Networks", "Authors": ["Ruibo Fan", "Wei Wang", "Xiaowen Chu"], "Sources": "2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Graph Neural Networks (GNNs) are gaining huge traction recently as they achieve state-of-the-art performance on various graph-related problems. GNN training typically follows the standard Message Passing Paradigm, in which SpMM and SDDMM are the two essential sparse kernels. However, existing sparse GPU kernels are inefficient and may suffer from load imbalance, dynamics in GNN computing, poor memory efficiency, and tail effect. We propose two new kernels, Hybrid-Parallel SpMM (HP-SpMM) and Hybrid-Parallel SDDMM (HP-SDDMM), that efficiently perform SpMM and SDDMM on GPUs with a unified hybrid parallel strategy of mixing nodes and edges. In view of the emerging graph-sampling training, we design the Dynamic Task Partition (DTP) method to minimize the tail effect by exposing sufficient parallelism. We further devise the Hierarchical Vectorized Memory Access scheme to achieve?\u2026", "IdName": "fan2023fast", "Citation": "", "Keywords": ""}, {"Name": "Benchmarking and Dissecting the Nvidia Hopper GPU Architecture", "Authors": ["Weile Luo", "Ruibo Fan", "Zeyu Li", "Dayou Du", "Qiang Wang", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2402.13499", "PublishedYears": "2024", "Doi": "", "Abstracts": "Graphics processing units (GPUs) are continually evolving to cater to the computational demands of contemporary general-purpose workloads, particularly those driven by artificial intelligence (AI) utilizing deep learning techniques. A substantial body of studies have been dedicated to dissecting the microarchitectural metrics characterizing diverse GPU generations, which helps researchers understand the hardware details and leverage them to optimize the GPU programs. However, the latest Hopper GPUs present a set of novel attributes, including new tensor cores supporting FP8, DPX, and distributed shared memory. Their details still remain mysterious in terms of performance and operational characteristics. In this research, we propose an extensive benchmarking study focused on the Hopper GPU. The objective is to unveil its microarchitectural intricacies through an examination of the new instruction-set architecture (ISA) of Nvidia GPUs and the utilization of new CUDA APIs. Our approach involves two main aspects. Firstly, we conduct conventional latency and throughput comparison benchmarks across the three most recent GPU architectures, namely Hopper, Ada, and Ampere. Secondly, we delve into a comprehensive discussion and benchmarking of the latest Hopper features, encompassing the Hopper DPX dynamic programming (DP) instruction set, distributed shared memory, and the availability of FP8 tensor cores. The microbenchmarking results we present offer a deeper understanding of the novel GPU AI function units and programming features introduced by the Hopper architecture. This newfound understanding is expected to?\u2026", "IdName": "luo2024benchmarking", "Citation": "", "Keywords": ""}, {"Name": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS", "Authors": ["Peijie Dong", "Lujun Li", "Xinglin Pan", "Zimian Wei", "Xiang Liu", "Qiang Wang", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2402.02105", "PublishedYears": "2024", "Doi": "", "Abstracts": "Recent advancements in Zero-shot Neural Architecture Search (NAS) highlight the efficacy of zero-cost proxies in various NAS benchmarks. Several studies propose the automated design of zero-cost proxies to achieve SOTA performance but require tedious searching progress. Furthermore, we identify a critical issue with current zero-cost proxies: they aggregate node-wise zero-cost statistics without considering the fact that not all nodes in a neural network equally impact performance estimation. Our observations reveal that node-wise zero-cost statistics significantly vary in their contributions to performance, with each node exhibiting a degree of uncertainty. Based on this insight, we introduce a novel method called Parametric Zero-Cost Proxies (ParZC) framework to enhance the adaptability of zero-cost proxies through parameterization. To address the node indiscrimination, we propose a Mixer Architecture with Bayesian Network (MABN) to explore the node-wise zero-cost statistics and estimate node-specific uncertainty. Moreover, we propose DiffKendall as a loss function to directly optimize Kendall's Tau coefficient in a differentiable manner so that our ParZC can better handle the discrepancies in ranking architectures. Comprehensive experiments on NAS-Bench-101, 201, and NDS demonstrate the superiority of our proposed ParZC compared to existing zero-shot NAS methods. Additionally, we demonstrate the versatility and adaptability of ParZC by transferring it to the Vision Transformer search space.", "IdName": "dong2024parzc", "Citation": "", "Keywords": ""}, {"Name": "Reliable and Efficient In-Memory Fault Tolerance of Large Language Model Pretraining", "Authors": ["Yuxin Wang", "Shaohuai Shi", "Xin He", "Zhenheng Tang", "Xinglin Pan", "Yang Zheng", "Xiaoyu Wu", "Amelie Chi Zhou", "Bingsheng He", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2310.12670", "PublishedYears": "2023", "Doi": "", "Abstracts": "Extensive system scales (i.e. thousands of GPU/TPUs) and prolonged training periods (i.e. months of pretraining) significantly escalate the probability of failures when training large language models (LLMs). Thus, efficient and reliable fault-tolerance methods are in urgent need. Checkpointing is the primary fault-tolerance method to periodically save parameter snapshots from GPU memory to disks via CPU memory. In this paper, we identify the frequency of existing checkpoint-based fault-tolerance being significantly limited by the storage I/O overheads, which results in hefty re-training costs on restarting from the nearest checkpoint. In response to this gap, we introduce an in-memory fault-tolerance framework for large-scale LLM pretraining. The framework boosts the efficiency and reliability of fault tolerance from three aspects: (1) Reduced Data Transfer and I/O: By asynchronously caching parameters, i.e., sharded model parameters, optimizer states, and RNG states, to CPU volatile memory, Our framework significantly reduces communication costs and bypasses checkpoint I/O. (2) Enhanced System Reliability: Our framework enhances parameter protection with a two-layer hierarchy: snapshot management processes (SMPs) safeguard against software failures, together with Erasure Coding (EC) protecting against node failures. This double-layered protection greatly improves the survival probability of the parameters compared to existing checkpointing methods. (3) Improved Snapshotting Frequency: Our framework achieves more frequent snapshotting compared with asynchronous checkpointing optimizations under the same saving time?\u2026", "IdName": "wang2023reliable", "Citation": "", "Keywords": ""}, {"Name": "An LLVM-based open-source compiler for NVIDIA GPUs", "Authors": ["Da Yan", "Wei Wang", "Xiaowen Chu"], "Sources": "Proceedings of the 27th ACM SIGPLAN Symposium on Principles and Practice of?\u2026", "PublishedYears": "2022", "Doi": "", "Abstracts": "We present GASS, an LLVM-based open-source compiler for NVIDIA GPU's SASS machine assembly. GASS is the first open-source compiler targeting SASS, and it provides a unified toolchain for currently fragmented low-level performance research on NVIDIA GPUs. GASS supports all recent architectures, including Volta, Turing, and Ampere. Our evaluation shows that our specialized optimizations deliver significant speedup over LLVM's algorithms.", "IdName": "yan2022llvm", "Citation": "", "Keywords": ""}, {"Name": "Multi-Fingerprint for wireless localization in time-varying indoor environment", "Authors": ["Lu Yu", "Yiu-Wing Leung", "Xiaowen Chu", "Joseph KY Ng"], "Sources": "GLOBECOM 2020-2020 IEEE Global Communications Conference", "PublishedYears": "2020", "Doi": "", "Abstracts": "Fingerprint is one of the representative methods for wireless indoor localization. It uses a fingerprint database (measured in the offline phase) and the current received signal strengths (RSSs) (measured by the user's device in the online phase) to determine the location of this device. However, the RSSs and hence the localization accuracy would be affected by time-varying environmental factors (e.g., number of people in a shopping mall). In this paper, we propose a new method for wireless localization in time-varying indoor environments. In the offline phase, the proposed method measures extra information: it measures E fingerprint databases for E respective environmental conditions, where E is a design parameter (e.g., E=2 for the peak period and the non-peak period in a shopping mall). In the online phase, it leverages the extra information for better localization in time-varying indoor environment, even when?\u2026", "IdName": "yu2020multi", "Citation": "", "Keywords": ""}, {"Name": "Benchmarking Deep Learning Models and Automated Model Design for COVID-19 Detection with Chest CT Scans (preprint)", "Authors": ["Xin He", "Shihao Wang", "Shaohuai Shi", "Xiaowen Chu", "Jiangping Tang", "Xin Liu", "Chenggang Yan", "Jiyong Zhang", "Guiguang Ding"], "Sources": "None", "PublishedYears": "2020", "Doi": "", "Abstracts": "COVID-19 pandemic has spread all over the world for months. As its transmissibility and high pathogenicity seriously threaten people's lives, the accurate and fast detection of the COVID-19 infection is crucial. Although many recent studies have shown that deep learning based solutions can help detect COVID-19 based on chest CT scans, there lacks a consistent and systematic comparison and evaluation on these techniques. In this paper, we first build a clean and segmented CT dataset called Clean-CC-CCII by fixing the errors and removing some noises in a large CT scan dataset CC-CCII with three classes novel coronavirus pneumonia (NCP), common pneumonia (CP), and normal controls (Normal). After cleaning, our dataset consists of a total of 340,190 slices of 3,993 scans from 2,698 patients. Then we benchmark and compare the performance of a series of state-of-the-art (SOTA) 3D and 2D convolutional neural networks (CNNs). The results show that 3D CNNs outperform 2D CNNs in general. With extensive effort of hyperparameter tuning, we find that the 3D CNN model DenseNet3D121 achieves the highest accuracy of 88.63%(F1-score is 88.14% and AUC is 0.940), and another 3D CNN model ResNet3D34 achieves the best AUC of 0.959 (accuracy is 87.83% and F1-score is 86.04%). We further demonstrate that the mixup data augmentation technique can largely improve the model performance. At last, we design an automated deep learning methodology to generate a lightweight deep learning model MNas3DNet41 that achieves an accuracy of 87.14%, F1-score of 87.25%, and AUC of 0.957, which are on par with the best?\u2026", "IdName": "he2020benchmarking", "Citation": "", "Keywords": ""}, {"Name": "Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices", "Authors": ["Shengyuan Ye", "Liekang Zeng", "Xiaowen Chu", "Guoliang Xing", "Xu Chen"], "Sources": "Proceedings of the 30th Annual International Conference on Mobile Computing?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "On-device Deep Neural Network (DNN) training has been recognized as crucial for privacy-preserving machine learning at the edge. However, the intensive training workload and limited onboard computing resources pose significant challenges to the availability and efficiency of model training. While existing works address these challenges through native resource management optimization, we instead leverage our observation that edge environments usually comprise a rich set of accompanying trusted edge devices with idle resources beyond a single terminal. We propose Asteroid, a distributed edge training system that breaks the resource walls across heterogeneous edge devices for efficient model training acceleration. Asteroid adopts a hybrid pipeline parallelism to orchestrate distributed training, along with a judicious parallelism planning for maximizing throughput under certain resource constraints?\u2026", "IdName": "ye2024asteroid", "Citation": "", "Keywords": ""}, {"Name": "Model quantization and hardware acceleration for vision transformers: A comprehensive survey", "Authors": ["Dayou Du", "Gu Gong", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2405.00314", "PublishedYears": "2024", "Doi": "", "Abstracts": "Vision Transformers (ViTs) have recently garnered considerable attention, emerging as a promising alternative to convolutional neural networks (CNNs) in several vision-related applications. However, their large model sizes and high computational and memory demands hinder deployment, especially on resource-constrained devices. This underscores the necessity of algorithm-hardware co-design specific to ViTs, aiming to optimize their performance by tailoring both the algorithmic structure and the underlying hardware accelerator to each other's strengths. Model quantization, by converting high-precision numbers to lower-precision, reduces the computational demands and memory needs of ViTs, allowing the creation of hardware specifically optimized for these quantized algorithms, boosting efficiency. This article provides a comprehensive survey of ViTs quantization and its hardware acceleration. We first delve into the unique architectural attributes of ViTs and their runtime characteristics. Subsequently, we examine the fundamental principles of model quantization, followed by a comparative analysis of the state-of-the-art quantization techniques for ViTs. Additionally, we explore the hardware acceleration of quantized ViTs, highlighting the importance of hardware-friendly algorithm design. In conclusion, this article will discuss ongoing challenges and future research paths. We consistently maintain the related open-source materials at https://github.com/DD-DuDa/awesome-vit-quantization-acceleration.", "IdName": "du2024model", "Citation": "", "Keywords": ""}, {"Name": "ScheMoE: An Extensible Mixture-of-Experts Distributed Training System with Tasks Scheduling", "Authors": ["Shaohuai Shi", "Xinglin Pan", "Qiang Wang", "Chengjian Liu", "Xiaozhe Ren", "Zhongzhe Hu", "Yu Yang", "Bo Li", "Xiaowen Chu"], "Sources": "Proceedings of the Nineteenth European Conference on Computer Systems", "PublishedYears": "2024", "Doi": "", "Abstracts": "In recent years, large-scale models can be easily scaled to trillions of parameters with sparsely activated mixture-of-experts (MoE), which significantly improves the model quality while only requiring a sub-linear increase in computational costs. However, MoE layers require the input data to be dynamically routed to a particular GPU for computing during distributed training. The highly dynamic property of data routing and high communication costs in MoE make the training system low scaling efficiency on GPU clusters. In this work, we propose an extensible and efficient MoE training system, ScheMoE, which is equipped with several features. 1) ScheMoE provides a generic scheduling framework that allows the communication and computation tasks in training MoE models to be scheduled in an optimal way. 2) ScheMoE integrates our proposed novel all-to-all collective which better utilizes intra- and inter-connect?\u2026", "IdName": "shi2024schemoe", "Citation": "", "Keywords": ""}, {"Name": "CF-NeRF: Camera Parameter Free Neural Radiance Fields with Incremental Learning", "Authors": ["Qingsong Yan", "Qiang Wang", "Kaiyong Zhao", "Jie Chen", "Bo Li", "Xiaowen Chu", "Fei Deng"], "Sources": "Proceedings of the AAAI Conference on Artificial Intelligence", "PublishedYears": "2024", "Doi": "", "Abstracts": "Neural Radiance Fields (NeRF) have demonstrated impressive performance in novel view synthesis. However, NeRF and most of its variants still rely on traditional complex pipelines to provide extrinsic and intrinsic camera parameters, such as COLMAP. Recent works, like NeRFmm, BARF, and L2G-NeRF, directly treat camera parameters as learnable and estimate them through differential volume rendering. However, these methods work for forward-looking scenes with slight motions and fail to tackle the rotation scenario in practice.To overcome this limitation, we propose a novel \\underline{c}amera parameter \\underline{f}ree neural radiance field (CF-NeRF), which incrementally reconstructs 3D representations and recovers the camera parameters inspired by incremental structure from motion (SfM). Given a sequence of images, CF-NeRF estimates the camera parameters of images one by one and reconstructs the scene through initialization, implicit localization, and implicit optimization. To evaluate our method, we use a challenging real-world dataset NeRFBuster which provides 12 scenes under complex trajectories. Results demonstrate that CF-NeRF is robust to camera rotation and achieves state-of-the-art results without providing prior information and constraints.", "IdName": "yan2024cf", "Citation": "", "Keywords": ""}, {"Name": "FedImpro: Measuring and Improving Client Update in Federated Learning", "Authors": ["Zhenheng Tang", "Yonggang Zhang", "Shaohuai Shi", "Xinmei Tian", "Tongliang Liu", "Bo Han", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2402.07011", "PublishedYears": "2024", "Doi": "", "Abstracts": "Federated Learning (FL) models often experience client drift caused by heterogeneous data, where the distribution of data differs across clients. To address this issue, advanced research primarily focuses on manipulating the existing gradients to achieve more consistent client models. In this paper, we present an alternative perspective on client drift and aim to mitigate it by generating improved local models. First, we analyze the generalization contribution of local training and conclude that this generalization contribution is bounded by the conditional Wasserstein distance between the data distribution of different clients. Then, we propose FedImpro, to construct similar conditional distributions for local training. Specifically, FedImpro decouples the model into high-level and low-level components, and trains the high-level portion on reconstructed feature distributions. This approach enhances the generalization contribution and reduces the dissimilarity of gradients in FL. Experimental results show that FedImpro can help FL defend against data heterogeneity and enhance the generalization performance of the model.", "IdName": "tang2024fedimpro", "Citation": "", "Keywords": ""}, {"Name": "MedPipe: End-to-End Joint Search of Data Augmentation and Neural Architecture for 3D Medical Image Classification", "Authors": ["Xin He", "Xiaowen Chu"], "Sources": "2023 IEEE International Conference on Medical Artificial Intelligence (MedAI?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Data augmentation plays a crucial role in deep learning-based medical imaging analysis, but manually designing tailored data augmentation strategies for each dataset is impractical. Although automatic data augmentation (ADA) techniques have been explored, they often focus solely on data augmentation without considering the importance of neural architecture. Similarly, neural architecture search (NAS) methods mainly concentrate on optimizing the neural architecture while overlooking the impact of data augmentation. However, both data augmentation and neural architecture are interrelated and should be considered together. The joint optimization of data augmentation and neural architecture can lead to improved model performance by harnessing the complementary effects of customized data augmentation strategies and compatible neural architectures. Despite this, the seamless integration of data?\u2026", "IdName": "he2023medpipe", "Citation": "", "Keywords": ""}, {"Name": "SMCoEdge: Simultaneous Multi-server Offloading for Collaborative Mobile Edge Computing", "Authors": ["Changfu Xu", "Yupeng Li", "Xiaowen Chu", "Haodong Zou", "Weijia Jia", "Tian Wang"], "Sources": "International Conference on Algorithms and Architectures for Parallel?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Collaborative Mobile Edge Computing (MEC) has emerged as a promising solution for low service delay in computation-intensive Internet of Things (IoT) applications. However, current approaches typically perform offline task partitioning and offload each subtask to an Edge Server (ES) for processing. This leads to varying delays in subtask processing across different ESs, resulting in a high make-span of task offloading. To address this issue, we propose a novel approach called SMCoEdge, which utilizes simultaneous multi-ES offloading to minimize the make-span of task offloading for computation-intensive IoT applications. Specifically, we formulate our problem as a mixed integer non-linear programming problem and prove its NP-hardness. We then decompose our problem into two sub-problems of multi-ES selection and task allocation, and propose a Deep Reinforcement Learning-based Simultaneous Multi?\u2026", "IdName": "xu2023smcoedge", "Citation": "", "Keywords": ""}, {"Name": "Improving Fairness in Coexisting 5G and Wi-Fi Network on Unlicensed Band with URLLC", "Authors": ["Haodong Zou", "Yupeng Li", "Xiaowen Chu", "Changfu Xu", "Tian Wang"], "Sources": "2023 IEEE/ACM 31st International Symposium on Quality of Service (IWQoS)", "PublishedYears": "2023", "Doi": "", "Abstracts": "To meet the growing need of mobile traffic with Ultra-Reliable and Low Latency Communication (URLLC) requirement, 5G New Radio (NR) is extending from licensed band to unlicensed band on which Wi-Fi has already been operated, resulting in coexisting NR/Wi-Fi network. Existing works have made great efforts on throughput and latency of coexisting NR/Wi-Fi network. However, excessive NR requests offloaded from licensed band lead to unfair utilization of unlicensed band, which further causes unsatisfaction on URLLC and performance degradation of Wi-Fi. In this paper, we propose a novel Reinforcement Learning based Transmission Revoking Approach (RL-TRA) to address this problem aiming at fairer utilization of unlicensed band restrained by URLLC. Firstly, we formulate the coexistence problem of NR/Wi-Fi as integer non-linear programming and show its NP-hardness. Secondly, we decompose the?\u2026", "IdName": "zou2023improving", "Citation": "", "Keywords": ""}, {"Name": "PipeMoE: Accelerating Mixture-of-Experts through Adaptive Pipelining", "Authors": ["Shaohuai Shi", "Xinglin Pan", "Xiaowen Chu", "Bo Li"], "Sources": "IEEE INFOCOM 2023-IEEE Conference on Computer Communications", "PublishedYears": "2023", "Doi": "", "Abstracts": "Large models have attracted much attention in the AI area. The sparsely activated mixture-of-experts (MoE) technique pushes the model size to a trillion-level with a sub-linear increase of computations as an MoE layer can be equipped with many separate experts, but only one or two experts need to be trained for each input data. However, the feature of dynamically activating experts of MoE introduces extensive communications in distributed training. In this work, we propose PipeMoE to adaptively pipeline the communications and computations in MoE to maximally hide the communication time. Specifically, we first identify the root reason why a higher pipeline degree does not always achieve better performance in training MoE models. Then we formulate an optimization problem that aims to minimize the training iteration time. To solve this problem, we build performance models for computation and communication?\u2026", "IdName": "shi2023pipemoe", "Citation": "", "Keywords": ""}, {"Name": "SphereDepth: Panorama Depth Estimation from Spherical Domain", "Authors": ["Qingsong Yan", "Qiang Wang", "Kaiyong Zhao", "Bo Li", "Xiaowen Chu", "Fei Deng"], "Sources": "2022 International Conference on 3D Vision (3DV)", "PublishedYears": "2022", "Doi": "", "Abstracts": "The panorama image can simultaneously demonstrate complete information of the surrounding environment and has many advantages in virtual tourism, games, robotics, etc. However, the progress of panorama depth estimation cannot completely solve the problems of distortion and discontinuity caused by the commonly used projection methods. This paper proposes SphereDepth, a novel panorama depth estimation method that predicts the depth directly on the spherical mesh without projection preprocessing. The core idea is to establish the relationship between the panorama image and the spherical mesh and then use a deep neural network to extract features on the spherical domain to predict depth. To address the efficiency challenges brought by the high-resolution panorama data, we introduce two hyper-parameters for the proposed spherical mesh processing framework to balance the inference speed?\u2026", "IdName": "yan2022spheredepth", "Citation": "", "Keywords": ""}, {"Name": "Traffic Management for Distributed Machine Learning in RDMA-enabled Data Center Networks", "Authors": ["Weihong Yang", "Yang Qin", "Zukai Jiang", "Xiaowen Chu"], "Sources": "ICC 2021-IEEE International Conference on Communications", "PublishedYears": "2021", "Doi": "", "Abstracts": "It has become a common practice to train large machine learning (ML) models across a cluster of computing nodes connected by RDMA-enabled networks. However, the communication overhead caused by parameter synchronization deteriorates the performance of such distributed ML (DML), especially in a large-scale setting. This paper tackles this issue by developing a traffic management scheme to support DML traffic, called TMDML (Traffic Management for DML), which needs only a minor modification to the existing RDMA congestion control scheme DCQCN. We assume that there is only one instance of DML workload running in a network. Existing literature has shown that Fat-Tree, a predominant topology in the data center, poorly supports DML compared with BCube. With our proposed TMDML, training DML in Fat-Tree can achieve better performance than that in BCube. We first study the impact of multi?\u2026", "IdName": "yang2021traffic", "Citation": "", "Keywords": ""}, {"Name": "Simplifying low-level GPU programming with GAS", "Authors": ["Da Yan", "Wei Wang", "Xiaowen Chu"], "Sources": "Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of?\u2026", "PublishedYears": "2021", "Doi": "", "Abstracts": "Many low-level optimizations for NVIDIA GPU can only be implemented in native hardware assembly (SASS). However, programming in SASS is unproductive and not portable. To simplify low-level GPU programming, we present GAS (Gpu ASsembly), a PTX-like language that provides a stable instruction set across hardware architectures while giving programmers a low-level control of code execution. We demonstrate that GAS can be used with ease for low-level benchmarking and performance tuning in the context of Tensor Core HGEMM.", "IdName": "yan2021simplifying", "Citation": "", "Keywords": ""}, {"Name": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models", "Authors": ["Peijie Dong", "Lujun Li", "Zhenheng Tang", "Xiang Liu", "Xinglin Pan", "Qiang Wang", "Xiaowen Chu"], "Sources": "Forty-first International Conference on Machine Learning", "PublishedYears": "2024", "Doi": "", "Abstracts": "Despite the remarkable capabilities, Large Language Models (LLMs) face deployment challenges due to their extensive size. Pruning methods drop a subset of weights to accelerate, but many of them require retraining, which is prohibitively expensive and computationally demanding. Recently, post-training pruning approaches introduced novel metrics, enabling the pruning of LLMs without retraining. However, these metrics require the involvement of human experts and tedious trial and error. To efficiently identify superior pruning metrics, we develop an automatic framework for searching symbolic pruning metrics using genetic programming. In particular, we devise an elaborate search space encompassing the existing pruning metrics to discover the potential symbolic pruning metric. We propose an opposing operation simplification strategy to increase the diversity of the population. In this way, Pruner-Zero allows auto-generation of symbolic pruning metrics. Based on the searched results, we explore the correlation between pruning metrics and performance after pruning and summarize some principles. Extensive experiments on LLaMA and LLaMA-2 on language modeling and zero-shot tasks demonstrate that our Pruner-Zero obtains superior performance than SOTA post-training pruning methods. Code at: https://github.com/pprp/Pruner-Zero.", "IdName": "dong2024pruner", "Citation": "", "Keywords": ""}, {"Name": "Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ Transformer Inference", "Authors": ["Shengyuan Ye", "Jiangsu Du", "Liekang Zeng", "Wenzhong Ou", "Xiaowen Chu", "Yutong Lu", "Xu Chen"], "Sources": "arXiv preprint arXiv:2405.17245", "PublishedYears": "2024", "Doi": "", "Abstracts": "Transformer-based models have unlocked a plethora of powerful intelligent applications at the edge, such as voice assistant in smart home. Traditional deployment approaches offload the inference workloads to the remote cloud server, which would induce substantial pressure on the backbone network as well as raise users' privacy concerns. To address that, in-situ inference has been recently recognized for edge intelligence, but it still confronts significant challenges stemming from the conflict between intensive workloads and limited on-device computing resources. In this paper, we leverage our observation that many edge environments usually comprise a rich set of accompanying trusted edge devices with idle resources and propose Galaxy, a collaborative edge AI system that breaks the resource walls across heterogeneous edge devices for efficient Transformer inference acceleration. Galaxy introduces a novel hybrid model parallelism to orchestrate collaborative inference, along with a heterogeneity-aware parallelism planning for fully exploiting the resource potential. Furthermore, Galaxy devises a tile-based fine-grained overlapping of communication and computation to mitigate the impact of tensor synchronizations on inference latency under bandwidth-constrained edge environments. Extensive evaluation based on prototype implementation demonstrates that Galaxy remarkably outperforms state-of-the-art approaches under various edge environment setups, achieving up to 2.5x end-to-end latency reduction.", "IdName": "ye2024galaxy", "Citation": "", "Keywords": ""}, {"Name": "DTC-SpMM: Bridging the Gap in Accelerating General Sparse Matrix Multiplication with Tensor Cores", "Authors": ["Ruibo Fan", "Wei Wang", "Xiaowen Chu"], "Sources": "Proceedings of the 29th ACM International Conference on Architectural?\u2026", "PublishedYears": "2024", "Doi": "", "Abstracts": "Sparse Matrix-Matrix Multiplication (SpMM) is a building-block operation in scientific computing and machine learning applications. Recent advancements in hardware, notably Tensor Cores (TCs), have created promising opportunities for accelerating SpMM. However, harnessing these hardware accelerators to speed up general SpMM necessitates considerable effort. In this paper, we undertake a comprehensive analysis of the state-of-the-art techniques for accelerating TC-based SpMM and identify crucial performance gaps. Drawing upon these insights, we propose DTC-SpMM, a novel approach with systematic optimizations tailored for accelerating general SpMM on TCs. DTC-SpMM encapsulates diverse aspects, including efficient compression formats, reordering methods, and runtime pipeline optimizations. Our extensive experiments on modern GPUs with a diverse range of benchmark matrices?\u2026", "IdName": "fan2024dtc", "Citation": "", "Keywords": ""}, {"Name": "Multipath Based Congestion Propagation via Information Network Interaction in IIoT", "Authors": ["Ruonan Li", "Yang Qin", "Jie Liu", "Xiaowen Chu", "Jinlong Li"], "Sources": "IEEE Transactions on Industrial Informatics", "PublishedYears": "2024", "Doi": "", "Abstracts": "The Industrial Internet of Things (IIoT) has found extensive applications in intelligent transportation. However, as the number of vehicles increases, the issue of traffic congestion becomes more prominent, emphasizing the need for accurate congestion propagation prediction to enhance traffic conditions. Current methods for predicting congestion propagation lack consideration for the influence of communication networks and do not incorporate the path characteristics of congestion propagation. Therefore, we propose a path-based congestion propagation model, UAU_SIS_Path, employing multigrain abstraction of traffic congestion and information propagation. Specifically, UAU_SIS_Path effectively captures the propagation dynamics of congestion in IIoT by leveraging the interaction of two-layer networks and the path propagation characteristics of traffic congestion. Subsequently, we validate the effectiveness of?\u2026", "IdName": "li2024multipath", "Citation": "", "Keywords": ""}, {"Name": "LF-Net: A Learning-based Frenet Planning Approach for Urban Autonomous Driving", "Authors": ["Zihan Yu", "Meixin Zhu", "Kehua Chen", "Xiaowen Chu", "Xuesong Wang"], "Sources": "IEEE Transactions on Intelligent Vehicles", "PublishedYears": "2023", "Doi": "", "Abstracts": "Learning-based approaches hold great potential for autonomous urban driving motion planning. Compared to traditional rule-based methods, they offer greater flexibility in planning safe and human-like trajectories based on human driver demonstration data and diverse traffic scenarios. Frenet planning is widely applied in autonomous driving motion planning due to itssimplerepresentationofself-drivingvehicleinformation.However,it is challenging to select proper terminal statesand generate human-like trajectories. To address this issue, we propose a learning-based Frenet planning network (LF-Net) that learns a policy to sample and select the most human-like terminal states and then generate safe trajectories. The LF-Net includes 1) a Transformer-based sub-network that encodes environmental and vehicle interaction features, 2) a classification and scoring subnetwork based on cross-attention mechanisms that?\u2026", "IdName": "yu2023lf", "Citation": "", "Keywords": ""}, {"Name": "Guest Editorial: Interplay Between Machine Learning and Networking Systems", "Authors": ["Xiaowen Chu", "Shadi Ibrahim", "Jia Liu", "Shiqiang Wang", "Chuan Wu", "Rongfei Zeng"], "Sources": "IEEE Network", "PublishedYears": "2023", "Doi": "", "Abstracts": "IEEE Network? July/August 2023 73 erated Learning) to detect and mitigate the effects of Byzantine agents, while maintaining high accuracy and efficiency. In the article,\u201cFDSFL: Filtering Defense Strategies Toward Targeted Poisoning Attacks in IIoT-based Federated Learning Networking System,\u201d the authors present filtering defense strategies to mitigate the impact of these attacks and ensure the security and privacy of the data being used in the federated learning process. In the article,\u201cBC-MetaCast: A Blockchain-Enhanced Intelligent Computing Framework for Metaverse Livecast,\u201d the authors present a cutting-edge blockchain-enhanced intelligent computing framework for metaverse livecast. The proposed framework offers an efficient, decentralized, and truthful task assignment for live stream processing.In the article,\u201cBlockchain-Enabled Cross-Layer Radio Frequency Fingerprinting Identification with Machine Learning for IIoT,\u201d a blockchain-enabled cross-layer radio frequency fingerprinting (RFF) identification framework is proposed. It enhances security in the industrial Internet of Things (IIoT) by using physical layer authentication, machine learning, and blockchain technology.", "IdName": "chu2023guest", "Citation": "", "Keywords": ""}, {"Name": "All for One and One for All: A Collaborative FL Framework for Generic Federated Learning with Personalized Plug-ins", "Authors": ["Lei Shen", "Zhenheng Tang", "Lijun Wu", "Yonggang Zhang", "Xiaowen Chu", "Tao Qin", "Bo Han"], "Sources": "None", "PublishedYears": "2023", "Doi": "", "Abstracts": "Personalized federated learning (PFL) mitigates the notorious data heterogeneity issue in generic federated learning (GFL) by assuming that client models only need to fit on local datasets individually. However, real-world FL clients may meet with test data from other distributions. To endow clients with the ability to handle other datasets, we theoretically formulate a new problem named as Selective FL (SFL), bridging the GFL and PFL together. To practically solve SFL, we design a general effective framework named as Hot-Pluggable Federated Learning (HPFL). In HPFL, clients firstly learn a global shared feature extractor. Next, with the frozen feature extractor, multiple personalized plug-in modules are individually learned based on the local data and saved in a modular store on the server. In inference stage, an accurate selection algorithm allows clients to choose and download suitable plug-in modules from the modular store to achieve the high generalization performance on target data distribution. We conduct comprehensive experiments and ablation studies following common FL settings including four datasets and three neural networks, showing that HPFL significantly outperforms advanced FL algorithms. Additionally, we empirically show the remarkable potential of HPFL to resolve other practical FL problems like continual federated learning and discuss its possible applications in one-shot FL, anarchic FL and an FL plug-in market.", "IdName": "shenall", "Citation": "", "Keywords": ""}, {"Name": "Stochastic Performance Analysis of Phase Decomposition in Hyperledger Fabric", "Authors": ["Canhui Wang", "Xiaowen Chu"], "Sources": "arXiv preprint arXiv:2309.09547", "PublishedYears": "2023", "Doi": "", "Abstracts": "Hyperledger Fabric is one of the most popular permissioned blockchain platforms. Although many existing works on the overall system performance of Hyperledger Fabric are available, a decomposition of each phase in Hyperledger Fabric remains to be explored. Admittedly, the overall system performance of Hyperledger Fabric might provide an end-user with satisfied performance information when invoking a transaction; however, it is far from informative when deploying a distributed system with specific performance goals, except for understanding each phase in Hyperledger Fabric. In this paper, we develop a measurement framework to characterize each phase's transaction and block data in Hyperledger Fabric based on the Fabric SDK Nodejs, where we thoroughly analyze and open source the implementation details of the measurement framework. We evaluate the performance of Hyperledger Fabric and have some interesting observations; 1. The number of CPU cores has a linear impact on the throughput of an endorsing peer. 2. The Raft-based ordering service shows good scalability with the number of ordering service nodes. 3. The communication latencies between the client and service in Hyperledger Fabric are significant. We then identify each phase's dominant latency in Hyperledger Fabric via primitive operation analysis and propose a stochastic computation model for performance analysis. We also use the alpha-beta communication model to analyze the corresponding communication latency. Finally, we validate the accuracy of the performance model on both local and cloud clusters. The experiment results and the?\u2026", "IdName": "wang2023stochastic", "Citation": "", "Keywords": ""}, {"Name": "A Quality-Aware Rendezvous Framework for Cognitive Radio Networks", "Authors": ["Hai Liu", "Lu Yu", "Chung Keung Poon", "Zhiyong Lin", "Yiu-Wing Leung", "Xiaowen Chu"], "Sources": "2022 18th International Conference on Mobility", "PublishedYears": "2022", "Doi": "", "Abstracts": "In cognitive radio networks, rendezvous is a fundamental operation by which cognitive users establish communication links. Most of existing works were devoted to shortening the time-to-rendezvous (TTR) but paid little attention to qualities of the channels on which rendezvous is achieved. In fact, qualities of channels, such as resistance to primary users' activities, have a great effect on the rendezvous operation. If users achieve a rendezvous on a low-quality channel, the communication link is unstable and the communication performance is poor. In this case, re- rendezvous is required which results in considerable communication overhead and a large latency. In this paper, we first show that actual TTRs of existing rendezvous solutions increase by 65.40-104.38% if qualities of channels are not perfect. Then we propose a Quality-Aware Rendezvous Framework (QARF) that can be applied to any existing ren-dezvous algorithms to?\u2026", "IdName": "liu2022quality", "Citation": "", "Keywords": ""}, {"Name": "Harnessing Client Drift with Decoupled Gradient Dissimilarity", "Authors": ["TANG Zhenheng", "Yonggang Zhang", "Shaohuai Shi", "Xinmei Tian", "Tongliang Liu", "Bo Han", "Xiaowen Chu"], "Sources": "None", "PublishedYears": "2022", "Doi": "", "Abstracts": "The performance of Federated learning (FL) typically suffers from client drift caused by heterogeneous data, where data distributions vary with clients. Recent studies show that the gradient dissimilarity between clients induced by the data distribution discrepancy causes the client drift. Thus, existing methods mainly focus on correcting the gradients. However, it is challenging to identify which client should (or not) be corrected. This challenge raises a series of questions: will the local training, without gradient correction, contribute to the server model's generalization of other clients' distributions? when the generalization contribution holds? how to address the challenge when it fails? To answer these questions, we analyze the generalization contribution of local training and conclude that the generalization contribution of local training is bounded by the conditional Wasserstein distance between clients' distributions. Thus, the key to promote generalization contribution is to leverage similar conditional distributions for local training. As collecting data distribution can cause privacy leakage, we propose decoupling the deep models, i.e., splitting into high-level models and low-level models, for harnessing client drift. Namely, high-level models are trained on shared feature distributions, causing promoted generalization contribution and alleviated gradient dissimilarity. Experimental results demonstrate that FL with decoupled gradient dissimilarity is robust to data heterogeneity.", "IdName": "zhenhengharnessing", "Citation": "", "Keywords": ""}, {"Name": "FedPD: Defying data heterogeneity through privacy distillation", "Authors": ["Zhiqin Brian Yang", "Yonggang Zhang", "Yu Zheng", "TANG Zhenheng", "Xiaowen Chu", "Hao Peng", "Bo Han"], "Sources": "None", "PublishedYears": "2022", "Doi": "", "Abstracts": "Model performance of federated learning (FL) typically suffers from data heterogeneity, i.e., data distribution varies with clients. Advanced works have already shown great potential for sharing client information to mitigate data heterogeneity. Yet, some literature shows a dilemma in preserving strong privacy and promoting model performance simultaneously. Revisiting the purpose of sharing information motivates us to raise the fundamental questions: Which part of the data is more critical for model generalization? Which part of the data is more privacy-sensitive? Can we solve this dilemma by sharing useful (for generalization) features and maintaining more sensitive data locally? Our work sheds light on data-dominated sharing and training, in a way that we decouple original training data into sensitive features and generalizable features. To be specific, we propose a \\textbf{Fed}erated \\textbf{P}rivacy \\textbf{D}istillation framework named FedPD to alleviate the privacy-performance dilemma. Namely, FedPD keeps the distilled sensitive features locally and constructs a global dataset using shared generalizable features in a differentially private manner. Accordingly, clients can perform local training on both the local and securely shared data for acquiring high model performance and avoiding the leakage of not distilled privacy. Theoretically, we demonstrate the superiority of the sharing-only useful feature strategy over sharing raw data. Empirically, we show the efficacy of FedPD in promoting performance with comprehensive experiments.", "IdName": "yangfedpd", "Citation": "", "Keywords": ""}, {"Name": "Guest Editorial: Introduction to the Special Section on Communication-Efficient Distributed Machine Learning", "Authors": ["Xiaowen Chu", "Fausto Giunchiglia", "Giovanni Neglia", "David Gregg", "Jiangchuang Liu"], "Sources": "IEEE Transactions on Network Science and Engineering", "PublishedYears": "2022", "Doi": "", "Abstracts": "The papers in this special section focus on communication-efficient distributed machine learning. Machine learning, especially deep learning, has been successfully applied in a wealth of practical AI applications in the field of computer vision, natural language processing, healthcare, finance, robotics, etc. With the increasing size of machine learning models and training data sets, training deep learning models requires significant amount of computations and may take days to months on a single GPU or TPU. Therefore, it becomes a common practice to exploit distributed machine learning to accelerate the training process with multiple processors. Distributed machine learning typically requires the processors to exchange information repeatedly throughout the training process. With the fast-growing computing power of the AI processors, the data communications among processors gradually become the performance?\u2026", "IdName": "chu2022guest", "Citation": "", "Keywords": ""}, {"Name": "Practical Federated Gradient Boosting Decision Trees", "Authors": ["Qinbin Li", "Zeyi Wen", "Bingsheng He"], "Sources": "AAAI Conference on Artificial Intelligence (AAAI)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Gradient Boosting Decision Trees (GBDTs) have become very successful in recent years, with many awards in machine learning and data mining competitions. There have been several recent studies on how to train GBDTs in the federated learning setting. In this paper, we focus on horizontal federated learning, where data samples with the same features are distributed among multiple parties. However, existing studies are not efficient or effective enough for practical use. They suffer either from the inefficiency due to the usage of costly data transformations such as secure sharing and homomorphic encryption, or from the low model accuracy due to differential privacy designs. In this paper, we study a practical federated environment with relaxed privacy constraints. In this environment, a dishonest party might obtain some information about the other parties' data, but it is still impossible for the dishonest party to derive the actual raw data of other parties. Specifically, each party boosts a number of trees by exploiting similarity information based on locality-sensitive hashing. We prove that our framework is secure without exposing the original record to other parties, while the computation overhead in the training process is kept low. Our experimental studies show that, compared with normal training with the local data of each party, our approach can significantly improve the predictive accuracy, and achieve comparable accuracy to the original GBDT with the data from all parties.", "IdName": "li2020practical", "Citation": "", "Keywords": ""}, {"Name": "Privacy-Preserving Gradient Boosting Decision Trees", "Authors": ["Qinbin Li", "Zhaomin Wu", "Zeyi Wen", "Bingsheng He"], "Sources": "AAAI Conference on Artificial Intelligence (AAAI)", "PublishedYears": "2020", "Doi": "", "Abstracts": "The Gradient Boosting Decision Tree (GBDT) is a popular machine learning model for various tasks in recent years. In this paper, we study how to improve model accuracy of GBDT while preserving the strong guarantee of differential privacy. Sensitivity and privacy budget are two key design aspects for the effectiveness of differential private models. Existing solutions for GBDT with differential privacy suffer from the significant accuracy loss due to too loose sensitivity bounds and ineffective privacy budget allocations (especially across different trees in the GBDT model). Loose sensitivity bounds lead to more noise to obtain a fixed privacy level. Ineffective privacy budget allocations worsen the accuracy loss especially when the number of trees is large. Therefore, we propose a new GBDT training algorithm that achieves tighter sensitivity bounds and more effective noise allocations. Specifically, by investigating the property of gradient and the contribution of each tree in GBDTs, we propose to adaptively control the gradients of training data for each iteration and leaf node clipping in order to tighten the sensitivity bounds. Furthermore, we design a novel boosting framework to allocate the privacy budget between trees so that the accuracy loss can be further reduced. Our experiments show that our approach can achieve much better model accuracy than other baselines.", "IdName": "li2020privacy", "Citation": "", "Keywords": ""}, {"Name": "ThunderGBM: Fast GBDTs and Random Forests on GPUs", "Authors": ["Zeyi Wen", "Hanfeng Liu", "Jiashuai Shi", "Bingsheng He", "Qinbin Li", "Jian Chen"], "Sources": "Journal of Machine Learning Research (JMLR)", "PublishedYears": "2020", "Doi": "", "Abstracts": "Gradient Boosting Decision Trees (GBDTs) and Random Forests (RFs) have been used in many real-world applications. They are often a standard recipe for building state-of-the-art solutions to machine learning and data mining problems. However, training and prediction are very expensive computationally for large and high dimensional problems. This article presents an efficient and open source software toolkit called ThunderGBM which exploits the high-performance Graphics Processing Units (GPUs) for GBDTs and RFs. ThunderGBM supports classification, regression and ranking, and can run on single or multiple GPUs of a machine. Our experimental results show that ThunderGBM outperforms the existing libraries while producing similar models, and can handle high dimensional problems where existing GPU-based libraries fail. Documentation, examples, and more details about ThunderGBM are available at https://github.com/xtra-computing/thundergbm.", "IdName": "wen2020thundergbm", "Citation": "", "Keywords": ""}, {"Name": "Local Path Integration for Attribution", "Authors": ["Peiyu Yang", "Naveed Akhtar", "Zeyi Wen", "Ajmal Mian"], "Sources": "The 37th AAAI Conference on Artificial Intelligence (AAAI)", "PublishedYears": "2023", "Doi": "", "Abstracts": "Path attribution methods are a popular tool to interpret a visual model's prediction on an input. They integrate model gradients for the input features over a path defined between the input and a reference, thereby satisfying certain desirable theoretical properties. However, their reliability hinges on the choice of the reference. Moreover, they do not exhibit weak dependence on the input, which leads to counter-intuitive feature attribution mapping. We show that path-based attribution can account for the weak dependence property by choosing the reference from the local distribution of the input. We devise a method to identify the local input distribution and propose a technique to stochastically integrate the model gradients over the paths defined by the references sampled from that distribution. Our local path integration (LPI) method is found to consistently outperform existing path attribution techniques when evaluated on deep visual models. Contributing to the ongoing search of reliable evaluation metrics for the interpretation methods, we also introduce DiffID metric that uses the relative difference between insertion and deletion games to alleviate the distribution shift problem faced by existing metrics. Our code is available at https://github. com/ypeiyu/LPI.", "IdName": "yang2023local", "Citation": "", "Keywords": ""}, {"Name": "POSTER:Fast Parallel Bayesian Network Structure Learning", "Authors": ["Jiantong Jiang", "Zeyi Wen", "Ajmal Mian"], "Sources": "IEEE International Parallel and Distributed Processing Symposium (IPDPS)", "PublishedYears": "2022", "Doi": "", "Abstracts": "Bayesian networks (BNs) are a widely used graphical model in machine learning for representing knowledge with uncertainty. The mainstream BN structure learning methods require performing a large number of conditional independence (CI) tests. The learning process is very time-consuming, especially for high-dimensional problems, which hinders the adoption of BNs to more applications. Existing works attempt to accelerate the learning process with parallelism, but face issues including load unbalancing, costly atomic operations and dominant parallel overhead. In this paper, we propose a fast solution named Fast-BNS on multi-core CPUs to enhance the efficiency of the BN structure learning. Fast-Bns is powered by a series of efficiency optimizations including (i) designing a dynamic work pool to monitor the processing of edges and to better schedule the workloads among threads, (ii) grouping the CI tests of?\u2026", "IdName": "jiang2022fast", "Citation": "", "Keywords": ""}, {"Name": "Parallel and Distributed Structured SVM Training", "Authors": ["Jiantong Jiang", "Zeyi Wen", "Zeke Wang", "Bingsheng He", "Jian Chen"], "Sources": "IEEE Transactions on Parallel and Distributed Systems (TPDS)", "PublishedYears": "2021", "Doi": "", "Abstracts": "Structured Support Vector Machines (structured SVMs) are a fundamental machine learning algorithm, and have solid theoretical foundation and high effectiveness in applications such as natural language parsing and computer vision. However, training structured SVMs is very time-consuming, due to the large number of constraints and inferior convergence rates, especially for large training data sets. The high cost of training structured SVMs has hindered its adoption to new applications. In this article, we aim to improve the efficiency of structured SVMs by proposing a parallel and distributed solution (namely  FastSSVM ) for training structured SVMs building on top of MPI and OpenMP. FastSSVM exploits a series of optimizations (e.g., optimizations on data storage and synchronization) to efficiently use the resources of the nodes in a cluster and the cores of the nodes. Moreover, FastSSVM tackles the large?\u2026", "IdName": "jiang2021parallel", "Citation": "", "Keywords": ""}, {"Name": "Re-calibrating Feature Attributions for Model Interpretation", "Authors": ["Peiyu Yang", "Naveed Akhtar", "Zeyi Wen", "Mubarak Shah", "Ajmal Mian"], "Sources": "The International Conference on Learning Representations (ICLR)", "PublishedYears": "2023", "Doi": "", "Abstracts": "The ability to interpret machine learning models is critical for high-stakes applications. Due to its desirable theoretical properties, path integration is a widely used scheme for feature attribution to interpret model predictions. However, the methods implementing this scheme currently rely on absolute attribution scores to eventually provide sensible interpretations. This not only contradicts the premise that the features with larger attribution scores are more relevant to the model prediction, but also conflicts with the theoretical settings for which the desirable properties of the attributions are proven. We address this by devising a method to first compute an appropriate reference for the path integration scheme. This reference further helps in identifying valid interpolation points on a desired integration path. The reference is computed in a gradient ascending direction on the model's loss surface, while the interpolations are performed by analyzing the model gradients and variations between the reference and the input. The eventual integration is effectively performed along a non-linear path. Our scheme can be incorporated into the existing integral-based attribution methods. We also devise an effective sampling and integration procedure that enables employing our scheme with multi-reference path integration efficiently. We achieve a marked performance boost for a range of integral-based attribution methods on both local and global evaluation metrics by enhancing them with our scheme. Our extensive results also show improved sensitivity, sanity preservation and model robustness with the proposed re-calibration of the attribution techniques with our?\u2026", "IdName": "yang2022re", "Citation": "", "Keywords": ""}, {"Name": "Fast Parallel Exact Inference on Bayesian Networks", "Authors": ["Jiantong Jiang", "Zeyi Wen", "Atif Mansoor", "Ajmal Mian"], "Sources": "Proceedings of the 28th ACM SIGPLAN Annual Symposium on Principles and?\u2026", "PublishedYears": "2023", "Doi": "", "Abstracts": "Bayesian networks (BNs) are attractive, because they are graphical and interpretable machine learning models. However, exact inference on BNs is time-consuming, especially for complex problems. To improve the efficiency, we propose a fast BN exact inference solution named Fast-BNI on multi-core CPUs. Fast-BNI enhances the efficiency of exact inference through hybrid parallelism that tightly integrates coarse- and fine-grained parallelism. We also propose techniques to further simplify the bottleneck operations of BN exact inference. Fast-BNI source code is freely available at https://github.com/jjiantong/FastBN.", "IdName": "jiang2023fast", "Citation": "", "Keywords": ""}]